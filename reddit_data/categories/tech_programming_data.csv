id,title,selftext,created_utc,score,num_comments,permalink,url,author,subreddit,upvote_ratio,is_self,over_18,spoiler,stickied,gilded,collection_time,category,title_length,selftext_length,total_length,day_of_week,hour_of_day,month,year,is_weekend,sentiment_compound,sentiment_pos,sentiment_neg,sentiment_neu,sentiment_category,clean_title,clean_selftext,combined_text,top_keywords,created_datetime,full_clean_text,processed_tokens,clean_body,body,post_id,comment_length
144sn8r,Apollo dev posts backend code to Git to disprove Reddit’s claims of scrapping and inefficiency,,1686277449.0,45036.0,2397.0,/r/programming/comments/144sn8r/apollo_dev_posts_backend_code_to_git_to_disprove/,https://github.com/christianselig/apollo-backend,GhostalMedia,programming,0.97,False,False,False,False,2.0,1745832463.439587,Tech & Programming,15.0,0.0,15.0,Thursday,22.0,June,2023.0,False,0.0,0.0,0.0,1.0,neutral,apollo dev posts backend code to git to disprove reddits claims of scrapping and inefficiency,,apollo dev posts backend code to git to disprove reddits claims of scrapping and inefficiency ,"apollo, dev, post, backend, code",2023-06-09 02:24:09,apollo dev posts backend code to git to disprove reddits claims of scrapping and inefficiency ,"['apollo', 'dev', 'post', 'backend', 'code', 'git', 'disprove', 'reddits', 'claim', 'scrapping', 'inefficiency']",,,,
8f2lzu,"There’s a reason that programmers always want to throw away old code and start over: they think the old code is a mess. They are probably wrong. The reason that they think the old code is a mess is because of a cardinal, fundamental law of programming: It’s harder to read code than to write it.",,1524749052.0,26847.0,1077.0,/r/programming/comments/8f2lzu/theres_a_reason_that_programmers_always_want_to/,https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/,the_phet,programming,0.94,False,False,False,False,1.0,1745832466.691506,Tech & Programming,56.0,0.0,56.0,Thursday,9.0,April,2018.0,False,-0.7783,0.023,0.141,0.836,negative,theres a reason that programmers always want to throw away old code and start over they think the old code is a mess they are probably wrong the reason that they think the old code is a mess is because of a cardinal fundamental law of programming its harder to read code than to write it,,theres a reason that programmers always want to throw away old code and start over they think the old code is a mess they are probably wrong the reason that they think the old code is a mess is because of a cardinal fundamental law of programming its harder to read code than to write it ,"code, old, reason, think, mess",2018-04-26 13:24:12,theres a reason that programmers always want to throw away old code and start over they think the old code is a mess they are probably wrong the reason that they think the old code is a mess is because of a cardinal fundamental law of programming its harder to read code than to write it ,"['there', 'reason', 'programmer', 'always', 'want', 'throw', 'away', 'old', 'code', 'start', 'think', 'old', 'code', 'mess', 'probably', 'wrong', 'reason', 'think', 'old', 'code', 'mess', 'cardinal', 'fundamental', 'law', 'programming', 'harder', 'read', 'code', 'write']",,,,
91i0mc,YouTube page load is 5x slower in Firefox and Edge than in Chrome because YouTube's Polymer redesign relies on the deprecated Shadow DOM v0 API only implemented in Chrome.,,1532443617.0,23691.0,1849.0,/r/programming/comments/91i0mc/youtube_page_load_is_5x_slower_in_firefox_and/,https://twitter.com/cpeterso/status/1021626510296285185,malicious_turtle,programming,0.95,False,False,False,False,0.0,1745832470.422261,Tech & Programming,29.0,0.0,29.0,Tuesday,10.0,July,2018.0,False,0.0,0.0,0.0,1.0,neutral,youtube page load is x slower in firefox and edge than in chrome because youtubes polymer redesign relies on the deprecated shadow dom v api only implemented in chrome,,youtube page load is x slower in firefox and edge than in chrome because youtubes polymer redesign relies on the deprecated shadow dom v api only implemented in chrome ,"chrome, youtube, page, load, slower",2018-07-24 14:46:57,youtube page load is x slower in firefox and edge than in chrome because youtubes polymer redesign relies on the deprecated shadow dom v api only implemented in chrome ,"['youtube', 'page', 'load', 'slower', 'firefox', 'edge', 'chrome', 'youtubes', 'polymer', 'redesign', 'relies', 'deprecated', 'shadow', 'dom', 'api', 'implemented', 'chrome']",,,,
4l77w2,Google wins trial against Oracle as jury finds Android is “fair use”,,1464293195.0,21401.0,1262.0,/r/programming/comments/4l77w2/google_wins_trial_against_oracle_as_jury_finds/,http://arstechnica.com/tech-policy/2016/05/google-wins-trial-against-oracle-as-jury-finds-android-is-fair-use/,hondaaccords,programming,0.94,False,False,False,False,0.0,1745832473.842725,Tech & Programming,12.0,0.0,12.0,Thursday,16.0,May,2016.0,False,0.7184,0.375,0.0,0.625,positive,google wins trial against oracle as jury finds android is fair use,,google wins trial against oracle as jury finds android is fair use ,"google, win, trial, oracle, jury",2016-05-26 20:06:35,google wins trial against oracle as jury finds android is fair use ,"['google', 'win', 'trial', 'oracle', 'jury', 'find', 'android', 'fair', 'use']",,,,
7m8770,"TIL there's a community called ""dwitter"" where people compose 140 character JavaScript programs that produce interesting visuals",,1514300701.0,20658.0,331.0,/r/programming/comments/7m8770/til_theres_a_community_called_dwitter_where/,https://www.dwitter.net/top,bemmu,programming,0.94,False,False,False,False,1.0,1745832477.106506,Tech & Programming,17.0,0.0,16.0,Tuesday,10.0,December,2017.0,False,0.4019,0.162,0.0,0.838,positive,til theres a community called dwitter where people compose character javascript programs that produce interesting visuals,,til theres a community called dwitter where people compose character javascript programs that produce interesting visuals ,"til, there, community, called, dwitter",2017-12-26 15:05:01,til theres a community called dwitter where people compose character javascript programs that produce interesting visuals ,"['til', 'there', 'community', 'called', 'dwitter', 'people', 'compose', 'character', 'javascript', 'program', 'produce', 'interesting', 'visuals']",,,,
3ke7ug,"Eye tracking software for sufferers of ALS/MND can cost tens of thousands of dollars, so I've spent 3.5 years of my spare time writing a free & open-source alternative - meet OptiKey (C#, Rx, WPF) (x-post from r/Software)",,1441890289.0,19803.0,492.0,/r/programming/comments/3ke7ug/eye_tracking_software_for_sufferers_of_alsmnd_can/,https://www.reddit.com/r/software/comments/3kdghp/eye_tracking_software_for_sufferers_of_alsmnd_can/?ref=share&ref_source=link,YeahIWroteOptiKey,programming,0.96,False,False,False,False,5.0,1745832479.10867,Tech & Programming,38.0,0.0,35.0,Thursday,9.0,September,2015.0,False,-0.0258,0.088,0.09,0.822,neutral,eye tracking software for sufferers of alsmnd can cost tens of thousands of dollars so ive spent years of my spare time writing a free opensource alternative meet optikey c rx wpf xpost from rsoftware,,eye tracking software for sufferers of alsmnd can cost tens of thousands of dollars so ive spent years of my spare time writing a free opensource alternative meet optikey c rx wpf xpost from rsoftware ,"eye, tracking, software, sufferer, alsmnd",2015-09-10 13:04:49,eye tracking software for sufferers of alsmnd can cost tens of thousands of dollars so ive spent years of my spare time writing a free opensource alternative meet optikey c rx wpf xpost from rsoftware ,"['eye', 'tracking', 'software', 'sufferer', 'alsmnd', 'cost', 'ten', 'thousand', 'dollar', 'ive', 'spent', 'year', 'spare', 'time', 'writing', 'free', 'opensource', 'alternative', 'meet', 'optikey', 'wpf', 'xpost', 'rsoftware']",,,,
8530uf,Cool website that explains algorithms as if they are IKEA instruction manuals,,1521283754.0,19165.0,236.0,/r/programming/comments/8530uf/cool_website_that_explains_algorithms_as_if_they/,https://idea-instructions.com/,TheSpaceOfAdes,programming,0.94,False,False,False,False,0.0,1745832482.236871,Tech & Programming,12.0,0.0,12.0,Saturday,6.0,March,2018.0,True,0.3182,0.173,0.0,0.827,positive,cool website that explains algorithms as if they are ikea instruction manuals,,cool website that explains algorithms as if they are ikea instruction manuals ,"cool, website, explains, algorithm, ikea",2018-03-17 10:49:14,cool website that explains algorithms as if they are ikea instruction manuals ,"['cool', 'website', 'explains', 'algorithm', 'ikea', 'instruction', 'manual']",,,,
luq9oz,How I cut GTA Online loading times by 70%,,1614545840.0,18998.0,996.0,/r/programming/comments/luq9oz/how_i_cut_gta_online_loading_times_by_70/,https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/,simspelaaja,programming,0.97,False,False,False,False,3.0,1745832483.985966,Tech & Programming,9.0,0.0,8.0,Sunday,15.0,February,2021.0,True,-0.2732,0.0,0.259,0.741,negative,how i cut gta online loading times by,,how i cut gta online loading times by ,"cut, gta, online, loading, time",2021-02-28 20:57:20,how i cut gta online loading times by ,"['cut', 'gta', 'online', 'loading', 'time']",,,,
7o203z,"Linus Torvalds: I think somebody inside of Intel needs to really take a long hard look at their CPU's, and actually admit that they have issues instead of writing PR blurbs that say that everything works as designed.",,1515059555.0,18240.0,1547.0,/r/programming/comments/7o203z/linus_torvalds_i_think_somebody_inside_of_intel/,https://lkml.org/lkml/2018/1/3/797,,programming,0.94,False,False,False,False,0.0,1745832486.785083,Tech & Programming,38.0,0.0,38.0,Thursday,4.0,January,2018.0,False,0.0352,0.048,0.044,0.908,neutral,linus torvalds i think somebody inside of intel needs to really take a long hard look at their cpus and actually admit that they have issues instead of writing pr blurbs that say that everything works as designed,,linus torvalds i think somebody inside of intel needs to really take a long hard look at their cpus and actually admit that they have issues instead of writing pr blurbs that say that everything works as designed ,"linus, torvalds, think, somebody, inside",2018-01-04 09:52:35,linus torvalds i think somebody inside of intel needs to really take a long hard look at their cpus and actually admit that they have issues instead of writing pr blurbs that say that everything works as designed ,"['linus', 'torvalds', 'think', 'somebody', 'inside', 'intel', 'need', 'really', 'take', 'long', 'hard', 'look', 'cpu', 'actually', 'admit', 'issue', 'instead', 'writing', 'blurb', 'say', 'everything', 'work', 'designed']",,,,
8q3kp8,Inventor says Google is patenting work he put in the public domain,,1528662197.0,18055.0,817.0,/r/programming/comments/8q3kp8/inventor_says_google_is_patenting_work_he_put_in/,https://arstechnica.com/tech-policy/2018/06/inventor-says-google-is-patenting-work-he-put-in-the-public-domain/,Balance-,programming,0.96,False,False,False,False,1.0,1745832490.094247,Tech & Programming,12.0,0.0,12.0,Sunday,16.0,June,2018.0,True,0.0,0.0,0.0,1.0,neutral,inventor says google is patenting work he put in the public domain,,inventor says google is patenting work he put in the public domain ,"inventor, say, google, patenting, work",2018-06-10 20:23:17,inventor says google is patenting work he put in the public domain ,"['inventor', 'say', 'google', 'patenting', 'work', 'put', 'public', 'domain']",,,,
rka1s4,TikTok streaming software is an illegal fork of OBS,,1639960220.0,16139.0,1039.0,/r/programming/comments/rka1s4/tiktok_streaming_software_is_an_illegal_fork_of/,https://twitter.com/Naaackers/status/1471494415306788870,Kok_Nikol,programming,0.97,False,False,False,False,1.0,1745832493.685672,Tech & Programming,9.0,0.0,9.0,Sunday,19.0,December,2021.0,True,-0.5574,0.0,0.31,0.69,negative,tiktok streaming software is an illegal fork of obs,,tiktok streaming software is an illegal fork of obs ,"tiktok, streaming, software, illegal, fork",2021-12-20 00:30:20,tiktok streaming software is an illegal fork of obs ,"['tiktok', 'streaming', 'software', 'illegal', 'fork', 'ob']",,,,
adjw6g,GitHub now gives free users unlimited private repositories,,1546881949.0,15699.0,1009.0,/r/programming/comments/adjw6g/github_now_gives_free_users_unlimited_private/,https://thenextweb.com/dd/2019/01/05/github-now-gives-free-users-unlimited-private-repositories/,i_wonder_as_i_wander,programming,0.96,False,False,False,False,0.0,1745832496.645286,Tech & Programming,8.0,0.0,8.0,Monday,12.0,January,2019.0,False,0.5106,0.32,0.0,0.68,positive,github now gives free users unlimited private repositories,,github now gives free users unlimited private repositories ,"github, give, free, user, unlimited",2019-01-07 17:25:49,github now gives free users unlimited private repositories ,"['github', 'give', 'free', 'user', 'unlimited', 'private', 'repository']",,,,
6xh3xp,Reddit's main code is no longer open-source.,,1504296547.0,15314.0,851.0,/r/programming/comments/6xh3xp/reddits_main_code_is_no_longer_opensource/,https://www.reddit.com/r/changelog/comments/6xfyfg/an_update_on_the_state_of_the_redditreddit_and/,interiot,programming,0.94,False,False,False,False,1.0,1745832499.510696,Tech & Programming,7.0,0.0,7.0,Friday,16.0,September,2017.0,False,-0.296,0.0,0.268,0.732,negative,reddits main code is no longer opensource,,reddits main code is no longer opensource ,"reddits, main, code, longer, opensource",2017-09-01 20:09:07,reddits main code is no longer opensource ,"['reddits', 'main', 'code', 'longer', 'opensource']",,,,
656z8t,How We Built r/Place,,1492104916.0,15015.0,836.0,/r/programming/comments/656z8t/how_we_built_rplace/,https://redditblog.com/2017/04/13/how-we-built-rplace/,bsimpson,programming,0.84,False,False,False,False,0.0,1745832504.269257,Tech & Programming,4.0,0.0,4.0,Thursday,13.0,April,2017.0,False,0.0,0.0,0.0,1.0,neutral,how we built rplace,,how we built rplace ,"built, rplace",2017-04-13 17:35:16,how we built rplace ,"['built', 'rplace']",,,,
6p89yq,18yo arrested for reporting a bug in the new Budapest e-Ticket system,,1500901997.0,14017.0,803.0,/r/programming/comments/6p89yq/18yo_arrested_for_reporting_a_bug_in_the_new/,https://blog.marai.me/2017/07/24/18-year-old-arrested-bkk-tsystems-e-ticket/,minusSeven,programming,0.94,False,False,False,False,0.0,1745832506.770458,Tech & Programming,12.0,0.0,12.0,Monday,9.0,July,2017.0,False,-0.4767,0.0,0.237,0.763,negative,yo arrested for reporting a bug in the new budapest eticket system,,yo arrested for reporting a bug in the new budapest eticket system ,"arrested, reporting, bug, new, budapest",2017-07-24 13:13:17,yo arrested for reporting a bug in the new budapest eticket system ,"['arrested', 'reporting', 'bug', 'new', 'budapest', 'eticket', 'system']",,,,
puok1h,"A single person answered 76k questions about SQL on StackOverflow. Averaging 22.8 answers per day, every day, for the past 8.6 years.",,1632504575.0,13888.0,599.0,/r/programming/comments/puok1h/a_single_person_answered_76k_questions_about_sql/,https://stackoverflow.com/search?q=user%3A1144035+%5Bsql%5D+is%3Aanswer,youwillnevercatme,programming,0.98,False,False,False,False,0.0,1745832509.502534,Tech & Programming,22.0,0.0,20.0,Friday,13.0,September,2021.0,False,0.0,0.0,0.0,1.0,neutral,a single person answered k questions about sql on stackoverflow averaging answers per day every day for the past years,,a single person answered k questions about sql on stackoverflow averaging answers per day every day for the past years ,"day, single, person, answered, question",2021-09-24 17:29:35,a single person answered k questions about sql on stackoverflow averaging answers per day every day for the past years ,"['single', 'person', 'answered', 'question', 'sql', 'stackoverflow', 'averaging', 'answer', 'per', 'day', 'every', 'day', 'past', 'year']",,,,
76ohly,Severe flaw in WPA2 protocol leaves Wi-Fi traffic open to eavesdropping,,1508132425.0,13454.0,1078.0,/r/programming/comments/76ohly/severe_flaw_in_wpa2_protocol_leaves_wifi_traffic/,https://arstechnica.com/information-technology/2017/10/severe-flaw-in-wpa2-protocol-leaves-wi-fi-traffic-open-to-eavesdropping/,karptonite,programming,0.96,False,False,False,False,1.0,1745832512.23778,Tech & Programming,11.0,0.0,11.0,Monday,1.0,October,2017.0,False,-0.3818,0.0,0.206,0.794,negative,severe flaw in wpa protocol leaves wifi traffic open to eavesdropping,,severe flaw in wpa protocol leaves wifi traffic open to eavesdropping ,"severe, flaw, wpa, protocol, leaf",2017-10-16 05:40:25,severe flaw in wpa protocol leaves wifi traffic open to eavesdropping ,"['severe', 'flaw', 'wpa', 'protocol', 'leaf', 'wifi', 'traffic', 'open', 'eavesdropping']",,,,
141oyj9,r/programming should shut down from 12th to 14th June,,1685993299.0,13387.0,541.0,/r/programming/comments/141oyj9/rprogramming_should_shut_down_from_12th_to_14th/,https://www.reddit.com/r/Save3rdPartyApps/comments/13yh0jf/dont_let_reddit_kill_3rd_party_apps/,Tintin_Quarentino,programming,0.95,False,False,False,False,0.0,1745832515.46156,Tech & Programming,9.0,0.0,9.0,Monday,15.0,June,2023.0,False,0.0,0.0,0.0,1.0,neutral,rprogramming should shut down from th to th june,,rprogramming should shut down from th to th june ,"rprogramming, shut, june",2023-06-05 19:28:19,rprogramming should shut down from th to th june ,"['rprogramming', 'shut', 'june']",,,,
13wuj25,Reddit may force Apollo dev and other third party clients to shut down,,1685558990.0,12521.0,867.0,/r/programming/comments/13wuj25/reddit_may_force_apollo_dev_and_other_third_party/,https://9to5mac.com/2023/05/31/reddit-may-force-apollo-and-third-party-clients-to-shut-down/,aniforprez,programming,0.97,False,False,False,False,1.0,1745832519.222495,Tech & Programming,13.0,0.0,13.0,Wednesday,14.0,May,2023.0,False,0.4019,0.184,0.0,0.816,positive,reddit may force apollo dev and other third party clients to shut down,,reddit may force apollo dev and other third party clients to shut down ,"reddit, may, force, apollo, dev",2023-05-31 18:49:50,reddit may force apollo dev and other third party clients to shut down ,"['reddit', 'may', 'force', 'apollo', 'dev', 'third', 'party', 'client', 'shut']",,,,
rtgwcf,"In 2022, YYMMDDhhmm formatted times exceed signed int range, breaking Microsoft services",,1641033351.0,12393.0,1149.0,/r/programming/comments/rtgwcf/in_2022_yymmddhhmm_formatted_times_exceed_signed/,https://twitter.com/miketheitguy/status/1477097527593734144,rk-imn,programming,0.97,False,False,False,False,0.0,1745832522.282945,Tech & Programming,12.0,0.0,11.0,Saturday,5.0,January,2022.0,True,0.0,0.0,0.0,1.0,neutral,in yymmddhhmm formatted times exceed signed int range breaking microsoft services,,in yymmddhhmm formatted times exceed signed int range breaking microsoft services ,"yymmddhhmm, formatted, time, exceed, signed",2022-01-01 10:35:51,in yymmddhhmm formatted times exceed signed int range breaking microsoft services ,"['yymmddhhmm', 'formatted', 'time', 'exceed', 'signed', 'int', 'range', 'breaking', 'microsoft', 'service']",,,,
i4xxnk,"20GB leak of Intel data: whole Git repositories, dev tools, backdoor mentions in source code",,1596740655.0,12156.0,901.0,/r/programming/comments/i4xxnk/20gb_leak_of_intel_data_whole_git_repositories/,https://twitter.com/deletescape/status/1291405688204402689,flaming_bird,programming,0.97,False,False,False,False,0.0,1745832524.789658,Tech & Programming,15.0,0.0,15.0,Thursday,15.0,August,2020.0,False,-0.34,0.0,0.146,0.854,negative,gb leak of intel data whole git repositories dev tools backdoor mentions in source code,,gb leak of intel data whole git repositories dev tools backdoor mentions in source code ,"leak, intel, data, whole, git",2020-08-06 19:04:15,gb leak of intel data whole git repositories dev tools backdoor mentions in source code ,"['leak', 'intel', 'data', 'whole', 'git', 'repository', 'dev', 'tool', 'backdoor', 'mention', 'source', 'code']",,,,
qeuaxf,“Digging around HTML code” is criminal. Missouri Governor doubles down again in attack ad,,1635089029.0,12003.0,1311.0,/r/programming/comments/qeuaxf/digging_around_html_code_is_criminal_missouri/,https://youtu.be/9IBPeRa7U8E,purforium,programming,0.96,False,False,False,False,0.0,1745832529.141004,Tech & Programming,14.0,0.0,14.0,Sunday,11.0,October,2021.0,True,-0.7579,0.0,0.351,0.649,negative,digging around html code is criminal missouri governor doubles down again in attack ad,,digging around html code is criminal missouri governor doubles down again in attack ad ,"digging, around, html, code, criminal",2021-10-24 15:23:49,digging around html code is criminal missouri governor doubles down again in attack ad ,"['digging', 'around', 'html', 'code', 'criminal', 'missouri', 'governor', 'double', 'attack']",,,,
6ph49n,Adobe to end-of-life Flash by 2020,,1500998714.0,11545.0,1324.0,/r/programming/comments/6ph49n/adobe_to_endoflife_flash_by_2020/,https://blogs.adobe.com/conversations/2017/07/adobe-flash-update.html,Pandalism,programming,0.94,False,False,False,False,0.0,1745832531.757847,Tech & Programming,6.0,0.0,5.0,Tuesday,12.0,July,2017.0,False,0.0,0.0,0.0,1.0,neutral,adobe to endoflife flash by,,adobe to endoflife flash by ,"adobe, endoflife, flash",2017-07-25 16:05:14,adobe to endoflife flash by ,"['adobe', 'endoflife', 'flash']",,,,
q3smfr,Unfollow Everything developer banned for life from Facebook services for creating plug-in to clean up news feed,,1633677126.0,10996.0,694.0,/r/programming/comments/q3smfr/unfollow_everything_developer_banned_for_life/,https://slate.com/technology/2021/10/facebook-unfollow-everything-cease-desist.html,a_false_vacuum,programming,0.98,False,False,False,False,1.0,1745832534.771741,Tech & Programming,17.0,0.0,17.0,Friday,3.0,October,2021.0,False,0.2263,0.224,0.137,0.639,positive,unfollow everything developer banned for life from facebook services for creating plugin to clean up news feed,,unfollow everything developer banned for life from facebook services for creating plugin to clean up news feed ,"unfollow, everything, developer, banned, life",2021-10-08 07:12:06,unfollow everything developer banned for life from facebook services for creating plugin to clean up news feed ,"['unfollow', 'everything', 'developer', 'banned', 'life', 'facebook', 'service', 'creating', 'plugin', 'clean', 'news', 'feed']",,,,
4caow0,"Yesterday, I used glitches to inject the source code for Flappy Bird into Super Mario World on SNES. Here’s how.",,1459180020.0,10793.0,545.0,/r/programming/comments/4caow0/yesterday_i_used_glitches_to_inject_the_source/,https://www.youtube.com/watch?v=hB6eY73sLV0,SethBling,programming,0.91,False,False,False,False,2.0,1745832537.15986,Tech & Programming,20.0,0.0,20.0,Monday,11.0,March,2016.0,False,0.5994,0.178,0.0,0.822,positive,yesterday i used glitches to inject the source code for flappy bird into super mario world on snes heres how,,yesterday i used glitches to inject the source code for flappy bird into super mario world on snes heres how ,"yesterday, used, glitch, inject, source",2016-03-28 15:47:00,yesterday i used glitches to inject the source code for flappy bird into super mario world on snes heres how ,"['yesterday', 'used', 'glitch', 'inject', 'source', 'code', 'flappy', 'bird', 'super', 'mario', 'world', 'snes', 'here']",,,,
6j8fdi,Mozilla is offering $2 million of you can architect a plan to decentralize the web,,1498314596.0,10481.0,849.0,/r/programming/comments/6j8fdi/mozilla_is_offering_2_million_of_you_can/,https://blog.mozilla.org/blog/2017/06/21/2-million-prize-decentralize-web-apply-today/,donrhummy,programming,0.93,False,False,False,False,0.0,1745832540.790795,Tech & Programming,15.0,0.0,14.0,Saturday,10.0,June,2017.0,True,0.0,0.0,0.0,1.0,neutral,mozilla is offering million of you can architect a plan to decentralize the web,,mozilla is offering million of you can architect a plan to decentralize the web ,"mozilla, offering, million, architect, plan",2017-06-24 14:29:56,mozilla is offering million of you can architect a plan to decentralize the web ,"['mozilla', 'offering', 'million', 'architect', 'plan', 'decentralize', 'web']",,,,
fem3g2,hentAI: Detecting and removing censors with Deep Learning and Image Segmentation,,1583536328.0,9955.0,382.0,/r/programming/comments/fem3g2/hentai_detecting_and_removing_censors_with_deep/,https://github.com/natethegreate/hentAI,7cmStrangler,programming,0.96,False,False,False,False,2.0,1745832543.529317,Tech & Programming,11.0,0.0,11.0,Friday,18.0,March,2020.0,False,-0.296,0.0,0.18,0.82,negative,hentai detecting and removing censors with deep learning and image segmentation,,hentai detecting and removing censors with deep learning and image segmentation ,"hentai, detecting, removing, censor, deep",2020-03-06 23:12:08,hentai detecting and removing censors with deep learning and image segmentation ,"['hentai', 'detecting', 'removing', 'censor', 'deep', 'learning', 'image', 'segmentation']",,,,
8kd7r9,The most sophisticated piece of software/code ever written,,1526650574.0,9661.0,841.0,/r/programming/comments/8kd7r9/the_most_sophisticated_piece_of_softwarecode_ever/,https://www.quora.com/What-is-the-most-sophisticated-piece-of-software-code-ever-written/answer/John-Byrd-2,jailbird,programming,0.95,False,False,False,False,0.0,1745832546.00279,Tech & Programming,8.0,0.0,8.0,Friday,9.0,May,2018.0,False,0.5984,0.357,0.0,0.643,positive,the most sophisticated piece of softwarecode ever written,,the most sophisticated piece of softwarecode ever written ,"sophisticated, piece, softwarecode, ever, written",2018-05-18 13:36:14,the most sophisticated piece of softwarecode ever written ,"['sophisticated', 'piece', 'softwarecode', 'ever', 'written']",,,,
nd26jh,Humanity wastes about 500 years per day on CAPTCHAs. It’s time to end this madness,,1621094692.0,9597.0,805.0,/r/programming/comments/nd26jh/humanity_wastes_about_500_years_per_day_on/,https://blog.cloudflare.com/introducing-cryptographic-attestation-of-personhood/,Atulin,programming,0.91,False,False,False,False,1.0,1745832549.156832,Tech & Programming,15.0,0.0,14.0,Saturday,12.0,May,2021.0,True,-0.5228,0.0,0.206,0.794,negative,humanity wastes about years per day on captchas its time to end this madness,,humanity wastes about years per day on captchas its time to end this madness ,"humanity, waste, year, per, day",2021-05-15 16:04:52,humanity wastes about years per day on captchas its time to end this madness ,"['humanity', 'waste', 'year', 'per', 'day', 'captchas', 'time', 'end', 'madness']",,,,
fjk9lq,US Politicians Want to Ban End-to-End Encryption,,1584362188.0,9569.0,512.0,/r/programming/comments/fjk9lq/us_politicians_want_to_ban_endtoend_encryption/,https://news.bitcoin.com/us-ban-encryption/,CarrotRobber,programming,0.98,False,False,False,False,0.0,1745832551.935426,Tech & Programming,7.0,0.0,7.0,Monday,8.0,March,2020.0,False,-0.5106,0.131,0.364,0.505,negative,us politicians want to ban endtoend encryption,,us politicians want to ban endtoend encryption ,"politician, want, ban, endtoend, encryption",2020-03-16 12:36:28,us politicians want to ban endtoend encryption ,"['politician', 'want', 'ban', 'endtoend', 'encryption']",,,,
6gr2fc,"TIL the current hash function for Java strings is of unknown author. In 2004 Joshua Bloch ""went so far as to call up Dennis Ritchie, who said that he did not know where the hash function came from. He walked across the hall and asked Brian Kernighan, who also had no recollection."" [x-post /r/java]",,1497257997.0,9211.0,479.0,/r/programming/comments/6gr2fc/til_the_current_hash_function_for_java_strings_is/,http://bugs.java.com/bugdatabase/view_bug.do?bug_id=4045622,walen,programming,0.92,False,False,False,False,0.0,1745832555.07409,Tech & Programming,54.0,0.0,53.0,Monday,4.0,June,2017.0,False,-0.296,0.0,0.041,0.959,negative,til the current hash function for java strings is of unknown author in joshua bloch went so far as to call up dennis ritchie who said that he did not know where the hash function came from he walked across the hall and asked brian kernighan who also had no recollection xpost rjava,,til the current hash function for java strings is of unknown author in joshua bloch went so far as to call up dennis ritchie who said that he did not know where the hash function came from he walked across the hall and asked brian kernighan who also had no recollection xpost rjava ,"hash, function, til, current, java",2017-06-12 08:59:57,til the current hash function for java strings is of unknown author in joshua bloch went so far as to call up dennis ritchie who said that he did not know where the hash function came from he walked across the hall and asked brian kernighan who also had no recollection xpost rjava ,"['til', 'current', 'hash', 'function', 'java', 'string', 'unknown', 'author', 'joshua', 'bloch', 'went', 'far', 'call', 'dennis', 'ritchie', 'said', 'know', 'hash', 'function', 'came', 'walked', 'across', 'hall', 'asked', 'brian', 'kernighan', 'also', 'recollection', 'xpost', 'rjava']",,,,
b799yb,"GitHub Protest Over Chinese Tech Companies' ""996"" Culture Goes Viral. ""996"" refers to the idea tech employees should work 9am-9pm 6 days a week. Chinese tech companies really make their employees feel that they own all of their time. Not only while in the office, but also in after hours with WeChat.",,1553937688.0,9210.0,768.0,/r/programming/comments/b799yb/github_protest_over_chinese_tech_companies_996/,https://radiichina.com/github-protest-chinese-tech-996/,Xiaomizi,programming,0.97,False,False,False,False,0.0,1745832557.771498,Tech & Programming,52.0,0.0,49.0,Saturday,5.0,March,2019.0,True,-0.128,0.0,0.031,0.969,negative,github protest over chinese tech companies culture goes viral refers to the idea tech employees should work ampm days a week chinese tech companies really make their employees feel that they own all of their time not only while in the office but also in after hours with wechat,,github protest over chinese tech companies culture goes viral refers to the idea tech employees should work ampm days a week chinese tech companies really make their employees feel that they own all of their time not only while in the office but also in after hours with wechat ,"tech, chinese, company, employee, github",2019-03-30 09:21:28,github protest over chinese tech companies culture goes viral refers to the idea tech employees should work ampm days a week chinese tech companies really make their employees feel that they own all of their time not only while in the office but also in after hours with wechat ,"['github', 'protest', 'chinese', 'tech', 'company', 'culture', 'go', 'viral', 'refers', 'idea', 'tech', 'employee', 'work', 'ampm', 'day', 'week', 'chinese', 'tech', 'company', 'really', 'make', 'employee', 'feel', 'time', 'office', 'also', 'hour', 'wechat']",,,,
3ytdsi,"Ian Murdock, creator of Debian, has died",,1451502225.0,9178.0,831.0,/r/programming/comments/3ytdsi/ian_murdock_creator_of_debian_has_died/,http://blog.docker.com/2015/12/ian-murdock/,Daishiman,programming,0.93,False,False,False,False,0.0,1745832560.290693,Tech & Programming,7.0,0.0,7.0,Wednesday,14.0,December,2015.0,False,-0.5574,0.0,0.375,0.625,negative,ian murdock creator of debian has died,,ian murdock creator of debian has died ,"ian, murdock, creator, debian, died",2015-12-30 19:03:45,ian murdock creator of debian has died ,"['ian', 'murdock', 'creator', 'debian', 'died']",,,,
6cw1tf,Stack Overflow: Helping One Million Developers Exit Vim,,1495559669.0,9149.0,1071.0,/r/programming/comments/6cw1tf/stack_overflow_helping_one_million_developers/,https://stackoverflow.blog/2017/05/23/stack-overflow-helping-one-million-developers-exit-vim/,variance_explained,programming,0.93,False,False,False,False,1.0,1745832562.861086,Tech & Programming,8.0,0.0,8.0,Tuesday,13.0,May,2017.0,False,0.296,0.239,0.0,0.761,positive,stack overflow helping one million developers exit vim,,stack overflow helping one million developers exit vim ,"stack, overflow, helping, one, million",2017-05-23 17:14:29,stack overflow helping one million developers exit vim ,"['stack', 'overflow', 'helping', 'one', 'million', 'developer', 'exit', 'vim']",,,,
4r7il2,Bulgaria got a law requiring Open Source for all software written for the government,,1467643609.0,9033.0,392.0,/r/programming/comments/4r7il2/bulgaria_got_a_law_requiring_open_source_for_all/,https://medium.com/@bozhobg/bulgaria-got-a-law-requiring-open-source-98bf626cf70a#.mw66gspvz,shadowmarn,programming,0.93,False,False,False,False,0.0,1745832565.69295,Tech & Programming,14.0,0.0,14.0,Monday,10.0,July,2016.0,False,0.0,0.0,0.0,1.0,neutral,bulgaria got a law requiring open source for all software written for the government,,bulgaria got a law requiring open source for all software written for the government ,"bulgaria, got, law, requiring, open",2016-07-04 14:46:49,bulgaria got a law requiring open source for all software written for the government ,"['bulgaria', 'got', 'law', 'requiring', 'open', 'source', 'software', 'written', 'government']",,,,
zkj6pb,"“There should never be coding exercises in technical interviews. It favors people who have time to do them. Disfavors people with FT jobs and families. Plus, your job won’t have people over your shoulder watching you code.” My favorite hot take from a panel on 'Treating Devs Like Human Beings.'",,1670897255.0,8966.0,1326.0,/r/programming/comments/zkj6pb/there_should_never_be_coding_exercises_in/,https://devinterrupted.substack.com/p/treating-devs-like-human-beings-a,,programming,0.91,False,False,False,False,1.0,1745832568.366746,Tech & Programming,50.0,0.0,50.0,Monday,21.0,December,2022.0,False,0.7579,0.14,0.0,0.86,positive,there should never be coding exercises in technical interviews it favors people who have time to do them disfavors people with ft jobs and families plus your job wont have people over your shoulder watching you code my favorite hot take from a panel on treating devs like human beings,,there should never be coding exercises in technical interviews it favors people who have time to do them disfavors people with ft jobs and families plus your job wont have people over your shoulder watching you code my favorite hot take from a panel on treating devs like human beings ,"people, job, never, coding, exercise",2022-12-13 02:07:35,there should never be coding exercises in technical interviews it favors people who have time to do them disfavors people with ft jobs and families plus your job wont have people over your shoulder watching you code my favorite hot take from a panel on treating devs like human beings ,"['never', 'coding', 'exercise', 'technical', 'interview', 'favor', 'people', 'time', 'disfavor', 'people', 'job', 'family', 'plus', 'job', 'wont', 'people', 'shoulder', 'watching', 'code', 'favorite', 'hot', 'take', 'panel', 'treating', 'devs', 'like', 'human', 'being']",,,,
6k419t,Is it unethical for me to not tell my employer I’ve automated my job?,,1498687783.0,8665.0,1732.0,/r/programming/comments/6k419t/is_it_unethical_for_me_to_not_tell_my_employer/,https://workplace.stackexchange.com/questions/93696/is-it-unethical-for-me-to-not-tell-my-employer-i-ve-automated-my-job,grepnork,programming,0.94,False,False,False,False,0.0,1745832571.429308,Tech & Programming,14.0,0.0,14.0,Wednesday,18.0,June,2017.0,False,-0.5106,0.0,0.202,0.798,negative,is it unethical for me to not tell my employer ive automated my job,,is it unethical for me to not tell my employer ive automated my job ,"unethical, tell, employer, ive, automated",2017-06-28 22:09:43,is it unethical for me to not tell my employer ive automated my job ,"['unethical', 'tell', 'employer', 'ive', 'automated', 'job']",,,,
8ob3cl,Microsoft Is Said to Have Agreed to Acquire Coding Site GitHub,,1528054963.0,8645.0,1826.0,/r/programming/comments/8ob3cl/microsoft_is_said_to_have_agreed_to_acquire/,https://www.bloomberg.com/news/articles/2018-06-03/microsoft-is-said-to-have-agreed-to-acquire-coding-site-github,clubdirthill,programming,0.95,False,False,False,False,0.0,1745832574.629673,Tech & Programming,11.0,0.0,11.0,Sunday,15.0,June,2018.0,True,0.2732,0.174,0.0,0.826,positive,microsoft is said to have agreed to acquire coding site github,,microsoft is said to have agreed to acquire coding site github ,"microsoft, said, agreed, acquire, coding",2018-06-03 19:42:43,microsoft is said to have agreed to acquire coding site github ,"['microsoft', 'said', 'agreed', 'acquire', 'coding', 'site', 'github']",,,,
11wenmz,"""Software is a just a tool to help accomplish something for people - many programmers never understood that. Keep your eyes on the delivered value, and don't over focus on the specifics of the tools"" - John Carmack",,1679306923.0,8277.0,628.0,/r/programming/comments/11wenmz/software_is_a_just_a_tool_to_help_accomplish/,https://twitter.com/ID_AA_Carmack/status/1637087219591659520,piotrkarczmarz,programming,0.96,False,False,False,False,0.0,1745832578.117054,Tech & Programming,38.0,0.0,36.0,Monday,6.0,March,2023.0,False,0.7845,0.203,0.0,0.797,positive,software is a just a tool to help accomplish something for people many programmers never understood that keep your eyes on the delivered value and dont over focus on the specifics of the tools john carmack,,software is a just a tool to help accomplish something for people many programmers never understood that keep your eyes on the delivered value and dont over focus on the specifics of the tools john carmack ,"tool, software, help, accomplish, something",2023-03-20 10:08:43,software is a just a tool to help accomplish something for people many programmers never understood that keep your eyes on the delivered value and dont over focus on the specifics of the tools john carmack ,"['software', 'tool', 'help', 'accomplish', 'something', 'people', 'many', 'programmer', 'never', 'understood', 'keep', 'eye', 'delivered', 'value', 'dont', 'focus', 'specific', 'tool', 'john', 'carmack']",,,,
6t4iqa,"We did it Reddit! HTTP Error Code 418 - ""I'm a Teapot"" will not be removed from Node, Go, Asp.net, or Python's Request. The Internet Engineering Task Force is marking HTTP 418 as reserved, cementing ""I'm a Teapot""'s legacy for a long time to come.",,1502488994.0,8140.0,513.0,/r/programming/comments/6t4iqa/we_did_it_reddit_http_error_code_418_im_a_teapot/,http://save418.com/,Kamatotato,programming,0.9,False,False,False,False,0.0,1745832581.013168,Tech & Programming,45.0,0.0,42.0,Friday,18.0,August,2017.0,False,-0.4019,0.0,0.066,0.934,negative,we did it reddit http error code im a teapot will not be removed from node go aspnet or pythons request the internet engineering task force is marking http as reserved cementing im a teapots legacy for a long time to come,,we did it reddit http error code im a teapot will not be removed from node go aspnet or pythons request the internet engineering task force is marking http as reserved cementing im a teapots legacy for a long time to come ,"http, teapot, reddit, error, code",2017-08-11 22:03:14,we did it reddit http error code im a teapot will not be removed from node go aspnet or pythons request the internet engineering task force is marking http as reserved cementing im a teapots legacy for a long time to come ,"['reddit', 'http', 'error', 'code', 'teapot', 'removed', 'node', 'aspnet', 'python', 'request', 'internet', 'engineering', 'task', 'force', 'marking', 'http', 'reserved', 'cementing', 'teapot', 'legacy', 'long', 'time', 'come']",,,,
89cq6f,"No, Panera Bread doesn't take security seriously",,1522754936.0,8025.0,596.0,/r/programming/comments/89cq6f/no_panera_bread_doesnt_take_security_seriously/,https://medium.com/@djhoulihan/no-panera-bread-doesnt-take-security-seriously-bf078027f815,DevOrc,programming,0.96,False,False,False,False,0.0,1745832583.489245,Tech & Programming,7.0,0.0,7.0,Tuesday,7.0,April,2018.0,False,-0.4055,0.156,0.434,0.41,negative,no panera bread doesnt take security seriously,,no panera bread doesnt take security seriously ,"panera, bread, doesnt, take, security",2018-04-03 11:28:56,no panera bread doesnt take security seriously ,"['panera', 'bread', 'doesnt', 'take', 'security', 'seriously']",,,,
6heysw,Developers who use spaces make more money than those who use tabs - Stack Overflow Blog,,1497532970.0,8017.0,2027.0,/r/programming/comments/6heysw/developers_who_use_spaces_make_more_money_than/,https://stackoverflow.blog/2017/06/15/developers-use-spaces-make-money-use-tabs/,night_of_knee,programming,0.91,False,False,False,False,0.0,1745832586.072548,Tech & Programming,16.0,0.0,15.0,Thursday,9.0,June,2017.0,False,0.0,0.0,0.0,1.0,neutral,developers who use spaces make more money than those who use tabs stack overflow blog,,developers who use spaces make more money than those who use tabs stack overflow blog ,"use, developer, space, make, money",2017-06-15 13:22:50,developers who use spaces make more money than those who use tabs stack overflow blog ,"['developer', 'use', 'space', 'make', 'money', 'use', 'tab', 'stack', 'overflow', 'blog']",,,,
123cmm8,Twitter Source Code Leaked on GitHub,,1679894954.0,8006.0,726.0,/r/programming/comments/123cmm8/twitter_source_code_leaked_on_github/,https://www.cyberkendra.com/2023/03/twitter-source-code-leaked-on-github.html,geek_noob,programming,0.96,False,False,False,False,0.0,1745832589.069439,Tech & Programming,6.0,0.0,6.0,Monday,1.0,March,2023.0,False,-0.3182,0.0,0.315,0.685,negative,twitter source code leaked on github,,twitter source code leaked on github ,"twitter, source, code, leaked, github",2023-03-27 05:29:14,twitter source code leaked on github ,"['twitter', 'source', 'code', 'leaked', 'github']",,,,
i9luub,Mozilla: The Greatest Tech Company Left Behind,,1597411323.0,7721.0,1026.0,/r/programming/comments/i9luub/mozilla_the_greatest_tech_company_left_behind/,https://medium.com/young-coder/mozilla-the-greatest-tech-company-left-behind-9e912098a0e1?source=friends_link&sk=5137896f6c2495116608a5062570cc0f,matthewpmacdonald,programming,0.97,False,False,False,False,0.0,1745832591.46332,Tech & Programming,7.0,0.0,7.0,Friday,9.0,August,2020.0,False,0.6369,0.412,0.0,0.588,positive,mozilla the greatest tech company left behind,,mozilla the greatest tech company left behind ,"mozilla, greatest, tech, company, left",2020-08-14 13:22:03,mozilla the greatest tech company left behind ,"['mozilla', 'greatest', 'tech', 'company', 'left', 'behind']",,,,
5ym1fv,Password Rules Are Bullshit,,1489152469.0,7656.0,1364.0,/r/programming/comments/5ym1fv/password_rules_are_bullshit/,https://blog.codinghorror.com/password-rules-are-bullshit/,fl4v1,programming,0.93,False,False,False,False,0.0,1745832594.598764,Tech & Programming,4.0,0.0,4.0,Friday,8.0,March,2017.0,False,-0.5859,0.0,0.559,0.441,negative,password rules are bullshit,,password rules are bullshit ,"password, rule, bullshit",2017-03-10 13:27:49,password rules are bullshit ,"['password', 'rule', 'bullshit']",,,,
11gwypy,Nearly 40% of software engineers will only work remotely,,1677837831.0,7527.0,1304.0,/r/programming/comments/11gwypy/nearly_40_of_software_engineers_will_only_work/,https://www.techtarget.com/searchhrsoftware/news/365531979/Nearly-40-of-software-engineers-will-only-work-remotely,Discovensco,programming,0.96,False,False,False,False,0.0,1745832597.737093,Tech & Programming,9.0,0.0,8.0,Friday,5.0,March,2023.0,False,0.0,0.0,0.0,1.0,neutral,nearly of software engineers will only work remotely,,nearly of software engineers will only work remotely ,"nearly, software, engineer, work, remotely",2023-03-03 10:03:51,nearly of software engineers will only work remotely ,"['nearly', 'software', 'engineer', 'work', 'remotely']",,,,
4zp5dt,The true cost of interruptions: Game Developer Magazine discovered that a programmer needs up to 15 minutes to start editing code again following an interruption.,,1472225180.0,7524.0,830.0,/r/programming/comments/4zp5dt/the_true_cost_of_interruptions_game_developer/,https://jaxenter.com/aaaand-gone-true-cost-interruptions-128741.html,yourbasicgeek,programming,0.93,False,False,False,False,0.0,1745832600.887716,Tech & Programming,25.0,0.0,24.0,Friday,11.0,August,2016.0,False,-0.34,0.1,0.186,0.714,negative,the true cost of interruptions game developer magazine discovered that a programmer needs up to minutes to start editing code again following an interruption,,the true cost of interruptions game developer magazine discovered that a programmer needs up to minutes to start editing code again following an interruption ,"interruption, true, cost, game, developer",2016-08-26 15:26:20,the true cost of interruptions game developer magazine discovered that a programmer needs up to minutes to start editing code again following an interruption ,"['true', 'cost', 'interruption', 'game', 'developer', 'magazine', 'discovered', 'programmer', 'need', 'minute', 'start', 'editing', 'code', 'following', 'interruption']",,,,
bjsoeh,"It is perfectly OK to only code at work, you can have a life too.",,1556787271.0,7518.0,1075.0,/r/programming/comments/bjsoeh/it_is_perfectly_ok_to_only_code_at_work_you_can/,https://zeroequalsfalse.press/posts/it-is-ok-to-only-code-at-work/,woahdotcom,programming,0.94,False,False,False,False,0.0,1745832604.067058,Tech & Programming,15.0,0.0,15.0,Thursday,4.0,May,2019.0,False,0.7506,0.348,0.0,0.652,positive,it is perfectly ok to only code at work you can have a life too,,it is perfectly ok to only code at work you can have a life too ,"perfectly, code, work, life",2019-05-02 08:54:31,it is perfectly ok to only code at work you can have a life too ,"['perfectly', 'code', 'work', 'life']",,,,
aeweqw,"Netflix Software Engineers earn a salary of more than $300,000",,1547220294.0,7499.0,1361.0,/r/programming/comments/aeweqw/netflix_software_engineers_earn_a_salary_of_more/,https://blog.salaryproject.com/netflix-software-engineers-earn-a-salary-of-more-than-300000/,magenta_placenta,programming,0.95,False,False,False,False,0.0,1745832606.806927,Tech & Programming,10.0,0.0,9.0,Friday,10.0,January,2019.0,False,0.0,0.0,0.0,1.0,neutral,netflix software engineers earn a salary of more than,,netflix software engineers earn a salary of more than ,"netflix, software, engineer, earn, salary",2019-01-11 15:24:54,netflix software engineers earn a salary of more than ,"['netflix', 'software', 'engineer', 'earn', 'salary']",,,,
37h8ad,SourceForge took control of the GIMP account and is now distributing an ad-enabled installer of GIMP,,1432745330.0,7485.0,975.0,/r/programming/comments/37h8ad/sourceforge_took_control_of_the_gimp_account_and/,https://plus.google.com/+gimp/posts/cxhB1PScFpe,halax,programming,0.96,False,False,False,False,0.0,1745832610.122784,Tech & Programming,16.0,0.0,16.0,Wednesday,12.0,May,2015.0,False,0.0,0.0,0.0,1.0,neutral,sourceforge took control of the gimp account and is now distributing an adenabled installer of gimp,,sourceforge took control of the gimp account and is now distributing an adenabled installer of gimp ,"gimp, sourceforge, took, control, account",2015-05-27 16:48:50,sourceforge took control of the gimp account and is now distributing an adenabled installer of gimp ,"['sourceforge', 'took', 'control', 'gimp', 'account', 'distributing', 'adenabled', 'installer', 'gimp']",,,,
4nm8de,How you know you're fucked: when you google a compilation error and find GitHub issues instead of StackOverflow questions,,1465664863.0,7439.0,528.0,/r/programming/comments/4nm8de/how_you_know_youre_fucked_when_you_google_a/,https://github.com/sequelize/cli/issues/291,danield9tqh,programming,0.91,False,False,False,False,0.0,1745832613.101392,Tech & Programming,19.0,0.0,19.0,Saturday,13.0,June,2016.0,True,-0.7964,0.0,0.307,0.693,negative,how you know youre fucked when you google a compilation error and find github issues instead of stackoverflow questions,,how you know youre fucked when you google a compilation error and find github issues instead of stackoverflow questions ,"know, youre, fucked, google, compilation",2016-06-11 17:07:43,how you know youre fucked when you google a compilation error and find github issues instead of stackoverflow questions ,"['know', 'youre', 'fucked', 'google', 'compilation', 'error', 'find', 'github', 'issue', 'instead', 'stackoverflow', 'question']",,,,
e55j0i,Bubble sort visualization,,1575320796.0,7420.0,269.0,/r/programming/comments/e55j0i/bubble_sort_visualization/,https://v.redd.it/9w7r2g1uba241,pedrovhb,programming,0.94,False,False,False,False,0.0,1745832616.07357,Tech & Programming,3.0,0.0,3.0,Monday,16.0,December,2019.0,False,0.0,0.0,0.0,1.0,neutral,bubble sort visualization,,bubble sort visualization ,"bubble, sort, visualization",2019-12-02 21:06:36,bubble sort visualization ,"['bubble', 'sort', 'visualization']",,,,
ga7ae4,During lockdown my wife has been suffering mentally from pressure to stay at her desk 100% of the time otherwise after a few minutes her laptop locks and she is recorded as inactive. I wrote this small app to help her escape her desk by periodically moving the cursor. Hopefully it can help others.,,1588157605.0,7333.0,819.0,/r/programming/comments/ga7ae4/during_lockdown_my_wife_has_been_suffering/,https://github.com/aatwo/TheWiggler,silitbang6000,programming,0.95,False,False,False,False,1.0,1745832617.366777,Tech & Programming,54.0,0.0,53.0,Wednesday,6.0,April,2020.0,False,0.5423,0.163,0.088,0.749,positive,during lockdown my wife has been suffering mentally from pressure to stay at her desk of the time otherwise after a few minutes her laptop locks and she is recorded as inactive i wrote this small app to help her escape her desk by periodically moving the cursor hopefully it can help others,,during lockdown my wife has been suffering mentally from pressure to stay at her desk of the time otherwise after a few minutes her laptop locks and she is recorded as inactive i wrote this small app to help her escape her desk by periodically moving the cursor hopefully it can help others ,"desk, help, lockdown, wife, suffering",2020-04-29 10:53:25,during lockdown my wife has been suffering mentally from pressure to stay at her desk of the time otherwise after a few minutes her laptop locks and she is recorded as inactive i wrote this small app to help her escape her desk by periodically moving the cursor hopefully it can help others ,"['lockdown', 'wife', 'suffering', 'mentally', 'pressure', 'stay', 'desk', 'time', 'otherwise', 'minute', 'laptop', 'lock', 'recorded', 'inactive', 'wrote', 'small', 'app', 'help', 'escape', 'desk', 'periodically', 'moving', 'cursor', 'hopefully', 'help', 'others']",,,,
vki4ov,Italy declares Google Analytics illegal,,1656172888.0,7289.0,478.0,/r/programming/comments/vki4ov/italy_declares_google_analytics_illegal/,https://blog.simpleanalytics.com/italy-declares-google-analytics-illegal,DonutAccomplished422,programming,0.97,False,False,False,False,0.0,1745832620.190812,Tech & Programming,5.0,0.0,5.0,Saturday,12.0,June,2022.0,True,-0.5574,0.0,0.474,0.526,negative,italy declares google analytics illegal,,italy declares google analytics illegal ,"italy, declares, google, analytics, illegal",2022-06-25 16:01:28,italy declares google analytics illegal ,"['italy', 'declares', 'google', 'analytics', 'illegal']",,,,
wg8pam,"Terry Davis, an extremely talented programmer who was unfortunately diagnosed with schizophrenia, made an entire operating system in a language he made by himself, then compiled everything to machine code with a compiler he made himself.",,1659638239.0,7263.0,929.0,/r/programming/comments/wg8pam/terry_davis_an_extremely_talented_programmer_who/,https://en.wikipedia.org/wiki/Terry_A._Davis,BitPax,programming,0.94,False,False,False,False,0.0,1745832623.000977,Tech & Programming,36.0,0.0,36.0,Thursday,14.0,August,2022.0,False,0.2944,0.095,0.063,0.842,positive,terry davis an extremely talented programmer who was unfortunately diagnosed with schizophrenia made an entire operating system in a language he made by himself then compiled everything to machine code with a compiler he made himself,,terry davis an extremely talented programmer who was unfortunately diagnosed with schizophrenia made an entire operating system in a language he made by himself then compiled everything to machine code with a compiler he made himself ,"made, terry, davis, extremely, talented",2022-08-04 18:37:19,terry davis an extremely talented programmer who was unfortunately diagnosed with schizophrenia made an entire operating system in a language he made by himself then compiled everything to machine code with a compiler he made himself ,"['terry', 'davis', 'extremely', 'talented', 'programmer', 'unfortunately', 'diagnosed', 'schizophrenia', 'made', 'entire', 'operating', 'system', 'language', 'made', 'compiled', 'everything', 'machine', 'code', 'compiler', 'made']",,,,
7yb6cx,"It's perfectly fine to only code at work, don't let anyone tell you otherwise",,1518918199.0,7240.0,1111.0,/r/programming/comments/7yb6cx/its_perfectly_fine_to_only_code_at_work_dont_let/,https://dev.to/ben/its-perfectly-fine-to-only-code-at-work-dont-let-anyone-tell-you-otherwise--25i3,gregbaugues,programming,0.93,False,False,False,False,1.0,1745832625.844979,Tech & Programming,14.0,0.0,14.0,Saturday,20.0,February,2018.0,True,0.7184,0.333,0.0,0.667,positive,its perfectly fine to only code at work dont let anyone tell you otherwise,,its perfectly fine to only code at work dont let anyone tell you otherwise ,"perfectly, fine, code, work, dont",2018-02-18 01:43:19,its perfectly fine to only code at work dont let anyone tell you otherwise ,"['perfectly', 'fine', 'code', 'work', 'dont', 'let', 'anyone', 'tell', 'otherwise']",,,,
74uvc7,Fetlang - Fetish-themed programming language,,1507383127.0,7229.0,377.0,/r/programming/comments/74uvc7/fetlang_fetishthemed_programming_language/,https://github.com/Property404/fetlang,Property404,programming,0.88,False,True,False,False,1.0,1745832628.850373,Tech & Programming,5.0,0.0,4.0,Saturday,9.0,October,2017.0,True,0.0,0.0,0.0,1.0,neutral,fetlang fetishthemed programming language,,fetlang fetishthemed programming language ,"fetlang, fetishthemed, programming, language",2017-10-07 13:32:07,fetlang fetishthemed programming language ,"['fetlang', 'fetishthemed', 'programming', 'language']",,,,
71htzt,"If you are ever interested in using a Hexagonal Grid in your game / app / interface, I came across an absolute goldmine of an article!",,1505983483.0,7183.0,250.0,/r/programming/comments/71htzt/if_you_are_ever_interested_in_using_a_hexagonal/,https://www.redblobgames.com/grids/hexagons/,Whale_Eating_Cheese,programming,0.95,False,False,False,False,0.0,1745832631.522818,Tech & Programming,26.0,0.0,24.0,Thursday,4.0,September,2017.0,False,0.4019,0.114,0.0,0.886,positive,if you are ever interested in using a hexagonal grid in your game app interface i came across an absolute goldmine of an article,,if you are ever interested in using a hexagonal grid in your game app interface i came across an absolute goldmine of an article ,"ever, interested, using, hexagonal, grid",2017-09-21 08:44:43,if you are ever interested in using a hexagonal grid in your game app interface i came across an absolute goldmine of an article ,"['ever', 'interested', 'using', 'hexagonal', 'grid', 'game', 'app', 'interface', 'came', 'across', 'absolute', 'goldmine', 'article']",,,,
cz6f5r,"Former Google engineer breaks down interview problems he uses to screen candidates. Lots of good coding, algorithms, and interview tips.",,1567524730.0,7173.0,786.0,/r/programming/comments/cz6f5r/former_google_engineer_breaks_down_interview/,https://medium.com/@alexgolec/google-interview-problems-ratio-finder-d7aa8bf201e3,jfasi,programming,0.96,False,False,False,False,2.0,1745832633.169232,Tech & Programming,20.0,0.0,20.0,Tuesday,11.0,September,2019.0,False,0.0516,0.123,0.114,0.763,positive,former google engineer breaks down interview problems he uses to screen candidates lots of good coding algorithms and interview tips,,former google engineer breaks down interview problems he uses to screen candidates lots of good coding algorithms and interview tips ,"interview, former, google, engineer, break",2019-09-03 15:32:10,former google engineer breaks down interview problems he uses to screen candidates lots of good coding algorithms and interview tips ,"['former', 'google', 'engineer', 'break', 'interview', 'problem', 'us', 'screen', 'candidate', 'lot', 'good', 'coding', 'algorithm', 'interview', 'tip']",,,,
4kdmmb,Reverse Engineering a Mysterious UDP Stream in My Hotel,,1463838383.0,7059.0,349.0,/r/programming/comments/4kdmmb/reverse_engineering_a_mysterious_udp_stream_in_my/,http://wiki.gkbrk.com/Hotel_Music.html,javinpaul,programming,0.94,False,False,False,False,0.0,1745832636.317079,Tech & Programming,9.0,0.0,9.0,Saturday,9.0,May,2016.0,True,0.0,0.0,0.0,1.0,neutral,reverse engineering a mysterious udp stream in my hotel,,reverse engineering a mysterious udp stream in my hotel ,"reverse, engineering, mysterious, udp, stream",2016-05-21 13:46:23,reverse engineering a mysterious udp stream in my hotel ,"['reverse', 'engineering', 'mysterious', 'udp', 'stream', 'hotel']",,,,
jegq9k,"Blockchain, the amazing solution for almost nothing",,1603161127.0,7036.0,1455.0,/r/programming/comments/jegq9k/blockchain_the_amazing_solution_for_almost_nothing/,https://thecorrespondent.com/655/blockchain-the-amazing-solution-for-almost-nothing/86714927310-8f431cae,imogenchampagne,programming,0.95,False,False,False,False,1.0,1745832638.761377,Tech & Programming,7.0,0.0,7.0,Monday,22.0,October,2020.0,False,0.7269,0.55,0.0,0.45,positive,blockchain the amazing solution for almost nothing,,blockchain the amazing solution for almost nothing ,"blockchain, amazing, solution, almost, nothing",2020-10-20 02:32:07,blockchain the amazing solution for almost nothing ,"['blockchain', 'amazing', 'solution', 'almost', 'nothing']",,,,
9l5sxn,Jesus H. Christ. This guy reverse engineered Pokemon Red....... with Minecraft command blocks. Yep you heard that right.,,1538603899.0,6960.0,689.0,/r/programming/comments/9l5sxn/jesus_h_christ_this_guy_reverse_engineered/,https://youtu.be/H-U96W89Z90,Chaoscrasher,programming,0.9,False,False,False,False,0.0,1745832642.219531,Tech & Programming,18.0,0.0,18.0,Wednesday,17.0,October,2018.0,False,0.0772,0.115,0.099,0.785,positive,jesus h christ this guy reverse engineered pokemon red with minecraft command blocks yep you heard that right,,jesus h christ this guy reverse engineered pokemon red with minecraft command blocks yep you heard that right ,"jesus, christ, guy, reverse, engineered",2018-10-03 21:58:19,jesus h christ this guy reverse engineered pokemon red with minecraft command blocks yep you heard that right ,"['jesus', 'christ', 'guy', 'reverse', 'engineered', 'pokemon', 'red', 'minecraft', 'command', 'block', 'yep', 'heard', 'right']",,,,
90qs4q,Fascinating illustration of Deep Learning and LiDAR perception in Self Driving Cars and other Autonomous Vehicles,,1532192800.0,6935.0,532.0,/r/programming/comments/90qs4q/fascinating_illustration_of_deep_learning_and/,https://v.redd.it/v899qwd72cb11,kshitijmishra23,programming,0.96,False,False,False,False,0.0,1745832645.290602,Tech & Programming,16.0,0.0,16.0,Saturday,13.0,July,2018.0,True,0.5423,0.189,0.0,0.811,positive,fascinating illustration of deep learning and lidar perception in self driving cars and other autonomous vehicles,,fascinating illustration of deep learning and lidar perception in self driving cars and other autonomous vehicles ,"fascinating, illustration, deep, learning, lidar",2018-07-21 17:06:40,fascinating illustration of deep learning and lidar perception in self driving cars and other autonomous vehicles ,"['fascinating', 'illustration', 'deep', 'learning', 'lidar', 'perception', 'self', 'driving', 'car', 'autonomous', 'vehicle']",,,,
kvqy4z,Entire Computer Science Curriculum in 1000 YouTube Videos,,1610455362.0,6927.0,434.0,/r/programming/comments/kvqy4z/entire_computer_science_curriculum_in_1000/,https://laconicml.com/computer-science-curriculum-youtube-videos/,m3t3kh4n,programming,0.96,False,False,False,False,0.0,1745832648.34529,Tech & Programming,8.0,0.0,7.0,Tuesday,7.0,January,2021.0,False,0.0,0.0,0.0,1.0,neutral,entire computer science curriculum in youtube videos,,entire computer science curriculum in youtube videos ,"entire, computer, science, curriculum, youtube",2021-01-12 12:42:42,entire computer science curriculum in youtube videos ,"['entire', 'computer', 'science', 'curriculum', 'youtube', 'video']",,,,
4x2sjl,Text analysis of Trump's tweets confirms he writes only the (angrier) Android half,,1470844300.0,6919.0,455.0,/r/programming/comments/4x2sjl/text_analysis_of_trumps_tweets_confirms_he_writes/,http://varianceexplained.org/r/trump-tweets/,,programming,0.85,False,False,False,False,1.0,1745832651.128255,Tech & Programming,13.0,0.0,13.0,Wednesday,11.0,August,2016.0,False,-0.5106,0.0,0.216,0.784,negative,text analysis of trumps tweets confirms he writes only the angrier android half,,text analysis of trumps tweets confirms he writes only the angrier android half ,"text, analysis, trump, tweet, confirms",2016-08-10 15:51:40,text analysis of trumps tweets confirms he writes only the angrier android half ,"['text', 'analysis', 'trump', 'tweet', 'confirms', 'writes', 'angrier', 'android', 'half']",,,,
i7t6qv,"It is perfectly OK to only code at work, you can have a life too",,1597157569.0,6841.0,714.0,/r/programming/comments/i7t6qv/it_is_perfectly_ok_to_only_code_at_work_you_can/,https://zeroequalsfalse.com/posts/it-is-ok-to-only-code-at-work/,whackri,programming,0.94,False,False,False,False,0.0,1745832654.419901,Tech & Programming,15.0,0.0,15.0,Tuesday,10.0,August,2020.0,False,0.7506,0.348,0.0,0.652,positive,it is perfectly ok to only code at work you can have a life too,,it is perfectly ok to only code at work you can have a life too ,"perfectly, code, work, life",2020-08-11 14:52:49,it is perfectly ok to only code at work you can have a life too ,"['perfectly', 'code', 'work', 'life']",,,,
7omh1n,I’m harvesting credit card numbers and passwords from your site. Here’s how.,,1515277664.0,6815.0,599.0,/r/programming/comments/7omh1n/im_harvesting_credit_card_numbers_and_passwords/,https://hackernoon.com/im-harvesting-credit-card-numbers-and-passwords-from-your-site-here-s-how-9a8cb347c5b5,FUZxxl,programming,0.93,False,False,False,False,0.0,1745832657.415151,Tech & Programming,12.0,0.0,12.0,Saturday,17.0,January,2018.0,True,0.3818,0.191,0.0,0.809,positive,im harvesting credit card numbers and passwords from your site heres how,,im harvesting credit card numbers and passwords from your site heres how ,"harvesting, credit, card, number, password",2018-01-06 22:27:44,im harvesting credit card numbers and passwords from your site heres how ,"['harvesting', 'credit', 'card', 'number', 'password', 'site', 'here']",,,,
lmfi3b,Citibank just got a $500 million lesson in the importance of UI design,,1613628602.0,6772.0,764.0,/r/programming/comments/lmfi3b/citibank_just_got_a_500_million_lesson_in_the/,https://arstechnica.com/?post_type=post&p=1743040,lwl,programming,0.97,False,False,False,False,0.0,1745832660.43727,Tech & Programming,13.0,0.0,12.0,Thursday,1.0,February,2021.0,False,0.3612,0.2,0.0,0.8,positive,citibank just got a million lesson in the importance of ui design,,citibank just got a million lesson in the importance of ui design ,"citibank, got, million, lesson, importance",2021-02-18 06:10:02,citibank just got a million lesson in the importance of ui design ,"['citibank', 'got', 'million', 'lesson', 'importance', 'design']",,,,
cus0zu,"A 3mil downloads per month JavaScript library, which is already known for misleading newbies, is now adding paid advertisements to users' terminals",,1566644356.0,6719.0,929.0,/r/programming/comments/cus0zu/a_3mil_downloads_per_month_javascript_library/,https://github.com/standard/standard/issues/1381,Magnaboy,programming,0.97,False,False,False,False,1.0,1745832662.838253,Tech & Programming,22.0,0.0,22.0,Saturday,6.0,August,2019.0,True,-0.4019,0.0,0.119,0.881,negative,a mil downloads per month javascript library which is already known for misleading newbies is now adding paid advertisements to users terminals,,a mil downloads per month javascript library which is already known for misleading newbies is now adding paid advertisements to users terminals ,"mil, downloads, per, month, javascript",2019-08-24 10:59:16,a mil downloads per month javascript library which is already known for misleading newbies is now adding paid advertisements to users terminals ,"['mil', 'downloads', 'per', 'month', 'javascript', 'library', 'already', 'known', 'misleading', 'newbie', 'adding', 'paid', 'advertisement', 'user', 'terminal']",,,,
zhpkk1,StackOverflow to ban ChatGPT generated answers with possibly immediate suspensions of up to 30 days to users without prior notice or warning,,1670669435.0,6705.0,798.0,/r/programming/comments/zhpkk1/stackoverflow_to_ban_chatgpt_generated_answers/,https://stackoverflow.com/help/gpt-policy,3urny,programming,0.97,False,False,False,False,0.0,1745832666.646865,Tech & Programming,22.0,0.0,21.0,Saturday,5.0,December,2022.0,True,-0.7184,0.0,0.24,0.76,negative,stackoverflow to ban chatgpt generated answers with possibly immediate suspensions of up to days to users without prior notice or warning,,stackoverflow to ban chatgpt generated answers with possibly immediate suspensions of up to days to users without prior notice or warning ,"stackoverflow, ban, chatgpt, generated, answer",2022-12-10 10:50:35,stackoverflow to ban chatgpt generated answers with possibly immediate suspensions of up to days to users without prior notice or warning ,"['stackoverflow', 'ban', 'chatgpt', 'generated', 'answer', 'possibly', 'immediate', 'suspension', 'day', 'user', 'without', 'prior', 'notice', 'warning']",,,,
mnhjnz,Airline software super-bug: Flight loads miscalculated because women using 'Miss' were treated as children,,1617975975.0,6681.0,759.0,/r/programming/comments/mnhjnz/airline_software_superbug_flight_loads/,https://www.theregister.com/2021/04/08/tui_software_mistake/,self,programming,0.97,False,False,False,False,1.0,1745832669.111707,Tech & Programming,14.0,0.0,14.0,Friday,9.0,April,2021.0,False,-0.1531,0.0,0.11,0.89,negative,airline software superbug flight loads miscalculated because women using miss were treated as children,,airline software superbug flight loads miscalculated because women using miss were treated as children ,"airline, software, superbug, flight, load",2021-04-09 13:46:15,airline software superbug flight loads miscalculated because women using miss were treated as children ,"['airline', 'software', 'superbug', 'flight', 'load', 'miscalculated', 'woman', 'using', 'miss', 'treated', 'child']",,,,
cdgrxe,"Alan Turing, World War Two codebreaker and mathematician, will be the face of new Bank of England £50 note",,1563193295.0,6658.0,338.0,/r/programming/comments/cdgrxe/alan_turing_world_war_two_codebreaker_and/,https://www.bbc.com/news/business-48962557,JonathanTheZero,programming,0.96,False,False,False,False,0.0,1745832672.404602,Tech & Programming,19.0,0.0,18.0,Monday,8.0,July,2019.0,False,-0.5994,0.0,0.187,0.813,negative,alan turing world war two codebreaker and mathematician will be the face of new bank of england note,,alan turing world war two codebreaker and mathematician will be the face of new bank of england note ,"alan, turing, world, war, two",2019-07-15 12:21:35,alan turing world war two codebreaker and mathematician will be the face of new bank of england note ,"['alan', 'turing', 'world', 'war', 'two', 'codebreaker', 'mathematician', 'face', 'new', 'bank', 'england', 'note']",,,,
ieni93,"Blockchain, the amazing solution for almost nothing",,1598120356.0,6617.0,1474.0,/r/programming/comments/ieni93/blockchain_the_amazing_solution_for_almost_nothing/,https://thecorrespondent.com/655/blockchain-the-amazing-solution-for-almost-nothing/86649455475-f933fe63,jessefrederik,programming,0.95,False,False,False,False,1.0,1745832674.132484,Tech & Programming,7.0,0.0,7.0,Saturday,14.0,August,2020.0,True,0.7269,0.55,0.0,0.45,positive,blockchain the amazing solution for almost nothing,,blockchain the amazing solution for almost nothing ,"blockchain, amazing, solution, almost, nothing",2020-08-22 18:19:16,blockchain the amazing solution for almost nothing ,"['blockchain', 'amazing', 'solution', 'almost', 'nothing']",,,,
kcwqij,"Every single google service is currently out, including their cloud console. Let's take a moment to feel the pain of their devops team",,1607948872.0,6554.0,575.0,/r/programming/comments/kcwqij/every_single_google_service_is_currently_out/,https://www.google.com/appsstatus#hl=en&v=status,The_Grandmother,programming,0.95,False,False,False,False,0.0,1745832677.7132,Tech & Programming,23.0,0.0,23.0,Monday,7.0,December,2020.0,False,-0.5106,0.0,0.136,0.864,negative,every single google service is currently out including their cloud console lets take a moment to feel the pain of their devops team,,every single google service is currently out including their cloud console lets take a moment to feel the pain of their devops team ,"every, single, google, service, currently",2020-12-14 12:27:52,every single google service is currently out including their cloud console lets take a moment to feel the pain of their devops team ,"['every', 'single', 'google', 'service', 'currently', 'including', 'cloud', 'console', 'let', 'take', 'moment', 'feel', 'pain', 'devops', 'team']",,,,
zwjxsf,"""Dev burnout drastically decreases when your team actually ships things on a regular basis. Burnout primarily comes from toil, rework and never seeing the end of projects."" This was by far the the best lesson I learned this year and finally tracked down the the talk it was from. Hope it helps.",,1672159549.0,6539.0,305.0,/r/programming/comments/zwjxsf/dev_burnout_drastically_decreases_when_your_team/,https://devinterrupted.substack.com/p/the-best-solution-to-burnout-weve,Difficult_Pop_7689,programming,0.96,False,False,False,False,0.0,1745832680.126529,Tech & Programming,52.0,0.0,52.0,Tuesday,11.0,December,2022.0,False,0.8658,0.171,0.0,0.829,positive,dev burnout drastically decreases when your team actually ships things on a regular basis burnout primarily comes from toil rework and never seeing the end of projects this was by far the the best lesson i learned this year and finally tracked down the the talk it was from hope it helps,,dev burnout drastically decreases when your team actually ships things on a regular basis burnout primarily comes from toil rework and never seeing the end of projects this was by far the the best lesson i learned this year and finally tracked down the the talk it was from hope it helps ,"burnout, dev, drastically, decrease, team",2022-12-27 16:45:49,dev burnout drastically decreases when your team actually ships things on a regular basis burnout primarily comes from toil rework and never seeing the end of projects this was by far the the best lesson i learned this year and finally tracked down the the talk it was from hope it helps ,"['dev', 'burnout', 'drastically', 'decrease', 'team', 'actually', 'ship', 'thing', 'regular', 'basis', 'burnout', 'primarily', 'come', 'toil', 'rework', 'never', 'seeing', 'end', 'project', 'far', 'best', 'lesson', 'learned', 'year', 'finally', 'tracked', 'talk', 'hope', 'help']",,,,
725bbw,An in-depth explanation of how a 10 year old bug in Guitar Hero was reverse-engineered and fixed without using the source code,,1506263339.0,6529.0,380.0,/r/programming/comments/725bbw/an_indepth_explanation_of_how_a_10_year_old_bug/,https://www.youtube.com/watch?v=A9U5wK_boYM,generalguy26,programming,0.94,False,False,False,False,0.0,1745832681.687152,Tech & Programming,22.0,0.0,21.0,Sunday,10.0,September,2017.0,True,0.5574,0.159,0.0,0.841,positive,an indepth explanation of how a year old bug in guitar hero was reverseengineered and fixed without using the source code,,an indepth explanation of how a year old bug in guitar hero was reverseengineered and fixed without using the source code ,"indepth, explanation, year, old, bug",2017-09-24 14:28:59,an indepth explanation of how a year old bug in guitar hero was reverseengineered and fixed without using the source code ,"['indepth', 'explanation', 'year', 'old', 'bug', 'guitar', 'hero', 'reverseengineered', 'fixed', 'without', 'using', 'source', 'code']",,,,
2m2w3b,The .NET Core is now open-source.,,1415806947.0,6517.0,1817.0,/r/programming/comments/2m2w3b/the_net_core_is_now_opensource/,http://blogs.msdn.com/b/dotnet/archive/2014/11/12/net-core-is-open-source.aspx,rionmonster,programming,0.95,False,False,False,False,0.0,1745832683.54737,Tech & Programming,6.0,0.0,6.0,Wednesday,10.0,November,2014.0,False,0.0,0.0,0.0,1.0,neutral,the net core is now opensource,,the net core is now opensource ,"net, core, opensource",2014-11-12 15:42:27,the net core is now opensource ,"['net', 'core', 'opensource']",,,,
wlre5a,There aren't that many uses for blockchains,,1660224434.0,6501.0,2208.0,/r/programming/comments/wlre5a/there_arent_that_many_uses_for_blockchains/,https://calpaterson.com/blockchain.html,calp,programming,0.91,False,False,False,False,0.0,1745832686.692054,Tech & Programming,7.0,0.0,7.0,Thursday,9.0,August,2022.0,False,0.0,0.0,0.0,1.0,neutral,there arent that many uses for blockchains,,there arent that many uses for blockchains ,"arent, many, us, blockchains",2022-08-11 13:27:14,there arent that many uses for blockchains ,"['arent', 'many', 'us', 'blockchains']",,,,
mklggn,"In major copyright battle between tech giants, SCOTUS sides w/ Google over Oracle, finding that Google didnt commit copyright infringement when it reused lines of code in its Android operating system.",,1617631481.0,6472.0,640.0,/r/programming/comments/mklggn/in_major_copyright_battle_between_tech_giants/,https://www.supremecourt.gov/opinions/20pdf/18-956_d18f.pdf,Plaatinum_Spark,programming,0.97,False,False,False,False,0.0,1745832689.972519,Tech & Programming,31.0,0.0,31.0,Monday,10.0,April,2021.0,False,-0.2344,0.075,0.132,0.793,negative,in major copyright battle between tech giants scotus sides w google over oracle finding that google didnt commit copyright infringement when it reused lines of code in its android operating system,,in major copyright battle between tech giants scotus sides w google over oracle finding that google didnt commit copyright infringement when it reused lines of code in its android operating system ,"copyright, google, major, battle, tech",2021-04-05 14:04:41,in major copyright battle between tech giants scotus sides w google over oracle finding that google didnt commit copyright infringement when it reused lines of code in its android operating system ,"['major', 'copyright', 'battle', 'tech', 'giant', 'scotus', 'side', 'google', 'oracle', 'finding', 'google', 'didnt', 'commit', 'copyright', 'infringement', 'reused', 'line', 'code', 'android', 'operating', 'system']",,,,
ixo3px,Google engineer breaks down the problems he uses when doing technical interviews. Lots of advice on algorithms and programming.,,1600783760.0,6410.0,1090.0,/r/programming/comments/ixo3px/google_engineer_breaks_down_the_problems_he_uses/,https://alexgolec.dev/google-interview-questions-deconstructed-the-knights-dialer/,ldxtc,programming,0.95,False,False,False,False,0.0,1745832692.179307,Tech & Programming,19.0,0.0,19.0,Tuesday,10.0,September,2020.0,False,-0.4019,0.0,0.13,0.87,negative,google engineer breaks down the problems he uses when doing technical interviews lots of advice on algorithms and programming,,google engineer breaks down the problems he uses when doing technical interviews lots of advice on algorithms and programming ,"google, engineer, break, problem, us",2020-09-22 14:09:20,google engineer breaks down the problems he uses when doing technical interviews lots of advice on algorithms and programming ,"['google', 'engineer', 'break', 'problem', 'us', 'technical', 'interview', 'lot', 'advice', 'algorithm', 'programming']",,,,
ukptue,"Ian Goodfellow, Apple's Director of Machine Learning, Inventor of GAN, Resigns Due to Apple's Return to Office Work",,1651968423.0,6376.0,608.0,/r/programming/comments/ukptue/ian_goodfellow_apples_director_of_machine/,https://www.macrumors.com/2022/05/07/apple-director-of-machine-learning-resigns/,Mcnst,programming,0.96,False,False,False,False,0.0,1745832695.371552,Tech & Programming,18.0,0.0,18.0,Saturday,20.0,May,2022.0,True,-0.3182,0.0,0.119,0.881,negative,ian goodfellow apples director of machine learning inventor of gan resigns due to apples return to office work,,ian goodfellow apples director of machine learning inventor of gan resigns due to apples return to office work ,"apple, ian, goodfellow, director, machine",2022-05-08 00:07:03,ian goodfellow apples director of machine learning inventor of gan resigns due to apples return to office work ,"['ian', 'goodfellow', 'apple', 'director', 'machine', 'learning', 'inventor', 'gan', 'resigns', 'due', 'apple', 'return', 'office', 'work']",,,,
1czk8nv,Study Finds That 52 Percent of ChatGPT Answers to Programming Questions Are Wrong,,1716555858.0,6375.0,816.0,/r/programming/comments/1czk8nv/study_finds_that_52_percent_of_chatgpt_answers_to/,https://futurism.com/the-byte/study-chatgpt-answers-wrong,anseho,programming,0.95,False,False,False,False,0.0,1745832698.75505,Tech & Programming,13.0,0.0,12.0,Friday,9.0,May,2024.0,False,-0.4767,0.0,0.22,0.78,negative,study finds that percent of chatgpt answers to programming questions are wrong,,study finds that percent of chatgpt answers to programming questions are wrong ,"study, find, percent, chatgpt, answer",2024-05-24 13:04:18,study finds that percent of chatgpt answers to programming questions are wrong ,"['study', 'find', 'percent', 'chatgpt', 'answer', 'programming', 'question', 'wrong']",,,,
p93vw3,Getting GPLv2 compliance from a Chinese company- in person,,1629597369.0,6340.0,1141.0,/r/programming/comments/p93vw3/getting_gplv2_compliance_from_a_chinese_company/,https://streamable.com/2b56qa,DougTheFunny,programming,0.92,False,False,False,False,0.0,1745832701.353206,Tech & Programming,9.0,0.0,9.0,Saturday,21.0,August,2021.0,True,0.0,0.0,0.0,1.0,neutral,getting gplv compliance from a chinese company in person,,getting gplv compliance from a chinese company in person ,"getting, gplv, compliance, chinese, company",2021-08-22 01:56:09,getting gplv compliance from a chinese company in person ,"['getting', 'gplv', 'compliance', 'chinese', 'company', 'person']",,,,
ghto13,Why we at $FAMOUS_COMPANY Switched to $HYPED_TECHNOLOGY,,1589222729.0,6205.0,681.0,/r/programming/comments/ghto13/why_we_at_famous_company_switched_to_hyped/,https://saagarjha.com/blog/2020/05/10/why-we-at-famous-company-switched-to-hyped-technology/,swizec,programming,0.96,False,False,False,False,2.0,1745832704.25256,Tech & Programming,7.0,0.0,7.0,Monday,14.0,May,2020.0,False,0.0,0.0,0.0,1.0,neutral,why we at famous_company switched to hyped_technology,,why we at famous_company switched to hyped_technology ,"famous_company, switched, hyped_technology",2020-05-11 18:45:29,why we at famous_company switched to hyped_technology ,"['famous_company', 'switched', 'hyped_technology']",,,,
ndyp0s,"URL shorteners are so last year, so I made a URL lengthener",,1621201201.0,6140.0,229.0,/r/programming/comments/ndyp0s/url_shorteners_are_so_last_year_so_i_made_a_url/,https://aaa.aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa.com/,ImplosiveTech,programming,0.96,False,False,False,False,0.0,1745832707.242323,Tech & Programming,12.0,0.0,12.0,Sunday,17.0,May,2021.0,True,0.0,0.0,0.0,1.0,neutral,url shorteners are so last year so i made a url lengthener,,url shorteners are so last year so i made a url lengthener ,"url, shortener, last, year, made",2021-05-16 21:40:01,url shorteners are so last year so i made a url lengthener ,"['url', 'shortener', 'last', 'year', 'made', 'url', 'lengthener']",,,,
ceh1gn,The entire Apollo 11 computer code that helped get us to the Moon is available on github.,,1563389455.0,6135.0,386.0,/r/programming/comments/ceh1gn/the_entire_apollo_11_computer_code_that_helped/,https://github.com/chrislgarry/Apollo-11,ankur-anand,programming,0.97,False,False,False,False,0.0,1745832708.756303,Tech & Programming,17.0,0.0,16.0,Wednesday,14.0,July,2019.0,False,0.0,0.0,0.0,1.0,neutral,the entire apollo computer code that helped get us to the moon is available on github,,the entire apollo computer code that helped get us to the moon is available on github ,"entire, apollo, computer, code, helped",2019-07-17 18:50:55,the entire apollo computer code that helped get us to the moon is available on github ,"['entire', 'apollo', 'computer', 'code', 'helped', 'get', 'moon', 'available', 'github']",,,,
6whz9e,Software development 450 words per minute,,1503906670.0,6108.0,291.0,/r/programming/comments/6whz9e/software_development_450_words_per_minute/,https://www.vincit.fi/en/blog/software-development-450-words-per-minute/,pkovanen,programming,0.93,False,False,False,False,0.0,1745832710.875426,Tech & Programming,6.0,0.0,5.0,Monday,3.0,August,2017.0,False,0.0,0.0,0.0,1.0,neutral,software development words per minute,,software development words per minute ,"software, development, word, per, minute",2017-08-28 07:51:10,software development words per minute ,"['software', 'development', 'word', 'per', 'minute']",,,,
k16g2e,Dark Mode Coming to GitHub After 7 Years,,1606357353.0,6095.0,357.0,/r/programming/comments/k16g2e/dark_mode_coming_to_github_after_7_years/,https://github.com/isaacs/github/issues/66#issuecomment-733446758,rxsel,programming,0.97,False,False,False,False,0.0,1745832712.855978,Tech & Programming,8.0,0.0,7.0,Wednesday,21.0,November,2020.0,False,0.0,0.0,0.0,1.0,neutral,dark mode coming to github after years,,dark mode coming to github after years ,"dark, mode, coming, github, year",2020-11-26 02:22:33,dark mode coming to github after years ,"['dark', 'mode', 'coming', 'github', 'year']",,,,
1i9xtgz,"The ""First AI Software Engineer"" Is Bungling the Vast Majority of Tasks It's Asked to Do",,1737841243.0,6084.0,675.0,/r/programming/comments/1i9xtgz/the_first_ai_software_engineer_is_bungling_the/,https://futurism.com/first-ai-software-engineer-devin-bungling-tasks,creaturefeature16,programming,0.96,False,False,False,False,0.0,1745832714.771768,Tech & Programming,16.0,0.0,16.0,Saturday,16.0,January,2025.0,True,0.0,0.0,0.0,1.0,neutral,the first ai software engineer is bungling the vast majority of tasks its asked to do,,the first ai software engineer is bungling the vast majority of tasks its asked to do ,"first, software, engineer, bungling, vast",2025-01-25 21:40:43,the first ai software engineer is bungling the vast majority of tasks its asked to do ,"['first', 'software', 'engineer', 'bungling', 'vast', 'majority', 'task', 'asked']",,,,
6eh7gw,"Apple has released a free, beginner-level, 900-page book ""App Development with Swift"" + related teaching materials.",,1496257953.0,6084.0,479.0,/r/programming/comments/6eh7gw/apple_has_released_a_free_beginnerlevel_900page/,https://itunes.apple.com/us/book/app-development-with-swift/id1219117996?mt=11,satisfyinghump,programming,0.92,False,False,False,False,0.0,1745832717.445614,Tech & Programming,16.0,0.0,15.0,Wednesday,15.0,May,2017.0,False,0.6249,0.298,0.0,0.702,positive,apple has released a free beginnerlevel page book app development with swift related teaching materials,,apple has released a free beginnerlevel page book app development with swift related teaching materials ,"apple, released, free, beginnerlevel, page",2017-05-31 19:12:33,apple has released a free beginnerlevel page book app development with swift related teaching materials ,"['apple', 'released', 'free', 'beginnerlevel', 'page', 'book', 'app', 'development', 'swift', 'related', 'teaching', 'material']",,,,
qhg9yh,"Viewing website HTML code is not illegal or “hacking,” prof. tells Missouri gov.",,1635400692.0,6052.0,499.0,/r/programming/comments/qhg9yh/viewing_website_html_code_is_not_illegal_or/,https://arstechnica.com/tech-policy/2021/10/viewing-website-html-code-is-not-illegal-or-hacking-prof-tells-missouri-gov/,RobertVandenberg,programming,0.98,False,False,False,False,0.0,1745832720.438294,Tech & Programming,13.0,0.0,13.0,Thursday,1.0,October,2021.0,False,0.4449,0.196,0.0,0.804,positive,viewing website html code is not illegal or hacking prof tells missouri gov,,viewing website html code is not illegal or hacking prof tells missouri gov ,"viewing, website, html, code, illegal",2021-10-28 05:58:12,viewing website html code is not illegal or hacking prof tells missouri gov ,"['viewing', 'website', 'html', 'code', 'illegal', 'hacking', 'prof', 'tell', 'missouri', 'gov']",,,,
d2qrx6,This video shows the most popular programming languages on Stack Overflow since September 2008,,1568211051.0,6044.0,556.0,/r/programming/comments/d2qrx6/this_video_shows_the_most_popular_programming/,https://v.redd.it/ugbxngs91zl31,qaops,programming,0.95,False,False,False,False,0.0,1745832723.367458,Tech & Programming,14.0,0.0,13.0,Wednesday,10.0,September,2019.0,False,0.4754,0.205,0.0,0.795,positive,this video shows the most popular programming languages on stack overflow since september,,this video shows the most popular programming languages on stack overflow since september ,"video, show, popular, programming, language",2019-09-11 14:10:51,this video shows the most popular programming languages on stack overflow since september ,"['video', 'show', 'popular', 'programming', 'language', 'stack', 'overflow', 'since', 'september']",,,,
4s37pk,"The code that took America to the moon was just published to GitHub, and it’s like a 1960s time capsule",,1468112174.0,6034.0,422.0,/r/programming/comments/4s37pk/the_code_that_took_america_to_the_moon_was_just/,http://qz.com/726338/the-code-that-took-america-to-the-moon-was-just-published-to-github-and-its-like-a-1960s-time-capsule/,watchmakerfromfuture,programming,0.92,False,False,False,False,0.0,1745832725.970119,Tech & Programming,20.0,0.0,20.0,Saturday,20.0,July,2016.0,True,0.3612,0.128,0.0,0.872,positive,the code that took america to the moon was just published to github and its like a s time capsule,,the code that took america to the moon was just published to github and its like a s time capsule ,"code, took, america, moon, published",2016-07-10 00:56:14,the code that took america to the moon was just published to github and its like a s time capsule ,"['code', 'took', 'america', 'moon', 'published', 'github', 'like', 'time', 'capsule']",,,,
gel0ed,"No cookie consent walls — and no, scrolling isn’t consent, says EU data protection body",,1588775261.0,6021.0,860.0,/r/programming/comments/gel0ed/no_cookie_consent_walls_and_no_scrolling_isnt/,https://techcrunch.com/2020/05/06/no-cookie-consent-walls-and-no-scrolling-isnt-consent-says-eu-data-protection-body/,PowerOfLove1985,programming,0.98,False,False,False,False,0.0,1745832729.001032,Tech & Programming,15.0,0.0,14.0,Wednesday,10.0,May,2020.0,False,-0.1531,0.209,0.242,0.549,negative,no cookie consent walls and no scrolling isnt consent says eu data protection body,,no cookie consent walls and no scrolling isnt consent says eu data protection body ,"consent, cookie, wall, scrolling, isnt",2020-05-06 14:27:41,no cookie consent walls and no scrolling isnt consent says eu data protection body ,"['cookie', 'consent', 'wall', 'scrolling', 'isnt', 'consent', 'say', 'data', 'protection', 'body']",,,,
5741xk,Your Social Media Fingerprint,,1476278995.0,5987.0,439.0,/r/programming/comments/5741xk/your_social_media_fingerprint/,https://robinlinus.github.io/socialmedia-leak/,stanislavb,programming,0.93,False,True,False,False,0.0,1745832732.057851,Tech & Programming,4.0,0.0,4.0,Wednesday,9.0,October,2016.0,False,0.0,0.0,0.0,1.0,neutral,your social media fingerprint,,your social media fingerprint ,"social, medium, fingerprint",2016-10-12 13:29:55,your social media fingerprint ,"['social', 'medium', 'fingerprint']",,,,
f6g64p,"The Computer Scientist Responsible for Cut, Copy, and Paste, Has Passed Away",,1582141498.0,5964.0,529.0,/r/programming/comments/f6g64p/the_computer_scientist_responsible_for_cut_copy/,https://gizmodo.com/larry-tessler-modeless-computing-advocate-has-passed-1841787408,m_hdurina,programming,0.97,False,False,False,False,0.0,1745832734.594525,Tech & Programming,12.0,0.0,12.0,Wednesday,14.0,February,2020.0,False,0.0516,0.16,0.146,0.694,positive,the computer scientist responsible for cut copy and paste has passed away,,the computer scientist responsible for cut copy and paste has passed away ,"computer, scientist, responsible, cut, copy",2020-02-19 19:44:58,the computer scientist responsible for cut copy and paste has passed away ,"['computer', 'scientist', 'responsible', 'cut', 'copy', 'paste', 'passed', 'away']",,,,
7nsh9o,"'Kernel memory leaking' Intel processor design flaw forces Linux, Windows redesign",,1514956399.0,5920.0,1091.0,/r/programming/comments/7nsh9o/kernel_memory_leaking_intel_processor_design_flaw/,https://www.theregister.co.uk/2018/01/02/intel_cpu_design_flaw/,mzaiady,programming,0.96,False,False,False,False,0.0,1745832737.153853,Tech & Programming,11.0,0.0,11.0,Wednesday,0.0,January,2018.0,False,0.0,0.0,0.0,1.0,neutral,kernel memory leaking intel processor design flaw forces linux windows redesign,,kernel memory leaking intel processor design flaw forces linux windows redesign ,"kernel, memory, leaking, intel, processor",2018-01-03 05:13:19,kernel memory leaking intel processor design flaw forces linux windows redesign ,"['kernel', 'memory', 'leaking', 'intel', 'processor', 'design', 'flaw', 'force', 'linux', 'window', 'redesign']",,,,
9x096s,"An insane answer to ""What's the largest amount of bad code you have ever seen work?""",,1542203383.0,5894.0,1156.0,/r/programming/comments/9x096s/an_insane_answer_to_whats_the_largest_amount_of/,https://news.ycombinator.com/item?id=18442941,jailbird,programming,0.96,False,False,False,False,0.0,1745832740.241434,Tech & Programming,16.0,0.0,16.0,Wednesday,8.0,November,2018.0,False,-0.7351,0.0,0.307,0.693,negative,an insane answer to whats the largest amount of bad code you have ever seen work,,an insane answer to whats the largest amount of bad code you have ever seen work ,"insane, answer, whats, largest, amount",2018-11-14 13:49:43,an insane answer to whats the largest amount of bad code you have ever seen work ,"['insane', 'answer', 'whats', 'largest', 'amount', 'bad', 'code', 'ever', 'seen', 'work']",,,,
blewqm,"Microsoft unveils Windows Terminal, a new command line app for Windows",,1557163063.0,5847.0,1079.0,/r/programming/comments/blewqm/microsoft_unveils_windows_terminal_a_new_command/,https://www.theverge.com/2019/5/6/18527870/microsoft-windows-terminal-command-line-tool,zbhoy,programming,0.96,False,False,False,False,0.0,1745832743.566943,Tech & Programming,11.0,0.0,11.0,Monday,13.0,May,2019.0,False,0.0,0.0,0.0,1.0,neutral,microsoft unveils windows terminal a new command line app for windows,,microsoft unveils windows terminal a new command line app for windows ,"window, microsoft, unveils, terminal, new",2019-05-06 17:17:43,microsoft unveils windows terminal a new command line app for windows ,"['microsoft', 'unveils', 'window', 'terminal', 'new', 'command', 'line', 'app', 'window']",,,,
kpq460,Linus Torvalds rails against 80-character-lines as a de facto programming standard,,1609699324.0,5837.0,1146.0,/r/programming/comments/kpq460/linus_torvalds_rails_against_80characterlines_as/,https://www.theregister.com/2020/06/01/linux_5_7/,whackri,programming,0.94,False,False,False,False,0.0,1745832746.368763,Tech & Programming,11.0,0.0,11.0,Sunday,13.0,January,2021.0,True,0.0,0.0,0.0,1.0,neutral,linus torvalds rails against characterlines as a de facto programming standard,,linus torvalds rails against characterlines as a de facto programming standard ,"linus, torvalds, rail, characterlines, facto",2021-01-03 18:42:04,linus torvalds rails against characterlines as a de facto programming standard ,"['linus', 'torvalds', 'rail', 'characterlines', 'facto', 'programming', 'standard']",,,,
a3kk7u,Australian programmers could be fired by their companies for implementing government backdoors,,1544070848.0,5763.0,777.0,/r/programming/comments/a3kk7u/australian_programmers_could_be_fired_by_their/,https://tendaily.com.au/amp/news/australia/a181206zli/if-encryption-laws-go-through-australia-may-lose-apple-20181206,drizzcool,programming,0.98,False,False,False,False,1.0,1745832750.120121,Tech & Programming,12.0,0.0,12.0,Wednesday,23.0,December,2018.0,False,-0.5574,0.0,0.247,0.753,negative,australian programmers could be fired by their companies for implementing government backdoors,,australian programmers could be fired by their companies for implementing government backdoors ,"australian, programmer, could, fired, company",2018-12-06 04:34:08,australian programmers could be fired by their companies for implementing government backdoors ,"['australian', 'programmer', 'could', 'fired', 'company', 'implementing', 'government', 'backdoor']",,,,
1215iel,"Gordon Moore, Intel Co-Founder, Dies at 94",,1679706337.0,5752.0,191.0,/r/programming/comments/1215iel/gordon_moore_intel_cofounder_dies_at_94/,https://www.intel.com/content/www/us/en/newsroom/news/gordon-moore-obituary.html?cid=iosm&source=twitter&campid=newsroom_posts&content=100003944017761&icid=always-on&linkId=100000196297982,unixbhaskar,programming,0.97,False,False,False,False,0.0,1745832753.424316,Tech & Programming,7.0,0.0,6.0,Friday,21.0,March,2023.0,False,0.0,0.0,0.0,1.0,neutral,gordon moore intel cofounder dies at,,gordon moore intel cofounder dies at ,"gordon, moore, intel, cofounder, dy",2023-03-25 01:05:37,gordon moore intel cofounder dies at ,"['gordon', 'moore', 'intel', 'cofounder', 'dy']",,,,
val2x3,"A discussion between a Google engineer and their conversational AI model helped cause the engineer to believe the AI is becoming sentient, kick up an internal shitstorm, and get suspended from his job.",,1655037414.0,5734.0,1135.0,/r/programming/comments/val2x3/a_discussion_between_a_google_engineer_and_their/,https://twitter.com/tomgara/status/1535716256585859073?s=20&t=XQUrNh1QxFKwxiaxM7ox2A,Kusthi,programming,0.9,False,False,False,False,0.0,1745832754.808629,Tech & Programming,33.0,0.0,33.0,Sunday,8.0,June,2022.0,True,-0.4767,0.0,0.094,0.906,negative,a discussion between a google engineer and their conversational ai model helped cause the engineer to believe the ai is becoming sentient kick up an internal shitstorm and get suspended from his job,,a discussion between a google engineer and their conversational ai model helped cause the engineer to believe the ai is becoming sentient kick up an internal shitstorm and get suspended from his job ,"engineer, discussion, google, conversational, model",2022-06-12 12:36:54,a discussion between a google engineer and their conversational ai model helped cause the engineer to believe the ai is becoming sentient kick up an internal shitstorm and get suspended from his job ,"['discussion', 'google', 'engineer', 'conversational', 'model', 'helped', 'cause', 'engineer', 'believe', 'becoming', 'sentient', 'kick', 'internal', 'shitstorm', 'get', 'suspended', 'job']",,,,
bumy8i,Chrome to limit full ad blocking extensions to enterprise users,,1559178427.0,5703.0,1260.0,/r/programming/comments/bumy8i/chrome_to_limit_full_ad_blocking_extensions_to/,https://9to5google.com/2019/05/29/chrome-ad-blocking-enterprise-manifest-v3/,zial,programming,0.97,False,False,False,False,2.0,1745832757.665501,Tech & Programming,10.0,0.0,10.0,Wednesday,21.0,May,2019.0,False,-0.3818,0.0,0.224,0.776,negative,chrome to limit full ad blocking extensions to enterprise users,,chrome to limit full ad blocking extensions to enterprise users ,"chrome, limit, full, blocking, extension",2019-05-30 01:07:07,chrome to limit full ad blocking extensions to enterprise users ,"['chrome', 'limit', 'full', 'blocking', 'extension', 'enterprise', 'user']",,,,
86j3ps,"I made a simple iOS app that fetches the crowd-sourced data from OpenStreetMaps, and shows toilets within walking distance. 🚽",,1521793808.0,5683.0,219.0,/r/programming/comments/86j3ps/i_made_a_simple_ios_app_that_fetches_the/,https://github.com/samkhawse/OpenStreetAmenities,flyingsnake,programming,0.94,False,False,False,False,0.0,1745832760.657187,Tech & Programming,20.0,0.0,19.0,Friday,4.0,March,2018.0,False,0.0,0.0,0.0,1.0,neutral,i made a simple ios app that fetches the crowdsourced data from openstreetmaps and shows toilets within walking distance,,i made a simple ios app that fetches the crowdsourced data from openstreetmaps and shows toilets within walking distance ,"made, simple, io, app, fetch",2018-03-23 08:30:08,i made a simple ios app that fetches the crowdsourced data from openstreetmaps and shows toilets within walking distance ,"['made', 'simple', 'io', 'app', 'fetch', 'crowdsourced', 'data', 'openstreetmaps', 'show', 'toilet', 'within', 'walking', 'distance']",,,,
4wfasw,IBM's Watson makes a correct diagnosis after woman's condition stumps experts.,,1470477414.0,5649.0,436.0,/r/programming/comments/4wfasw/ibms_watson_makes_a_correct_diagnosis_after/,http://siliconangle.com/blog/2016/08/05/watson-correctly-diagnoses-woman-after-doctors-were-stumped/,damian2000,programming,0.92,False,False,False,False,0.0,1745832761.879822,Tech & Programming,11.0,0.0,11.0,Saturday,5.0,August,2016.0,True,0.0,0.0,0.0,1.0,neutral,ibms watson makes a correct diagnosis after womans condition stumps experts,,ibms watson makes a correct diagnosis after womans condition stumps experts ,"ibms, watson, make, correct, diagnosis",2016-08-06 09:56:54,ibms watson makes a correct diagnosis after womans condition stumps experts ,"['ibms', 'watson', 'make', 'correct', 'diagnosis', 'woman', 'condition', 'stump', 'expert']",,,,
pdjnfr,Software development topics I've changed my mind on after 6 years in the industry,,1630190871.0,5616.0,1965.0,/r/programming/comments/pdjnfr/software_development_topics_ive_changed_my_mind/,https://chriskiehl.com/article/thoughts-after-6-years,whackri,programming,0.95,False,False,False,False,0.0,1745832764.858105,Tech & Programming,14.0,0.0,13.0,Saturday,18.0,August,2021.0,True,0.0,0.0,0.0,1.0,neutral,software development topics ive changed my mind on after years in the industry,,software development topics ive changed my mind on after years in the industry ,"software, development, topic, ive, changed",2021-08-28 22:47:51,software development topics ive changed my mind on after years in the industry ,"['software', 'development', 'topic', 'ive', 'changed', 'mind', 'year', 'industry']",,,,
8qt1iv,"“Let’s broadcast the key over Bluetooth. Oh, and use HTTP, no one will know” — the creators of the Tapplock, probably.",,1528901705.0,5615.0,430.0,/r/programming/comments/8qt1iv/lets_broadcast_the_key_over_bluetooth_oh_and_use/,https://www.pentestpartners.com/security-blog/totally-pwning-the-tapplock-smart-lock/,DecidedlyAmbigous,programming,0.96,False,False,False,False,0.0,1745832768.493105,Tech & Programming,21.0,0.0,19.0,Wednesday,10.0,June,2018.0,False,-0.296,0.0,0.109,0.891,negative,lets broadcast the key over bluetooth oh and use no one will know the creators of the tapplock probably,,lets broadcast the key over bluetooth oh and use no one will know the creators of the tapplock probably ,"let, broadcast, key, bluetooth, use",2018-06-13 14:55:05,lets broadcast the key over bluetooth oh and use no one will know the creators of the tapplock probably ,"['let', 'broadcast', 'key', 'bluetooth', 'use', 'one', 'know', 'creator', 'tapplock', 'probably']",,,,
6u3alr,TIL The original Pokemon games were written in assembly.,,1502901725.0,5586.0,823.0,/r/programming/comments/6u3alr/til_the_original_pokemon_games_were_written_in/,https://youtu.be/9l8V_eQ6wGQ?t=5m11s,,programming,0.9,False,False,False,False,0.0,1745832770.972104,Tech & Programming,9.0,0.0,9.0,Wednesday,12.0,August,2017.0,False,0.3182,0.223,0.0,0.777,positive,til the original pokemon games were written in assembly,,til the original pokemon games were written in assembly ,"til, original, pokemon, game, written",2017-08-16 16:42:05,til the original pokemon games were written in assembly ,"['til', 'original', 'pokemon', 'game', 'written', 'assembly']",,,,
3cw14a,"The unsung saviors of Healthcare.gov: a small startup, working in hotel rooms, who rewrote the site for less than *1/50th* the cost of the initial gov't contractors",,1436596079.0,5581.0,612.0,/r/programming/comments/3cw14a/the_unsung_saviors_of_healthcaregov_a_small/,http://www.theatlantic.com/technology/archive/2015/07/the-secret-startup-saved-healthcare-gov-the-worst-website-in-america/397784/,jtredact,programming,0.94,False,False,False,False,0.0,1745832773.9707,Tech & Programming,27.0,0.0,27.0,Saturday,2.0,July,2015.0,True,0.0,0.0,0.0,1.0,neutral,the unsung saviors of healthcaregov a small startup working in hotel rooms who rewrote the site for less than th the cost of the initial govt contractors,,the unsung saviors of healthcaregov a small startup working in hotel rooms who rewrote the site for less than th the cost of the initial govt contractors ,"unsung, savior, healthcaregov, small, startup",2015-07-11 06:27:59,the unsung saviors of healthcaregov a small startup working in hotel rooms who rewrote the site for less than th the cost of the initial govt contractors ,"['unsung', 'savior', 'healthcaregov', 'small', 'startup', 'working', 'hotel', 'room', 'rewrote', 'site', 'less', 'cost', 'initial', 'govt', 'contractor']",,,,
110mj6p,Open source code with swearing in the comments is statistically better than that without,,1676226395.0,5562.0,345.0,/r/programming/comments/110mj6p/open_source_code_with_swearing_in_the_comments_is/,https://www.jwz.org/blog/2023/02/code-with-swearing-is-better-code/,humdaaks_lament,programming,0.95,False,False,False,False,0.0,1745832776.403148,Tech & Programming,14.0,0.0,14.0,Sunday,13.0,February,2023.0,True,0.2263,0.172,0.118,0.71,positive,open source code with swearing in the comments is statistically better than that without,,open source code with swearing in the comments is statistically better than that without ,"open, source, code, swearing, comment",2023-02-12 18:26:35,open source code with swearing in the comments is statistically better than that without ,"['open', 'source', 'code', 'swearing', 'comment', 'statistically', 'better', 'without']",,,,
jv7kls,YouTube-dl's repository has been restored.,,1605536679.0,5566.0,517.0,/r/programming/comments/jv7kls/youtubedls_repository_has_been_restored/,https://github.com/ytdl-org/youtube-dl,jiayounokim,programming,0.98,False,False,False,False,0.0,1745832777.983406,Tech & Programming,5.0,0.0,5.0,Monday,9.0,November,2020.0,False,0.34,0.375,0.0,0.625,positive,youtubedls repository has been restored,,youtubedls repository has been restored ,"youtubedls, repository, restored",2020-11-16 14:24:39,youtubedls repository has been restored ,"['youtubedls', 'repository', 'restored']",,,,
4clk26,Microsoft is bringing the Bash shell to Windows 10,,1459355721.0,5529.0,1160.0,/r/programming/comments/4clk26/microsoft_is_bringing_the_bash_shell_to_windows_10/,http://techcrunch.com/2016/03/30/be-very-afraid-hell-has-frozen-over-bash-is-coming-to-windows-10/,,programming,0.93,False,False,False,False,0.0,1745832780.601071,Tech & Programming,9.0,0.0,8.0,Wednesday,12.0,March,2016.0,False,0.0,0.0,0.0,1.0,neutral,microsoft is bringing the bash shell to windows,,microsoft is bringing the bash shell to windows ,"microsoft, bringing, bash, shell, window",2016-03-30 16:35:21,microsoft is bringing the bash shell to windows ,"['microsoft', 'bringing', 'bash', 'shell', 'window']",,,,
mwnz3s,Googling is one of the most important skills for every developer. Here are some tips to Google efficiently!,,1619154791.0,5499.0,400.0,/r/programming/comments/mwnz3s/googling_is_one_of_the_most_important_skills_for/,https://markodenic.com/use-google-like-a-pro/,mdenic,programming,0.95,False,False,False,False,1.0,1745832783.899469,Tech & Programming,18.0,0.0,18.0,Friday,1.0,April,2021.0,False,0.5849,0.231,0.0,0.769,positive,googling is one of the most important skills for every developer here are some tips to google efficiently,,googling is one of the most important skills for every developer here are some tips to google efficiently ,"googling, one, important, skill, every",2021-04-23 05:13:11,googling is one of the most important skills for every developer here are some tips to google efficiently ,"['googling', 'one', 'important', 'skill', 'every', 'developer', 'tip', 'google', 'efficiently']",,,,
8cn9ef,7-Zip exposes a bug in Windows's large memory pages. Causes data corruption and crashes in Windows and other programs.,,1523882981.0,5482.0,369.0,/r/programming/comments/8cn9ef/7zip_exposes_a_bug_in_windowss_large_memory_pages/,https://sourceforge.net/p/sevenzip/discussion/45797/thread/e730c709/,tambry,programming,0.96,False,False,False,False,0.0,1745832785.880836,Tech & Programming,19.0,0.0,19.0,Monday,8.0,April,2018.0,False,-0.128,0.0,0.081,0.919,negative,zip exposes a bug in windowss large memory pages causes data corruption and crashes in windows and other programs,,zip exposes a bug in windowss large memory pages causes data corruption and crashes in windows and other programs ,"zip, expose, bug, windows, large",2018-04-16 12:49:41,zip exposes a bug in windowss large memory pages causes data corruption and crashes in windows and other programs ,"['zip', 'expose', 'bug', 'windows', 'large', 'memory', 'page', 'cause', 'data', 'corruption', 'crash', 'window', 'program']",,,,
115j300,"Voice.AI Stole Open Source Code, Banned The Developer Who Informed Them About This, From Discord Server",,1676737678.0,5473.0,423.0,/r/programming/comments/115j300/voiceai_stole_open_source_code_banned_the/,https://www.theinsaneapp.com/2023/02/voice-ai-stole-open-source-code.html,vadhavaniyafaijan,programming,0.96,False,False,False,False,0.0,1745832788.321322,Tech & Programming,16.0,0.0,16.0,Saturday,11.0,February,2023.0,True,-0.6908,0.0,0.289,0.711,negative,voiceai stole open source code banned the developer who informed them about this from discord server,,voiceai stole open source code banned the developer who informed them about this from discord server ,"voiceai, stole, open, source, code",2023-02-18 16:27:58,voiceai stole open source code banned the developer who informed them about this from discord server ,"['voiceai', 'stole', 'open', 'source', 'code', 'banned', 'developer', 'informed', 'discord', 'server']",,,,
601zmg,"Google reduces JPEG file size by 35%, new algorithm uses research on human psychovisual system",,1489804818.0,5450.0,422.0,/r/programming/comments/601zmg/google_reduces_jpeg_file_size_by_35_new_algorithm/,https://arstechnica.co.uk/information-technology/2017/03/google-jpeg-guetzli-encoder-file-size/,xorandor,programming,0.94,False,False,False,False,0.0,1745832790.639167,Tech & Programming,15.0,0.0,14.0,Friday,22.0,March,2017.0,False,0.0,0.0,0.0,1.0,neutral,google reduces jpeg file size by new algorithm uses research on human psychovisual system,,google reduces jpeg file size by new algorithm uses research on human psychovisual system ,"google, reduces, jpeg, file, size",2017-03-18 02:40:18,google reduces jpeg file size by new algorithm uses research on human psychovisual system ,"['google', 'reduces', 'jpeg', 'file', 'size', 'new', 'algorithm', 'us', 'research', 'human', 'psychovisual', 'system']",,,,
7hhbdq,European Parliament has approved budget for VLC bug bounty program,,1512394256.0,5446.0,372.0,/r/programming/comments/7hhbdq/european_parliament_has_approved_budget_for_vlc/,https://hackerone.com/vlc,twiggy99999,programming,0.95,False,False,False,False,0.0,1745832793.764126,Tech & Programming,10.0,0.0,10.0,Monday,8.0,December,2017.0,False,0.4215,0.237,0.0,0.763,positive,european parliament has approved budget for vlc bug bounty program,,european parliament has approved budget for vlc bug bounty program ,"european, parliament, approved, budget, vlc",2017-12-04 13:30:56,european parliament has approved budget for vlc bug bounty program ,"['european', 'parliament', 'approved', 'budget', 'vlc', 'bug', 'bounty', 'program']",,,,
ygnhs0,"RIP: Kathleen Booth, the inventor of assembly language",,1667059647.0,5437.0,292.0,/r/programming/comments/ygnhs0/rip_kathleen_booth_the_inventor_of_assembly/,https://www.theregister.com/2022/10/29/kathleen_booth_obit/,videoj,programming,0.98,False,False,False,False,0.0,1745832796.37578,Tech & Programming,8.0,0.0,8.0,Saturday,12.0,October,2022.0,True,0.0,0.0,0.0,1.0,neutral,rip kathleen booth the inventor of assembly language,,rip kathleen booth the inventor of assembly language ,"rip, kathleen, booth, inventor, assembly",2022-10-29 16:07:27,rip kathleen booth the inventor of assembly language ,"['rip', 'kathleen', 'booth', 'inventor', 'assembly', 'language']",,,,
99e0yw,"Proton, a modified version of WINE for playing Windows games on Linux... Officially by Valve.",,1534949819.0,5404.0,670.0,/r/programming/comments/99e0yw/proton_a_modified_version_of_wine_for_playing/,https://github.com/ValveSoftware/Proton,FlashDaggerX,programming,0.97,False,False,False,False,0.0,1745832798.21574,Tech & Programming,15.0,0.0,15.0,Wednesday,10.0,August,2018.0,False,0.2023,0.122,0.0,0.878,positive,proton a modified version of wine for playing windows games on linux officially by valve,,proton a modified version of wine for playing windows games on linux officially by valve ,"proton, modified, version, wine, playing",2018-08-22 14:56:59,proton a modified version of wine for playing windows games on linux officially by valve ,"['proton', 'modified', 'version', 'wine', 'playing', 'window', 'game', 'linux', 'officially', 'valve']",,,,
wvwukw,"Unix legend Brian Kernighan, who owes us nothing, keeps fixing foundational AWK code | Co-creator of core Unix utility ""awk"" (he's the ""k"" in ""awk""), now 80, just needs to run a few more tests on adding Unicode support",,1661280915.0,5388.0,414.0,/r/programming/comments/wvwukw/unix_legend_brian_kernighan_who_owes_us_nothing/,https://arstechnica.com/gadgets/2022/08/unix-legend-who-owes-us-nothing-keeps-fixing-foundational-awk-code/,mepper,programming,0.97,False,False,False,False,0.0,1745832801.144745,Tech & Programming,39.0,0.0,37.0,Tuesday,14.0,August,2022.0,False,0.4019,0.074,0.0,0.926,positive,unix legend brian kernighan who owes us nothing keeps fixing foundational awk code cocreator of core unix utility awk hes the k in awk now just needs to run a few more tests on adding unicode support,,unix legend brian kernighan who owes us nothing keeps fixing foundational awk code cocreator of core unix utility awk hes the k in awk now just needs to run a few more tests on adding unicode support ,"awk, unix, legend, brian, kernighan",2022-08-23 18:55:15,unix legend brian kernighan who owes us nothing keeps fixing foundational awk code cocreator of core unix utility awk hes the k in awk now just needs to run a few more tests on adding unicode support ,"['unix', 'legend', 'brian', 'kernighan', 'owes', 'nothing', 'keep', 'fixing', 'foundational', 'awk', 'code', 'cocreator', 'core', 'unix', 'utility', 'awk', 'he', 'awk', 'need', 'run', 'test', 'adding', 'unicode', 'support']",,,,
81exa9,"I built Hackterms, an Urban Dictionary for coding terms, to help connect the dots while learning - and we're picking up steam! Want to help?",,1520003871.0,5365.0,236.0,/r/programming/comments/81exa9/i_built_hackterms_an_urban_dictionary_for_coding/,https://insights.dice.com/2018/03/01/hackterms-urban-dictionary-tech-pros/,maxverse,programming,0.93,False,False,False,False,0.0,1745832803.683743,Tech & Programming,25.0,0.0,24.0,Friday,10.0,March,2018.0,False,0.6908,0.251,0.0,0.749,positive,i built hackterms an urban dictionary for coding terms to help connect the dots while learning and were picking up steam want to help,,i built hackterms an urban dictionary for coding terms to help connect the dots while learning and were picking up steam want to help ,"help, built, hackterms, urban, dictionary",2018-03-02 15:17:51,i built hackterms an urban dictionary for coding terms to help connect the dots while learning and were picking up steam want to help ,"['built', 'hackterms', 'urban', 'dictionary', 'coding', 'term', 'help', 'connect', 'dot', 'learning', 'picking', 'steam', 'want', 'help']",,,,
aoqawt,Sony Pictures Has Open-Sourced Software Used to Make ‘Spider-Man: Into the Spider-Verse’,,1549698347.0,5353.0,152.0,/r/programming/comments/aoqawt/sony_pictures_has_opensourced_software_used_to/,https://variety.com/2019/digital/news/sony-pictures-opencolorio-academy-software-foundation-1203133108/,epic_within,programming,0.97,False,False,False,False,0.0,1745832805.028262,Tech & Programming,12.0,0.0,12.0,Saturday,2.0,February,2019.0,True,0.0,0.0,0.0,1.0,neutral,sony pictures has opensourced software used to make spiderman into the spiderverse,,sony pictures has opensourced software used to make spiderman into the spiderverse ,"sony, picture, opensourced, software, used",2019-02-09 07:45:47,sony pictures has opensourced software used to make spiderman into the spiderverse ,"['sony', 'picture', 'opensourced', 'software', 'used', 'make', 'spiderman', 'spiderverse']",,,,
6geyut,Apple will remove ability for developers to only give an Always On location setting in their apps,,1497097346.0,5333.0,493.0,/r/programming/comments/6geyut/apple_will_remove_ability_for_developers_to_only/,https://m.rover.io/wwdc-2017-update-significant-updates-to-location-permissions-coming-with-ios-11-41f96001f87f,GoinFerARipEh,programming,0.95,False,False,False,False,0.0,1745832806.184838,Tech & Programming,17.0,0.0,17.0,Saturday,8.0,June,2017.0,True,0.3182,0.126,0.0,0.874,positive,apple will remove ability for developers to only give an always on location setting in their apps,,apple will remove ability for developers to only give an always on location setting in their apps ,"apple, remove, ability, developer, give",2017-06-10 12:22:26,apple will remove ability for developers to only give an always on location setting in their apps ,"['apple', 'remove', 'ability', 'developer', 'give', 'always', 'location', 'setting', 'apps']",,,,
whnwxq,"Vim, infamous for its steep learning curve, often leaves new users confused where to start. Today is the 10th anniversary of the infamous ""How do I exit Vim"" question, which made news when it first hit 1 million views.",,1659791198.0,5286.0,625.0,/r/programming/comments/whnwxq/vim_infamous_for_its_steep_learning_curve_often/,https://stackoverflow.com/questions/11828270/how-do-i-exit-vim,Skenvy,programming,0.96,False,False,False,False,0.0,1745832809.045461,Tech & Programming,39.0,0.0,38.0,Saturday,9.0,August,2022.0,True,-0.3182,0.0,0.06,0.94,negative,vim infamous for its steep learning curve often leaves new users confused where to start today is the th anniversary of the infamous how do i exit vim question which made news when it first hit million views,,vim infamous for its steep learning curve often leaves new users confused where to start today is the th anniversary of the infamous how do i exit vim question which made news when it first hit million views ,"vim, infamous, steep, learning, curve",2022-08-06 13:06:38,vim infamous for its steep learning curve often leaves new users confused where to start today is the th anniversary of the infamous how do i exit vim question which made news when it first hit million views ,"['vim', 'infamous', 'steep', 'learning', 'curve', 'often', 'leaf', 'new', 'user', 'confused', 'start', 'today', 'anniversary', 'infamous', 'exit', 'vim', 'question', 'made', 'news', 'first', 'hit', 'million', 'view']",,,,
7sec31,80's kids started programming at an earlier age than today's millennials,,1516713767.0,5281.0,1336.0,/r/programming/comments/7sec31/80s_kids_started_programming_at_an_earlier_age/,https://thenextweb.com/dd/2018/01/23/report-80s-kids-started-programming-at-an-earlier-age-than-todays-millennials/,jakdak,programming,0.88,False,False,False,False,0.0,1745832811.481438,Tech & Programming,11.0,0.0,11.0,Tuesday,8.0,January,2018.0,False,0.0,0.0,0.0,1.0,neutral,s kids started programming at an earlier age than todays millennials,,s kids started programming at an earlier age than todays millennials ,"kid, started, programming, earlier, age",2018-01-23 13:22:47,s kids started programming at an earlier age than todays millennials ,"['kid', 'started', 'programming', 'earlier', 'age', 'today', 'millennials']",,,,
5dz1t5,Programmers are having a huge discussion about the unethical and illegal things they’ve been asked to do,,1479663054.0,5280.0,1211.0,/r/programming/comments/5dz1t5/programmers_are_having_a_huge_discussion_about/,http://www.businessinsider.com/programmers-confess-unethical-illegal-tasks-asked-of-them-2016-11,gocolts12,programming,0.93,False,False,False,False,0.0,1745832814.298533,Tech & Programming,17.0,0.0,17.0,Sunday,12.0,November,2016.0,True,-0.6808,0.104,0.311,0.586,negative,programmers are having a huge discussion about the unethical and illegal things theyve been asked to do,,programmers are having a huge discussion about the unethical and illegal things theyve been asked to do ,"programmer, huge, discussion, unethical, illegal",2016-11-20 17:30:54,programmers are having a huge discussion about the unethical and illegal things theyve been asked to do ,"['programmer', 'huge', 'discussion', 'unethical', 'illegal', 'thing', 'theyve', 'asked']",,,,
iwlxud,"Kernighan's Law - Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.",,1600634944.0,5264.0,412.0,/r/programming/comments/iwlxud/kernighans_law_debugging_is_twice_as_hard_as/,https://github.com/dwmkerr/hacker-laws#kernighans-law,whackri,programming,0.96,False,False,False,False,0.0,1745832816.88092,Tech & Programming,36.0,0.0,35.0,Sunday,16.0,September,2020.0,True,0.1635,0.085,0.094,0.821,positive,kernighans law debugging is twice as hard as writing the code in the first place therefore if you write the code as cleverly as possible you are by definition not smart enough to debug it,,kernighans law debugging is twice as hard as writing the code in the first place therefore if you write the code as cleverly as possible you are by definition not smart enough to debug it ,"code, kernighans, law, debugging, twice",2020-09-20 20:49:04,kernighans law debugging is twice as hard as writing the code in the first place therefore if you write the code as cleverly as possible you are by definition not smart enough to debug it ,"['kernighans', 'law', 'debugging', 'twice', 'hard', 'writing', 'code', 'first', 'place', 'therefore', 'write', 'code', 'cleverly', 'possible', 'definition', 'smart', 'enough', 'debug']",,,,
73nnv1,Clever way of skirting game code quality tests from the 90s (x-post /r/Games),,1506885592.0,5147.0,321.0,/r/programming/comments/73nnv1/clever_way_of_skirting_game_code_quality_tests/,https://youtu.be/i9bkKw32dGw,redditchao999,programming,0.94,False,False,False,False,0.0,1745832819.579175,Tech & Programming,13.0,0.0,13.0,Sunday,15.0,October,2017.0,True,0.4588,0.214,0.0,0.786,positive,clever way of skirting game code quality tests from the s xpost rgames,,clever way of skirting game code quality tests from the s xpost rgames ,"clever, way, skirting, game, code",2017-10-01 19:19:52,clever way of skirting game code quality tests from the s xpost rgames ,"['clever', 'way', 'skirting', 'game', 'code', 'quality', 'test', 'xpost', 'rgames']",,,,
hmern8,Guy makes a game engine that works in a very different way,,1594064104.0,5151.0,266.0,/r/programming/comments/hmern8/guy_makes_a_game_engine_that_works_in_a_very/,https://www.youtube.com/watch?v=kEB11PQ9Eo8,weegee22,programming,0.93,False,False,False,False,0.0,1745832821.429937,Tech & Programming,12.0,0.0,12.0,Monday,15.0,July,2020.0,False,0.0,0.0,0.0,1.0,neutral,guy makes a game engine that works in a very different way,,guy makes a game engine that works in a very different way ,"guy, make, game, engine, work",2020-07-06 19:35:04,guy makes a game engine that works in a very different way ,"['guy', 'make', 'game', 'engine', 'work', 'different', 'way']",,,,
m5yo7y,"Rockstar thanks GTA Online player who fixed poor load times, official update coming",,1615861037.0,5109.0,446.0,/r/programming/comments/m5yo7y/rockstar_thanks_gta_online_player_who_fixed_poor/,https://www.pcgamer.com/rockstar-thanks-gta-online-player-who-fixed-poor-load-times-official-update-coming/,IceBlast24,programming,0.98,False,False,False,False,0.0,1745832823.036001,Tech & Programming,13.0,0.0,13.0,Monday,22.0,March,2021.0,False,-0.0516,0.171,0.182,0.647,negative,rockstar thanks gta online player who fixed poor load times official update coming,,rockstar thanks gta online player who fixed poor load times official update coming ,"rockstar, thanks, gta, online, player",2021-03-16 02:17:17,rockstar thanks gta online player who fixed poor load times official update coming ,"['rockstar', 'thanks', 'gta', 'online', 'player', 'fixed', 'poor', 'load', 'time', 'official', 'update', 'coming']",,,,
7kjpuc,Mining Bitcoin with pencil and paper: 0.67 hashes per day,,1513581551.0,5111.0,229.0,/r/programming/comments/7kjpuc/mining_bitcoin_with_pencil_and_paper_067_hashes/,http://www.righto.com/2014/09/mining-bitcoin-with-pencil-and-paper.html,aliweb,programming,0.93,False,False,False,False,0.0,1745832825.590636,Tech & Programming,10.0,0.0,9.0,Monday,2.0,December,2017.0,False,0.0,0.0,0.0,1.0,neutral,mining bitcoin with pencil and paper hashes per day,,mining bitcoin with pencil and paper hashes per day ,"mining, bitcoin, pencil, paper, hash",2017-12-18 07:19:11,mining bitcoin with pencil and paper hashes per day ,"['mining', 'bitcoin', 'pencil', 'paper', 'hash', 'per', 'day']",,,,
v45rb6,I spent a year building a desktop environment that runs in the browser,,1654281081.0,5103.0,427.0,/r/programming/comments/v45rb6/i_spent_a_year_building_a_desktop_environment/,https://puter.com/,mitousa,programming,0.97,False,False,False,False,0.0,1745832827.207041,Tech & Programming,13.0,0.0,13.0,Friday,14.0,June,2022.0,False,0.0,0.0,0.0,1.0,neutral,i spent a year building a desktop environment that runs in the browser,,i spent a year building a desktop environment that runs in the browser ,"spent, year, building, desktop, environment",2022-06-03 18:31:21,i spent a year building a desktop environment that runs in the browser ,"['spent', 'year', 'building', 'desktop', 'environment', 'run', 'browser']",,,,
84607r,Let's Encrypt releases support for wildcard certificates,,1520962291.0,5086.0,353.0,/r/programming/comments/84607r/lets_encrypt_releases_support_for_wildcard/,https://community.letsencrypt.org/t/acme-v2-and-wildcard-certificate-support-is-live/55579,Ajedi32,programming,0.96,False,False,False,False,0.0,1745832829.784503,Tech & Programming,7.0,0.0,7.0,Tuesday,13.0,March,2018.0,False,0.4019,0.31,0.0,0.69,positive,lets encrypt releases support for wildcard certificates,,lets encrypt releases support for wildcard certificates ,"let, encrypt, release, support, wildcard",2018-03-13 17:31:31,lets encrypt releases support for wildcard certificates ,"['let', 'encrypt', 'release', 'support', 'wildcard', 'certificate']",,,,
2xone3,Unreal Engine 4 available for free,,1425315789.0,5057.0,555.0,/r/programming/comments/2xone3/unreal_engine_4_available_for_free/,https://www.unrealengine.com/blog/ue4-is-free,johang88,programming,0.94,False,False,False,False,0.0,1745832832.143935,Tech & Programming,6.0,0.0,5.0,Monday,12.0,March,2015.0,False,0.5106,0.452,0.0,0.548,positive,unreal engine available for free,,unreal engine available for free ,"unreal, engine, available, free",2015-03-02 17:03:09,unreal engine available for free ,"['unreal', 'engine', 'available', 'free']",,,,
7uosax,Tractor Hacking: The Farmers Breaking Big Tech's Repair Monopoly,,1517544999.0,5045.0,396.0,/r/programming/comments/7uosax/tractor_hacking_the_farmers_breaking_big_techs/,https://www.youtube.com/watch?v=F8JCh0owT4w,sivscripts,programming,0.95,False,False,False,False,0.0,1745832835.164241,Tech & Programming,9.0,0.0,9.0,Thursday,23.0,February,2018.0,False,0.0,0.0,0.0,1.0,neutral,tractor hacking the farmers breaking big techs repair monopoly,,tractor hacking the farmers breaking big techs repair monopoly ,"tractor, hacking, farmer, breaking, big",2018-02-02 04:16:39,tractor hacking the farmers breaking big techs repair monopoly ,"['tractor', 'hacking', 'farmer', 'breaking', 'big', 'tech', 'repair', 'monopoly']",,,,
j06gd7,"Found these comments by a developer inside the Windows Media Player source code leaked with the WinXP files yesterday, sort of hilarious",,1601128589.0,5011.0,397.0,/r/programming/comments/j06gd7/found_these_comments_by_a_developer_inside_the/,https://pastebin.com/PTLeWhc2,theusualguy512,programming,0.98,False,False,False,False,1.0,1745832837.068928,Tech & Programming,22.0,0.0,22.0,Saturday,9.0,September,2020.0,True,0.0276,0.102,0.097,0.801,neutral,found these comments by a developer inside the windows media player source code leaked with the winxp files yesterday sort of hilarious,,found these comments by a developer inside the windows media player source code leaked with the winxp files yesterday sort of hilarious ,"found, comment, developer, inside, window",2020-09-26 13:56:29,found these comments by a developer inside the windows media player source code leaked with the winxp files yesterday sort of hilarious ,"['found', 'comment', 'developer', 'inside', 'window', 'medium', 'player', 'source', 'code', 'leaked', 'winxp', 'file', 'yesterday', 'sort', 'hilarious']",,,,
80whkc,Why I Quit Google to Work for Myself,,1519828723.0,4985.0,948.0,/r/programming/comments/80whkc/why_i_quit_google_to_work_for_myself/,https://mtlynch.io/why-i-quit-google/,mtlynch,programming,0.93,False,False,False,False,0.0,1745832838.951234,Tech & Programming,8.0,0.0,8.0,Wednesday,9.0,February,2018.0,False,0.0,0.0,0.0,1.0,neutral,why i quit google to work for myself,,why i quit google to work for myself ,"quit, google, work",2018-02-28 14:38:43,why i quit google to work for myself ,"['quit', 'google', 'work']",,,,
119yovz,Reverse Engineering a mysterious UDP stream in my hotel,,1677161588.0,4971.0,302.0,/r/programming/comments/119yovz/reverse_engineering_a_mysterious_udp_stream_in_my/,https://www.gkbrk.com/2016/05/hotel-music/,Witty-Play9499,programming,0.95,False,False,False,False,1.0,1745832844.098526,Tech & Programming,9.0,0.0,9.0,Thursday,9.0,February,2023.0,False,0.0,0.0,0.0,1.0,neutral,reverse engineering a mysterious udp stream in my hotel,,reverse engineering a mysterious udp stream in my hotel ,"reverse, engineering, mysterious, udp, stream",2023-02-23 14:13:08,reverse engineering a mysterious udp stream in my hotel ,"['reverse', 'engineering', 'mysterious', 'udp', 'stream', 'hotel']",,,,
hfi3vz,A bug with a surprisingly cool side effect,,1593071396.0,4958.0,253.0,/r/programming/comments/hfi3vz/a_bug_with_a_surprisingly_cool_side_effect/,https://youtu.be/us1IqknNYmw,PezzzasWork,programming,0.97,False,False,False,False,3.0,1745832846.254879,Tech & Programming,8.0,0.0,8.0,Thursday,3.0,June,2020.0,False,0.5423,0.529,0.0,0.471,positive,a bug with a surprisingly cool side effect,,a bug with a surprisingly cool side effect ,"bug, surprisingly, cool, side, effect",2020-06-25 07:49:56,a bug with a surprisingly cool side effect ,"['bug', 'surprisingly', 'cool', 'side', 'effect']",,,,
m37lt7,7-Zip developer releases the first official Linux version,,1615516766.0,4943.0,380.0,/r/programming/comments/m37lt7/7zip_developer_releases_the_first_official_linux/,https://www.bleepingcomputer.com/news/software/7-zip-developer-releases-the-first-official-linux-version/,RobertVandenberg,programming,0.98,False,False,False,False,0.0,1745832847.55243,Tech & Programming,8.0,0.0,8.0,Thursday,21.0,March,2021.0,False,0.0,0.0,0.0,1.0,neutral,zip developer releases the first official linux version,,zip developer releases the first official linux version ,"zip, developer, release, first, official",2021-03-12 02:39:26,zip developer releases the first official linux version ,"['zip', 'developer', 'release', 'first', 'official', 'linux', 'version']",,,,
5vq9h8,SHAttered: SHA-1 broken in practice.,,1487855087.0,4933.0,661.0,/r/programming/comments/5vq9h8/shattered_sha1_broken_in_practice/,https://shattered.io/,Serialk,programming,0.94,False,False,False,False,0.0,1745832850.330868,Tech & Programming,5.0,0.0,5.0,Thursday,8.0,February,2017.0,False,-0.7351,0.0,0.674,0.326,negative,shattered sha broken in practice,,shattered sha broken in practice ,"shattered, sha, broken, practice",2017-02-23 13:04:47,shattered sha broken in practice ,"['shattered', 'sha', 'broken', 'practice']",,,,
13bg9zi,Spacetraders is an online multiplayer game based entirely on APIs. You have to build your own management and UI on your own with any programming language.,,1683527457.0,4940.0,311.0,/r/programming/comments/13bg9zi/spacetraders_is_an_online_multiplayer_game_based/,https://spacetraders.io/,theKovah,programming,0.96,False,False,False,False,0.0,1745832853.247397,Tech & Programming,26.0,0.0,26.0,Monday,2.0,May,2023.0,False,0.0,0.0,0.0,1.0,neutral,spacetraders is an online multiplayer game based entirely on apis you have to build your own management and ui on your own with any programming language,,spacetraders is an online multiplayer game based entirely on apis you have to build your own management and ui on your own with any programming language ,"spacetraders, online, multiplayer, game, based",2023-05-08 06:30:57,spacetraders is an online multiplayer game based entirely on apis you have to build your own management and ui on your own with any programming language ,"['spacetraders', 'online', 'multiplayer', 'game', 'based', 'entirely', 'apis', 'build', 'management', 'programming', 'language']",,,,
5q3va6,Chrome 56 Will Aggressively Throttle Background Tabs,,1485359100.0,4923.0,523.0,/r/programming/comments/5q3va6/chrome_56_will_aggressively_throttle_background/,http://blog.strml.net/2017/01/chrome-56-now-aggressively-throttles.html,sumdudeinhisundrware,programming,0.94,False,False,False,False,0.0,1745832855.218602,Tech & Programming,7.0,0.0,6.0,Wednesday,10.0,January,2017.0,False,-0.3182,0.0,0.315,0.685,negative,chrome will aggressively throttle background tabs,,chrome will aggressively throttle background tabs ,"chrome, aggressively, throttle, background, tab",2017-01-25 15:45:00,chrome will aggressively throttle background tabs ,"['chrome', 'aggressively', 'throttle', 'background', 'tab']",,,,
362doj,A website coding itself live,,1431701503.0,4903.0,422.0,/r/programming/comments/362doj/a_website_coding_itself_live/,http://strml.net,t3cm3n,programming,0.93,False,False,False,False,0.0,1745832858.095895,Tech & Programming,5.0,0.0,5.0,Friday,10.0,May,2015.0,False,0.0,0.0,0.0,1.0,neutral,a website coding itself live,,a website coding itself live ,"website, coding, live",2015-05-15 14:51:43,a website coding itself live ,"['website', 'coding', 'live']",,,,
gwijha,"I created the first 64-bit computer in minecraft, along with an assembly-ide to program it",,1591281080.0,4892.0,256.0,/r/programming/comments/gwijha/i_created_the_first_64bit_computer_in_minecraft/,https://www.youtube.com/watch?v=A_EStNvK2MQ,rockfarmor,programming,0.95,False,False,False,False,2.0,1745832860.12036,Tech & Programming,15.0,0.0,15.0,Thursday,10.0,June,2020.0,False,0.25,0.133,0.0,0.867,positive,i created the first bit computer in minecraft along with an assemblyide to program it,,i created the first bit computer in minecraft along with an assemblyide to program it ,"created, first, bit, computer, minecraft",2020-06-04 14:31:20,i created the first bit computer in minecraft along with an assemblyide to program it ,"['created', 'first', 'bit', 'computer', 'minecraft', 'along', 'assemblyide', 'program']",,,,
6g7iyz,"Why every user agent string start with ""Mozilla""",,1497003212.0,4872.0,589.0,/r/programming/comments/6g7iyz/why_every_user_agent_string_start_with_mozilla/,http://webaim.org/blog/user-agent-string-history/,m4nz,programming,0.93,False,False,False,False,0.0,1745832861.858995,Tech & Programming,8.0,0.0,8.0,Friday,6.0,June,2017.0,False,0.0,0.0,0.0,1.0,neutral,why every user agent string start with mozilla,,why every user agent string start with mozilla ,"every, user, agent, string, start",2017-06-09 10:13:32,why every user agent string start with mozilla ,"['every', 'user', 'agent', 'string', 'start', 'mozilla']",,,,
68kpzj,Six programming paradigms that will change how you think about coding,,1493625393.0,4866.0,388.0,/r/programming/comments/68kpzj/six_programming_paradigms_that_will_change_how/,http://www.ybrikman.com/writing/2014/04/09/six-programming-paradigms-that-will/,,programming,0.89,False,False,False,False,0.0,1745832865.181682,Tech & Programming,11.0,0.0,11.0,Monday,3.0,May,2017.0,False,0.0,0.0,0.0,1.0,neutral,six programming paradigms that will change how you think about coding,,six programming paradigms that will change how you think about coding ,"six, programming, paradigm, change, think",2017-05-01 07:56:33,six programming paradigms that will change how you think about coding ,"['six', 'programming', 'paradigm', 'change', 'think', 'coding']",,,,
nwfx4l,Bad managers are a huge problem in tech and developers can only compensate so much,,1623302879.0,4836.0,595.0,/r/programming/comments/nwfx4l/bad_managers_are_a_huge_problem_in_tech_and/,https://iism.org/article/developers-can-t-fix-bad-management-57,adroit-panda,programming,0.97,False,False,False,False,0.0,1745832867.780314,Tech & Programming,15.0,0.0,15.0,Thursday,1.0,June,2021.0,False,-0.5994,0.118,0.318,0.564,negative,bad managers are a huge problem in tech and developers can only compensate so much,,bad managers are a huge problem in tech and developers can only compensate so much ,"bad, manager, huge, problem, tech",2021-06-10 05:27:59,bad managers are a huge problem in tech and developers can only compensate so much ,"['bad', 'manager', 'huge', 'problem', 'tech', 'developer', 'compensate', 'much']",,,,
9rdfqz,190 universities just launched 600 free online courses. Here’s the full list.,,1540495621.0,4816.0,153.0,/r/programming/comments/9rdfqz/190_universities_just_launched_600_free_online/,https://qz.com/1437623/600-free-online-courses-you-can-take-from-universities-worldwide/,jailbird,programming,0.97,False,False,False,False,0.0,1745832871.089802,Tech & Programming,12.0,0.0,10.0,Thursday,15.0,October,2018.0,False,0.5859,0.375,0.0,0.625,positive,universities just launched free online courses heres the full list,,universities just launched free online courses heres the full list ,"university, launched, free, online, course",2018-10-25 19:27:01,universities just launched free online courses heres the full list ,"['university', 'launched', 'free', 'online', 'course', 'here', 'full', 'list']",,,,
9fzlbm,'Impostor syndrome' affects almost 58% of tech professionals,,1536995248.0,4796.0,886.0,/r/programming/comments/9fzlbm/impostor_syndrome_affects_almost_58_of_tech/,https://jaxenter.com/impostor-syndrome-survey-149402.html,pidoid,programming,0.95,False,False,False,False,0.0,1745832872.110975,Tech & Programming,8.0,0.0,7.0,Saturday,3.0,September,2018.0,True,0.0,0.0,0.0,1.0,neutral,impostor syndrome affects almost of tech professionals,,impostor syndrome affects almost of tech professionals ,"impostor, syndrome, affect, almost, tech",2018-09-15 07:07:28,impostor syndrome affects almost of tech professionals ,"['impostor', 'syndrome', 'affect', 'almost', 'tech', 'professional']",,,,
edij12,"The modern web is becoming an unusable, user-hostile wasteland",,1576887857.0,4778.0,771.0,/r/programming/comments/edij12/the_modern_web_is_becoming_an_unusable/,https://omarabid.com/the-modern-web,omarous,programming,0.96,False,False,False,False,1.0,1745832874.724778,Tech & Programming,9.0,0.0,9.0,Friday,19.0,December,2019.0,False,0.0,0.0,0.0,1.0,neutral,the modern web is becoming an unusable userhostile wasteland,,the modern web is becoming an unusable userhostile wasteland ,"modern, web, becoming, unusable, userhostile",2019-12-21 00:24:17,the modern web is becoming an unusable userhostile wasteland ,"['modern', 'web', 'becoming', 'unusable', 'userhostile', 'wasteland']",,,,
ayoo0q,Researchers asked 43 freelance developers to code the user registration for a web app and assessed how they implemented password storage. 26 devs initially chose to leave passwords as plaintext.,,1552039989.0,4761.0,639.0,/r/programming/comments/ayoo0q/researchers_asked_43_freelance_developers_to_code/,http://net.cs.uni-bonn.de/fileadmin/user_upload/naiakshi/Naiakshina_Password_Study.pdf,drsatan1,programming,0.94,False,False,False,False,0.0,1745832877.752524,Tech & Programming,30.0,0.0,28.0,Friday,5.0,March,2019.0,False,0.25,0.077,0.042,0.88,positive,researchers asked freelance developers to code the user registration for a web app and assessed how they implemented password storage devs initially chose to leave passwords as plaintext,,researchers asked freelance developers to code the user registration for a web app and assessed how they implemented password storage devs initially chose to leave passwords as plaintext ,"password, researcher, asked, freelance, developer",2019-03-08 10:13:09,researchers asked freelance developers to code the user registration for a web app and assessed how they implemented password storage devs initially chose to leave passwords as plaintext ,"['researcher', 'asked', 'freelance', 'developer', 'code', 'user', 'registration', 'web', 'app', 'assessed', 'implemented', 'password', 'storage', 'devs', 'initially', 'chose', 'leave', 'password', 'plaintext']",,,,
o3cap6,State of the Windows: How many layers of UI inconsistencies are in Windows 10?,,1624095499.0,4745.0,848.0,/r/programming/comments/o3cap6/state_of_the_windows_how_many_layers_of_ui/,https://ntdotdev.wordpress.com/2021/02/06/state-of-the-windows-how-many-layers-of-ui-inconsistencies-are-in-windows-10/,bartturner,programming,0.96,False,False,False,False,0.0,1745832880.373233,Tech & Programming,14.0,0.0,13.0,Saturday,5.0,June,2021.0,True,0.0,0.0,0.0,1.0,neutral,state of the windows how many layers of ui inconsistencies are in windows,,state of the windows how many layers of ui inconsistencies are in windows ,"window, state, many, layer, inconsistency",2021-06-19 09:38:19,state of the windows how many layers of ui inconsistencies are in windows ,"['state', 'window', 'many', 'layer', 'inconsistency', 'window']",,,,
6lvux0,Being good at programming competitions correlates negatively with being good on the job,,1499454126.0,4742.0,471.0,/r/programming/comments/6lvux0/being_good_at_programming_competitions_correlates/,http://www.catonmat.net/blog/programming-competitions-work-performance/,CodePlea,programming,0.91,False,False,False,False,0.0,1745832882.895717,Tech & Programming,13.0,0.0,13.0,Friday,15.0,July,2017.0,False,0.7003,0.345,0.0,0.655,positive,being good at programming competitions correlates negatively with being good on the job,,being good at programming competitions correlates negatively with being good on the job ,"good, programming, competition, correlate, negatively",2017-07-07 19:02:06,being good at programming competitions correlates negatively with being good on the job ,"['good', 'programming', 'competition', 'correlate', 'negatively', 'good', 'job']",,,,
ybmnzb,"TOMORROW is UNIX timestamp 1,666,666,666, peak halloween",,1666543921.0,4730.0,170.0,/r/programming/comments/ybmnzb/tomorrow_is_unix_timestamp_1666666666_peak/,https://time.is/unix,stefaanthedude,programming,0.96,False,False,False,False,0.0,1745832885.71756,Tech & Programming,7.0,0.0,6.0,Sunday,12.0,October,2022.0,True,0.0,0.0,0.0,1.0,neutral,tomorrow is unix timestamp peak halloween,,tomorrow is unix timestamp peak halloween ,"tomorrow, unix, timestamp, peak, halloween",2022-10-23 16:52:01,tomorrow is unix timestamp peak halloween ,"['tomorrow', 'unix', 'timestamp', 'peak', 'halloween']",,,,
68472f,"Reckon you've seen some stupid security things? Here, hold my beer... | Troy Hunt",,1493401476.0,4660.0,471.0,/r/programming/comments/68472f/reckon_youve_seen_some_stupid_security_things/,https://www.troyhunt.com/reckon-youve-seen-some-stupid-security-things-here-hold-my-beer/,QuirkySpiceBush,programming,0.93,False,False,False,False,0.0,1745832886.607595,Tech & Programming,14.0,0.0,13.0,Friday,13.0,April,2017.0,False,-0.25,0.143,0.202,0.655,negative,reckon youve seen some stupid security things here hold my beer troy hunt,,reckon youve seen some stupid security things here hold my beer troy hunt ,"reckon, youve, seen, stupid, security",2017-04-28 17:44:36,reckon youve seen some stupid security things here hold my beer troy hunt ,"['reckon', 'youve', 'seen', 'stupid', 'security', 'thing', 'hold', 'beer', 'troy', 'hunt']",,,,
16y1ie7,Return to Office Is Bullshit And Everyone Knows It,,1696264881.0,4653.0,1036.0,/r/programming/comments/16y1ie7/return_to_office_is_bullshit_and_everyone_knows_it/,https://soatok.blog/2023/10/02/return-to-office-is-bullshit-and-everyone-knows-it/,JohnDoe_John,programming,0.89,False,False,False,False,0.0,1745832889.790543,Tech & Programming,9.0,0.0,9.0,Monday,12.0,October,2023.0,False,-0.5859,0.0,0.322,0.678,negative,return to office is bullshit and everyone knows it,,return to office is bullshit and everyone knows it ,"return, office, bullshit, everyone, know",2023-10-02 16:41:21,return to office is bullshit and everyone knows it ,"['return', 'office', 'bullshit', 'everyone', 'know']",,,,
gmqv6n,Microsoft announces the Windows Package Manager Preview,,1589902582.0,4652.0,640.0,/r/programming/comments/gmqv6n/microsoft_announces_the_windows_package_manager/,https://devblogs.microsoft.com/commandline/windows-package-manager-preview/?WT.mc_id=ITOPSTALK-reddit-abartolo,Wireless_Life,programming,0.95,False,False,False,False,1.0,1745832892.690568,Tech & Programming,7.0,0.0,7.0,Tuesday,11.0,May,2020.0,False,0.0,0.0,0.0,1.0,neutral,microsoft announces the windows package manager preview,,microsoft announces the windows package manager preview ,"microsoft, announces, window, package, manager",2020-05-19 15:36:22,microsoft announces the windows package manager preview ,"['microsoft', 'announces', 'window', 'package', 'manager', 'preview']",,,,
9tqxd9,Python is becoming the world’s most popular coding language,,1541215046.0,4645.0,1306.0,/r/programming/comments/9tqxd9/python_is_becoming_the_worlds_most_popular_coding/,https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language,monica_b1998,programming,0.91,False,False,False,False,0.0,1745832895.372933,Tech & Programming,9.0,0.0,9.0,Friday,23.0,November,2018.0,False,0.4754,0.279,0.0,0.721,positive,python is becoming the worlds most popular coding language,,python is becoming the worlds most popular coding language ,"python, becoming, world, popular, coding",2018-11-03 03:17:26,python is becoming the worlds most popular coding language ,"['python', 'becoming', 'world', 'popular', 'coding', 'language']",,,,
11kj91n,How Discord Stores Trillions of Messages,,1678148402.0,4641.0,477.0,/r/programming/comments/11kj91n/how_discord_stores_trillions_of_messages/,https://discord.com/blog/how-discord-stores-trillions-of-messages,Pink401k,programming,0.98,False,False,False,False,0.0,1745832898.228618,Tech & Programming,6.0,0.0,6.0,Monday,19.0,March,2023.0,False,-0.4019,0.0,0.351,0.649,negative,how discord stores trillions of messages,,how discord stores trillions of messages ,"discord, store, trillion, message",2023-03-07 00:20:02,how discord stores trillions of messages ,"['discord', 'store', 'trillion', 'message']",,,,
t7xvjo,"No, ""Open Source"" does not mean ""Includes Free Support""",,1646570146.0,4644.0,840.0,/r/programming/comments/t7xvjo/no_open_source_does_not_mean_includes_free_support/,https://raccoon.onyxbits.de/blog/bugreport-free-support/,pocketbandit,programming,0.95,False,False,False,False,1.0,1745832900.970363,Tech & Programming,9.0,0.0,9.0,Sunday,7.0,March,2022.0,True,-0.2964,0.199,0.36,0.441,negative,no open source does not mean includes free support,,no open source does not mean includes free support ,"open, source, mean, includes, free",2022-03-06 12:35:46,no open source does not mean includes free support ,"['open', 'source', 'mean', 'includes', 'free', 'support']",,,,
m7pz7r,I wrote an algorithm to draw portraits from thread... thought you might enjoy!,,1616071397.0,4617.0,131.0,/r/programming/comments/m7pz7r/i_wrote_an_algorithm_to_draw_portraits_from/,https://youtu.be/UsbBSttaJos,L-aerodyne,programming,0.95,False,False,False,False,0.0,1745832903.756742,Tech & Programming,13.0,0.0,13.0,Thursday,8.0,March,2021.0,False,0.4939,0.225,0.0,0.775,positive,i wrote an algorithm to draw portraits from thread thought you might enjoy,,i wrote an algorithm to draw portraits from thread thought you might enjoy ,"wrote, algorithm, draw, portrait, thread",2021-03-18 12:43:17,i wrote an algorithm to draw portraits from thread thought you might enjoy ,"['wrote', 'algorithm', 'draw', 'portrait', 'thread', 'thought', 'might', 'enjoy']",,,,
5d56fo,The code I’m still ashamed of,,1479245143.0,4616.0,800.0,/r/programming/comments/5d56fo/the_code_im_still_ashamed_of/,https://medium.freecodecamp.com/the-code-im-still-ashamed-of-e4c021dff55e#.vmbgbtgin,devmastery,programming,0.92,False,False,False,False,0.0,1745832904.532582,Tech & Programming,6.0,0.0,6.0,Tuesday,16.0,November,2016.0,False,-0.4767,0.0,0.383,0.617,negative,the code im still ashamed of,,the code im still ashamed of ,"code, still, ashamed",2016-11-15 21:25:43,the code im still ashamed of ,"['code', 'still', 'ashamed']",,,,
8hylve,Windows Notepad will soon have Unix line ending support,,1525800948.0,4616.0,689.0,/r/programming/comments/8hylve/windows_notepad_will_soon_have_unix_line_ending/,https://blogs.msdn.microsoft.com/commandline/2018/05/08/extended-eol-in-notepad/,Twistedsc,programming,0.96,False,False,False,False,0.0,1745832907.377202,Tech & Programming,9.0,0.0,9.0,Tuesday,13.0,May,2018.0,False,0.4019,0.252,0.0,0.748,positive,windows notepad will soon have unix line ending support,,windows notepad will soon have unix line ending support ,"window, notepad, soon, unix, line",2018-05-08 17:35:48,windows notepad will soon have unix line ending support ,"['window', 'notepad', 'soon', 'unix', 'line', 'ending', 'support']",,,,
32uh79,An actual guy named “Null” messes up people's databases,,1429216166.0,4597.0,627.0,/r/programming/comments/32uh79/an_actual_guy_named_null_messes_up_peoples/,http://stackoverflow.com/questions/4456438/how-do-i-correctly-pass-the-string-null-an-employees-proper-surname-to-a-so,henk53,programming,0.95,False,False,False,False,0.0,1745832910.449069,Tech & Programming,9.0,0.0,9.0,Thursday,16.0,April,2015.0,False,0.0,0.0,0.0,1.0,neutral,an actual guy named null messes up peoples databases,,an actual guy named null messes up peoples databases ,"actual, guy, named, null, mess",2015-04-16 20:29:26,an actual guy named null messes up peoples databases ,"['actual', 'guy', 'named', 'null', 'mess', 'people', 'database']",,,,
gh1dj9,[Project] From books to presentations in 10s with AR + ML,,1589116794.0,8431.0,196.0,/r/MachineLearning/comments/gh1dj9/project_from_books_to_presentations_in_10s_with/,https://v.redd.it/v492uoheuxx41,cyrildiagne,MachineLearning,0.99,False,False,False,False,0.0,1745833707.443361,Tech & Programming,11.0,0.0,10.0,Sunday,9.0,May,2020.0,True,0.0,0.0,0.0,1.0,neutral,project from books to presentations in s with ar ml,,project from books to presentations in s with ar ml ,"project, book, presentation",2020-05-10 13:19:54,project from books to presentations in s with ar ml ,"['project', 'book', 'presentation']",,,,
kuc6tz,[D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition,,1610274636.0,6288.0,135.0,/r/MachineLearning/comments/kuc6tz/d_a_demo_from_1993_of_32yearold_yann_lecun/,https://v.redd.it/25nxi9ojfha61,TheInsaneApp,MachineLearning,0.98,False,False,False,False,0.0,1745833708.377816,Tech & Programming,19.0,0.0,18.0,Sunday,5.0,January,2021.0,True,0.0,0.0,0.0,1.0,neutral,d a demo from of yearold yann lecun showing off the worlds first convolutional network for text recognition,,d a demo from of yearold yann lecun showing off the worlds first convolutional network for text recognition ,"demo, yearold, yann, lecun, showing",2021-01-10 10:30:36,d a demo from of yearold yann lecun showing off the worlds first convolutional network for text recognition ,"['demo', 'yearold', 'yann', 'lecun', 'showing', 'world', 'first', 'convolutional', 'network', 'text', 'recognition']",,,,
g7nfvb,[R] First Order Motion Model applied to animate paintings,,1587788843.0,4874.0,109.0,/r/MachineLearning/comments/g7nfvb/r_first_order_motion_model_applied_to_animate/,https://v.redd.it/rlmmjm1q5wu41,programmerChilli,MachineLearning,0.97,False,False,False,False,0.0,1745833709.16789,Tech & Programming,9.0,0.0,9.0,Saturday,0.0,April,2020.0,True,0.0,0.0,0.0,1.0,neutral,r first order motion model applied to animate paintings,,r first order motion model applied to animate paintings ,"first, order, motion, model, applied",2020-04-25 04:27:23,r first order motion model applied to animate paintings ,"['first', 'order', 'motion', 'model', 'applied', 'animate', 'painting']",,,,
ohxnts,[D] This AI reveals how much time politicians stare at their phone at work,,1625977139.0,4875.0,236.0,/r/MachineLearning/comments/ohxnts/d_this_ai_reveals_how_much_time_politicians_stare/,https://i.redd.it/34sgziebfia71.jpg,TheInsaneApp,MachineLearning,0.96,False,False,False,False,0.0,1745833709.739706,Tech & Programming,14.0,0.0,14.0,Sunday,0.0,July,2021.0,True,0.0,0.0,0.0,1.0,neutral,d this ai reveals how much time politicians stare at their phone at work,,d this ai reveals how much time politicians stare at their phone at work ,"reveals, much, time, politician, stare",2021-07-11 04:18:59,d this ai reveals how much time politicians stare at their phone at work ,"['reveals', 'much', 'time', 'politician', 'stare', 'phone', 'work']",,,,
lui92h,[N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this,,1614525148.0,4802.0,230.0,/r/MachineLearning/comments/lui92h/n_ai_can_turn_old_photos_into_moving_images_link/,https://v.redd.it/ikd5gjlbi8k61,TheInsaneApp,MachineLearning,0.97,False,False,False,False,0.0,1745833710.788719,Tech & Programming,26.0,0.0,24.0,Sunday,10.0,February,2021.0,True,0.3612,0.102,0.0,0.898,positive,n ai can turn old photos into moving images link is given in the comments you can also turn your old photo like this,,n ai can turn old photos into moving images link is given in the comments you can also turn your old photo like this ,"turn, old, photo, moving, image",2021-02-28 15:12:28,n ai can turn old photos into moving images link is given in the comments you can also turn your old photo like this ,"['turn', 'old', 'photo', 'moving', 'image', 'link', 'given', 'comment', 'also', 'turn', 'old', 'photo', 'like']",,,,
n2f0ld,[D] Types of Machine Learning Papers,,1619861540.0,4670.0,214.0,/r/MachineLearning/comments/n2f0ld/d_types_of_machine_learning_papers/,https://i.redd.it/6z2s8h1iahw61.jpg,TheInsaneApp,MachineLearning,0.98,False,False,False,False,0.0,1745833712.115435,Tech & Programming,6.0,0.0,6.0,Saturday,5.0,May,2021.0,True,0.0,0.0,0.0,1.0,neutral,d types of machine learning papers,,d types of machine learning papers ,"type, machine, learning, paper",2021-05-01 09:32:20,d types of machine learning papers ,"['type', 'machine', 'learning', 'paper']",,,,
vkxsf2,I made a robot that punishes me if it detects that if I am procrastinating on my assignments [P],,1656222743.0,4216.0,166.0,/r/MachineLearning/comments/vkxsf2/i_made_a_robot_that_punishes_me_if_it_detects/,https://v.redd.it/dihfgy0umw791,_ayushp_,MachineLearning,0.95,False,False,False,False,0.0,1745833713.538981,Tech & Programming,19.0,0.0,19.0,Sunday,1.0,June,2022.0,True,-0.4767,0.0,0.181,0.819,negative,i made a robot that punishes me if it detects that if i am procrastinating on my assignments p,,i made a robot that punishes me if it detects that if i am procrastinating on my assignments p ,"made, robot, punishes, detects, procrastinating",2022-06-26 05:52:23,i made a robot that punishes me if it detects that if i am procrastinating on my assignments p ,"['made', 'robot', 'punishes', 'detects', 'procrastinating', 'assignment']",,,,
hiv3vf,[D] The machine learning community has a toxicity problem,"It is omnipresent!

**First** of all, the peer-review process is *broken*. Every fourth NeurIPS submission is put on arXiv. There are DeepMind researchers publicly going after reviewers who are criticizing their ICLR submission. On top of that, papers by well-known institutes that were put on arXiv are accepted at top conferences, despite the reviewers agreeing on rejection. In contrast, vice versa, some papers with a majority of accepts are overruled by the AC. (I don't want to call any names, just have a look the openreview page of this year's ICRL).

**Secondly,** there is a *reproducibility crisis*. Tuning hyperparameters on the test set seem to be the standard practice nowadays. Papers that do not beat the current state-of-the-art method have a zero chance of getting accepted at a good conference. As a result, hyperparameters get tuned and subtle tricks implemented to observe a gain in performance where there isn't any.

**Thirdly,** there is a *worshiping* problem. Every paper with a Stanford or DeepMind affiliation gets praised like a breakthrough. For instance, BERT has seven times more citations than ULMfit. The Google affiliation gives so much credibility and visibility to a paper. At every ICML conference, there is a crowd of people in front of every DeepMind poster, regardless of the content of the work. The same story happened with the Zoom meetings at the virtual ICLR 2020. Moreover, NeurIPS 2020 had twice as many submissions as ICML, even though both are top-tier ML conferences. Why? Why is the name ""neural"" praised so much? Next, Bengio, Hinton, and LeCun are truly deep learning pioneers but calling them the ""godfathers"" of AI is insane. It has reached the level of a cult.

**Fourthly**, the way Yann LeCun talked about biases and fairness topics was insensitive. However, the *toxicity* and backlash that he received are beyond any reasonable quantity. Getting rid of LeCun and silencing people won't solve any issue.

**Fifthly**, machine learning, and computer science in general, have a huge *diversity problem*. At our CS faculty, only 30% of undergrads and 15% of the professors are women. Going on parental leave during a PhD or post-doc usually means the end of an academic career. However, this lack of diversity is often abused as an excuse to shield certain people from any form of criticism.  Reducing every negative comment in a scientific discussion to race and gender creates a toxic environment. People are becoming afraid to engage in fear of being called a racist or sexist, which in turn reinforces the diversity problem.

**Sixthly**, moral and ethics are set *arbitrarily*. The U.S. domestic politics dominate every discussion. At this very moment, thousands of Uyghurs are put into concentration camps based on computer vision algorithms invented by this community, and nobody seems even remotely to care. Adding a ""broader impact"" section at the end of every people will not make this stop. There are huge shitstorms because a researcher wasn't mentioned in an article. Meanwhile, the 1-billion+ people continent of Africa is virtually excluded from any meaningful ML discussion (besides a few Indaba workshops).

**Seventhly**, there is a cut-throat publish-or-perish *mentality*. If you don't publish 5+ NeurIPS/ICML papers per year, you are a looser. Research groups have become so large that the PI does not even know the name of every PhD student anymore. Certain people submit 50+ papers per year to NeurIPS. The sole purpose of writing a paper has become to having one more NeurIPS paper in your CV. Quality is secondary; passing the peer-preview stage has become the primary objective.

**Finally**, discussions have become *disrespectful*. Schmidhuber calls Hinton a thief, Gebru calls LeCun a white supremacist, Anandkumar calls Marcus a sexist, everybody is under attack, but nothing is improved.

Albert Einstein was opposing the theory of [quantum mechanics](https://en.wikipedia.org/wiki/Albert_Einstein#Einstein's_objections_to_quantum_mechanics). Can we please stop demonizing those who do not share our exact views. We are allowed to disagree without going for the jugular. 

The moment we start silencing people because of their opinion is the moment scientific and societal progress dies. 

Best intentions, Yusuf",1593547579.0,3902.0,568.0,/r/MachineLearning/comments/hiv3vf/d_the_machine_learning_community_has_a_toxicity/,https://www.reddit.com/r/MachineLearning/comments/hiv3vf/d_the_machine_learning_community_has_a_toxicity/,yusuf-bengio,MachineLearning,0.95,True,False,False,False,2.0,1745833714.343199,Tech & Programming,9.0,671.0,674.0,Tuesday,16.0,June,2020.0,False,-0.9835,0.09,0.123,0.787,negative,d the machine learning community has a toxicity problem,it is omnipresent first of all the peerreview process is broken every fourth neurips submission is put on arxiv there are deepmind researchers publicly going after reviewers who are criticizing their iclr submission on top of that papers by wellknown institutes that were put on arxiv are accepted at top conferences despite the reviewers agreeing on rejection in contrast vice versa some papers with a majority of accepts are overruled by the ac i dont want to call any names just have a look the openreview page of this years icrl secondly there is a reproducibility crisis tuning hyperparameters on the test set seem to be the standard practice nowadays papers that do not beat the current stateoftheart method have a zero chance of getting accepted at a good conference as a result hyperparameters get tuned and subtle tricks implemented to observe a gain in performance where there isnt any thirdly there is a worshiping problem every paper with a stanford or deepmind affiliation gets praised like a breakthrough for instance bert has seven times more citations than ulmfit the google affiliation gives so much credibility and visibility to a paper at every icml conference there is a crowd of people in front of every deepmind poster regardless of the content of the work the same story happened with the zoom meetings at the virtual iclr moreover neurips had twice as many submissions as icml even though both are toptier ml conferences why why is the name neural praised so much next bengio hinton and lecun are truly deep learning pioneers but calling them the godfathers of ai is insane it has reached the level of a cult fourthly the way yann lecun talked about biases and fairness topics was insensitive however the toxicity and backlash that he received are beyond any reasonable quantity getting rid of lecun and silencing people wont solve any issue fifthly machine learning and computer science in general have a huge diversity problem at our cs faculty only of undergrads and of the professors are women going on parental leave during a phd or postdoc usually means the end of an academic career however this lack of diversity is often abused as an excuse to shield certain people from any form of criticism reducing every negative comment in a scientific discussion to race and gender creates a toxic environment people are becoming afraid to engage in fear of being called a racist or sexist which in turn reinforces the diversity problem sixthly moral and ethics are set arbitrarily the us domestic politics dominate every discussion at this very moment thousands of uyghurs are put into concentration camps based on computer vision algorithms invented by this community and nobody seems even remotely to care adding a broader impact section at the end of every people will not make this stop there are huge shitstorms because a researcher wasnt mentioned in an article meanwhile the billion people continent of africa is virtually excluded from any meaningful ml discussion besides a few indaba workshops seventhly there is a cutthroat publishorperish mentality if you dont publish neuripsicml papers per year you are a looser research groups have become so large that the pi does not even know the name of every phd student anymore certain people submit papers per year to neurips the sole purpose of writing a paper has become to having one more neurips paper in your cv quality is secondary passing the peerpreview stage has become the primary objective finally discussions have become disrespectful schmidhuber calls hinton a thief gebru calls lecun a white supremacist anandkumar calls marcus a sexist everybody is under attack but nothing is improved albert einstein was opposing the theory of quantum mechanics can we please stop demonizing those who do not share our exact views we are allowed to disagree without going for the jugular the moment we start silencing people because of their opinion is the moment scientific and societal progress dies best intentions yusuf,d the machine learning community has a toxicity problem it is omnipresent first of all the peerreview process is broken every fourth neurips submission is put on arxiv there are deepmind researchers publicly going after reviewers who are criticizing their iclr submission on top of that papers by wellknown institutes that were put on arxiv are accepted at top conferences despite the reviewers agreeing on rejection in contrast vice versa some papers with a majority of accepts are overruled by the ac i dont want to call any names just have a look the openreview page of this years icrl secondly there is a reproducibility crisis tuning hyperparameters on the test set seem to be the standard practice nowadays papers that do not beat the current stateoftheart method have a zero chance of getting accepted at a good conference as a result hyperparameters get tuned and subtle tricks implemented to observe a gain in performance where there isnt any thirdly there is a worshiping problem every paper with a stanford or deepmind affiliation gets praised like a breakthrough for instance bert has seven times more citations than ulmfit the google affiliation gives so much credibility and visibility to a paper at every icml conference there is a crowd of people in front of every deepmind poster regardless of the content of the work the same story happened with the zoom meetings at the virtual iclr moreover neurips had twice as many submissions as icml even though both are toptier ml conferences why why is the name neural praised so much next bengio hinton and lecun are truly deep learning pioneers but calling them the godfathers of ai is insane it has reached the level of a cult fourthly the way yann lecun talked about biases and fairness topics was insensitive however the toxicity and backlash that he received are beyond any reasonable quantity getting rid of lecun and silencing people wont solve any issue fifthly machine learning and computer science in general have a huge diversity problem at our cs faculty only of undergrads and of the professors are women going on parental leave during a phd or postdoc usually means the end of an academic career however this lack of diversity is often abused as an excuse to shield certain people from any form of criticism reducing every negative comment in a scientific discussion to race and gender creates a toxic environment people are becoming afraid to engage in fear of being called a racist or sexist which in turn reinforces the diversity problem sixthly moral and ethics are set arbitrarily the us domestic politics dominate every discussion at this very moment thousands of uyghurs are put into concentration camps based on computer vision algorithms invented by this community and nobody seems even remotely to care adding a broader impact section at the end of every people will not make this stop there are huge shitstorms because a researcher wasnt mentioned in an article meanwhile the billion people continent of africa is virtually excluded from any meaningful ml discussion besides a few indaba workshops seventhly there is a cutthroat publishorperish mentality if you dont publish neuripsicml papers per year you are a looser research groups have become so large that the pi does not even know the name of every phd student anymore certain people submit papers per year to neurips the sole purpose of writing a paper has become to having one more neurips paper in your cv quality is secondary passing the peerpreview stage has become the primary objective finally discussions have become disrespectful schmidhuber calls hinton a thief gebru calls lecun a white supremacist anandkumar calls marcus a sexist everybody is under attack but nothing is improved albert einstein was opposing the theory of quantum mechanics can we please stop demonizing those who do not share our exact views we are allowed to disagree without going for the jugular the moment we start silencing people because of their opinion is the moment scientific and societal progress dies best intentions yusuf,"paper, every, people, problem, neurips",2020-06-30 20:06:19,d the machine learning community has a toxicity problem it is omnipresent first of all the peerreview process is broken every fourth neurips submission is put on arxiv there are deepmind researchers publicly going after reviewers who are criticizing their iclr submission on top of that papers by wellknown institutes that were put on arxiv are accepted at top conferences despite the reviewers agreeing on rejection in contrast vice versa some papers with a majority of accepts are overruled by the ac i dont want to call any names just have a look the openreview page of this years icrl secondly there is a reproducibility crisis tuning hyperparameters on the test set seem to be the standard practice nowadays papers that do not beat the current stateoftheart method have a zero chance of getting accepted at a good conference as a result hyperparameters get tuned and subtle tricks implemented to observe a gain in performance where there isnt any thirdly there is a worshiping problem every paper with a stanford or deepmind affiliation gets praised like a breakthrough for instance bert has seven times more citations than ulmfit the google affiliation gives so much credibility and visibility to a paper at every icml conference there is a crowd of people in front of every deepmind poster regardless of the content of the work the same story happened with the zoom meetings at the virtual iclr moreover neurips had twice as many submissions as icml even though both are toptier ml conferences why why is the name neural praised so much next bengio hinton and lecun are truly deep learning pioneers but calling them the godfathers of ai is insane it has reached the level of a cult fourthly the way yann lecun talked about biases and fairness topics was insensitive however the toxicity and backlash that he received are beyond any reasonable quantity getting rid of lecun and silencing people wont solve any issue fifthly machine learning and computer science in general have a huge diversity problem at our cs faculty only of undergrads and of the professors are women going on parental leave during a phd or postdoc usually means the end of an academic career however this lack of diversity is often abused as an excuse to shield certain people from any form of criticism reducing every negative comment in a scientific discussion to race and gender creates a toxic environment people are becoming afraid to engage in fear of being called a racist or sexist which in turn reinforces the diversity problem sixthly moral and ethics are set arbitrarily the us domestic politics dominate every discussion at this very moment thousands of uyghurs are put into concentration camps based on computer vision algorithms invented by this community and nobody seems even remotely to care adding a broader impact section at the end of every people will not make this stop there are huge shitstorms because a researcher wasnt mentioned in an article meanwhile the billion people continent of africa is virtually excluded from any meaningful ml discussion besides a few indaba workshops seventhly there is a cutthroat publishorperish mentality if you dont publish neuripsicml papers per year you are a looser research groups have become so large that the pi does not even know the name of every phd student anymore certain people submit papers per year to neurips the sole purpose of writing a paper has become to having one more neurips paper in your cv quality is secondary passing the peerpreview stage has become the primary objective finally discussions have become disrespectful schmidhuber calls hinton a thief gebru calls lecun a white supremacist anandkumar calls marcus a sexist everybody is under attack but nothing is improved albert einstein was opposing the theory of quantum mechanics can we please stop demonizing those who do not share our exact views we are allowed to disagree without going for the jugular the moment we start silencing people because of their opinion is the moment scientific and societal progress dies best intentions yusuf,"['machine', 'learning', 'community', 'toxicity', 'problem', 'omnipresent', 'first', 'peerreview', 'process', 'broken', 'every', 'fourth', 'neurips', 'submission', 'put', 'arxiv', 'deepmind', 'researcher', 'publicly', 'going', 'reviewer', 'criticizing', 'iclr', 'submission', 'top', 'paper', 'wellknown', 'institute', 'put', 'arxiv', 'accepted', 'top', 'conference', 'despite', 'reviewer', 'agreeing', 'rejection', 'contrast', 'vice', 'versa', 'paper', 'majority', 'accepts', 'overruled', 'dont', 'want', 'call', 'name', 'look', 'openreview', 'page', 'year', 'icrl', 'secondly', 'reproducibility', 'crisis', 'tuning', 'hyperparameters', 'test', 'set', 'seem', 'standard', 'practice', 'nowadays', 'paper', 'beat', 'current', 'stateoftheart', 'method', 'zero', 'chance', 'getting', 'accepted', 'good', 'conference', 'result', 'hyperparameters', 'get', 'tuned', 'subtle', 'trick', 'implemented', 'observe', 'gain', 'performance', 'isnt', 'thirdly', 'worshiping', 'problem', 'every', 'paper', 'stanford', 'deepmind', 'affiliation', 'get', 'praised', 'like', 'breakthrough', 'instance', 'bert', 'seven', 'time', 'citation', 'ulmfit', 'google', 'affiliation', 'give', 'much', 'credibility', 'visibility', 'paper', 'every', 'icml', 'conference', 'crowd', 'people', 'front', 'every', 'deepmind', 'poster', 'regardless', 'content', 'work', 'story', 'happened', 'zoom', 'meeting', 'virtual', 'iclr', 'moreover', 'neurips', 'twice', 'many', 'submission', 'icml', 'even', 'though', 'toptier', 'conference', 'name', 'neural', 'praised', 'much', 'next', 'bengio', 'hinton', 'lecun', 'truly', 'deep', 'learning', 'pioneer', 'calling', 'godfather', 'insane', 'reached', 'level', 'cult', 'fourthly', 'way', 'yann', 'lecun', 'talked', 'bias', 'fairness', 'topic', 'insensitive', 'however', 'toxicity', 'backlash', 'received', 'beyond', 'reasonable', 'quantity', 'getting', 'rid', 'lecun', 'silencing', 'people', 'wont', 'solve', 'issue', 'fifthly', 'machine', 'learning', 'computer', 'science', 'general', 'huge', 'diversity', 'problem', 'faculty', 'undergrad', 'professor', 'woman', 'going', 'parental', 'leave', 'phd', 'postdoc', 'usually', 'mean', 'end', 'academic', 'career', 'however', 'lack', 'diversity', 'often', 'abused', 'excuse', 'shield', 'certain', 'people', 'form', 'criticism', 'reducing', 'every', 'negative', 'comment', 'scientific', 'discussion', 'race', 'gender', 'creates', 'toxic', 'environment', 'people', 'becoming', 'afraid', 'engage', 'fear', 'called', 'racist', 'sexist', 'turn', 'reinforces', 'diversity', 'problem', 'sixthly', 'moral', 'ethic', 'set', 'arbitrarily', 'domestic', 'politics', 'dominate', 'every', 'discussion', 'moment', 'thousand', 'uyghurs', 'put', 'concentration', 'camp', 'based', 'computer', 'vision', 'algorithm', 'invented', 'community', 'nobody', 'seems', 'even', 'remotely', 'care', 'adding', 'broader', 'impact', 'section', 'end', 'every', 'people', 'make', 'stop', 'huge', 'shitstorms', 'researcher', 'wasnt', 'mentioned', 'article', 'meanwhile', 'billion', 'people', 'continent', 'africa', 'virtually', 'excluded', 'meaningful', 'discussion', 'besides', 'indaba', 'workshop', 'seventhly', 'cutthroat', 'publishorperish', 'mentality', 'dont', 'publish', 'neuripsicml', 'paper', 'per', 'year', 'looser', 'research', 'group', 'become', 'large', 'even', 'know', 'name', 'every', 'phd', 'student', 'anymore', 'certain', 'people', 'submit', 'paper', 'per', 'year', 'neurips', 'sole', 'purpose', 'writing', 'paper', 'become', 'one', 'neurips', 'paper', 'quality', 'secondary', 'passing', 'peerpreview', 'stage', 'become', 'primary', 'objective', 'finally', 'discussion', 'become', 'disrespectful', 'schmidhuber', 'call', 'hinton', 'thief', 'gebru', 'call', 'lecun', 'white', 'supremacist', 'anandkumar', 'call', 'marcus', 'sexist', 'everybody', 'attack', 'nothing', 'improved', 'albert', 'einstein', 'opposing', 'theory', 'quantum', 'mechanic', 'please', 'stop', 'demonizing', 'share', 'exact', 'view', 'allowed', 'disagree', 'without', 'going', 'jugular', 'moment', 'start', 'silencing', 'people', 'opinion', 'moment', 'scientific', 'societal', 'progress', 'dy', 'best', 'intention', 'yusuf']",,,,
m554cq,"[Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with ""Lucid Sonic Dreams""! (Link in Comments)",,1615758395.0,3710.0,174.0,/r/MachineLearning/comments/m554cq/project_new_python_package_sync_gan_art_to_music/,https://v.redd.it/wacguxsnd2n61,mencil47,MachineLearning,0.99,False,False,False,False,0.0,1745833716.583046,Tech & Programming,16.0,0.0,16.0,Sunday,17.0,March,2021.0,True,0.4019,0.153,0.0,0.847,positive,project new python package sync gan art to music with lucid sonic dreams link in comments,,project new python package sync gan art to music with lucid sonic dreams link in comments ,"project, new, python, package, sync",2021-03-14 21:46:35,project new python package sync gan art to music with lucid sonic dreams link in comments ,"['project', 'new', 'python', 'package', 'sync', 'gan', 'art', 'music', 'lucid', 'sonic', 'dream', 'link', 'comment']",,,,
j0oyk6,[P] Using oil portraits and First Order Model to bring the paintings back to life,,1601202717.0,3501.0,111.0,/r/MachineLearning/comments/j0oyk6/p_using_oil_portraits_and_first_order_model_to/,https://v.redd.it/vivz68p44op51,Enguzelharf,MachineLearning,0.98,False,False,False,False,0.0,1745833717.521324,Tech & Programming,15.0,0.0,15.0,Sunday,6.0,September,2020.0,True,0.0,0.0,0.0,1.0,neutral,p using oil portraits and first order model to bring the paintings back to life,,p using oil portraits and first order model to bring the paintings back to life ,"using, oil, portrait, first, order",2020-09-27 10:31:57,p using oil portraits and first order model to bring the paintings back to life ,"['using', 'oil', 'portrait', 'first', 'order', 'model', 'bring', 'painting', 'back', 'life']",,,,
leq2kf,[D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG),,1612716403.0,3428.0,75.0,/r/MachineLearning/comments/leq2kf/d_convolution_neural_network_visualization_made/,https://v.redd.it/tgnm4z2443g61,TheInsaneApp,MachineLearning,0.99,False,False,False,False,0.0,1745833718.123454,Tech & Programming,19.0,0.0,16.0,Sunday,11.0,February,2021.0,True,0.0,0.0,0.0,1.0,neutral,d convolution neural network visualization made with unity d and lots of code source stefsietz ig,,d convolution neural network visualization made with unity d and lots of code source stefsietz ig ,"convolution, neural, network, visualization, made",2021-02-07 16:46:43,d convolution neural network visualization made with unity d and lots of code source stefsietz ig ,"['convolution', 'neural', 'network', 'visualization', 'made', 'unity', 'lot', 'code', 'source', 'stefsietz']",,,,
klbvaw,[P] Doing a clone of Rocket League for AI experiments. Trained an agent to air dribble the ball.,,1609104382.0,3259.0,65.0,/r/MachineLearning/comments/klbvaw/p_doing_a_clone_of_rocket_league_for_ai/,https://v.redd.it/379qv12hrs761,Roboserg,MachineLearning,0.99,False,False,False,False,0.0,1745833719.001247,Tech & Programming,18.0,0.0,18.0,Sunday,16.0,December,2020.0,True,0.0,0.0,0.0,1.0,neutral,p doing a clone of rocket league for ai experiments trained an agent to air dribble the ball,,p doing a clone of rocket league for ai experiments trained an agent to air dribble the ball ,"clone, rocket, league, experiment, trained",2020-12-27 21:26:22,p doing a clone of rocket league for ai experiments trained an agent to air dribble the ball ,"['clone', 'rocket', 'league', 'experiment', 'trained', 'agent', 'air', 'dribble', 'ball']",,,,
ybnnra,[R] Speech-to-speech translation for a real-world unwritten language,,1666546219.0,3076.0,213.0,/r/MachineLearning/comments/ybnnra/r_speechtospeech_translation_for_a_realworld/,https://v.redd.it/g1cwi3ozblv91,Illustrious_Row_9971,MachineLearning,0.93,False,False,False,False,0.0,1745833719.470668,Tech & Programming,8.0,0.0,8.0,Sunday,13.0,October,2022.0,True,0.0,0.0,0.0,1.0,neutral,r speechtospeech translation for a realworld unwritten language,,r speechtospeech translation for a realworld unwritten language ,"speechtospeech, translation, realworld, unwritten, language",2022-10-23 17:30:19,r speechtospeech translation for a realworld unwritten language ,"['speechtospeech', 'translation', 'realworld', 'unwritten', 'language']",,,,
11sboh1,[D] Our community must get serious about opposing OpenAI,"OpenAI was founded for the explicit purpose of democratizing access to AI and acting as a counterbalance to the closed off world of big tech by developing open source tools.

They have abandoned this idea entirely.

Today, with the release of GPT4 and their direct statement that they will not release details of the model creation due to ""safety concerns"" and the competitive environment, they have created a precedent worse than those that existed before they entered the field. We're at risk now of other major players, who previously at least published their work and contributed to open source tools, close themselves off as well.

AI alignment is a serious issue that we definitely have not solved. Its a huge field with a dizzying array of ideas, beliefs and approaches. We're talking about trying to capture the interests and goals of all humanity, after all. In this space, the one approach that is horrifying (and the one that OpenAI was LITERALLY created to prevent) is a singular or oligarchy of for profit corporations making this decision for us. This is exactly what OpenAI plans to do.

I get it, GPT4 is incredible. However, we are talking about the single most transformative technology and societal change that humanity has ever made. It needs to be for everyone or else the average person is going to be left behind.

We need to unify around open source development; choose companies that contribute to science, and condemn the ones that don't.

This conversation will only ever get more important.",1678919641.0,3045.0,449.0,/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/,https://www.reddit.com/r/MachineLearning/comments/11sboh1/d_our_community_must_get_serious_about_opposing/,SOCSChamp,MachineLearning,0.95,True,False,False,False,0.0,1745833720.546565,Tech & Programming,9.0,255.0,264.0,Wednesday,18.0,March,2023.0,False,0.1573,0.084,0.074,0.842,positive,d our community must get serious about opposing openai,openai was founded for the explicit purpose of democratizing access to ai and acting as a counterbalance to the closed off world of big tech by developing open source tools they have abandoned this idea entirely today with the release of gpt and their direct statement that they will not release details of the model creation due to safety concerns and the competitive environment they have created a precedent worse than those that existed before they entered the field were at risk now of other major players who previously at least published their work and contributed to open source tools close themselves off as well ai alignment is a serious issue that we definitely have not solved its a huge field with a dizzying array of ideas beliefs and approaches were talking about trying to capture the interests and goals of all humanity after all in this space the one approach that is horrifying and the one that openai was literally created to prevent is a singular or oligarchy of for profit corporations making this decision for us this is exactly what openai plans to do i get it gpt is incredible however we are talking about the single most transformative technology and societal change that humanity has ever made it needs to be for everyone or else the average person is going to be left behind we need to unify around open source development choose companies that contribute to science and condemn the ones that dont this conversation will only ever get more important,d our community must get serious about opposing openai openai was founded for the explicit purpose of democratizing access to ai and acting as a counterbalance to the closed off world of big tech by developing open source tools they have abandoned this idea entirely today with the release of gpt and their direct statement that they will not release details of the model creation due to safety concerns and the competitive environment they have created a precedent worse than those that existed before they entered the field were at risk now of other major players who previously at least published their work and contributed to open source tools close themselves off as well ai alignment is a serious issue that we definitely have not solved its a huge field with a dizzying array of ideas beliefs and approaches were talking about trying to capture the interests and goals of all humanity after all in this space the one approach that is horrifying and the one that openai was literally created to prevent is a singular or oligarchy of for profit corporations making this decision for us this is exactly what openai plans to do i get it gpt is incredible however we are talking about the single most transformative technology and societal change that humanity has ever made it needs to be for everyone or else the average person is going to be left behind we need to unify around open source development choose companies that contribute to science and condemn the ones that dont this conversation will only ever get more important,"openai, get, open, source, one",2023-03-15 22:34:01,d our community must get serious about opposing openai openai was founded for the explicit purpose of democratizing access to ai and acting as a counterbalance to the closed off world of big tech by developing open source tools they have abandoned this idea entirely today with the release of gpt and their direct statement that they will not release details of the model creation due to safety concerns and the competitive environment they have created a precedent worse than those that existed before they entered the field were at risk now of other major players who previously at least published their work and contributed to open source tools close themselves off as well ai alignment is a serious issue that we definitely have not solved its a huge field with a dizzying array of ideas beliefs and approaches were talking about trying to capture the interests and goals of all humanity after all in this space the one approach that is horrifying and the one that openai was literally created to prevent is a singular or oligarchy of for profit corporations making this decision for us this is exactly what openai plans to do i get it gpt is incredible however we are talking about the single most transformative technology and societal change that humanity has ever made it needs to be for everyone or else the average person is going to be left behind we need to unify around open source development choose companies that contribute to science and condemn the ones that dont this conversation will only ever get more important,"['community', 'must', 'get', 'serious', 'opposing', 'openai', 'openai', 'founded', 'explicit', 'purpose', 'democratizing', 'access', 'acting', 'counterbalance', 'closed', 'world', 'big', 'tech', 'developing', 'open', 'source', 'tool', 'abandoned', 'idea', 'entirely', 'today', 'release', 'gpt', 'direct', 'statement', 'release', 'detail', 'model', 'creation', 'due', 'safety', 'concern', 'competitive', 'environment', 'created', 'precedent', 'worse', 'existed', 'entered', 'field', 'risk', 'major', 'player', 'previously', 'least', 'published', 'work', 'contributed', 'open', 'source', 'tool', 'close', 'well', 'alignment', 'serious', 'issue', 'definitely', 'solved', 'huge', 'field', 'dizzying', 'array', 'idea', 'belief', 'approach', 'talking', 'trying', 'capture', 'interest', 'goal', 'humanity', 'space', 'one', 'approach', 'horrifying', 'one', 'openai', 'literally', 'created', 'prevent', 'singular', 'oligarchy', 'profit', 'corporation', 'making', 'decision', 'exactly', 'openai', 'plan', 'get', 'gpt', 'incredible', 'however', 'talking', 'single', 'transformative', 'technology', 'societal', 'change', 'humanity', 'ever', 'made', 'need', 'everyone', 'else', 'average', 'person', 'going', 'left', 'behind', 'need', 'unify', 'around', 'open', 'source', 'development', 'choose', 'company', 'contribute', 'science', 'condemn', 'one', 'dont', 'conversation', 'ever', 'get', 'important']",,,,
zhrgln,[P] I made a command-line tool that explains your errors using ChatGPT (link in comments),,1670675577.0,2892.0,112.0,/r/MachineLearning/comments/zhrgln/p_i_made_a_commandline_tool_that_explains_your/,https://i.redd.it/kq518l9ne25a1.gif,jsonathan,MachineLearning,0.97,False,False,False,False,0.0,1745833724.466678,Tech & Programming,15.0,0.0,15.0,Saturday,7.0,December,2022.0,True,-0.34,0.0,0.179,0.821,negative,p i made a commandline tool that explains your errors using chatgpt link in comments,,p i made a commandline tool that explains your errors using chatgpt link in comments ,"made, commandline, tool, explains, error",2022-12-10 12:32:57,p i made a commandline tool that explains your errors using chatgpt link in comments ,"['made', 'commandline', 'tool', 'explains', 'error', 'using', 'chatgpt', 'link', 'comment']",,,,
pmqtj9,[P] Using Deep Learning to draw and write with your hand and webcam 👆. The model tries to predict whether you want to have 'pencil up' or 'pencil down' (see at the end of the video). You can try it online (link in comments),,1631445082.0,2850.0,60.0,/r/MachineLearning/comments/pmqtj9/p_using_deep_learning_to_draw_and_write_with_your/,https://v.redd.it/3r1texiu12n71,Lairv,MachineLearning,0.98,False,False,False,False,0.0,1745833725.262223,Tech & Programming,44.0,0.0,43.0,Sunday,7.0,September,2021.0,True,0.5423,0.101,0.0,0.899,positive,p using deep learning to draw and write with your hand and webcam the model tries to predict whether you want to have pencil up or pencil down see at the end of the video you can try it online link in comments,,p using deep learning to draw and write with your hand and webcam the model tries to predict whether you want to have pencil up or pencil down see at the end of the video you can try it online link in comments ,"try, pencil, using, deep, learning",2021-09-12 11:11:22,p using deep learning to draw and write with your hand and webcam the model tries to predict whether you want to have pencil up or pencil down see at the end of the video you can try it online link in comments ,"['using', 'deep', 'learning', 'draw', 'write', 'hand', 'webcam', 'model', 'try', 'predict', 'whether', 'want', 'pencil', 'pencil', 'see', 'end', 'video', 'try', 'online', 'link', 'comment']",,,,
gc2wo9,[R] Consistent Video Depth Estimation (SIGGRAPH 2020) - Links in the comments.,,1588407275.0,2843.0,102.0,/r/MachineLearning/comments/gc2wo9/r_consistent_video_depth_estimation_siggraph_2020/,https://v.redd.it/kq07lzwr8bw41,hardmaru,MachineLearning,0.99,False,False,False,False,0.0,1745833725.649413,Tech & Programming,12.0,0.0,10.0,Saturday,4.0,May,2020.0,True,0.0,0.0,0.0,1.0,neutral,r consistent video depth estimation siggraph links in the comments,,r consistent video depth estimation siggraph links in the comments ,"consistent, video, depth, estimation, siggraph",2020-05-02 08:14:35,r consistent video depth estimation siggraph links in the comments ,"['consistent', 'video', 'depth', 'estimation', 'siggraph', 'link', 'comment']",,,,
juv419,"[R] [RIFE: 15FPS to 60FPS] Video frame interpolation , GPU real-time flow-based method",,1605479814.0,2802.0,146.0,/r/MachineLearning/comments/juv419/r_rife_15fps_to_60fps_video_frame_interpolation/,https://v.redd.it/q2emqbi0ehz51,hzwer,MachineLearning,0.99,False,False,False,False,0.0,1745833726.313164,Tech & Programming,13.0,0.0,12.0,Sunday,17.0,November,2020.0,True,0.0,0.0,0.0,1.0,neutral,r rife fps to fps video frame interpolation gpu realtime flowbased method,,r rife fps to fps video frame interpolation gpu realtime flowbased method ,"fps, rife, video, frame, interpolation",2020-11-15 22:36:54,r rife fps to fps video frame interpolation gpu realtime flowbased method ,"['rife', 'fps', 'fps', 'video', 'frame', 'interpolation', 'gpu', 'realtime', 'flowbased', 'method']",,,,
hciw10,[R] Wolfenstein and Doom Guy upscaled into realistic faces with PULSE,,1592643524.0,2798.0,104.0,/r/MachineLearning/comments/hciw10/r_wolfenstein_and_doom_guy_upscaled_into/,https://i.redd.it/612v6lqc51651.png,programmerChilli,MachineLearning,0.98,False,False,False,False,0.0,1745833727.207422,Tech & Programming,11.0,0.0,11.0,Saturday,4.0,June,2020.0,True,-0.4019,0.0,0.231,0.769,negative,r wolfenstein and doom guy upscaled into realistic faces with pulse,,r wolfenstein and doom guy upscaled into realistic faces with pulse ,"wolfenstein, doom, guy, upscaled, realistic",2020-06-20 08:58:44,r wolfenstein and doom guy upscaled into realistic faces with pulse ,"['wolfenstein', 'doom', 'guy', 'upscaled', 'realistic', 'face', 'pulse']",,,,
10ys3md,[P] I'm using Instruct GPT to show anti-clickbait summaries on youtube videos,,1676035973.0,2783.0,249.0,/r/MachineLearning/comments/10ys3md/p_im_using_instruct_gpt_to_show_anticlickbait/,https://www.reddit.com/gallery/10ys3md,AlesioRFM,MachineLearning,0.97,False,False,False,False,0.0,1745833727.833035,Tech & Programming,12.0,0.0,12.0,Friday,8.0,February,2023.0,False,0.0,0.0,0.0,1.0,neutral,p im using instruct gpt to show anticlickbait summaries on youtube videos,,p im using instruct gpt to show anticlickbait summaries on youtube videos ,"using, instruct, gpt, show, anticlickbait",2023-02-10 13:32:53,p im using instruct gpt to show anticlickbait summaries on youtube videos ,"['using', 'instruct', 'gpt', 'show', 'anticlickbait', 'summary', 'youtube', 'video']",,,,
s4tu5x,[P] I made an AI twitter bot that draws people’s dream jobs for them.,,1642279633.0,2726.0,73.0,/r/MachineLearning/comments/s4tu5x/p_i_made_an_ai_twitter_bot_that_draws_peoples/,https://i.redd.it/fc7mxpozywb81.jpg,maaartiin_mac,MachineLearning,0.97,False,False,False,False,0.0,1745833729.03589,Tech & Programming,14.0,0.0,14.0,Saturday,15.0,January,2022.0,True,0.25,0.154,0.0,0.846,positive,p i made an ai twitter bot that draws peoples dream jobs for them,,p i made an ai twitter bot that draws peoples dream jobs for them ,"made, twitter, bot, draw, people",2022-01-15 20:47:13,p i made an ai twitter bot that draws peoples dream jobs for them ,"['made', 'twitter', 'bot', 'draw', 'people', 'dream', 'job']",,,,
xtxe6f,[D] Types of Machine Learning Papers,,1664738749.0,2646.0,92.0,/r/MachineLearning/comments/xtxe6f/d_types_of_machine_learning_papers/,https://i.redd.it/xspt97vg1gr91.jpg,Lost-Parfait568,MachineLearning,0.97,False,False,False,False,1.0,1745833729.512875,Tech & Programming,6.0,0.0,6.0,Sunday,15.0,October,2022.0,True,0.0,0.0,0.0,1.0,neutral,d types of machine learning papers,,d types of machine learning papers ,"type, machine, learning, paper",2022-10-02 19:25:49,d types of machine learning papers ,"['type', 'machine', 'learning', 'paper']",,,,
14265di,Should r/MachineLearning join the reddit blackout to protest changes to their API?,"Hello there, r/MachineLearning,

Recently, Reddit has announced some [changes to their API](https://www.reddit.com/r/modnews/comments/13wshdp/api_update_continued_access_to_our_api_for/) that may have pretty serious impact on many of it's users.

[You may have already seen quite a few posts like these](https://www.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/) across some of the other subreddits that you browse, so we're just going to cut to the chase.

# What's Happening

Third Party Reddit apps (such as Apollo, Reddit is Fun and others) are going to become ludicrously more expensive for it's developers to run, which will in turn either kill the apps, or result in a monthly fee to the users if they choose to use one of those apps to browse. Put simply, each request to Reddit within these mobile apps will cost the developer money. The developers of Apollo [were quoted around $2 million per month](https://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/) for the current rate of usage. The only way for these apps to continue to be viable for the developer is if you (the user) pay a monthly fee, and realistically, this is most likely going to just outright kill them. **Put simply: If you use a third party app to browse Reddit, you will most likely no longer be able to do so, or be charged a monthly fee to keep it viable.**

In lieu of what's happening, [an open letter](https://www.reddit.com/r/ModCoord/comments/13xh1e7/an_open_letter_on_the_state_of_affairs_regarding/) has been released by the broader moderation community. Part of this initiative includes a potential subreddit blackout (meaning, the subreddit will be privatized) on June 12th, lasting 24-48 hours or longer. On one hand, this is great to hopefully make enough of an impact to influence Reddit to change their minds on this. On the other hand, we usually stay out of these blackouts, and we would rather not negatively impact usage of the subreddit.

We would like to give the community a voice in this. Is this an important enough matter that r/machinelearning should fully support the protest and blackout the subreddit on June 12th? Feel free to leave your thoughts and opinions below. 

Also, please use up/downvotes for this submission to make yourself heard: upvote: r/ML should join the protest, downvote: r/ML should not join the protest.",1686032558.0,2627.0,217.0,/r/MachineLearning/comments/14265di/should_rmachinelearning_join_the_reddit_blackout/,https://www.reddit.com/r/MachineLearning/comments/14265di/should_rmachinelearning_join_the_reddit_blackout/,BeatLeJuce,MachineLearning,0.96,True,False,False,False,0.0,1745833730.182109,Tech & Programming,12.0,354.0,363.0,Tuesday,2.0,June,2023.0,False,0.9665,0.121,0.072,0.807,positive,should rmachinelearning join the reddit blackout to protest changes to their api,hello there rmachinelearning recently reddit has announced some changes to their api that may have pretty serious impact on many of its users you may have already seen quite a few posts like these across some of the other subreddits that you browse so were just going to cut to the chase whats happening third party reddit apps such as apollo reddit is fun and others are going to become ludicrously more expensive for its developers to run which will in turn either kill the apps or result in a monthly fee to the users if they choose to use one of those apps to browse put simply each request to reddit within these mobile apps will cost the developer money the developers of apollo were quoted around million per month for the current rate of usage the only way for these apps to continue to be viable for the developer is if you the user pay a monthly fee and realistically this is most likely going to just outright kill them put simply if you use a third party app to browse reddit you will most likely no longer be able to do so or be charged a monthly fee to keep it viable in lieu of whats happening an open letter has been released by the broader moderation community part of this initiative includes a potential subreddit blackout meaning the subreddit will be privatized on june th lasting hours or longer on one hand this is great to hopefully make enough of an impact to influence reddit to change their minds on this on the other hand we usually stay out of these blackouts and we would rather not negatively impact usage of the subreddit we would like to give the community a voice in this is this an important enough matter that rmachinelearning should fully support the protest and blackout the subreddit on june th feel free to leave your thoughts and opinions below also please use updownvotes for this submission to make yourself heard upvote rml should join the protest downvote rml should not join the protest,should rmachinelearning join the reddit blackout to protest changes to their api hello there rmachinelearning recently reddit has announced some changes to their api that may have pretty serious impact on many of its users you may have already seen quite a few posts like these across some of the other subreddits that you browse so were just going to cut to the chase whats happening third party reddit apps such as apollo reddit is fun and others are going to become ludicrously more expensive for its developers to run which will in turn either kill the apps or result in a monthly fee to the users if they choose to use one of those apps to browse put simply each request to reddit within these mobile apps will cost the developer money the developers of apollo were quoted around million per month for the current rate of usage the only way for these apps to continue to be viable for the developer is if you the user pay a monthly fee and realistically this is most likely going to just outright kill them put simply if you use a third party app to browse reddit you will most likely no longer be able to do so or be charged a monthly fee to keep it viable in lieu of whats happening an open letter has been released by the broader moderation community part of this initiative includes a potential subreddit blackout meaning the subreddit will be privatized on june th lasting hours or longer on one hand this is great to hopefully make enough of an impact to influence reddit to change their minds on this on the other hand we usually stay out of these blackouts and we would rather not negatively impact usage of the subreddit we would like to give the community a voice in this is this an important enough matter that rmachinelearning should fully support the protest and blackout the subreddit on june th feel free to leave your thoughts and opinions below also please use updownvotes for this submission to make yourself heard upvote rml should join the protest downvote rml should not join the protest,"reddit, apps, blackout, protest, developer",2023-06-06 06:22:38,should rmachinelearning join the reddit blackout to protest changes to their api hello there rmachinelearning recently reddit has announced some changes to their api that may have pretty serious impact on many of its users you may have already seen quite a few posts like these across some of the other subreddits that you browse so were just going to cut to the chase whats happening third party reddit apps such as apollo reddit is fun and others are going to become ludicrously more expensive for its developers to run which will in turn either kill the apps or result in a monthly fee to the users if they choose to use one of those apps to browse put simply each request to reddit within these mobile apps will cost the developer money the developers of apollo were quoted around million per month for the current rate of usage the only way for these apps to continue to be viable for the developer is if you the user pay a monthly fee and realistically this is most likely going to just outright kill them put simply if you use a third party app to browse reddit you will most likely no longer be able to do so or be charged a monthly fee to keep it viable in lieu of whats happening an open letter has been released by the broader moderation community part of this initiative includes a potential subreddit blackout meaning the subreddit will be privatized on june th lasting hours or longer on one hand this is great to hopefully make enough of an impact to influence reddit to change their minds on this on the other hand we usually stay out of these blackouts and we would rather not negatively impact usage of the subreddit we would like to give the community a voice in this is this an important enough matter that rmachinelearning should fully support the protest and blackout the subreddit on june th feel free to leave your thoughts and opinions below also please use updownvotes for this submission to make yourself heard upvote rml should join the protest downvote rml should not join the protest,"['rmachinelearning', 'join', 'reddit', 'blackout', 'protest', 'change', 'api', 'hello', 'rmachinelearning', 'recently', 'reddit', 'announced', 'change', 'api', 'may', 'pretty', 'serious', 'impact', 'many', 'user', 'may', 'already', 'seen', 'quite', 'post', 'like', 'across', 'subreddits', 'browse', 'going', 'cut', 'chase', 'whats', 'happening', 'third', 'party', 'reddit', 'apps', 'apollo', 'reddit', 'fun', 'others', 'going', 'become', 'ludicrously', 'expensive', 'developer', 'run', 'turn', 'either', 'kill', 'apps', 'result', 'monthly', 'fee', 'user', 'choose', 'use', 'one', 'apps', 'browse', 'put', 'simply', 'request', 'reddit', 'within', 'mobile', 'apps', 'cost', 'developer', 'money', 'developer', 'apollo', 'quoted', 'around', 'million', 'per', 'month', 'current', 'rate', 'usage', 'way', 'apps', 'continue', 'viable', 'developer', 'user', 'pay', 'monthly', 'fee', 'realistically', 'likely', 'going', 'outright', 'kill', 'put', 'simply', 'use', 'third', 'party', 'app', 'browse', 'reddit', 'likely', 'longer', 'able', 'charged', 'monthly', 'fee', 'keep', 'viable', 'lieu', 'whats', 'happening', 'open', 'letter', 'released', 'broader', 'moderation', 'community', 'part', 'initiative', 'includes', 'potential', 'subreddit', 'blackout', 'meaning', 'subreddit', 'privatized', 'june', 'lasting', 'hour', 'longer', 'one', 'hand', 'great', 'hopefully', 'make', 'enough', 'impact', 'influence', 'reddit', 'change', 'mind', 'hand', 'usually', 'stay', 'blackout', 'would', 'rather', 'negatively', 'impact', 'usage', 'subreddit', 'would', 'like', 'give', 'community', 'voice', 'important', 'enough', 'matter', 'rmachinelearning', 'fully', 'support', 'protest', 'blackout', 'subreddit', 'june', 'feel', 'free', 'leave', 'thought', 'opinion', 'also', 'please', 'use', 'updownvotes', 'submission', 'make', 'heard', 'upvote', 'rml', 'join', 'protest', 'downvote', 'rml', 'join', 'protest']",,,,
ma8xbq,[D] An example of machine learning bias on popular. Is this specific case a problem? Thoughts?,,1616368763.0,2607.0,408.0,/r/MachineLearning/comments/ma8xbq/d_an_example_of_machine_learning_bias_on_popular/,https://imgur.com/8io3hvP.png,,MachineLearning,0.96,False,False,False,False,0.0,1745833731.242377,Tech & Programming,16.0,0.0,16.0,Sunday,19.0,March,2021.0,True,-0.0772,0.156,0.229,0.615,negative,d an example of machine learning bias on popular is this specific case a problem thoughts,,d an example of machine learning bias on popular is this specific case a problem thoughts ,"example, machine, learning, bias, popular",2021-03-21 23:19:23,d an example of machine learning bias on popular is this specific case a problem thoughts ,"['example', 'machine', 'learning', 'bias', 'popular', 'specific', 'case', 'problem', 'thought']",,,,
5z8110,[D] A Super Harsh Guide to Machine Learning,"First, read fucking Hastie, Tibshirani, and whoever. Chapters 1-4 and 7-8. If you don't understand it, keep reading it until you do. 

You can read the rest of the book if you want. You probably should, but I'll assume you know all of it. 

Take Andrew Ng's Coursera. Do all the exercises in python and R. Make sure you get the same answers with all of them. 

Now forget all of that and read the deep learning book. Put tensorflow and pytorch on a Linux box and run examples until you get it. Do stuff with CNNs and RNNs and just feed forward NNs.

Once you do all of that, go on arXiv and read the most recent useful papers. The literature changes every few months, so keep up. 

There. Now you can probably be hired most places. If you need resume filler, so some Kaggle competitions. If you have debugging questions, use StackOverflow. If you have math questions, read more. If you have life questions, I have no idea.",1489441878.0,2596.0,304.0,/r/MachineLearning/comments/5z8110/d_a_super_harsh_guide_to_machine_learning/,https://www.reddit.com/r/MachineLearning/comments/5z8110/d_a_super_harsh_guide_to_machine_learning/,thatguydr,MachineLearning,0.97,True,False,False,False,0.0,1745833733.869838,Tech & Programming,8.0,170.0,176.0,Monday,17.0,March,2017.0,False,0.0045,0.059,0.058,0.883,neutral,d a super harsh guide to machine learning,first read fucking hastie tibshirani and whoever chapters and if you dont understand it keep reading it until you do you can read the rest of the book if you want you probably should but ill assume you know all of it take andrew ngs coursera do all the exercises in python and r make sure you get the same answers with all of them now forget all of that and read the deep learning book put tensorflow and pytorch on a linux box and run examples until you get it do stuff with cnns and rnns and just feed forward nns once you do all of that go on arxiv and read the most recent useful papers the literature changes every few months so keep up there now you can probably be hired most places if you need resume filler so some kaggle competitions if you have debugging questions use stackoverflow if you have math questions read more if you have life questions i have no idea,d a super harsh guide to machine learning first read fucking hastie tibshirani and whoever chapters and if you dont understand it keep reading it until you do you can read the rest of the book if you want you probably should but ill assume you know all of it take andrew ngs coursera do all the exercises in python and r make sure you get the same answers with all of them now forget all of that and read the deep learning book put tensorflow and pytorch on a linux box and run examples until you get it do stuff with cnns and rnns and just feed forward nns once you do all of that go on arxiv and read the most recent useful papers the literature changes every few months so keep up there now you can probably be hired most places if you need resume filler so some kaggle competitions if you have debugging questions use stackoverflow if you have math questions read more if you have life questions i have no idea,"read, question, learning, keep, book",2017-03-13 21:51:18,d a super harsh guide to machine learning first read fucking hastie tibshirani and whoever chapters and if you dont understand it keep reading it until you do you can read the rest of the book if you want you probably should but ill assume you know all of it take andrew ngs coursera do all the exercises in python and r make sure you get the same answers with all of them now forget all of that and read the deep learning book put tensorflow and pytorch on a linux box and run examples until you get it do stuff with cnns and rnns and just feed forward nns once you do all of that go on arxiv and read the most recent useful papers the literature changes every few months so keep up there now you can probably be hired most places if you need resume filler so some kaggle competitions if you have debugging questions use stackoverflow if you have math questions read more if you have life questions i have no idea,"['super', 'harsh', 'guide', 'machine', 'learning', 'first', 'read', 'fucking', 'hastie', 'tibshirani', 'whoever', 'chapter', 'dont', 'understand', 'keep', 'reading', 'read', 'rest', 'book', 'want', 'probably', 'ill', 'assume', 'know', 'take', 'andrew', 'ng', 'coursera', 'exercise', 'python', 'make', 'sure', 'get', 'answer', 'forget', 'read', 'deep', 'learning', 'book', 'put', 'tensorflow', 'pytorch', 'linux', 'box', 'run', 'example', 'get', 'stuff', 'cnns', 'rnns', 'feed', 'forward', 'nns', 'arxiv', 'read', 'recent', 'useful', 'paper', 'literature', 'change', 'every', 'month', 'keep', 'probably', 'hired', 'place', 'need', 'resume', 'filler', 'kaggle', 'competition', 'debugging', 'question', 'use', 'stackoverflow', 'math', 'question', 'read', 'life', 'question', 'idea']",,,,
dh2xfs,[D] Siraj has a new paper: 'The Neural Qubit'. It's plagiarised,"Exposed in this Twitter thread: https://twitter.com/AndrewM_Webb/status/1183150368945049605

Text, figures, tables, captions, equations (even equation numbers) are all lifted from another paper with minimal changes.

Siraj's paper: http://vixra.org/pdf/1909.0060v1.pdf

The original paper: https://arxiv.org/pdf/1806.06871.pdf

Edit: I've chosen to expose this publicly because he has a lot of fans and currently a lot of paying customers. They really trust this guy, and I don't think he's going to change.",1570924133.0,2567.0,451.0,/r/MachineLearning/comments/dh2xfs/d_siraj_has_a_new_paper_the_neural_qubit_its/,https://www.reddit.com/r/MachineLearning/comments/dh2xfs/d_siraj_has_a_new_paper_the_neural_qubit_its/,grey--area,MachineLearning,0.98,True,False,False,False,0.0,1745833735.827292,Tech & Programming,11.0,64.0,72.0,Saturday,19.0,October,2019.0,True,0.6115,0.082,0.04,0.878,positive,d siraj has a new paper the neural qubit its plagiarised,exposed in this twitter thread text figures tables captions equations even equation numbers are all lifted from another paper with minimal changes sirajs paper the original paper edit ive chosen to expose this publicly because he has a lot of fans and currently a lot of paying customers they really trust this guy and i dont think hes going to change,d siraj has a new paper the neural qubit its plagiarised exposed in this twitter thread text figures tables captions equations even equation numbers are all lifted from another paper with minimal changes sirajs paper the original paper edit ive chosen to expose this publicly because he has a lot of fans and currently a lot of paying customers they really trust this guy and i dont think hes going to change,"paper, equation, change, lot, siraj",2019-10-12 23:48:53,d siraj has a new paper the neural qubit its plagiarised exposed in this twitter thread text figures tables captions equations even equation numbers are all lifted from another paper with minimal changes sirajs paper the original paper edit ive chosen to expose this publicly because he has a lot of fans and currently a lot of paying customers they really trust this guy and i dont think hes going to change,"['siraj', 'new', 'paper', 'neural', 'qubit', 'plagiarised', 'exposed', 'twitter', 'thread', 'text', 'figure', 'table', 'caption', 'equation', 'even', 'equation', 'number', 'lifted', 'another', 'paper', 'minimal', 'change', 'sirajs', 'paper', 'original', 'paper', 'edit', 'ive', 'chosen', 'expose', 'publicly', 'lot', 'fan', 'currently', 'lot', 'paying', 'customer', 'really', 'trust', 'guy', 'dont', 'think', 'he', 'going', 'change']",,,,
jm86z9,A little seasonal homage... [P],,1604258581.0,2565.0,33.0,/r/MachineLearning/comments/jm86z9/a_little_seasonal_homage_p/,https://i.redd.it/e0eptfheiow51.png,kilsekddd,MachineLearning,0.98,False,False,False,False,0.0,1745833738.334387,Tech & Programming,5.0,0.0,5.0,Sunday,14.0,November,2020.0,True,0.0,0.0,0.0,1.0,neutral,a little seasonal homage p,,a little seasonal homage p ,"little, seasonal, homage",2020-11-01 19:23:01,a little seasonal homage p ,"['little', 'seasonal', 'homage']",,,,
748cco,[R] Neural Color Transfer between Images,,1507125950.0,2461.0,90.0,/r/MachineLearning/comments/748cco/r_neural_color_transfer_between_images/,https://i.redd.it/1qync11pltpz.jpg,e_walker,MachineLearning,0.96,False,False,False,False,0.0,1745833738.615965,Tech & Programming,6.0,0.0,6.0,Wednesday,10.0,October,2017.0,False,0.0,0.0,0.0,1.0,neutral,r neural color transfer between images,,r neural color transfer between images ,"neural, color, transfer, image",2017-10-04 14:05:50,r neural color transfer between images ,"['neural', 'color', 'transfer', 'image']",,,,
132w40c,[R] Video of experiments from DeepMind's recent “Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning” (OP3 Soccer) project,,1682779841.0,2447.0,142.0,/r/MachineLearning/comments/132w40c/r_video_of_experiments_from_deepminds_recent/,https://v.redd.it/jks9k9eo6uwa1,hardmaru,MachineLearning,0.99,False,False,False,False,0.0,1745833739.472307,Tech & Programming,22.0,0.0,22.0,Saturday,10.0,April,2023.0,True,0.0,0.0,0.0,1.0,neutral,r video of experiments from deepminds recent learning agile soccer skills for a bipedal robot with deep reinforcement learning op soccer project,,r video of experiments from deepminds recent learning agile soccer skills for a bipedal robot with deep reinforcement learning op soccer project ,"learning, soccer, video, experiment, deepminds",2023-04-29 14:50:41,r video of experiments from deepminds recent learning agile soccer skills for a bipedal robot with deep reinforcement learning op soccer project ,"['video', 'experiment', 'deepminds', 'recent', 'learning', 'agile', 'soccer', 'skill', 'bipedal', 'robot', 'deep', 'reinforcement', 'learning', 'soccer', 'project']",,,,
o843t5,[D] Types of Machine Learning Papers,,1624683123.0,2407.0,101.0,/r/MachineLearning/comments/o843t5/d_types_of_machine_learning_papers/,https://i.redd.it/y24wbhmjjj771.jpg,TheInsaneApp,MachineLearning,0.96,False,False,False,False,0.0,1745833740.29574,Tech & Programming,6.0,0.0,6.0,Saturday,0.0,June,2021.0,True,0.0,0.0,0.0,1.0,neutral,d types of machine learning papers,,d types of machine learning papers ,"type, machine, learning, paper",2021-06-26 04:52:03,d types of machine learning papers ,"['type', 'machine', 'learning', 'paper']",,,,
i1aafb,[P] I trained a GAN to generate photorealistic fake penises,"# This Dick Pic Does Not Exist

A StyleGAN2 model to make AI-generated dicks

**Website**

[https://thisdickpicdoesnotexist.com/](https://thisdickpicdoesnotexist.com/)

**Make your own dicks**

[Google Colab](https://colab.research.google.com/drive/1DoCxr2pYlxCRv6RmITtFWahVXsbTexYp?usp=sharing)

**Github**

[https://github.com/beezeetee/TDPDNE](https://github.com/beezeetee/TDPDNE)

*Edit:* ***Interpolation***  
u/arfafax created an interpolation notebook with the model

[Interpolation Colab Notebook](https://colab.research.google.com/drive/1-SDjR6ztiExBRmf5xzspNsA5t8y3kEXk?usp=sharing)

[Cursed Interpolation Video](https://thcf7.redgifs.com/HiddenImmaterialBrownbutterfly.webm)

&#x200B;

# But Why?

Like most men, I had the problem of too many women asking for my dick pics.

So I spent the last 2 years learning linear algebra, Bayesian statistics, and multivariable calculus so that I could finally keep up with the demand by generating thousands of fake penises with AI.

The above website features those thousands of penises, do with it what you will.

If you're curious about the machine learning, the training dataset consisted of 40k dick pics from Reddit. Specifically the subreddits: r/penis r/cock, r/dicks, r/averagepenis, r/MassiveCock, and r/tinydick to keep it well rounded.

I then cleaned the dataset by training a Mask R-CNN Model to segment out the penis, used PCA on the segment to find the tilt of the shaft, then rotated the image so the schlong was aligned with the vertical axis.

The images were then put into a [StyleGAN2 ](https://github.com/NVlabs/stylegan2)model and trained for \~9 days on a TPUv3-8.

The dataset, in case you want to see what 42,273 dick pics look like is posted in the Github.

https://preview.redd.it/txq644l8w7e51.png?width=1200&format=png&auto=webp&s=bb6687c5ec53dc9454fd8bf1eec9f45af1d5f48e",1596212065.0,2357.0,274.0,/r/MachineLearning/comments/i1aafb/p_i_trained_a_gan_to_generate_photorealistic_fake/,https://www.reddit.com/r/MachineLearning/comments/i1aafb/p_i_trained_a_gan_to_generate_photorealistic_fake/,DicksDontExist,MachineLearning,0.97,True,True,False,False,2.0,1745833740.807049,Tech & Programming,10.0,217.0,218.0,Friday,12.0,July,2020.0,False,-0.9319,0.064,0.115,0.82,negative,p i trained a gan to generate photorealistic fake penises,this dick pic does not exist a stylegan model to make aigenerated dicks website make your own dicks google colab github edit interpolation uarfafax created an interpolation notebook with the model interpolation colab notebook cursed interpolation video xb but why like most men i had the problem of too many women asking for my dick pics so i spent the last years learning linear algebra bayesian statistics and multivariable calculus so that i could finally keep up with the demand by generating thousands of fake penises with ai the above website features those thousands of penises do with it what you will if youre curious about the machine learning the training dataset consisted of k dick pics from reddit specifically the subreddits rpenis rcock rdicks raveragepenis rmassivecock and rtinydick to keep it well rounded i then cleaned the dataset by training a mask rcnn model to segment out the penis used pca on the segment to find the tilt of the shaft then rotated the image so the schlong was aligned with the vertical axis the images were then put into a stylegan and trained for days on a tpuv the dataset in case you want to see what dick pics look like is posted in the github,p i trained a gan to generate photorealistic fake penises this dick pic does not exist a stylegan model to make aigenerated dicks website make your own dicks google colab github edit interpolation uarfafax created an interpolation notebook with the model interpolation colab notebook cursed interpolation video xb but why like most men i had the problem of too many women asking for my dick pics so i spent the last years learning linear algebra bayesian statistics and multivariable calculus so that i could finally keep up with the demand by generating thousands of fake penises with ai the above website features those thousands of penises do with it what you will if youre curious about the machine learning the training dataset consisted of k dick pics from reddit specifically the subreddits rpenis rcock rdicks raveragepenis rmassivecock and rtinydick to keep it well rounded i then cleaned the dataset by training a mask rcnn model to segment out the penis used pca on the segment to find the tilt of the shaft then rotated the image so the schlong was aligned with the vertical axis the images were then put into a stylegan and trained for days on a tpuv the dataset in case you want to see what dick pics look like is posted in the github,"dick, penis, pic, interpolation, model",2020-07-31 16:14:25,p i trained a gan to generate photorealistic fake penises this dick pic does not exist a stylegan model to make aigenerated dicks website make your own dicks google colab github edit interpolation uarfafax created an interpolation notebook with the model interpolation colab notebook cursed interpolation video xb but why like most men i had the problem of too many women asking for my dick pics so i spent the last years learning linear algebra bayesian statistics and multivariable calculus so that i could finally keep up with the demand by generating thousands of fake penises with ai the above website features those thousands of penises do with it what you will if youre curious about the machine learning the training dataset consisted of k dick pics from reddit specifically the subreddits rpenis rcock rdicks raveragepenis rmassivecock and rtinydick to keep it well rounded i then cleaned the dataset by training a mask rcnn model to segment out the penis used pca on the segment to find the tilt of the shaft then rotated the image so the schlong was aligned with the vertical axis the images were then put into a stylegan and trained for days on a tpuv the dataset in case you want to see what dick pics look like is posted in the github,"['trained', 'gan', 'generate', 'photorealistic', 'fake', 'penis', 'dick', 'pic', 'exist', 'stylegan', 'model', 'make', 'aigenerated', 'dick', 'website', 'make', 'dick', 'google', 'colab', 'github', 'edit', 'interpolation', 'uarfafax', 'created', 'interpolation', 'notebook', 'model', 'interpolation', 'colab', 'notebook', 'cursed', 'interpolation', 'video', 'like', 'men', 'problem', 'many', 'woman', 'asking', 'dick', 'pic', 'spent', 'last', 'year', 'learning', 'linear', 'algebra', 'bayesian', 'statistic', 'multivariable', 'calculus', 'could', 'finally', 'keep', 'demand', 'generating', 'thousand', 'fake', 'penis', 'website', 'feature', 'thousand', 'penis', 'youre', 'curious', 'machine', 'learning', 'training', 'dataset', 'consisted', 'dick', 'pic', 'reddit', 'specifically', 'subreddits', 'rpenis', 'rcock', 'rdicks', 'raveragepenis', 'rmassivecock', 'rtinydick', 'keep', 'well', 'rounded', 'cleaned', 'dataset', 'training', 'mask', 'rcnn', 'model', 'segment', 'penis', 'used', 'pca', 'segment', 'find', 'tilt', 'shaft', 'rotated', 'image', 'schlong', 'aligned', 'vertical', 'axis', 'image', 'put', 'stylegan', 'trained', 'day', 'tpuv', 'dataset', 'case', 'want', 'see', 'dick', 'pic', 'look', 'like', 'posted', 'github']",,,,
g7wvpb,[R] Adversarial Latent Autoencoders (CVPR2020 paper + code),,1587833869.0,2341.0,98.0,/r/MachineLearning/comments/g7wvpb/r_adversarial_latent_autoencoders_cvpr2020_paper/,https://v.redd.it/0bzww3okvzu41,stpidhorskyi,MachineLearning,0.99,False,False,False,False,0.0,1745833742.033283,Tech & Programming,8.0,0.0,7.0,Saturday,12.0,April,2020.0,True,-0.3612,0.0,0.333,0.667,negative,r adversarial latent autoencoders cvpr paper code,,r adversarial latent autoencoders cvpr paper code ,"adversarial, latent, autoencoders, cvpr, paper",2020-04-25 16:57:49,r adversarial latent autoencoders cvpr paper code ,"['adversarial', 'latent', 'autoencoders', 'cvpr', 'paper', 'code']",,,,
kythnj,[D]Neural-Style-PT is capable of creating complex artworks under 20 minutes.,,1610837825.0,2246.0,175.0,/r/MachineLearning/comments/kythnj/dneuralstylept_is_capable_of_creating_complex/,https://i.redd.it/og2m53b0yrb61.jpg,vic8760,MachineLearning,0.98,False,False,False,False,0.0,1745833742.621271,Tech & Programming,10.0,0.0,9.0,Saturday,17.0,January,2021.0,True,0.5859,0.407,0.0,0.593,positive,dneuralstylept is capable of creating complex artworks under minutes,,dneuralstylept is capable of creating complex artworks under minutes ,"dneuralstylept, capable, creating, complex, artwork",2021-01-16 22:57:05,dneuralstylept is capable of creating complex artworks under minutes ,"['dneuralstylept', 'capable', 'creating', 'complex', 'artwork', 'minute']",,,,
kp5pxi,[P] Trained an AI with ML to navigate an obstacle course from Rocket League,,1609621471.0,2207.0,55.0,/r/MachineLearning/comments/kp5pxi/p_trained_an_ai_with_ml_to_navigate_an_obstacle/,https://gfycat.com/oldfashionedhorriblegreathornedowl,Roboserg,MachineLearning,0.98,False,False,False,False,0.0,1745833743.442862,Tech & Programming,14.0,0.0,14.0,Saturday,16.0,January,2021.0,True,-0.3612,0.0,0.172,0.828,negative,p trained an ai with ml to navigate an obstacle course from rocket league,,p trained an ai with ml to navigate an obstacle course from rocket league ,"trained, navigate, obstacle, course, rocket",2021-01-02 21:04:31,p trained an ai with ml to navigate an obstacle course from rocket league ,"['trained', 'navigate', 'obstacle', 'course', 'rocket', 'league']",,,,
sfbtds,[P] WebtoonMe Project: Selfie to Webtoon style,,1643437233.0,2166.0,85.0,/r/MachineLearning/comments/sfbtds/p_webtoonme_project_selfie_to_webtoon_style/,https://v.redd.it/y1s3desykke81,Illustrious_Row_9971,MachineLearning,0.95,False,False,False,False,0.0,1745833744.004145,Tech & Programming,7.0,0.0,7.0,Saturday,1.0,January,2022.0,True,0.0,0.0,0.0,1.0,neutral,p webtoonme project selfie to webtoon style,,p webtoonme project selfie to webtoon style ,"webtoonme, project, selfie, webtoon, style",2022-01-29 06:20:33,p webtoonme project selfie to webtoon style ,"['webtoonme', 'project', 'selfie', 'webtoon', 'style']",,,,
wmypmh,"A demo of Stable Diffusion, a text-to-image model, being used in an interactive video editing application.",,1660345426.0,2155.0,79.0,/r/MachineLearning/comments/wmypmh/a_demo_of_stable_diffusion_a_texttoimage_model/,https://v.redd.it/cd2iei8m5dh91,hardmaru,MachineLearning,0.98,False,False,False,False,0.0,1745833744.509531,Tech & Programming,16.0,0.0,16.0,Friday,19.0,August,2022.0,False,0.296,0.145,0.0,0.855,positive,a demo of stable diffusion a texttoimage model being used in an interactive video editing application,,a demo of stable diffusion a texttoimage model being used in an interactive video editing application ,"demo, stable, diffusion, texttoimage, model",2022-08-12 23:03:46,a demo of stable diffusion a texttoimage model being used in an interactive video editing application ,"['demo', 'stable', 'diffusion', 'texttoimage', 'model', 'used', 'interactive', 'video', 'editing', 'application']",,,,
jcuch4,"[P] Creating ""real"" versions of Pixar characters using the pixel2style2pixel framework. Process and links to more examples in comments.",,1602938044.0,2137.0,136.0,/r/MachineLearning/comments/jcuch4/p_creating_real_versions_of_pixar_characters/,https://www.reddit.com/gallery/jcuch4,AtreveteTeTe,MachineLearning,0.98,False,False,False,False,0.0,1745833744.948144,Tech & Programming,19.0,0.0,19.0,Saturday,8.0,October,2020.0,True,0.296,0.115,0.0,0.885,positive,p creating real versions of pixar characters using the pixelstylepixel framework process and links to more examples in comments,,p creating real versions of pixar characters using the pixelstylepixel framework process and links to more examples in comments ,"creating, real, version, pixar, character",2020-10-17 12:34:04,p creating real versions of pixar characters using the pixelstylepixel framework process and links to more examples in comments ,"['creating', 'real', 'version', 'pixar', 'character', 'using', 'pixelstylepixel', 'framework', 'process', 'link', 'example', 'comment']",,,,
rdsepx,[P] ArcaneGAN: face portrait to Arcane style,,1639199901.0,2069.0,50.0,/r/MachineLearning/comments/rdsepx/p_arcanegan_face_portrait_to_arcane_style/,https://v.redd.it/90f2u61zku481,Illustrious_Row_9971,MachineLearning,0.98,False,False,False,False,0.0,1745833745.934569,Tech & Programming,7.0,0.0,7.0,Saturday,0.0,December,2021.0,True,0.0,0.0,0.0,1.0,neutral,p arcanegan face portrait to arcane style,,p arcanegan face portrait to arcane style ,"arcanegan, face, portrait, arcane, style",2021-12-11 05:18:21,p arcanegan face portrait to arcane style ,"['arcanegan', 'face', 'portrait', 'arcane', 'style']",,,,
xyxe8w,[R] VToonify: Controllable High-Resolution Portrait Video Style Transfer,,1665247535.0,2062.0,87.0,/r/MachineLearning/comments/xyxe8w/r_vtoonify_controllable_highresolution_portrait/,https://v.redd.it/lgz57y0c2ms91,Illustrious_Row_9971,MachineLearning,0.97,False,False,False,False,0.0,1745833746.277473,Tech & Programming,8.0,0.0,8.0,Saturday,12.0,October,2022.0,True,0.0,0.0,0.0,1.0,neutral,r vtoonify controllable highresolution portrait video style transfer,,r vtoonify controllable highresolution portrait video style transfer ,"vtoonify, controllable, highresolution, portrait, video",2022-10-08 16:45:35,r vtoonify controllable highresolution portrait video style transfer ,"['vtoonify', 'controllable', 'highresolution', 'portrait', 'video', 'style', 'transfer']",,,,
t7qe6b,[R] End-to-End Referring Video Object Segmentation with Multimodal Transformers,,1646538763.0,2031.0,46.0,/r/MachineLearning/comments/t7qe6b/r_endtoend_referring_video_object_segmentation/,https://v.redd.it/pie3qopyqol81,Illustrious_Row_9971,MachineLearning,0.99,False,False,False,False,0.0,1745833746.775982,Tech & Programming,9.0,0.0,9.0,Saturday,22.0,March,2022.0,True,0.0,0.0,0.0,1.0,neutral,r endtoend referring video object segmentation with multimodal transformers,,r endtoend referring video object segmentation with multimodal transformers ,"endtoend, referring, video, object, segmentation",2022-03-06 03:52:43,r endtoend referring video object segmentation with multimodal transformers ,"['endtoend', 'referring', 'video', 'object', 'segmentation', 'multimodal', 'transformer']",,,,
10tovhn,[N] [R] Google announces Dreamix: a model that generates videos when given a prompt and an input image/video.,,1675538796.0,2031.0,125.0,/r/MachineLearning/comments/10tovhn/n_r_google_announces_dreamix_a_model_that/,https://v.redd.it/j9f0y49738ga1,radi-cho,MachineLearning,0.98,False,False,False,False,0.0,1745833747.173014,Tech & Programming,18.0,0.0,18.0,Saturday,14.0,February,2023.0,True,0.0,0.0,0.0,1.0,neutral,n r google announces dreamix a model that generates videos when given a prompt and an input imagevideo,,n r google announces dreamix a model that generates videos when given a prompt and an input imagevideo ,"google, announces, dreamix, model, generates",2023-02-04 19:26:36,n r google announces dreamix a model that generates videos when given a prompt and an input imagevideo ,"['google', 'announces', 'dreamix', 'model', 'generates', 'video', 'given', 'prompt', 'input', 'imagevideo']",,,,
o3804y,"[R] GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",,1624076466.0,2022.0,118.0,/r/MachineLearning/comments/o3804y/r_gans_n_roses_stable_controllable_diverse_image/,https://i.redd.it/3e3m6nvef5671.gif,Illustrious_Row_9971,MachineLearning,0.95,False,False,False,False,0.0,1745833747.909323,Tech & Programming,15.0,0.0,15.0,Saturday,0.0,June,2021.0,True,0.296,0.155,0.0,0.845,positive,r gans n roses stable controllable diverse image to image translation works for videos too,,r gans n roses stable controllable diverse image to image translation works for videos too ,"image, gans, rose, stable, controllable",2021-06-19 04:21:06,r gans n roses stable controllable diverse image to image translation works for videos too ,"['gans', 'rose', 'stable', 'controllable', 'diverse', 'image', 'image', 'translation', 'work', 'video']",,,,
qo4kp8,[R] [P] AnimeGANv2 Face Portrait v2,,1636218407.0,2003.0,102.0,/r/MachineLearning/comments/qo4kp8/r_p_animeganv2_face_portrait_v2/,https://i.redd.it/k25gkmonb0y71.gif,Illustrious_Row_9971,MachineLearning,0.97,False,False,False,False,0.0,1745833748.617132,Tech & Programming,6.0,0.0,6.0,Saturday,13.0,November,2021.0,True,0.0,0.0,0.0,1.0,neutral,r p animeganv face portrait v,,r p animeganv face portrait v ,"animeganv, face, portrait",2021-11-06 17:06:47,r p animeganv face portrait v ,"['animeganv', 'face', 'portrait']",,,,
jybogw,[P] Vscode extension that automatically creates a summary part of Python docstring using CodeBERT,,1605969202.0,1979.0,51.0,/r/MachineLearning/comments/jybogw/p_vscode_extension_that_automatically_creates_a/,https://v.redd.it/jj7gqs1btl061,nlkey2022,MachineLearning,0.99,False,False,False,False,0.0,1745833749.178112,Tech & Programming,14.0,0.0,14.0,Saturday,9.0,November,2020.0,True,0.2732,0.16,0.0,0.84,positive,p vscode extension that automatically creates a summary part of python docstring using codebert,,p vscode extension that automatically creates a summary part of python docstring using codebert ,"vscode, extension, automatically, creates, summary",2020-11-21 14:33:22,p vscode extension that automatically creates a summary part of python docstring using codebert ,"['vscode', 'extension', 'automatically', 'creates', 'summary', 'part', 'python', 'docstring', 'using', 'codebert']",,,,
ia2aob,[R] Vid2Player: Controllable Video Sprites that Behave and Appear like Professional Tennis Players,,1597471374.0,1955.0,46.0,/r/MachineLearning/comments/ia2aob/r_vid2player_controllable_video_sprites_that/,https://v.redd.it/0i4pwldyw3h51,programmerChilli,MachineLearning,0.99,False,False,False,False,0.0,1745833749.600004,Tech & Programming,13.0,0.0,13.0,Saturday,2.0,August,2020.0,True,0.3612,0.185,0.0,0.815,positive,r vidplayer controllable video sprites that behave and appear like professional tennis players,,r vidplayer controllable video sprites that behave and appear like professional tennis players ,"vidplayer, controllable, video, sprite, behave",2020-08-15 06:02:54,r vidplayer controllable video sprites that behave and appear like professional tennis players ,"['vidplayer', 'controllable', 'video', 'sprite', 'behave', 'appear', 'like', 'professional', 'tennis', 'player']",,,,
m47an8,[P] StyleGAN2-ADA trained on cute corgi images <3,,1615645578.0,1943.0,101.0,/r/MachineLearning/comments/m47an8/p_stylegan2ada_trained_on_cute_corgi_images_3/,https://v.redd.it/thn4v9m72tm61,seawee1,MachineLearning,0.98,False,False,False,False,0.0,1745833749.997981,Tech & Programming,8.0,0.0,7.0,Saturday,9.0,March,2021.0,True,0.4588,0.375,0.0,0.625,positive,p styleganada trained on cute corgi images,,p styleganada trained on cute corgi images ,"styleganada, trained, cute, corgi, image",2021-03-13 14:26:18,p styleganada trained on cute corgi images ,"['styleganada', 'trained', 'cute', 'corgi', 'image']",,,,
10ch0kw,"[P] I built an app that allows you to build Image Classifiers completely on your phone. Collect data, Train models, and Preview the predictions in realtime. You can also export the model/dataset to be used anywhere else. Would love some feedback.",,1673780232.0,1934.0,90.0,/r/MachineLearning/comments/10ch0kw/p_i_built_an_app_that_allows_you_to_build_image/,https://v.redd.it/hmcafqoit6ca1,Playgroundai,MachineLearning,0.97,False,False,False,False,0.0,1745833750.471133,Tech & Programming,41.0,0.0,41.0,Sunday,5.0,January,2023.0,True,0.6369,0.1,0.0,0.9,positive,p i built an app that allows you to build image classifiers completely on your phone collect data train models and preview the predictions in realtime you can also export the modeldataset to be used anywhere else would love some feedback,,p i built an app that allows you to build image classifiers completely on your phone collect data train models and preview the predictions in realtime you can also export the modeldataset to be used anywhere else would love some feedback ,"built, app, allows, build, image",2023-01-15 10:57:12,p i built an app that allows you to build image classifiers completely on your phone collect data train models and preview the predictions in realtime you can also export the modeldataset to be used anywhere else would love some feedback ,"['built', 'app', 'allows', 'build', 'image', 'classifier', 'completely', 'phone', 'collect', 'data', 'train', 'model', 'preview', 'prediction', 'realtime', 'also', 'export', 'modeldataset', 'used', 'anywhere', 'else', 'would', 'love', 'feedback']",,,,
thsx8t,[P] DeepForSpeed: A self driving car in Need For Speed Most Wanted with just a single ConvNet to play ( inspired by nvidia ),,1647687886.0,1876.0,59.0,/r/MachineLearning/comments/thsx8t/p_deepforspeed_a_self_driving_car_in_need_for/,https://v.redd.it/8rvzkfvsnbo81,toxickettle,MachineLearning,0.98,False,False,False,False,0.0,1745833751.247945,Tech & Programming,24.0,0.0,22.0,Saturday,7.0,March,2022.0,True,0.6808,0.248,0.0,0.752,positive,p deepforspeed a self driving car in need for speed most wanted with just a single convnet to play inspired by nvidia,,p deepforspeed a self driving car in need for speed most wanted with just a single convnet to play inspired by nvidia ,"deepforspeed, self, driving, car, need",2022-03-19 11:04:46,p deepforspeed a self driving car in need for speed most wanted with just a single convnet to play inspired by nvidia ,"['deepforspeed', 'self', 'driving', 'car', 'need', 'speed', 'wanted', 'single', 'convnet', 'play', 'inspired', 'nvidia']",,,,
yaqlvi,"[R][P] Runway Stable Diffusion Inpainting: Erase and Replace, add a mask and text prompt to replace objects in an image",,1666452408.0,1872.0,86.0,/r/MachineLearning/comments/yaqlvi/rp_runway_stable_diffusion_inpainting_erase_and/,https://v.redd.it/6isr7b7mjdv91,Illustrious_Row_9971,MachineLearning,0.98,False,False,False,False,0.0,1745833751.965103,Tech & Programming,20.0,0.0,20.0,Saturday,11.0,October,2022.0,True,0.296,0.109,0.0,0.891,positive,rp runway stable diffusion inpainting erase and replace add a mask and text prompt to replace objects in an image,,rp runway stable diffusion inpainting erase and replace add a mask and text prompt to replace objects in an image ,"replace, runway, stable, diffusion, inpainting",2022-10-22 15:26:48,rp runway stable diffusion inpainting erase and replace add a mask and text prompt to replace objects in an image ,"['runway', 'stable', 'diffusion', 'inpainting', 'erase', 'replace', 'add', 'mask', 'text', 'prompt', 'replace', 'object', 'image']",,,,
uks8zr,"[N] Ian Goodfellow, Apple’s director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said “I believe strongly that more flexibility would have been the best policy for my team.” He was likely the company’s most cited ML expert.",,1651977158.0,1839.0,203.0,/r/MachineLearning/comments/uks8zr/n_ian_goodfellow_apples_director_of_machine/,https://twitter.com/zoeschiffer/status/1523017143939309568,hardmaru,MachineLearning,0.98,False,False,False,False,0.0,1745833752.527358,Tech & Programming,50.0,0.0,50.0,Saturday,22.0,May,2022.0,True,0.8399,0.17,0.0,0.83,positive,n ian goodfellow apples director of machine learning is leaving the company due to its return to work policy in a note to staff he said i believe strongly that more flexibility would have been the best policy for my team he was likely the companys most cited ml expert,,n ian goodfellow apples director of machine learning is leaving the company due to its return to work policy in a note to staff he said i believe strongly that more flexibility would have been the best policy for my team he was likely the companys most cited ml expert ,"company, policy, ian, goodfellow, apple",2022-05-08 02:32:38,n ian goodfellow apples director of machine learning is leaving the company due to its return to work policy in a note to staff he said i believe strongly that more flexibility would have been the best policy for my team he was likely the companys most cited ml expert ,"['ian', 'goodfellow', 'apple', 'director', 'machine', 'learning', 'leaving', 'company', 'due', 'return', 'work', 'policy', 'note', 'staff', 'said', 'believe', 'strongly', 'flexibility', 'would', 'best', 'policy', 'team', 'likely', 'company', 'cited', 'expert']",,,,
j0btow,[P] Toonifying a photo using StyleGAN model blending and then animating with First Order Motion. Process and variations in comments.,,1601147326.0,1841.0,91.0,/r/MachineLearning/comments/j0btow/p_toonifying_a_photo_using_stylegan_model/,https://v.redd.it/b2rl2edfjjp51,AtreveteTeTe,MachineLearning,0.97,False,False,False,False,0.0,1745833766.241642,Tech & Programming,20.0,0.0,20.0,Saturday,15.0,September,2020.0,True,0.0,0.0,0.0,1.0,neutral,p toonifying a photo using stylegan model blending and then animating with first order motion process and variations in comments,,p toonifying a photo using stylegan model blending and then animating with first order motion process and variations in comments ,"toonifying, photo, using, stylegan, model",2020-09-26 19:08:46,p toonifying a photo using stylegan model blending and then animating with first order motion process and variations in comments ,"['toonifying', 'photo', 'using', 'stylegan', 'model', 'blending', 'animating', 'first', 'order', 'motion', 'process', 'variation', 'comment']",,,,
ro2567,[R] JoJoGAN: One Shot Face Stylization,,1640405697.0,1806.0,51.0,/r/MachineLearning/comments/ro2567/r_jojogan_one_shot_face_stylization/,https://i.redd.it/r4dtd7cs6m781.png,Illustrious_Row_9971,MachineLearning,0.96,False,False,False,False,0.0,1745833766.90489,Tech & Programming,6.0,0.0,6.0,Friday,23.0,December,2021.0,False,0.0,0.0,0.0,1.0,neutral,r jojogan one shot face stylization,,r jojogan one shot face stylization ,"jojogan, one, shot, face, stylization",2021-12-25 04:14:57,r jojogan one shot face stylization ,"['jojogan', 'one', 'shot', 'face', 'stylization']",,,,
g6og9l,[P] I trained a recurrent neural network trained to draw dick doodles,"# DICK-RNN

A recurrent neural network trained to draw dicks.

Demo: https://dickrnn.github.io/

GitHub: https://github.com/dickrnn/dickrnn.github.io/

This project is a fork of Google's [sketch-rnn demo](https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html). The methodology is described in this [paper](https://arxiv.org/abs/1704.03477), and the dataset used for training is based on [Quickdraw-appendix](https://github.com/studiomoniker/Quickdraw-appendix).

# Why?

From Studio Moniker's [Quickdraw-appendix](https://studiomoniker.com/projects/do-not-draw-a-penis) project:

*In 2018 Google open-sourced the [Quickdraw data set](https://github.com/googlecreativelab/quickdraw-dataset). “The world's largest doodling data set”. The set consists of 345 categories and over 50 million drawings. For obvious reasons the data set was missing a few specific categories that people seem to enjoy drawing. This made us at Moniker think about the moral reality big tech companies are imposing on our global community and that most people willingly accept this. Therefore we decided to publish an appendix to the Google Quickdraw data set.*

I also believe that [“Doodling a penis is a light-hearted symbol for a rebellious act”](https://www.theverge.com/tldr/2019/6/17/18681733/google-ai-doodle-detector-penis-protest-moniker-mozilla) and also “think our moral compasses should not be in the hands of big tech”.

# Dick Demos

[Main Dick Demo](https://dickrnn.github.io/)

[Predict Multiple Dicks](https://dickrnn.github.io/multi.html)

[Simple Dick Demo](https://dickrnn.github.io/simple.html)

[Predict Single Dick with Temperature Adjust](https://dickrnn.github.io/predict.html)

## Example Dicks from Main Demo

The dicks are embedded in the query string after `share.html`.

Examples of sharable generated dick doodles:

[Example 1](https://dickrnn.github.io/share.html?s=f38BfXcBe3wBeHsBfH4BfX4Bdn8BfIMBdogBfIYBfYgBfogBf40BgYYBg4YBhocBiYcBhIEBlX8BhHsBg3oBgnoBgXoBgHsBf3wBf48BiowBhIQBhIIBhoABhn8Bhn4Bh3gBjHABgnoBgXsBgHsBgHoBf3IBfXgBfXsBeHYBe30Ban8BfoABfYABe4AAW2kBf2wBf2QBf24Bf2wBgHUBf3EBgHIBgHkBgHkBgnQBgXsBgnkBgXwBgnwBgX8BgoABg4EBg4IBgoQBgYMBgYMBgokBgJABf74BfosBfYYBfogBfoUBf5MBf4sBgIIAVwABgIIBgIIBgYEBgIEBgn8BiYABhX8BhX4Bgn8Bg34BgX8Bg34BgH8Bf34Bgn0AZFMBgYUBgIMBgIEBf4MBgIIBf4MAf2cBf30BgXoBgngBg3gBhHgBhHoAhXgBgncBg3sBinYBiHoAWb8Bfn8Bf38BgX8Bgn4BhH8Bhn8BjYEBh4MBhoMAMXAA)

[Example 2](https://dickrnn.github.io/share.html?s=f38BfnYBe3sBensBeX0BeX4Bdn8BfIEBfoMBfYQBfoUBf48BgIgBhIgBiosBhIABg4ABgn4Bg3wBhXkBfX8Be4IBe4MBe4QBfYUBfoQBf4kBgIUBg4YBhIUBhYMBhIABhIABhX4BhXoBhHoBg3kBgncBgHcBgHkBf3sBfn0BfX4Bfn8Bfn4BfX4Bfn4BfX4Aa0gBhHwBhnsBiXkBiXsBinsBlHkBjXsBi3wBiX0BiX4Bh34Bjn4BiX8BhX4Bg38BhX8BhX8BgH8BgH8BgYABgIABgIEBgH8BgYABgIEBgoMBgIEBgIEBgYMBgIIBgYUBf4MBfoUBfYEBfIEBdYQBd4IBb4MBeIABd4EBd4EBZoQBbYUBdoIBd4IBeoEBdYIBeIEBeoABe4EBe4EBfYABfYABfn8BfoABfoABf38Bf38A/ikBf38Bf38Bf4EBf4QBgIQBgYMBgIEBgoMBgIEBgoQBgYEBgIEBgYEBgYEBf38Bf38Bf4AAhmsBf38Bf4ABf38Bf38Bf38Bf38Bf34Bf38Bf34Bf38Bf34Bfn8Bf38AipkA)

[Example 3](https://dickrnn.github.io/share.html?s=f38Bh30BjH8BkIMBjYQBhoQBgIgBf4sBe40BeoYBeoUBeoIBeIEBd4ABd38BdnkBeXkBe3cBe3UBfHUBenMBgn0BhH0BhHsBgn0AxocBgH8Bgn4BjHwBiH0BhX8Bgn8Bh4IBhYQBhoUBhYcBhIgBgYYBf4YBf4cBf4EBfIMBeoMBdoMBdYEBdoABd38BeH0Bd3sBensBdXEBfHcBfXcBfngBf3gAcmEBf34BgX4BgXsBgXgBgXIBgHcBgWYBgHUBf3UBgHABf3oBfnsBfnsBfnoBf30BgHwBgXsBgX0BgnwBg3wBiHoBiHsBgn4Bg38BhX8BgYABgoEBgYIBgIIBgYcBgYkBgIQBf4YBf4QBf4kBf4UBf4QBf4MBf4MBf4QBf4QBf4QBfoUBfYQBfoUBf4IBfYcBfYoBf4IBfoYBfoMBfoMBf4EAbAABf4MBf4EBf4IBf4ABfoMBf38Bf4AAfH0BgX8Bk4IBg4ABgn8BgoABgoAASrIA)

[Example 4](https://dickrnn.github.io/share.html?s=f38BZn8BdIUBdokBeo0BfY8BfpQBhY4BiowBj4YBkIEBlH8BjHkBi3IBiXEBgnUBgXkBf6YBgYwBhYkBi4gBjYIBjIEBi38BiHkBh3UBg3MBgm0BgXIBfnMBenUBenkBdXUAAEcBhH8BhXkBiXgBi3IBkG4BkHEBk28Bk3IBnmYBi3gBi3oBk3kBiX8BioIBjYkBh4kBhYwBgYkBgY0BfY4BdZEBc48Bd4gBd4cBcYoBd4UAMDEBf4EBgoABiocBk4gBlIUBjX8Bh34BhXoAZEMBe3wBfHsBfH4BfX0BfX0AtJQBin8BhX0BhX8Bf34AqHoBf30BgX4BhXIBgn0BinUAhXoBfn8BhH4Bj3oBlXgBjH8BjYMAkKUBhH8BloQBh4IBjYUAapkBjXkBpHoBkH8Ac8YBhYcBhocBiYsBh4sBhIgARGgA)

# Dataset

This recurrent neural network was trained on a [dataset](https://github.com/studiomoniker/Quickdraw-appendix) of roughly 10,000 dick doodles.",1587654906.0,1787.0,118.0,/r/MachineLearning/comments/g6og9l/p_i_trained_a_recurrent_neural_network_trained_to/,https://www.reddit.com/r/MachineLearning/comments/g6og9l/p_i_trained_a_recurrent_neural_network_trained_to/,RichardRNN,MachineLearning,0.96,True,True,False,False,0.0,1745833767.314611,Tech & Programming,12.0,223.0,220.0,Thursday,11.0,April,2020.0,False,-0.9586,0.038,0.124,0.838,negative,p i trained a recurrent neural network trained to draw dick doodles,dickrnn a recurrent neural network trained to draw dicks demo github this project is a fork of googles sketchrnn demo the methodology is described in this paper and the dataset used for training is based on quickdrawappendix why from studio monikers quickdrawappendix project in google opensourced the quickdraw data set the worlds largest doodling data set the set consists of categories and over million drawings for obvious reasons the data set was missing a few specific categories that people seem to enjoy drawing this made us at moniker think about the moral reality big tech companies are imposing on our global community and that most people willingly accept this therefore we decided to publish an appendix to the google quickdraw data set i also believe that doodling a penis is a lighthearted symbol for a rebellious act and also think our moral compasses should not be in the hands of big tech dick demos main dick demo predict multiple dicks simple dick demo predict single dick with temperature adjust example dicks from main demo the dicks are embedded in the query string after sharehtml examples of sharable generated dick doodles example example example example dataset this recurrent neural network was trained on a dataset of roughly dick doodles,p i trained a recurrent neural network trained to draw dick doodles dickrnn a recurrent neural network trained to draw dicks demo github this project is a fork of googles sketchrnn demo the methodology is described in this paper and the dataset used for training is based on quickdrawappendix why from studio monikers quickdrawappendix project in google opensourced the quickdraw data set the worlds largest doodling data set the set consists of categories and over million drawings for obvious reasons the data set was missing a few specific categories that people seem to enjoy drawing this made us at moniker think about the moral reality big tech companies are imposing on our global community and that most people willingly accept this therefore we decided to publish an appendix to the google quickdraw data set i also believe that doodling a penis is a lighthearted symbol for a rebellious act and also think our moral compasses should not be in the hands of big tech dick demos main dick demo predict multiple dicks simple dick demo predict single dick with temperature adjust example dicks from main demo the dicks are embedded in the query string after sharehtml examples of sharable generated dick doodles example example example example dataset this recurrent neural network was trained on a dataset of roughly dick doodles,"dick, demo, example, set, trained",2020-04-23 15:15:06,p i trained a recurrent neural network trained to draw dick doodles dickrnn a recurrent neural network trained to draw dicks demo github this project is a fork of googles sketchrnn demo the methodology is described in this paper and the dataset used for training is based on quickdrawappendix why from studio monikers quickdrawappendix project in google opensourced the quickdraw data set the worlds largest doodling data set the set consists of categories and over million drawings for obvious reasons the data set was missing a few specific categories that people seem to enjoy drawing this made us at moniker think about the moral reality big tech companies are imposing on our global community and that most people willingly accept this therefore we decided to publish an appendix to the google quickdraw data set i also believe that doodling a penis is a lighthearted symbol for a rebellious act and also think our moral compasses should not be in the hands of big tech dick demos main dick demo predict multiple dicks simple dick demo predict single dick with temperature adjust example dicks from main demo the dicks are embedded in the query string after sharehtml examples of sharable generated dick doodles example example example example dataset this recurrent neural network was trained on a dataset of roughly dick doodles,"['trained', 'recurrent', 'neural', 'network', 'trained', 'draw', 'dick', 'doodle', 'dickrnn', 'recurrent', 'neural', 'network', 'trained', 'draw', 'dick', 'demo', 'github', 'project', 'fork', 'google', 'sketchrnn', 'demo', 'methodology', 'described', 'paper', 'dataset', 'used', 'training', 'based', 'quickdrawappendix', 'studio', 'moniker', 'quickdrawappendix', 'project', 'google', 'opensourced', 'quickdraw', 'data', 'set', 'world', 'largest', 'doodling', 'data', 'set', 'set', 'consists', 'category', 'million', 'drawing', 'obvious', 'reason', 'data', 'set', 'missing', 'specific', 'category', 'people', 'seem', 'enjoy', 'drawing', 'made', 'moniker', 'think', 'moral', 'reality', 'big', 'tech', 'company', 'imposing', 'global', 'community', 'people', 'willingly', 'accept', 'therefore', 'decided', 'publish', 'appendix', 'google', 'quickdraw', 'data', 'set', 'also', 'believe', 'doodling', 'penis', 'lighthearted', 'symbol', 'rebellious', 'act', 'also', 'think', 'moral', 'compass', 'hand', 'big', 'tech', 'dick', 'demo', 'main', 'dick', 'demo', 'predict', 'multiple', 'dick', 'simple', 'dick', 'demo', 'predict', 'single', 'dick', 'temperature', 'adjust', 'example', 'dick', 'main', 'demo', 'dick', 'embedded', 'query', 'string', 'sharehtml', 'example', 'sharable', 'generated', 'dick', 'doodle', 'example', 'example', 'example', 'example', 'dataset', 'recurrent', 'neural', 'network', 'trained', 'dataset', 'roughly', 'dick', 'doodle']",,,,
ijkkbb,"[P] Cross-Model Interpolations between 5 StyleGanV2 models - furry, FFHQ, anime, ponies, and a fox model",,1598821637.0,1788.0,104.0,/r/MachineLearning/comments/ijkkbb/p_crossmodel_interpolations_between_5_styleganv2/,https://v.redd.it/47g1f9cuf7k51,programmerChilli,MachineLearning,0.97,False,False,False,False,0.0,1745833767.979227,Tech & Programming,16.0,0.0,14.0,Sunday,17.0,August,2020.0,True,0.0,0.0,0.0,1.0,neutral,p crossmodel interpolations between styleganv models furry ffhq anime ponies and a fox model,,p crossmodel interpolations between styleganv models furry ffhq anime ponies and a fox model ,"model, crossmodel, interpolation, styleganv, furry",2020-08-30 21:07:17,p crossmodel interpolations between styleganv models furry ffhq anime ponies and a fox model ,"['crossmodel', 'interpolation', 'styleganv', 'model', 'furry', 'ffhq', 'anime', 'pony', 'fox', 'model']",,,,
xtd8kc,[P] stablediffusion-infinity: Outpainting with Stable Diffusion on an infinite canvas,,1664678098.0,1761.0,60.0,/r/MachineLearning/comments/xtd8kc/p_stablediffusioninfinity_outpainting_with_stable/,https://v.redd.it/w00lkjcl0br91,Illustrious_Row_9971,MachineLearning,0.98,False,False,False,False,0.0,1745833768.705527,Tech & Programming,10.0,0.0,10.0,Saturday,22.0,October,2022.0,True,0.296,0.216,0.0,0.784,positive,p stablediffusioninfinity outpainting with stable diffusion on an infinite canvas,,p stablediffusioninfinity outpainting with stable diffusion on an infinite canvas ,"stablediffusioninfinity, outpainting, stable, diffusion, infinite",2022-10-02 02:34:58,p stablediffusioninfinity outpainting with stable diffusion on an infinite canvas ,"['stablediffusioninfinity', 'outpainting', 'stable', 'diffusion', 'infinite', 'canvas']",,,,
w6kj9y,[R] WHIRL algorithm: Robot performs diverse household tasks via exploration after watching one human video (link in comments),,1658628802.0,1745.0,69.0,/r/MachineLearning/comments/w6kj9y/r_whirl_algorithm_robot_performs_diverse/,https://v.redd.it/0bp98qjkcfd91,pathak22,MachineLearning,0.99,False,False,False,False,0.0,1745833769.173043,Tech & Programming,18.0,0.0,18.0,Saturday,22.0,July,2022.0,True,0.2263,0.106,0.0,0.894,positive,r whirl algorithm robot performs diverse household tasks via exploration after watching one human video link in comments,,r whirl algorithm robot performs diverse household tasks via exploration after watching one human video link in comments ,"whirl, algorithm, robot, performs, diverse",2022-07-24 02:13:22,r whirl algorithm robot performs diverse household tasks via exploration after watching one human video link in comments ,"['whirl', 'algorithm', 'robot', 'performs', 'diverse', 'household', 'task', 'via', 'exploration', 'watching', 'one', 'human', 'video', 'link', 'comment']",,,,
v5f8et,[R] It’s wild to see an AI literally eyeballing raytracing based on 100 photos to create a 3d scene you can step inside ☀️ Low key getting addicted to NeRF-ing imagery datasets🤩,,1654441554.0,1751.0,82.0,/r/MachineLearning/comments/v5f8et/r_its_wild_to_see_an_ai_literally_eyeballing/,https://v.redd.it/xxp22yx9it391,imaginfinity,MachineLearning,0.98,False,False,False,False,0.0,1745833769.682244,Tech & Programming,32.0,0.0,30.0,Sunday,11.0,June,2022.0,True,0.0,0.072,0.072,0.856,neutral,r its wild to see an ai literally eyeballing raytracing based on photos to create a d scene you can step inside low key getting addicted to nerfing imagery datasets,,r its wild to see an ai literally eyeballing raytracing based on photos to create a d scene you can step inside low key getting addicted to nerfing imagery datasets ,"wild, see, literally, eyeballing, raytracing",2022-06-05 15:05:54,r its wild to see an ai literally eyeballing raytracing based on photos to create a d scene you can step inside low key getting addicted to nerfing imagery datasets ,"['wild', 'see', 'literally', 'eyeballing', 'raytracing', 'based', 'photo', 'create', 'scene', 'step', 'inside', 'low', 'key', 'getting', 'addicted', 'nerfing', 'imagery', 'datasets']",,,,
p6hsoh,"[P] AppleNeuralHash2ONNX: Reverse-Engineered Apple NeuralHash, in ONNX and Python","As you may already know Apple is going to implement NeuralHash algorithm for on-device [CSAM detection](https://www.apple.com/child-safety/pdf/CSAM_Detection_Technical_Summary.pdf) soon. Believe it or not, this algorithm already exists as early as iOS 14.3, hidden under obfuscated class names. After some digging and reverse engineering on the hidden APIs I managed to export its model (which is MobileNetV3) to ONNX and rebuild the whole NeuralHash algorithm in Python. You can now try NeuralHash even on Linux!

Source code: [https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX](https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX)

No pre-exported model file will be provided here for obvious reasons. But it's very easy to export one yourself following the guide I included with the repo above. You don't even need any Apple devices to do it.

Early tests show that it can tolerate image resizing and compression, but not cropping or rotations.

Hope this will help us understand NeuralHash algorithm better and know its potential issues before it's enabled on all iOS devices.

Happy hacking!",1629252231.0,1738.0,223.0,/r/MachineLearning/comments/p6hsoh/p_appleneuralhash2onnx_reverseengineered_apple/,https://www.reddit.com/r/MachineLearning/comments/p6hsoh/p_appleneuralhash2onnx_reverseengineered_apple/,AsuharietYgvar,MachineLearning,0.99,True,False,False,False,5.0,1745833770.263324,Tech & Programming,9.0,152.0,159.0,Tuesday,22.0,August,2021.0,False,0.9682,0.12,0.009,0.871,positive,p appleneuralhashonnx reverseengineered apple neuralhash in onnx and python,as you may already know apple is going to implement neuralhash algorithm for ondevice csam detection soon believe it or not this algorithm already exists as early as ios hidden under obfuscated class names after some digging and reverse engineering on the hidden apis i managed to export its model which is mobilenetv to onnx and rebuild the whole neuralhash algorithm in python you can now try neuralhash even on linux source code no preexported model file will be provided here for obvious reasons but its very easy to export one yourself following the guide i included with the repo above you dont even need any apple devices to do it early tests show that it can tolerate image resizing and compression but not cropping or rotations hope this will help us understand neuralhash algorithm better and know its potential issues before its enabled on all ios devices happy hacking,p appleneuralhashonnx reverseengineered apple neuralhash in onnx and python as you may already know apple is going to implement neuralhash algorithm for ondevice csam detection soon believe it or not this algorithm already exists as early as ios hidden under obfuscated class names after some digging and reverse engineering on the hidden apis i managed to export its model which is mobilenetv to onnx and rebuild the whole neuralhash algorithm in python you can now try neuralhash even on linux source code no preexported model file will be provided here for obvious reasons but its very easy to export one yourself following the guide i included with the repo above you dont even need any apple devices to do it early tests show that it can tolerate image resizing and compression but not cropping or rotations hope this will help us understand neuralhash algorithm better and know its potential issues before its enabled on all ios devices happy hacking,"neuralhash, algorithm, apple, onnx, python",2021-08-18 02:03:51,p appleneuralhashonnx reverseengineered apple neuralhash in onnx and python as you may already know apple is going to implement neuralhash algorithm for ondevice csam detection soon believe it or not this algorithm already exists as early as ios hidden under obfuscated class names after some digging and reverse engineering on the hidden apis i managed to export its model which is mobilenetv to onnx and rebuild the whole neuralhash algorithm in python you can now try neuralhash even on linux source code no preexported model file will be provided here for obvious reasons but its very easy to export one yourself following the guide i included with the repo above you dont even need any apple devices to do it early tests show that it can tolerate image resizing and compression but not cropping or rotations hope this will help us understand neuralhash algorithm better and know its potential issues before its enabled on all ios devices happy hacking,"['appleneuralhashonnx', 'reverseengineered', 'apple', 'neuralhash', 'onnx', 'python', 'may', 'already', 'know', 'apple', 'going', 'implement', 'neuralhash', 'algorithm', 'ondevice', 'csam', 'detection', 'soon', 'believe', 'algorithm', 'already', 'exists', 'early', 'io', 'hidden', 'obfuscated', 'class', 'name', 'digging', 'reverse', 'engineering', 'hidden', 'apis', 'managed', 'export', 'model', 'mobilenetv', 'onnx', 'rebuild', 'whole', 'neuralhash', 'algorithm', 'python', 'try', 'neuralhash', 'even', 'linux', 'source', 'code', 'preexported', 'model', 'file', 'provided', 'obvious', 'reason', 'easy', 'export', 'one', 'following', 'guide', 'included', 'repo', 'dont', 'even', 'need', 'apple', 'device', 'early', 'test', 'show', 'tolerate', 'image', 'resizing', 'compression', 'cropping', 'rotation', 'hope', 'help', 'understand', 'neuralhash', 'algorithm', 'better', 'know', 'potential', 'issue', 'enabled', 'io', 'device', 'happy', 'hacking']",,,,
8n04hp,[P] Realtime multihand pose estimation demo,,1527608824.0,1726.0,128.0,/r/MachineLearning/comments/8n04hp/p_realtime_multihand_pose_estimation_demo/,https://media.giphy.com/media/RIX4ApOoVr5LmikK7K/giphy.gif,alexeykurov,MachineLearning,0.96,False,False,False,False,0.0,1745833771.509597,Tech & Programming,6.0,0.0,6.0,Tuesday,11.0,May,2018.0,False,0.0,0.0,0.0,1.0,neutral,p realtime multihand pose estimation demo,,p realtime multihand pose estimation demo ,"realtime, multihand, pose, estimation, demo",2018-05-29 15:47:04,p realtime multihand pose estimation demo ,"['realtime', 'multihand', 'pose', 'estimation', 'demo']",,,,
uyratt,"[D] I don't really trust papers out of ""Top Labs"" anymore","I mean, I trust that the numbers they got are accurate and that they really did the work and got the results. I believe those. It's just that, take the recent ""An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems"" paper. It's 18 pages of talking through this pretty convoluted evolutionary and multitask learning algorithm, it's pretty interesting, solves a bunch of problems. But two notes. 

One, the big number they cite as the success metric is 99.43 on CIFAR-10, against a SotA of 99.40, so woop-de-fucking-doo in the grand scheme of things.

Two, there's a chart towards the end of the paper that details how many TPU core-hours were used for just the training regimens that results in the final results. The sum total is 17,810 core-hours. Let's assume that for someone who doesn't work at Google, you'd have to use on-demand pricing of $3.22/hr. This means that these trained models cost $57,348. 

Strictly speaking, throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance, so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a pre-existing model, there's a meta-textual level on which this paper is just ""Jeff Dean spent enough money to feed a family of four for half a decade to get a 0.03% improvement on CIFAR-10.""

OpenAI is far and away the worst offender here, but it seems like everyone's doing it. You throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks, and then if your numbers are infinitesimally higher than their numbers, you get to put a lil' sticker on your CV. Why should I trust that your ideas are even any good? I can't check them, I can't apply them to my own projects. 

Is this really what we're comfortable with as a community? A handful of corporations and the occasional university waving their dicks at everyone because they've got the compute to burn and we don't? There's a level at which I think there should be a new journal, exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer GPU.",1653630414.0,1697.0,262.0,/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/,https://www.reddit.com/r/MachineLearning/comments/uyratt/d_i_dont_really_trust_papers_out_of_top_labs/,MrAcurite,MachineLearning,0.97,True,False,False,False,1.0,1745833772.303457,Tech & Programming,11.0,401.0,406.0,Friday,1.0,May,2022.0,False,0.9771,0.115,0.052,0.834,positive,d i dont really trust papers out of top labs anymore,i mean i trust that the numbers they got are accurate and that they really did the work and got the results i believe those its just that take the recent an evolutionary approach to dynamic introduction of tasks in largescale multitask learning systems paper its pages of talking through this pretty convoluted evolutionary and multitask learning algorithm its pretty interesting solves a bunch of problems but two notes one the big number they cite as the success metric is on cifar against a sota of so woopdefuckingdoo in the grand scheme of things two theres a chart towards the end of the paper that details how many tpu corehours were used for just the training regimens that results in the final results the sum total is corehours lets assume that for someone who doesnt work at google youd have to use ondemand pricing of hr this means that these trained models cost strictly speaking throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a preexisting model theres a metatextual level on which this paper is just jeff dean spent enough money to feed a family of four for half a decade to get a improvement on cifar openai is far and away the worst offender here but it seems like everyones doing it you throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks and then if your numbers are infinitesimally higher than their numbers you get to put a lil sticker on your cv why should i trust that your ideas are even any good i cant check them i cant apply them to my own projects is this really what were comfortable with as a community a handful of corporations and the occasional university waving their dicks at everyone because theyve got the compute to burn and we dont theres a level at which i think there should be a new journal exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer gpu,d i dont really trust papers out of top labs anymore i mean i trust that the numbers they got are accurate and that they really did the work and got the results i believe those its just that take the recent an evolutionary approach to dynamic introduction of tasks in largescale multitask learning systems paper its pages of talking through this pretty convoluted evolutionary and multitask learning algorithm its pretty interesting solves a bunch of problems but two notes one the big number they cite as the success metric is on cifar against a sota of so woopdefuckingdoo in the grand scheme of things two theres a chart towards the end of the paper that details how many tpu corehours were used for just the training regimens that results in the final results the sum total is corehours lets assume that for someone who doesnt work at google youd have to use ondemand pricing of hr this means that these trained models cost strictly speaking throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a preexisting model theres a metatextual level on which this paper is just jeff dean spent enough money to feed a family of four for half a decade to get a improvement on cifar openai is far and away the worst offender here but it seems like everyones doing it you throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks and then if your numbers are infinitesimally higher than their numbers you get to put a lil sticker on your cv why should i trust that your ideas are even any good i cant check them i cant apply them to my own projects is this really what were comfortable with as a community a handful of corporations and the occasional university waving their dicks at everyone because theyve got the compute to burn and we dont theres a level at which i think there should be a new journal exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer gpu,"paper, number, result, really, trust",2022-05-27 05:46:54,d i dont really trust papers out of top labs anymore i mean i trust that the numbers they got are accurate and that they really did the work and got the results i believe those its just that take the recent an evolutionary approach to dynamic introduction of tasks in largescale multitask learning systems paper its pages of talking through this pretty convoluted evolutionary and multitask learning algorithm its pretty interesting solves a bunch of problems but two notes one the big number they cite as the success metric is on cifar against a sota of so woopdefuckingdoo in the grand scheme of things two theres a chart towards the end of the paper that details how many tpu corehours were used for just the training regimens that results in the final results the sum total is corehours lets assume that for someone who doesnt work at google youd have to use ondemand pricing of hr this means that these trained models cost strictly speaking throwing enough compute at a general enough genetic algorithm will eventually produce arbitrarily good performance so while you can absolutely read this paper and collect interesting ideas about how to use genetic algorithms to accomplish multitask learning by having each new task leverage learned weights from previous tasks by defining modifications to a subset of components of a preexisting model theres a metatextual level on which this paper is just jeff dean spent enough money to feed a family of four for half a decade to get a improvement on cifar openai is far and away the worst offender here but it seems like everyones doing it you throw a fuckton of compute and a light ganache of new ideas at an existing problem with existing data and existing benchmarks and then if your numbers are infinitesimally higher than their numbers you get to put a lil sticker on your cv why should i trust that your ideas are even any good i cant check them i cant apply them to my own projects is this really what were comfortable with as a community a handful of corporations and the occasional university waving their dicks at everyone because theyve got the compute to burn and we dont theres a level at which i think there should be a new journal exclusively for papers in which you can replicate their experimental results in under eight hours on a single consumer gpu,"['dont', 'really', 'trust', 'paper', 'top', 'lab', 'anymore', 'mean', 'trust', 'number', 'got', 'accurate', 'really', 'work', 'got', 'result', 'believe', 'take', 'recent', 'evolutionary', 'approach', 'dynamic', 'introduction', 'task', 'largescale', 'multitask', 'learning', 'system', 'paper', 'page', 'talking', 'pretty', 'convoluted', 'evolutionary', 'multitask', 'learning', 'algorithm', 'pretty', 'interesting', 'solves', 'bunch', 'problem', 'two', 'note', 'one', 'big', 'number', 'cite', 'success', 'metric', 'cifar', 'sota', 'woopdefuckingdoo', 'grand', 'scheme', 'thing', 'two', 'there', 'chart', 'towards', 'end', 'paper', 'detail', 'many', 'tpu', 'corehours', 'used', 'training', 'regimen', 'result', 'final', 'result', 'sum', 'total', 'corehours', 'let', 'assume', 'someone', 'doesnt', 'work', 'google', 'youd', 'use', 'ondemand', 'pricing', 'mean', 'trained', 'model', 'cost', 'strictly', 'speaking', 'throwing', 'enough', 'compute', 'general', 'enough', 'genetic', 'algorithm', 'eventually', 'produce', 'arbitrarily', 'good', 'performance', 'absolutely', 'read', 'paper', 'collect', 'interesting', 'idea', 'use', 'genetic', 'algorithm', 'accomplish', 'multitask', 'learning', 'new', 'task', 'leverage', 'learned', 'weight', 'previous', 'task', 'defining', 'modification', 'subset', 'component', 'preexisting', 'model', 'there', 'metatextual', 'level', 'paper', 'jeff', 'dean', 'spent', 'enough', 'money', 'feed', 'family', 'four', 'half', 'decade', 'get', 'improvement', 'cifar', 'openai', 'far', 'away', 'worst', 'offender', 'seems', 'like', 'everyones', 'throw', 'fuckton', 'compute', 'light', 'ganache', 'new', 'idea', 'existing', 'problem', 'existing', 'data', 'existing', 'benchmark', 'number', 'infinitesimally', 'higher', 'number', 'get', 'put', 'lil', 'sticker', 'trust', 'idea', 'even', 'good', 'cant', 'check', 'cant', 'apply', 'project', 'really', 'comfortable', 'community', 'handful', 'corporation', 'occasional', 'university', 'waving', 'dick', 'everyone', 'theyve', 'got', 'compute', 'burn', 'dont', 'there', 'level', 'think', 'new', 'journal', 'exclusively', 'paper', 'replicate', 'experimental', 'result', 'eight', 'hour', 'single', 'consumer', 'gpu']",,,,
129sqba,[P] I built a chatbot that lets you talk to any Github repository,,1680458268.0,1691.0,155.0,/r/MachineLearning/comments/129sqba/p_i_built_a_chatbot_that_lets_you_talk_to_any/,https://v.redd.it/q1abnbrmfira1,jsonathan,MachineLearning,0.96,False,False,False,False,0.0,1745833773.502195,Tech & Programming,13.0,0.0,13.0,Sunday,13.0,April,2023.0,True,0.0,0.0,0.0,1.0,neutral,p i built a chatbot that lets you talk to any github repository,,p i built a chatbot that lets you talk to any github repository ,"built, chatbot, let, talk, github",2023-04-02 17:57:48,p i built a chatbot that lets you talk to any github repository ,"['built', 'chatbot', 'let', 'talk', 'github', 'repository']",,,,
68y8bb,[R] Deep Image Analogy,,1493785789.0,1689.0,119.0,/r/MachineLearning/comments/68y8bb/r_deep_image_analogy/,https://i.redd.it/4n1j4tvhq7vy.jpg,e_walker,MachineLearning,0.95,False,False,False,False,0.0,1745833774.360299,Tech & Programming,4.0,0.0,4.0,Wednesday,0.0,May,2017.0,False,0.0,0.0,0.0,1.0,neutral,r deep image analogy,,r deep image analogy ,"deep, image, analogy",2017-05-03 04:29:49,r deep image analogy ,"['deep', 'image', 'analogy']",,,,
ugg2bz,[P] The easiest way to process and tag video data,,1651460357.0,1683.0,55.0,/r/MachineLearning/comments/ugg2bz/p_the_easiest_way_to_process_and_tag_video_data/,https://v.redd.it/x6ihjnoa9zw81,happybirthday290,MachineLearning,0.97,False,False,False,False,0.0,1745833774.937316,Tech & Programming,10.0,0.0,10.0,Sunday,22.0,May,2022.0,True,0.4215,0.259,0.0,0.741,positive,p the easiest way to process and tag video data,,p the easiest way to process and tag video data ,"easiest, way, process, tag, video",2022-05-02 02:59:17,p the easiest way to process and tag video data ,"['easiest', 'way', 'process', 'tag', 'video', 'data']",,,,
ggspu2,[P] Pose Animator: SVG animation tool using real-time human perception TensorFlow.js models (links in comments),,1589076165.0,1669.0,31.0,/r/MachineLearning/comments/ggspu2/p_pose_animator_svg_animation_tool_using_realtime/,https://v.redd.it/s6xva1ohhux41,hardmaru,MachineLearning,0.99,False,False,False,False,0.0,1745833775.256934,Tech & Programming,15.0,0.0,15.0,Saturday,22.0,May,2020.0,True,0.0,0.0,0.0,1.0,neutral,p pose animator svg animation tool using realtime human perception tensorflowjs models links in comments,,p pose animator svg animation tool using realtime human perception tensorflowjs models links in comments ,"pose, animator, svg, animation, tool",2020-05-10 02:02:45,p pose animator svg animation tool using realtime human perception tensorflowjs models links in comments ,"['pose', 'animator', 'svg', 'animation', 'tool', 'using', 'realtime', 'human', 'perception', 'tensorflowjs', 'model', 'link', 'comment']",,,,
6l2esd,[D] Why can't you guys comment your fucking code?,"Seriously.

I spent the last few years doing web app development. Dug into DL a couple months ago. Supposedly, compared to the post-post-post-docs doing AI stuff, JavaScript developers should be inbred peasants. But every project these peasants release, even a fucking library that colorizes CLI output, has a catchy name, extensive docs, shitloads of comments, fuckton of tests, semantic versioning, changelog, and, oh my god, better variable names than `ctx_h` or `lang_hs` or `fuck_you_for_trying_to_understand`.

The concepts and ideas behind DL, GANs, LSTMs, CNNs, whatever – it's clear, it's simple, it's intuitive. The slog is to go through the jargon (that keeps changing beneath your feet - what's the point of using fancy words if you can't keep them consistent?), the unnecessary equations, trying to squeeze meaning from bullshit language used in papers, figuring out the super important steps, preprocessing, hyperparameters optimization that the authors, oops, failed to mention.

Sorry for singling out, but [look at this](https://github.com/facebookresearch/end-to-end-negotiator/blob/master/src/agent.py) - what the fuck? If a developer anywhere else at Facebook would get this code for a review they would throw up.

- Do you intentionally try to obfuscate your papers? Is pseudo-code a fucking premium? Can you at least try to give some intuition before showering the reader with equations?

- How the fuck do you dare to release a paper without source code?

- Why the fuck do you never ever add comments to you code?

- When naming things, are you charged by the character? Do you get a bonus for acronyms?

- Do you realize that OpenAI having needed to release a ""baseline"" TRPO implementation is a fucking disgrace to your profession?

- Jesus christ, who decided to name a tensor concatenation function `cat`?
",1499113449.0,1660.0,471.0,/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/,https://www.reddit.com/r/MachineLearning/comments/6l2esd/d_why_cant_you_guys_comment_your_fucking_code/,didntfinishhighschoo,MachineLearning,0.86,True,False,False,False,2.0,1745833775.539268,Tech & Programming,9.0,284.0,284.0,Monday,16.0,July,2017.0,False,-0.8473,0.081,0.107,0.811,negative,d why cant you guys comment your fucking code,seriously i spent the last few years doing web app development dug into dl a couple months ago supposedly compared to the postpostpostdocs doing ai stuff javascript developers should be inbred peasants but every project these peasants release even a fucking library that colorizes cli output has a catchy name extensive docs shitloads of comments fuckton of tests semantic versioning changelog and oh my god better variable names than ctx_h or lang_hs or fuck_you_for_trying_to_understand the concepts and ideas behind dl gans lstms cnns whatever its clear its simple its intuitive the slog is to go through the jargon that keeps changing beneath your feet whats the point of using fancy words if you cant keep them consistent the unnecessary equations trying to squeeze meaning from bullshit language used in papers figuring out the super important steps preprocessing hyperparameters optimization that the authors oops failed to mention sorry for singling out but look at this what the fuck if a developer anywhere else at facebook would get this code for a review they would throw up do you intentionally try to obfuscate your papers is pseudocode a fucking premium can you at least try to give some intuition before showering the reader with equations how the fuck do you dare to release a paper without source code why the fuck do you never ever add comments to you code when naming things are you charged by the character do you get a bonus for acronyms do you realize that openai having needed to release a baseline trpo implementation is a fucking disgrace to your profession jesus christ who decided to name a tensor concatenation function cat,d why cant you guys comment your fucking code seriously i spent the last few years doing web app development dug into dl a couple months ago supposedly compared to the postpostpostdocs doing ai stuff javascript developers should be inbred peasants but every project these peasants release even a fucking library that colorizes cli output has a catchy name extensive docs shitloads of comments fuckton of tests semantic versioning changelog and oh my god better variable names than ctx_h or lang_hs or fuck_you_for_trying_to_understand the concepts and ideas behind dl gans lstms cnns whatever its clear its simple its intuitive the slog is to go through the jargon that keeps changing beneath your feet whats the point of using fancy words if you cant keep them consistent the unnecessary equations trying to squeeze meaning from bullshit language used in papers figuring out the super important steps preprocessing hyperparameters optimization that the authors oops failed to mention sorry for singling out but look at this what the fuck if a developer anywhere else at facebook would get this code for a review they would throw up do you intentionally try to obfuscate your papers is pseudocode a fucking premium can you at least try to give some intuition before showering the reader with equations how the fuck do you dare to release a paper without source code why the fuck do you never ever add comments to you code when naming things are you charged by the character do you get a bonus for acronyms do you realize that openai having needed to release a baseline trpo implementation is a fucking disgrace to your profession jesus christ who decided to name a tensor concatenation function cat,"fucking, code, comment, release, name",2017-07-03 20:24:09,d why cant you guys comment your fucking code seriously i spent the last few years doing web app development dug into dl a couple months ago supposedly compared to the postpostpostdocs doing ai stuff javascript developers should be inbred peasants but every project these peasants release even a fucking library that colorizes cli output has a catchy name extensive docs shitloads of comments fuckton of tests semantic versioning changelog and oh my god better variable names than ctx_h or lang_hs or fuck_you_for_trying_to_understand the concepts and ideas behind dl gans lstms cnns whatever its clear its simple its intuitive the slog is to go through the jargon that keeps changing beneath your feet whats the point of using fancy words if you cant keep them consistent the unnecessary equations trying to squeeze meaning from bullshit language used in papers figuring out the super important steps preprocessing hyperparameters optimization that the authors oops failed to mention sorry for singling out but look at this what the fuck if a developer anywhere else at facebook would get this code for a review they would throw up do you intentionally try to obfuscate your papers is pseudocode a fucking premium can you at least try to give some intuition before showering the reader with equations how the fuck do you dare to release a paper without source code why the fuck do you never ever add comments to you code when naming things are you charged by the character do you get a bonus for acronyms do you realize that openai having needed to release a baseline trpo implementation is a fucking disgrace to your profession jesus christ who decided to name a tensor concatenation function cat,"['cant', 'guy', 'comment', 'fucking', 'code', 'seriously', 'spent', 'last', 'year', 'web', 'app', 'development', 'dug', 'couple', 'month', 'ago', 'supposedly', 'compared', 'postpostpostdocs', 'stuff', 'javascript', 'developer', 'inbred', 'peasant', 'every', 'project', 'peasant', 'release', 'even', 'fucking', 'library', 'colorizes', 'cli', 'output', 'catchy', 'name', 'extensive', 'doc', 'shitloads', 'comment', 'fuckton', 'test', 'semantic', 'versioning', 'changelog', 'god', 'better', 'variable', 'name', 'ctx_h', 'lang_hs', 'fuck_you_for_trying_to_understand', 'concept', 'idea', 'behind', 'gans', 'lstms', 'cnns', 'whatever', 'clear', 'simple', 'intuitive', 'slog', 'jargon', 'keep', 'changing', 'beneath', 'foot', 'whats', 'point', 'using', 'fancy', 'word', 'cant', 'keep', 'consistent', 'unnecessary', 'equation', 'trying', 'squeeze', 'meaning', 'bullshit', 'language', 'used', 'paper', 'figuring', 'super', 'important', 'step', 'preprocessing', 'hyperparameters', 'optimization', 'author', 'oops', 'failed', 'mention', 'sorry', 'singling', 'look', 'fuck', 'developer', 'anywhere', 'else', 'facebook', 'would', 'get', 'code', 'review', 'would', 'throw', 'intentionally', 'try', 'obfuscate', 'paper', 'pseudocode', 'fucking', 'premium', 'least', 'try', 'give', 'intuition', 'showering', 'reader', 'equation', 'fuck', 'dare', 'release', 'paper', 'without', 'source', 'code', 'fuck', 'never', 'ever', 'add', 'comment', 'code', 'naming', 'thing', 'charged', 'character', 'get', 'bonus', 'acronym', 'realize', 'openai', 'needed', 'release', 'baseline', 'trpo', 'implementation', 'fucking', 'disgrace', 'profession', 'jesus', 'christ', 'decided', 'name', 'tensor', 'concatenation', 'function', 'cat']",,,,
q9hhqt,[P] YoHa: A practical hand tracking engine.,,1634408399.0,1626.0,61.0,/r/MachineLearning/comments/q9hhqt/p_yoha_a_practical_hand_tracking_engine/,https://i.redd.it/steg0r0otut71.gif,b-3-n-,MachineLearning,0.98,False,False,False,False,1.0,1745833778.130381,Tech & Programming,7.0,0.0,7.0,Saturday,14.0,October,2021.0,True,0.4939,0.444,0.0,0.556,positive,p yoha a practical hand tracking engine,,p yoha a practical hand tracking engine ,"yoha, practical, hand, tracking, engine",2021-10-16 18:19:59,p yoha a practical hand tracking engine ,"['yoha', 'practical', 'hand', 'tracking', 'engine']",,,,
lozys9,[P] I made Communities: a library of clustering algorithms for network graphs (link in comments),,1613923184.0,1617.0,40.0,/r/MachineLearning/comments/lozys9/p_i_made_communities_a_library_of_clustering/,https://v.redd.it/m31lehttysi61,jsonathan,MachineLearning,0.98,False,False,False,False,0.0,1745833778.597182,Tech & Programming,15.0,0.0,15.0,Sunday,10.0,February,2021.0,True,0.0,0.0,0.0,1.0,neutral,p i made communities a library of clustering algorithms for network graphs link in comments,,p i made communities a library of clustering algorithms for network graphs link in comments ,"made, community, library, clustering, algorithm",2021-02-21 15:59:44,p i made communities a library of clustering algorithms for network graphs link in comments ,"['made', 'community', 'library', 'clustering', 'algorithm', 'network', 'graph', 'link', 'comment']",,,,
106q6m9,"[P] I built Adrenaline, a debugger that fixes errors and explains them with GPT-3",,1673202183.0,1572.0,92.0,/r/MachineLearning/comments/106q6m9/p_i_built_adrenaline_a_debugger_that_fixes_errors/,https://i.redd.it/8t0k9jkd3vaa1.gif,jsonathan,MachineLearning,0.96,False,False,False,False,0.0,1745833778.897131,Tech & Programming,14.0,0.0,14.0,Sunday,13.0,January,2023.0,True,-0.34,0.0,0.194,0.806,negative,p i built adrenaline a debugger that fixes errors and explains them with gpt,,p i built adrenaline a debugger that fixes errors and explains them with gpt ,"built, adrenaline, debugger, fix, error",2023-01-08 18:23:03,p i built adrenaline a debugger that fixes errors and explains them with gpt ,"['built', 'adrenaline', 'debugger', 'fix', 'error', 'explains', 'gpt']",,,,
13mpxbw,[R] Video Demo of “Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold”,,1684583683.0,1530.0,42.0,/r/MachineLearning/comments/13mpxbw/r_video_demo_of_drag_your_gan_interactive/,https://v.redd.it/1epqhji6o01b1,hardmaru,MachineLearning,0.98,False,False,False,False,0.0,1745833779.388049,Tech & Programming,15.0,0.0,15.0,Saturday,7.0,May,2023.0,True,-0.4767,0.0,0.255,0.745,negative,r video demo of drag your gan interactive pointbased manipulation on the generative image manifold,,r video demo of drag your gan interactive pointbased manipulation on the generative image manifold ,"video, demo, drag, gan, interactive",2023-05-20 11:54:43,r video demo of drag your gan interactive pointbased manipulation on the generative image manifold ,"['video', 'demo', 'drag', 'gan', 'interactive', 'pointbased', 'manipulation', 'generative', 'image', 'manifold']",,,,
13kfxzy,[D] Does anybody else despise OpenAI?," I  mean, don't get me started with the closed source models they have that were trained using the work of unassuming individuals who will never  see a penny for it. Put it up on Github they said. I'm all for  open-source, but when a company turns around and charges you for a  product they made with freely and publicly made content, while forbidding you from using the output to create competing models, that is where I  draw the line. It is simply ridiculous. 

Sam Altman couldn't be anymore predictable with his recent attempts to get the government to start regulating AI.

What  risks? The AI is just a messenger for information that is already out  there if one knows how/where to look. You don't need AI to learn how to  hack, to learn how to make weapons, etc. Fake news/propaganda? The  internet has all of that covered. LLMs are no where near the level of AI  you see in sci-fi. I mean, are people really afraid of text? Yes, I  know that text can sometimes be malicious code such as viruses, but  those can be found on github as well.  If they fall for this they might  as well shutdown the internet while they're at it.

He  is simply blowing things out of proportion and using fear to increase  the likelihood that they do what he wants, hurt the competition. I  bet he is probably teething with bitterness everytime a new huggingface  model comes out. The thought of us peasants being able to use AI  privately is too dangerous. No, instead we must be fed scraps while they  slowly take away our jobs and determine our future.

This  is not a doomer post, as I am all in favor of the advancement of AI.  However, the real danger here lies in having a company like OpenAI  dictate the future of humanity. I get it, the writing is on the wall;  the cost of human intelligence will go down, but if everyone has their  personal AI then it wouldn't seem so bad or unfair would it? Listen,  something that has the power to render a college degree that costs  thousands of dollars worthless should be available to the public. This  is to offset the damages and job layoffs that will come as a result of  such an entity. It wouldn't be as bitter of a taste as it would if you were replaced by it while still not being able to access it. Everyone should be able to use it as leverage, it is the only fair solution.

If  we don't take action now, a company like ClosedAI will, and they are  not in favor of the common folk. Sam Altman is so calculated to the  point where there were times when he seemed to be shooting OpenAI in the foot during his talk.  This move is to simply conceal his real intentions, to climb the ladder and take it with him. If he didn't include his company in his  ramblings, he would be easily read. So instead, he pretends to be scared of his own product, in an effort to legitimize his claim. Don't fall  for it.

They are slowly making a  reputation as one the most hated tech companies, right up there with  Adobe, and they don't show any sign of change. They have no moat,  othewise they wouldn't feel so threatened to the point where they would have to resort to creating barriers of entry via regulation. This only  means one thing, we are slowly catching up. We just need someone to  vouch for humanity's well-being, while acting as an opposing force to the  evil corporations who are only looking out for themselves. Question is,  who would be a good candidate?",1684361728.0,1516.0,428.0,/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/,https://www.reddit.com/r/MachineLearning/comments/13kfxzy/d_does_anybody_else_despise_openai/,,MachineLearning,0.86,True,False,False,False,1.0,1745833779.713515,Tech & Programming,6.0,623.0,629.0,Wednesday,18.0,May,2023.0,False,-0.9938,0.076,0.136,0.788,negative,d does anybody else despise openai,i mean dont get me started with the closed source models they have that were trained using the work of unassuming individuals who will never see a penny for it put it up on github they said im all for opensource but when a company turns around and charges you for a product they made with freely and publicly made content while forbidding you from using the output to create competing models that is where i draw the line it is simply ridiculous sam altman couldnt be anymore predictable with his recent attempts to get the government to start regulating ai what risks the ai is just a messenger for information that is already out there if one knows howwhere to look you dont need ai to learn how to hack to learn how to make weapons etc fake newspropaganda the internet has all of that covered llms are no where near the level of ai you see in scifi i mean are people really afraid of text yes i know that text can sometimes be malicious code such as viruses but those can be found on github as well if they fall for this they might as well shutdown the internet while theyre at it he is simply blowing things out of proportion and using fear to increase the likelihood that they do what he wants hurt the competition i bet he is probably teething with bitterness everytime a new huggingface model comes out the thought of us peasants being able to use ai privately is too dangerous no instead we must be fed scraps while they slowly take away our jobs and determine our future this is not a doomer post as i am all in favor of the advancement of ai however the real danger here lies in having a company like openai dictate the future of humanity i get it the writing is on the wall the cost of human intelligence will go down but if everyone has their personal ai then it wouldnt seem so bad or unfair would it listen something that has the power to render a college degree that costs thousands of dollars worthless should be available to the public this is to offset the damages and job layoffs that will come as a result of such an entity it wouldnt be as bitter of a taste as it would if you were replaced by it while still not being able to access it everyone should be able to use it as leverage it is the only fair solution if we dont take action now a company like closedai will and they are not in favor of the common folk sam altman is so calculated to the point where there were times when he seemed to be shooting openai in the foot during his talk this move is to simply conceal his real intentions to climb the ladder and take it with him if he didnt include his company in his ramblings he would be easily read so instead he pretends to be scared of his own product in an effort to legitimize his claim dont fall for it they are slowly making a reputation as one the most hated tech companies right up there with adobe and they dont show any sign of change they have no moat othewise they wouldnt feel so threatened to the point where they would have to resort to creating barriers of entry via regulation this only means one thing we are slowly catching up we just need someone to vouch for humanitys wellbeing while acting as an opposing force to the evil corporations who are only looking out for themselves question is who would be a good candidate,d does anybody else despise openai i mean dont get me started with the closed source models they have that were trained using the work of unassuming individuals who will never see a penny for it put it up on github they said im all for opensource but when a company turns around and charges you for a product they made with freely and publicly made content while forbidding you from using the output to create competing models that is where i draw the line it is simply ridiculous sam altman couldnt be anymore predictable with his recent attempts to get the government to start regulating ai what risks the ai is just a messenger for information that is already out there if one knows howwhere to look you dont need ai to learn how to hack to learn how to make weapons etc fake newspropaganda the internet has all of that covered llms are no where near the level of ai you see in scifi i mean are people really afraid of text yes i know that text can sometimes be malicious code such as viruses but those can be found on github as well if they fall for this they might as well shutdown the internet while theyre at it he is simply blowing things out of proportion and using fear to increase the likelihood that they do what he wants hurt the competition i bet he is probably teething with bitterness everytime a new huggingface model comes out the thought of us peasants being able to use ai privately is too dangerous no instead we must be fed scraps while they slowly take away our jobs and determine our future this is not a doomer post as i am all in favor of the advancement of ai however the real danger here lies in having a company like openai dictate the future of humanity i get it the writing is on the wall the cost of human intelligence will go down but if everyone has their personal ai then it wouldnt seem so bad or unfair would it listen something that has the power to render a college degree that costs thousands of dollars worthless should be available to the public this is to offset the damages and job layoffs that will come as a result of such an entity it wouldnt be as bitter of a taste as it would if you were replaced by it while still not being able to access it everyone should be able to use it as leverage it is the only fair solution if we dont take action now a company like closedai will and they are not in favor of the common folk sam altman is so calculated to the point where there were times when he seemed to be shooting openai in the foot during his talk this move is to simply conceal his real intentions to climb the ladder and take it with him if he didnt include his company in his ramblings he would be easily read so instead he pretends to be scared of his own product in an effort to legitimize his claim dont fall for it they are slowly making a reputation as one the most hated tech companies right up there with adobe and they dont show any sign of change they have no moat othewise they wouldnt feel so threatened to the point where they would have to resort to creating barriers of entry via regulation this only means one thing we are slowly catching up we just need someone to vouch for humanitys wellbeing while acting as an opposing force to the evil corporations who are only looking out for themselves question is who would be a good candidate,"dont, company, would, openai, mean",2023-05-17 22:15:28,d does anybody else despise openai i mean dont get me started with the closed source models they have that were trained using the work of unassuming individuals who will never see a penny for it put it up on github they said im all for opensource but when a company turns around and charges you for a product they made with freely and publicly made content while forbidding you from using the output to create competing models that is where i draw the line it is simply ridiculous sam altman couldnt be anymore predictable with his recent attempts to get the government to start regulating ai what risks the ai is just a messenger for information that is already out there if one knows howwhere to look you dont need ai to learn how to hack to learn how to make weapons etc fake newspropaganda the internet has all of that covered llms are no where near the level of ai you see in scifi i mean are people really afraid of text yes i know that text can sometimes be malicious code such as viruses but those can be found on github as well if they fall for this they might as well shutdown the internet while theyre at it he is simply blowing things out of proportion and using fear to increase the likelihood that they do what he wants hurt the competition i bet he is probably teething with bitterness everytime a new huggingface model comes out the thought of us peasants being able to use ai privately is too dangerous no instead we must be fed scraps while they slowly take away our jobs and determine our future this is not a doomer post as i am all in favor of the advancement of ai however the real danger here lies in having a company like openai dictate the future of humanity i get it the writing is on the wall the cost of human intelligence will go down but if everyone has their personal ai then it wouldnt seem so bad or unfair would it listen something that has the power to render a college degree that costs thousands of dollars worthless should be available to the public this is to offset the damages and job layoffs that will come as a result of such an entity it wouldnt be as bitter of a taste as it would if you were replaced by it while still not being able to access it everyone should be able to use it as leverage it is the only fair solution if we dont take action now a company like closedai will and they are not in favor of the common folk sam altman is so calculated to the point where there were times when he seemed to be shooting openai in the foot during his talk this move is to simply conceal his real intentions to climb the ladder and take it with him if he didnt include his company in his ramblings he would be easily read so instead he pretends to be scared of his own product in an effort to legitimize his claim dont fall for it they are slowly making a reputation as one the most hated tech companies right up there with adobe and they dont show any sign of change they have no moat othewise they wouldnt feel so threatened to the point where they would have to resort to creating barriers of entry via regulation this only means one thing we are slowly catching up we just need someone to vouch for humanitys wellbeing while acting as an opposing force to the evil corporations who are only looking out for themselves question is who would be a good candidate,"['anybody', 'else', 'despise', 'openai', 'mean', 'dont', 'get', 'started', 'closed', 'source', 'model', 'trained', 'using', 'work', 'unassuming', 'individual', 'never', 'see', 'penny', 'put', 'github', 'said', 'opensource', 'company', 'turn', 'around', 'charge', 'product', 'made', 'freely', 'publicly', 'made', 'content', 'forbidding', 'using', 'output', 'create', 'competing', 'model', 'draw', 'line', 'simply', 'ridiculous', 'sam', 'altman', 'couldnt', 'anymore', 'predictable', 'recent', 'attempt', 'get', 'government', 'start', 'regulating', 'risk', 'messenger', 'information', 'already', 'one', 'know', 'howwhere', 'look', 'dont', 'need', 'learn', 'hack', 'learn', 'make', 'weapon', 'etc', 'fake', 'newspropaganda', 'internet', 'covered', 'llm', 'near', 'level', 'see', 'scifi', 'mean', 'people', 'really', 'afraid', 'text', 'yes', 'know', 'text', 'sometimes', 'malicious', 'code', 'virus', 'found', 'github', 'well', 'fall', 'might', 'well', 'shutdown', 'internet', 'theyre', 'simply', 'blowing', 'thing', 'proportion', 'using', 'fear', 'increase', 'likelihood', 'want', 'hurt', 'competition', 'bet', 'probably', 'teething', 'bitterness', 'everytime', 'new', 'huggingface', 'model', 'come', 'thought', 'peasant', 'able', 'use', 'privately', 'dangerous', 'instead', 'must', 'fed', 'scrap', 'slowly', 'take', 'away', 'job', 'determine', 'future', 'doomer', 'post', 'favor', 'advancement', 'however', 'real', 'danger', 'lie', 'company', 'like', 'openai', 'dictate', 'future', 'humanity', 'get', 'writing', 'wall', 'cost', 'human', 'intelligence', 'everyone', 'personal', 'wouldnt', 'seem', 'bad', 'unfair', 'would', 'listen', 'something', 'power', 'render', 'college', 'degree', 'cost', 'thousand', 'dollar', 'worthless', 'available', 'public', 'offset', 'damage', 'job', 'layoff', 'come', 'result', 'entity', 'wouldnt', 'bitter', 'taste', 'would', 'replaced', 'still', 'able', 'access', 'everyone', 'able', 'use', 'leverage', 'fair', 'solution', 'dont', 'take', 'action', 'company', 'like', 'closedai', 'favor', 'common', 'folk', 'sam', 'altman', 'calculated', 'point', 'time', 'seemed', 'shooting', 'openai', 'foot', 'talk', 'move', 'simply', 'conceal', 'real', 'intention', 'climb', 'ladder', 'take', 'didnt', 'include', 'company', 'ramblings', 'would', 'easily', 'read', 'instead', 'pretend', 'scared', 'product', 'effort', 'legitimize', 'claim', 'dont', 'fall', 'slowly', 'making', 'reputation', 'one', 'hated', 'tech', 'company', 'right', 'adobe', 'dont', 'show', 'sign', 'change', 'moat', 'othewise', 'wouldnt', 'feel', 'threatened', 'point', 'would', 'resort', 'creating', 'barrier', 'entry', 'via', 'regulation', 'mean', 'one', 'thing', 'slowly', 'catching', 'need', 'someone', 'vouch', 'humanity', 'wellbeing', 'acting', 'opposing', 'force', 'evil', 'corporation', 'looking', 'question', 'would', 'good', 'candidate']",,,,
h98tt5,[R] AI Learns Playing Basketball Just Like Humans! [https://www.youtube.com/watch?v=Rzj3k3yerDk],,1592194896.0,1507.0,87.0,/r/MachineLearning/comments/h98tt5/r_ai_learns_playing_basketball_just_like_humans/,https://v.redd.it/35cks53j10551,-BlackSquirrel-,MachineLearning,0.96,False,False,False,False,0.0,1745833781.89864,Tech & Programming,9.0,0.0,8.0,Monday,0.0,June,2020.0,False,0.5106,0.462,0.0,0.538,positive,r ai learns playing basketball just like humans,,r ai learns playing basketball just like humans ,"learns, playing, basketball, like, human",2020-06-15 04:21:36,r ai learns playing basketball just like humans ,"['learns', 'playing', 'basketball', 'like', 'human']",,,,
wiqjxv,[D] The current and future state of AI/ML is shockingly demoralizing with little hope of redemption,"I recently encountered the PaLM (Scaling Language Modeling with Pathways) paper from Google Research and it opened up a can of worms of ideas I’ve felt I’ve intuitively had for a while, but have been unable to express – and I know I can’t be the only one. Sometimes I wonder what the original pioneers of AI – Turing, Neumann, McCarthy, etc. – would think if they could see the state of AI that we’ve gotten ourselves into. 67 authors, 83 pages, 540B parameters in a model, the internals of which no one can say they comprehend with a straight face, 6144 TPUs in a commercial lab that no one has access to, on a rig that no one can afford, trained on a volume of data that a human couldn’t process in a lifetime, 1 page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution – bias, racism, malicious use, etc. – for purposes that who asked for?

When I started my career as an AI/ML research engineer 2016, I was most interested in two types of tasks – 1.) those that most humans could do but that would universally be considered tedious and non-scalable. I’m talking image classification, sentiment analysis, even document summarization, etc. 2.) tasks that humans lack the capacity to perform as well as computers for various reasons – forecasting, risk analysis, game playing, and so forth. I still love my career, and I try to only work on projects in these areas, but it’s getting harder and harder.

This is because, somewhere along the way, it became popular and unquestionably acceptable to push AI into domains that were originally uniquely human, those areas that sit at the top of Maslows’s hierarchy of needs in terms of self-actualization – art, music, writing, singing, programming, and so forth. These areas of endeavor have negative logarithmic ability curves – the vast majority of people cannot do them well at all, about 10% can do them decently, and 1% or less can do them extraordinarily. The little discussed problem with AI-generation is that, without extreme deterrence, we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people, until the AI ability range is the norm. This is because relative to humans, AI is cheap, fast, and infinite, to the extent that investments in human achievement will be watered down at the societal, educational, and individual level with each passing year. And unlike AI gameplay which superseded humans decades ago, we won’t be able to just disqualify the machines and continue to play as if they didn’t exist.

Almost everywhere I go, even this forum, I encounter almost universal deference given to current SOTA AI generation systems like GPT-3, CODEX, DALL-E, etc., with almost no one extending their implications to its logical conclusion, which is long-term convergence to the mean, to mediocrity, in the fields they claim to address or even enhance. If you’re an artist or writer and you’re using DALL-E or GPT-3 to “enhance” your work, or if you’re a programmer saying, “GitHub Co-Pilot makes me a better programmer?”, then how could you possibly know? You’ve disrupted and bypassed your own creative process, which is thoughts -> (optionally words) -> actions -> feedback -> repeat, and instead seeded your canvas with ideas from a machine, the provenance of which you can’t understand, nor can the machine reliably explain. And the more you do this, the more you make your creative processes dependent on said machine, until you must question whether or not you could work at the same level without it.

When I was a college student, I often dabbled with weed, LSD, and mushrooms, and for a while, I thought the ideas I was having while under the influence were revolutionary and groundbreaking – that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober, when I realized they weren’t that special at all. What I eventually determined is that, under the influence, it was impossible for me to accurately evaluate the drug-induced ideas I was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas. This is the same principle of – if you took a pill and it made you stupider, would even know it? I believe that, especially over the long-term timeframe that crosses generations, there’s significant risk that current AI-generation developments produces a similar effect on humanity, and we mostly won’t even realize it has happened, much like a frog in boiling water. If you have children like I do, how can you be aware of the the current SOTA in these areas, project that 20 to 30 years, and then and tell them with a straight face that it is worth them pursuing their talent in art, writing, or music? How can you be honest and still say that widespread implementation of auto-correction hasn’t made you and others worse and worse at spelling over the years (a task that even I believe most would agree is tedious and worth automating).

Furthermore, I’ve yet to set anyone discuss the train – generate – train - generate feedback loop that long-term application of AI-generation systems imply. The first generations of these models were trained on wide swaths of web data generated by humans, but if these systems are permitted to continually spit out content without restriction or verification, especially to the extent that it reduces or eliminates development and investment in human talent over the long term, then what happens to the 4th or 5th generation of models? Eventually we encounter this situation where the AI is being trained almost exclusively on AI-generated content, and therefore with each generation, it settles more and more into the mean and mediocrity with no way out using current methods. By the time that happens, what will we have lost in terms of the creative capacity of people, and will we be able to get it back?

By relentlessly pursuing this direction so enthusiastically, I’m convinced that we as AI/ML developers, companies, and nations are past the point of no return, and it mostly comes down the investments in time and money that we’ve made, as well as a prisoner’s dilemma with our competitors. As a society though, this direction we’ve chosen for short-term gains will almost certainly make humanity worse off, mostly for those who are powerless to do anything about it – our children, our grandchildren, and generations to come.

If you’re an AI researcher or a data scientist like myself, how do you turn things back for yourself when you’ve spent years on years building your career in this direction? You’re likely making near or north of $200k annually TC and have a family to support, and so it’s too late, no matter how you feel about the direction the field has gone. If you’re a company, how do you standby and let your competitors aggressively push their AutoML solutions into more and more markets without putting out your own? Moreover, if you’re a manager or thought leader in this field like Jeff Dean how do you justify to your own boss and your shareholders your team’s billions of dollars in AI investment while simultaneously balancing ethical concerns? You can’t – the only answer is bigger and bigger models, more and more applications, more and more data, and more and more automation, and then automating that even further. If you’re a country like the US, how do responsibly develop AI while your competitors like China single-mindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics? Once again, failing to compete would be pre-emptively admitting defeat.

Even assuming that none of what I’ve described here happens to such an extent, how are so few people not taking this seriously and discounting this possibility? If everything I’m saying is fear-mongering and non-sense, then I’d be interested in hearing what you think human-AI co-existence looks like in 20 to 30 years and why it isn’t as demoralizing as I’ve made it out to be.

&#x200B;

EDIT: Day after posting this -- this post took off way more than I expected. Even if I received 20 - 25 comments, I would have considered that a success, but this went much further. Thank you to each one of you that has read this post, even more so if you left a comment, and triply so for those who gave awards! I've read almost every comment that has come in (even the troll ones), and am truly grateful for each one, including those in sharp disagreement. I've learned much more from this discussion with the sub than I could have imagined on this topic, from so many perspectives. While I will try to reply as many comments as I can, the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that I likely won't be able to get to. That will invariably include some that I would love respond to under the assumption of infinite time, but I will do my best, even if the latency stretches into days. Thank you all once again!",1659907526.0,1483.0,403.0,/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/,https://www.reddit.com/r/MachineLearning/comments/wiqjxv/d_the_current_and_future_state_of_aiml_is/,Flaky_Suit_8665,MachineLearning,0.88,True,False,False,False,2.0,1745833782.376963,Tech & Programming,16.0,1567.0,1546.0,Sunday,17.0,August,2022.0,True,0.9983,0.119,0.067,0.814,positive,d the current and future state of aiml is shockingly demoralizing with little hope of redemption,i recently encountered the palm scaling language modeling with pathways paper from google research and it opened up a can of worms of ideas ive felt ive intuitively had for a while but have been unable to express and i know i cant be the only one sometimes i wonder what the original pioneers of ai turing neumann mccarthy etc would think if they could see the state of ai that weve gotten ourselves into authors pages b parameters in a model the internals of which no one can say they comprehend with a straight face tpus in a commercial lab that no one has access to on a rig that no one can afford trained on a volume of data that a human couldnt process in a lifetime page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution bias racism malicious use etc for purposes that who asked for when i started my career as an aiml research engineer i was most interested in two types of tasks those that most humans could do but that would universally be considered tedious and nonscalable im talking image classification sentiment analysis even document summarization etc tasks that humans lack the capacity to perform as well as computers for various reasons forecasting risk analysis game playing and so forth i still love my career and i try to only work on projects in these areas but its getting harder and harder this is because somewhere along the way it became popular and unquestionably acceptable to push ai into domains that were originally uniquely human those areas that sit at the top of maslowss hierarchy of needs in terms of selfactualization art music writing singing programming and so forth these areas of endeavor have negative logarithmic ability curves the vast majority of people cannot do them well at all about can do them decently and or less can do them extraordinarily the little discussed problem with aigeneration is that without extreme deterrence we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people until the ai ability range is the norm this is because relative to humans ai is cheap fast and infinite to the extent that investments in human achievement will be watered down at the societal educational and individual level with each passing year and unlike ai gameplay which superseded humans decades ago we wont be able to just disqualify the machines and continue to play as if they didnt exist almost everywhere i go even this forum i encounter almost universal deference given to current sota ai generation systems like gpt codex dalle etc with almost no one extending their implications to its logical conclusion which is longterm convergence to the mean to mediocrity in the fields they claim to address or even enhance if youre an artist or writer and youre using dalle or gpt to enhance your work or if youre a programmer saying github copilot makes me a better programmer then how could you possibly know youve disrupted and bypassed your own creative process which is thoughts optionally words actions feedback repeat and instead seeded your canvas with ideas from a machine the provenance of which you cant understand nor can the machine reliably explain and the more you do this the more you make your creative processes dependent on said machine until you must question whether or not you could work at the same level without it when i was a college student i often dabbled with weed lsd and mushrooms and for a while i thought the ideas i was having while under the influence were revolutionary and groundbreaking that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober when i realized they werent that special at all what i eventually determined is that under the influence it was impossible for me to accurately evaluate the druginduced ideas i was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas this is the same principle of if you took a pill and it made you stupider would even know it i believe that especially over the longterm timeframe that crosses generations theres significant risk that current aigeneration developments produces a similar effect on humanity and we mostly wont even realize it has happened much like a frog in boiling water if you have children like i do how can you be aware of the the current sota in these areas project that to years and then and tell them with a straight face that it is worth them pursuing their talent in art writing or music how can you be honest and still say that widespread implementation of autocorrection hasnt made you and others worse and worse at spelling over the years a task that even i believe most would agree is tedious and worth automating furthermore ive yet to set anyone discuss the train generate train generate feedback loop that longterm application of aigeneration systems imply the first generations of these models were trained on wide swaths of web data generated by humans but if these systems are permitted to continually spit out content without restriction or verification especially to the extent that it reduces or eliminates development and investment in human talent over the long term then what happens to the th or th generation of models eventually we encounter this situation where the ai is being trained almost exclusively on aigenerated content and therefore with each generation it settles more and more into the mean and mediocrity with no way out using current methods by the time that happens what will we have lost in terms of the creative capacity of people and will we be able to get it back by relentlessly pursuing this direction so enthusiastically im convinced that we as aiml developers companies and nations are past the point of no return and it mostly comes down the investments in time and money that weve made as well as a prisoners dilemma with our competitors as a society though this direction weve chosen for shortterm gains will almost certainly make humanity worse off mostly for those who are powerless to do anything about it our children our grandchildren and generations to come if youre an ai researcher or a data scientist like myself how do you turn things back for yourself when youve spent years on years building your career in this direction youre likely making near or north of k annually tc and have a family to support and so its too late no matter how you feel about the direction the field has gone if youre a company how do you standby and let your competitors aggressively push their automl solutions into more and more markets without putting out your own moreover if youre a manager or thought leader in this field like jeff dean how do you justify to your own boss and your shareholders your teams billions of dollars in ai investment while simultaneously balancing ethical concerns you cant the only answer is bigger and bigger models more and more applications more and more data and more and more automation and then automating that even further if youre a country like the us how do responsibly develop ai while your competitors like china singlemindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics once again failing to compete would be preemptively admitting defeat even assuming that none of what ive described here happens to such an extent how are so few people not taking this seriously and discounting this possibility if everything im saying is fearmongering and nonsense then id be interested in hearing what you think humanai coexistence looks like in to years and why it isnt as demoralizing as ive made it out to be xb edit day after posting this this post took off way more than i expected even if i received comments i would have considered that a success but this went much further thank you to each one of you that has read this post even more so if you left a comment and triply so for those who gave awards ive read almost every comment that has come in even the troll ones and am truly grateful for each one including those in sharp disagreement ive learned much more from this discussion with the sub than i could have imagined on this topic from so many perspectives while i will try to reply as many comments as i can the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that i likely wont be able to get to that will invariably include some that i would love respond to under the assumption of infinite time but i will do my best even if the latency stretches into days thank you all once again,d the current and future state of aiml is shockingly demoralizing with little hope of redemption i recently encountered the palm scaling language modeling with pathways paper from google research and it opened up a can of worms of ideas ive felt ive intuitively had for a while but have been unable to express and i know i cant be the only one sometimes i wonder what the original pioneers of ai turing neumann mccarthy etc would think if they could see the state of ai that weve gotten ourselves into authors pages b parameters in a model the internals of which no one can say they comprehend with a straight face tpus in a commercial lab that no one has access to on a rig that no one can afford trained on a volume of data that a human couldnt process in a lifetime page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution bias racism malicious use etc for purposes that who asked for when i started my career as an aiml research engineer i was most interested in two types of tasks those that most humans could do but that would universally be considered tedious and nonscalable im talking image classification sentiment analysis even document summarization etc tasks that humans lack the capacity to perform as well as computers for various reasons forecasting risk analysis game playing and so forth i still love my career and i try to only work on projects in these areas but its getting harder and harder this is because somewhere along the way it became popular and unquestionably acceptable to push ai into domains that were originally uniquely human those areas that sit at the top of maslowss hierarchy of needs in terms of selfactualization art music writing singing programming and so forth these areas of endeavor have negative logarithmic ability curves the vast majority of people cannot do them well at all about can do them decently and or less can do them extraordinarily the little discussed problem with aigeneration is that without extreme deterrence we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people until the ai ability range is the norm this is because relative to humans ai is cheap fast and infinite to the extent that investments in human achievement will be watered down at the societal educational and individual level with each passing year and unlike ai gameplay which superseded humans decades ago we wont be able to just disqualify the machines and continue to play as if they didnt exist almost everywhere i go even this forum i encounter almost universal deference given to current sota ai generation systems like gpt codex dalle etc with almost no one extending their implications to its logical conclusion which is longterm convergence to the mean to mediocrity in the fields they claim to address or even enhance if youre an artist or writer and youre using dalle or gpt to enhance your work or if youre a programmer saying github copilot makes me a better programmer then how could you possibly know youve disrupted and bypassed your own creative process which is thoughts optionally words actions feedback repeat and instead seeded your canvas with ideas from a machine the provenance of which you cant understand nor can the machine reliably explain and the more you do this the more you make your creative processes dependent on said machine until you must question whether or not you could work at the same level without it when i was a college student i often dabbled with weed lsd and mushrooms and for a while i thought the ideas i was having while under the influence were revolutionary and groundbreaking that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober when i realized they werent that special at all what i eventually determined is that under the influence it was impossible for me to accurately evaluate the druginduced ideas i was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas this is the same principle of if you took a pill and it made you stupider would even know it i believe that especially over the longterm timeframe that crosses generations theres significant risk that current aigeneration developments produces a similar effect on humanity and we mostly wont even realize it has happened much like a frog in boiling water if you have children like i do how can you be aware of the the current sota in these areas project that to years and then and tell them with a straight face that it is worth them pursuing their talent in art writing or music how can you be honest and still say that widespread implementation of autocorrection hasnt made you and others worse and worse at spelling over the years a task that even i believe most would agree is tedious and worth automating furthermore ive yet to set anyone discuss the train generate train generate feedback loop that longterm application of aigeneration systems imply the first generations of these models were trained on wide swaths of web data generated by humans but if these systems are permitted to continually spit out content without restriction or verification especially to the extent that it reduces or eliminates development and investment in human talent over the long term then what happens to the th or th generation of models eventually we encounter this situation where the ai is being trained almost exclusively on aigenerated content and therefore with each generation it settles more and more into the mean and mediocrity with no way out using current methods by the time that happens what will we have lost in terms of the creative capacity of people and will we be able to get it back by relentlessly pursuing this direction so enthusiastically im convinced that we as aiml developers companies and nations are past the point of no return and it mostly comes down the investments in time and money that weve made as well as a prisoners dilemma with our competitors as a society though this direction weve chosen for shortterm gains will almost certainly make humanity worse off mostly for those who are powerless to do anything about it our children our grandchildren and generations to come if youre an ai researcher or a data scientist like myself how do you turn things back for yourself when youve spent years on years building your career in this direction youre likely making near or north of k annually tc and have a family to support and so its too late no matter how you feel about the direction the field has gone if youre a company how do you standby and let your competitors aggressively push their automl solutions into more and more markets without putting out your own moreover if youre a manager or thought leader in this field like jeff dean how do you justify to your own boss and your shareholders your teams billions of dollars in ai investment while simultaneously balancing ethical concerns you cant the only answer is bigger and bigger models more and more applications more and more data and more and more automation and then automating that even further if youre a country like the us how do responsibly develop ai while your competitors like china singlemindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics once again failing to compete would be preemptively admitting defeat even assuming that none of what ive described here happens to such an extent how are so few people not taking this seriously and discounting this possibility if everything im saying is fearmongering and nonsense then id be interested in hearing what you think humanai coexistence looks like in to years and why it isnt as demoralizing as ive made it out to be xb edit day after posting this this post took off way more than i expected even if i received comments i would have considered that a success but this went much further thank you to each one of you that has read this post even more so if you left a comment and triply so for those who gave awards ive read almost every comment that has come in even the troll ones and am truly grateful for each one including those in sharp disagreement ive learned much more from this discussion with the sub than i could have imagined on this topic from so many perspectives while i will try to reply as many comments as i can the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that i likely wont be able to get to that will invariably include some that i would love respond to under the assumption of infinite time but i will do my best even if the latency stretches into days thank you all once again,"even, human, idea, one, like",2022-08-07 21:25:26,d the current and future state of aiml is shockingly demoralizing with little hope of redemption i recently encountered the palm scaling language modeling with pathways paper from google research and it opened up a can of worms of ideas ive felt ive intuitively had for a while but have been unable to express and i know i cant be the only one sometimes i wonder what the original pioneers of ai turing neumann mccarthy etc would think if they could see the state of ai that weve gotten ourselves into authors pages b parameters in a model the internals of which no one can say they comprehend with a straight face tpus in a commercial lab that no one has access to on a rig that no one can afford trained on a volume of data that a human couldnt process in a lifetime page on ethics with the same ideas that have been rehashed over and over elsewhere with no attempt at a solution bias racism malicious use etc for purposes that who asked for when i started my career as an aiml research engineer i was most interested in two types of tasks those that most humans could do but that would universally be considered tedious and nonscalable im talking image classification sentiment analysis even document summarization etc tasks that humans lack the capacity to perform as well as computers for various reasons forecasting risk analysis game playing and so forth i still love my career and i try to only work on projects in these areas but its getting harder and harder this is because somewhere along the way it became popular and unquestionably acceptable to push ai into domains that were originally uniquely human those areas that sit at the top of maslowss hierarchy of needs in terms of selfactualization art music writing singing programming and so forth these areas of endeavor have negative logarithmic ability curves the vast majority of people cannot do them well at all about can do them decently and or less can do them extraordinarily the little discussed problem with aigeneration is that without extreme deterrence we will sacrifice human achievement at the top percentile in the name of lowering the bar for a larger volume of people until the ai ability range is the norm this is because relative to humans ai is cheap fast and infinite to the extent that investments in human achievement will be watered down at the societal educational and individual level with each passing year and unlike ai gameplay which superseded humans decades ago we wont be able to just disqualify the machines and continue to play as if they didnt exist almost everywhere i go even this forum i encounter almost universal deference given to current sota ai generation systems like gpt codex dalle etc with almost no one extending their implications to its logical conclusion which is longterm convergence to the mean to mediocrity in the fields they claim to address or even enhance if youre an artist or writer and youre using dalle or gpt to enhance your work or if youre a programmer saying github copilot makes me a better programmer then how could you possibly know youve disrupted and bypassed your own creative process which is thoughts optionally words actions feedback repeat and instead seeded your canvas with ideas from a machine the provenance of which you cant understand nor can the machine reliably explain and the more you do this the more you make your creative processes dependent on said machine until you must question whether or not you could work at the same level without it when i was a college student i often dabbled with weed lsd and mushrooms and for a while i thought the ideas i was having while under the influence were revolutionary and groundbreaking that is until took it upon myself to actually start writing down those ideas and then reviewing them while sober when i realized they werent that special at all what i eventually determined is that under the influence it was impossible for me to accurately evaluate the druginduced ideas i was having because the influencing agent the generates the ideas themselves was disrupting the same frame of reference that is responsible evaluating said ideas this is the same principle of if you took a pill and it made you stupider would even know it i believe that especially over the longterm timeframe that crosses generations theres significant risk that current aigeneration developments produces a similar effect on humanity and we mostly wont even realize it has happened much like a frog in boiling water if you have children like i do how can you be aware of the the current sota in these areas project that to years and then and tell them with a straight face that it is worth them pursuing their talent in art writing or music how can you be honest and still say that widespread implementation of autocorrection hasnt made you and others worse and worse at spelling over the years a task that even i believe most would agree is tedious and worth automating furthermore ive yet to set anyone discuss the train generate train generate feedback loop that longterm application of aigeneration systems imply the first generations of these models were trained on wide swaths of web data generated by humans but if these systems are permitted to continually spit out content without restriction or verification especially to the extent that it reduces or eliminates development and investment in human talent over the long term then what happens to the th or th generation of models eventually we encounter this situation where the ai is being trained almost exclusively on aigenerated content and therefore with each generation it settles more and more into the mean and mediocrity with no way out using current methods by the time that happens what will we have lost in terms of the creative capacity of people and will we be able to get it back by relentlessly pursuing this direction so enthusiastically im convinced that we as aiml developers companies and nations are past the point of no return and it mostly comes down the investments in time and money that weve made as well as a prisoners dilemma with our competitors as a society though this direction weve chosen for shortterm gains will almost certainly make humanity worse off mostly for those who are powerless to do anything about it our children our grandchildren and generations to come if youre an ai researcher or a data scientist like myself how do you turn things back for yourself when youve spent years on years building your career in this direction youre likely making near or north of k annually tc and have a family to support and so its too late no matter how you feel about the direction the field has gone if youre a company how do you standby and let your competitors aggressively push their automl solutions into more and more markets without putting out your own moreover if youre a manager or thought leader in this field like jeff dean how do you justify to your own boss and your shareholders your teams billions of dollars in ai investment while simultaneously balancing ethical concerns you cant the only answer is bigger and bigger models more and more applications more and more data and more and more automation and then automating that even further if youre a country like the us how do responsibly develop ai while your competitors like china singlemindedly push full steam ahead without an iota of ethical concern to replace you in numerous areas in global power dynamics once again failing to compete would be preemptively admitting defeat even assuming that none of what ive described here happens to such an extent how are so few people not taking this seriously and discounting this possibility if everything im saying is fearmongering and nonsense then id be interested in hearing what you think humanai coexistence looks like in to years and why it isnt as demoralizing as ive made it out to be xb edit day after posting this this post took off way more than i expected even if i received comments i would have considered that a success but this went much further thank you to each one of you that has read this post even more so if you left a comment and triply so for those who gave awards ive read almost every comment that has come in even the troll ones and am truly grateful for each one including those in sharp disagreement ive learned much more from this discussion with the sub than i could have imagined on this topic from so many perspectives while i will try to reply as many comments as i can the sheer comment volume combined with limited free time between work and family unfortunately means that there are many that i likely wont be able to get to that will invariably include some that i would love respond to under the assumption of infinite time but i will do my best even if the latency stretches into days thank you all once again,"['current', 'future', 'state', 'aiml', 'shockingly', 'demoralizing', 'little', 'hope', 'redemption', 'recently', 'encountered', 'palm', 'scaling', 'language', 'modeling', 'pathway', 'paper', 'google', 'research', 'opened', 'worm', 'idea', 'ive', 'felt', 'ive', 'intuitively', 'unable', 'express', 'know', 'cant', 'one', 'sometimes', 'wonder', 'original', 'pioneer', 'turing', 'neumann', 'mccarthy', 'etc', 'would', 'think', 'could', 'see', 'state', 'weve', 'gotten', 'author', 'page', 'parameter', 'model', 'internals', 'one', 'say', 'comprehend', 'straight', 'face', 'tpus', 'commercial', 'lab', 'one', 'access', 'rig', 'one', 'afford', 'trained', 'volume', 'data', 'human', 'couldnt', 'process', 'lifetime', 'page', 'ethic', 'idea', 'rehashed', 'elsewhere', 'attempt', 'solution', 'bias', 'racism', 'malicious', 'use', 'etc', 'purpose', 'asked', 'started', 'career', 'aiml', 'research', 'engineer', 'interested', 'two', 'type', 'task', 'human', 'could', 'would', 'universally', 'considered', 'tedious', 'nonscalable', 'talking', 'image', 'classification', 'sentiment', 'analysis', 'even', 'document', 'summarization', 'etc', 'task', 'human', 'lack', 'capacity', 'perform', 'well', 'computer', 'various', 'reason', 'forecasting', 'risk', 'analysis', 'game', 'playing', 'forth', 'still', 'love', 'career', 'try', 'work', 'project', 'area', 'getting', 'harder', 'harder', 'somewhere', 'along', 'way', 'became', 'popular', 'unquestionably', 'acceptable', 'push', 'domain', 'originally', 'uniquely', 'human', 'area', 'sit', 'top', 'maslowss', 'hierarchy', 'need', 'term', 'selfactualization', 'art', 'music', 'writing', 'singing', 'programming', 'forth', 'area', 'endeavor', 'negative', 'logarithmic', 'ability', 'curve', 'vast', 'majority', 'people', 'well', 'decently', 'less', 'extraordinarily', 'little', 'discussed', 'problem', 'aigeneration', 'without', 'extreme', 'deterrence', 'sacrifice', 'human', 'achievement', 'top', 'percentile', 'name', 'lowering', 'bar', 'larger', 'volume', 'people', 'ability', 'range', 'norm', 'relative', 'human', 'cheap', 'fast', 'infinite', 'extent', 'investment', 'human', 'achievement', 'watered', 'societal', 'educational', 'individual', 'level', 'passing', 'year', 'unlike', 'gameplay', 'superseded', 'human', 'decade', 'ago', 'wont', 'able', 'disqualify', 'machine', 'continue', 'play', 'didnt', 'exist', 'almost', 'everywhere', 'even', 'forum', 'encounter', 'almost', 'universal', 'deference', 'given', 'current', 'sota', 'generation', 'system', 'like', 'gpt', 'codex', 'dalle', 'etc', 'almost', 'one', 'extending', 'implication', 'logical', 'conclusion', 'longterm', 'convergence', 'mean', 'mediocrity', 'field', 'claim', 'address', 'even', 'enhance', 'youre', 'artist', 'writer', 'youre', 'using', 'dalle', 'gpt', 'enhance', 'work', 'youre', 'programmer', 'saying', 'github', 'copilot', 'make', 'better', 'programmer', 'could', 'possibly', 'know', 'youve', 'disrupted', 'bypassed', 'creative', 'process', 'thought', 'optionally', 'word', 'action', 'feedback', 'repeat', 'instead', 'seeded', 'canvas', 'idea', 'machine', 'provenance', 'cant', 'understand', 'machine', 'reliably', 'explain', 'make', 'creative', 'process', 'dependent', 'said', 'machine', 'must', 'question', 'whether', 'could', 'work', 'level', 'without', 'college', 'student', 'often', 'dabbled', 'weed', 'lsd', 'mushroom', 'thought', 'idea', 'influence', 'revolutionary', 'groundbreaking', 'took', 'upon', 'actually', 'start', 'writing', 'idea', 'reviewing', 'sober', 'realized', 'werent', 'special', 'eventually', 'determined', 'influence', 'impossible', 'accurately', 'evaluate', 'druginduced', 'idea', 'influencing', 'agent', 'generates', 'idea', 'disrupting', 'frame', 'reference', 'responsible', 'evaluating', 'said', 'idea', 'principle', 'took', 'pill', 'made', 'stupider', 'would', 'even', 'know', 'believe', 'especially', 'longterm', 'timeframe', 'cross', 'generation', 'there', 'significant', 'risk', 'current', 'aigeneration', 'development', 'produce', 'similar', 'effect', 'humanity', 'mostly', 'wont', 'even', 'realize', 'happened', 'much', 'like', 'frog', 'boiling', 'water', 'child', 'like', 'aware', 'current', 'sota', 'area', 'project', 'year', 'tell', 'straight', 'face', 'worth', 'pursuing', 'talent', 'art', 'writing', 'music', 'honest', 'still', 'say', 'widespread', 'implementation', 'autocorrection', 'hasnt', 'made', 'others', 'worse', 'worse', 'spelling', 'year', 'task', 'even', 'believe', 'would', 'agree', 'tedious', 'worth', 'automating', 'furthermore', 'ive', 'yet', 'set', 'anyone', 'discus', 'train', 'generate', 'train', 'generate', 'feedback', 'loop', 'longterm', 'application', 'aigeneration', 'system', 'imply', 'first', 'generation', 'model', 'trained', 'wide', 'swath', 'web', 'data', 'generated', 'human', 'system', 'permitted', 'continually', 'spit', 'content', 'without', 'restriction', 'verification', 'especially', 'extent', 'reduces', 'eliminates', 'development', 'investment', 'human', 'talent', 'long', 'term', 'happens', 'generation', 'model', 'eventually', 'encounter', 'situation', 'trained', 'almost', 'exclusively', 'aigenerated', 'content', 'therefore', 'generation', 'settle', 'mean', 'mediocrity', 'way', 'using', 'current', 'method', 'time', 'happens', 'lost', 'term', 'creative', 'capacity', 'people', 'able', 'get', 'back', 'relentlessly', 'pursuing', 'direction', 'enthusiastically', 'convinced', 'aiml', 'developer', 'company', 'nation', 'past', 'point', 'return', 'mostly', 'come', 'investment', 'time', 'money', 'weve', 'made', 'well', 'prisoner', 'dilemma', 'competitor', 'society', 'though', 'direction', 'weve', 'chosen', 'shortterm', 'gain', 'almost', 'certainly', 'make', 'humanity', 'worse', 'mostly', 'powerless', 'anything', 'child', 'grandchild', 'generation', 'come', 'youre', 'researcher', 'data', 'scientist', 'like', 'turn', 'thing', 'back', 'youve', 'spent', 'year', 'year', 'building', 'career', 'direction', 'youre', 'likely', 'making', 'near', 'north', 'annually', 'family', 'support', 'late', 'matter', 'feel', 'direction', 'field', 'gone', 'youre', 'company', 'standby', 'let', 'competitor', 'aggressively', 'push', 'automl', 'solution', 'market', 'without', 'putting', 'moreover', 'youre', 'manager', 'thought', 'leader', 'field', 'like', 'jeff', 'dean', 'justify', 'bos', 'shareholder', 'team', 'billion', 'dollar', 'investment', 'simultaneously', 'balancing', 'ethical', 'concern', 'cant', 'answer', 'bigger', 'bigger', 'model', 'application', 'data', 'automation', 'automating', 'even', 'youre', 'country', 'like', 'responsibly', 'develop', 'competitor', 'like', 'china', 'singlemindedly', 'push', 'full', 'steam', 'ahead', 'without', 'iota', 'ethical', 'concern', 'replace', 'numerous', 'area', 'global', 'power', 'dynamic', 'failing', 'compete', 'would', 'preemptively', 'admitting', 'defeat', 'even', 'assuming', 'none', 'ive', 'described', 'happens', 'extent', 'people', 'taking', 'seriously', 'discounting', 'possibility', 'everything', 'saying', 'fearmongering', 'nonsense', 'interested', 'hearing', 'think', 'humanai', 'coexistence', 'look', 'like', 'year', 'isnt', 'demoralizing', 'ive', 'made', 'edit', 'day', 'posting', 'post', 'took', 'way', 'expected', 'even', 'received', 'comment', 'would', 'considered', 'success', 'went', 'much', 'thank', 'one', 'read', 'post', 'even', 'left', 'comment', 'triply', 'gave', 'award', 'ive', 'read', 'almost', 'every', 'comment', 'come', 'even', 'troll', 'one', 'truly', 'grateful', 'one', 'including', 'sharp', 'disagreement', 'ive', 'learned', 'much', 'discussion', 'sub', 'could', 'imagined', 'topic', 'many', 'perspective', 'try', 'reply', 'many', 'comment', 'sheer', 'comment', 'volume', 'combined', 'limited', 'free', 'time', 'work', 'family', 'unfortunately', 'mean', 'many', 'likely', 'wont', 'able', 'get', 'invariably', 'include', 'would', 'love', 'respond', 'assumption', 'infinite', 'time', 'best', 'even', 'latency', 'stretch', 'day', 'thank']",,,,
g8s1af,"[R] Clova AI Research's StarGAN v2 (CVPR 2020 + code, pre-trained models, datasets)",,1587955165.0,1479.0,59.0,/r/MachineLearning/comments/g8s1af/r_clova_ai_researchs_stargan_v2_cvpr_2020_code/,https://v.redd.it/t940o9jjv9v41,yunjey,MachineLearning,0.98,False,False,False,False,0.0,1745833784.957739,Tech & Programming,13.0,0.0,11.0,Sunday,22.0,April,2020.0,True,0.0,0.0,0.0,1.0,neutral,r clova ai researchs stargan v cvpr code pretrained models datasets,,r clova ai researchs stargan v cvpr code pretrained models datasets ,"clova, research, stargan, cvpr, code",2020-04-27 02:39:25,r clova ai researchs stargan v cvpr code pretrained models datasets ,"['clova', 'research', 'stargan', 'cvpr', 'code', 'pretrained', 'model', 'datasets']",,,,
hlkwm1,[Project] From any text-dataset to valuable insights in seconds with Texthero,,1593947313.0,1480.0,79.0,/r/MachineLearning/comments/hlkwm1/project_from_any_textdataset_to_valuable_insights/,https://v.redd.it/47ccf1z2u0951,jonathanbesomi,MachineLearning,0.98,False,False,False,False,0.0,1745833785.333048,Tech & Programming,11.0,0.0,11.0,Sunday,7.0,July,2020.0,True,0.4767,0.237,0.0,0.763,positive,project from any textdataset to valuable insights in seconds with texthero,,project from any textdataset to valuable insights in seconds with texthero ,"project, textdataset, valuable, insight, second",2020-07-05 11:08:33,project from any textdataset to valuable insights in seconds with texthero ,"['project', 'textdataset', 'valuable', 'insight', 'second', 'texthero']",,,,
17sqal4,"[N] [P] Google Deepmind released an album with ""visualizations of AI"" to combat stereotypical depictions of glowing brains, blue screens, etc.",,1699691676.0,1461.0,131.0,/r/MachineLearning/comments/17sqal4/n_p_google_deepmind_released_an_album_with/,https://v.redd.it/0c5v1jrxjozb1,radi-cho,MachineLearning,0.97,False,False,False,False,0.0,1745833785.863914,Tech & Programming,21.0,0.0,21.0,Saturday,3.0,November,2023.0,True,-0.34,0.0,0.118,0.882,negative,n p google deepmind released an album with visualizations of ai to combat stereotypical depictions of glowing brains blue screens etc,,n p google deepmind released an album with visualizations of ai to combat stereotypical depictions of glowing brains blue screens etc ,"google, deepmind, released, album, visualization",2023-11-11 08:34:36,n p google deepmind released an album with visualizations of ai to combat stereotypical depictions of glowing brains blue screens etc ,"['google', 'deepmind', 'released', 'album', 'visualization', 'combat', 'stereotypical', 'depiction', 'glowing', 'brain', 'blue', 'screen', 'etc']",,,,
xbj6cn,[R] SIMPLERECON — 3D Reconstruction without 3D Convolutions — 73ms per frame !,,1662904474.0,1411.0,35.0,/r/MachineLearning/comments/xbj6cn/r_simplerecon_3d_reconstruction_without_3d/,https://v.redd.it/8fsyfg86h8n91,SpatialComputing,MachineLearning,0.99,False,False,False,False,0.0,1745833786.722568,Tech & Programming,13.0,0.0,10.0,Sunday,9.0,September,2022.0,True,0.0,0.0,0.0,1.0,neutral,r simplerecon d reconstruction without d convolutions ms per frame,,r simplerecon d reconstruction without d convolutions ms per frame ,"simplerecon, reconstruction, without, convolution, per",2022-09-11 13:54:34,r simplerecon d reconstruction without d convolutions ms per frame ,"['simplerecon', 'reconstruction', 'without', 'convolution', 'per', 'frame']",,,,
uqk878,[News] New Google tech - Geospatial API uses computer vision and machine learning to turn 15 years of street view imagery into a 3d canvas for augmented reality developers,,1652663574.0,1403.0,38.0,/r/MachineLearning/comments/uqk878/news_new_google_tech_geospatial_api_uses_computer/,https://v.redd.it/3yjjeuprnqz81,imaginfinity,MachineLearning,0.99,False,False,False,False,0.0,1745833787.136974,Tech & Programming,29.0,0.0,27.0,Sunday,21.0,May,2022.0,True,0.25,0.077,0.0,0.923,positive,news new google tech geospatial api uses computer vision and machine learning to turn years of street view imagery into a d canvas for augmented reality developers,,news new google tech geospatial api uses computer vision and machine learning to turn years of street view imagery into a d canvas for augmented reality developers ,"news, new, google, tech, geospatial",2022-05-16 01:12:54,news new google tech geospatial api uses computer vision and machine learning to turn years of street view imagery into a d canvas for augmented reality developers ,"['news', 'new', 'google', 'tech', 'geospatial', 'api', 'us', 'computer', 'vision', 'machine', 'learning', 'turn', 'year', 'street', 'view', 'imagery', 'canvas', 'augmented', 'reality', 'developer']",,,,
ggakn3,[R] RigNet: Neural Rigging for Articulated Characters,,1589006945.0,1401.0,37.0,/r/MachineLearning/comments/ggakn3/r_rignet_neural_rigging_for_articulated_characters/,https://v.redd.it/ot0lwqfvrox41,programmerChilli,MachineLearning,0.99,False,False,False,False,0.0,1745833787.513358,Tech & Programming,7.0,0.0,7.0,Saturday,2.0,May,2020.0,True,0.0,0.0,0.0,1.0,neutral,r rignet neural rigging for articulated characters,,r rignet neural rigging for articulated characters ,"rignet, neural, rigging, articulated, character",2020-05-09 06:49:05,r rignet neural rigging for articulated characters ,"['rignet', 'neural', 'rigging', 'articulated', 'character']",,,,
11rizyb,[D] Anyone else witnessing a panic inside NLP orgs of big tech companies?,"I'm in a big tech company working along side a science team for a product you've all probably used. We have these year long initiatives to productionalize ""state of the art NLP models"" that are now completely obsolete in the face of GPT-4. I think at first the science orgs were quiet/in denial. But now it's very obvious we are basically working on worthless technology. And by ""we"", I mean a large organization with scores of teams. 

Anyone else seeing this? What is the long term effect on science careers that get disrupted like this? Whats even more odd is the ego's of some of these science people

Clearly the model is not a catch all, but still",1678846362.0,1378.0,482.0,/r/MachineLearning/comments/11rizyb/d_anyone_else_witnessing_a_panic_inside_nlp_orgs/,https://www.reddit.com/r/MachineLearning/comments/11rizyb/d_anyone_else_witnessing_a_panic_inside_nlp_orgs/,thrwsitaway4321,MachineLearning,0.99,True,False,False,False,0.0,1745833787.79304,Tech & Programming,13.0,118.0,131.0,Tuesday,22.0,March,2023.0,False,-0.5165,0.051,0.083,0.866,negative,d anyone else witnessing a panic inside nlp orgs of big tech companies,im in a big tech company working along side a science team for a product youve all probably used we have these year long initiatives to productionalize state of the art nlp models that are now completely obsolete in the face of gpt i think at first the science orgs were quietin denial but now its very obvious we are basically working on worthless technology and by we i mean a large organization with scores of teams anyone else seeing this what is the long term effect on science careers that get disrupted like this whats even more odd is the egos of some of these science people clearly the model is not a catch all but still,d anyone else witnessing a panic inside nlp orgs of big tech companies im in a big tech company working along side a science team for a product youve all probably used we have these year long initiatives to productionalize state of the art nlp models that are now completely obsolete in the face of gpt i think at first the science orgs were quietin denial but now its very obvious we are basically working on worthless technology and by we i mean a large organization with scores of teams anyone else seeing this what is the long term effect on science careers that get disrupted like this whats even more odd is the egos of some of these science people clearly the model is not a catch all but still,"science, anyone, else, nlp, orgs",2023-03-15 02:12:42,d anyone else witnessing a panic inside nlp orgs of big tech companies im in a big tech company working along side a science team for a product youve all probably used we have these year long initiatives to productionalize state of the art nlp models that are now completely obsolete in the face of gpt i think at first the science orgs were quietin denial but now its very obvious we are basically working on worthless technology and by we i mean a large organization with scores of teams anyone else seeing this what is the long term effect on science careers that get disrupted like this whats even more odd is the egos of some of these science people clearly the model is not a catch all but still,"['anyone', 'else', 'witnessing', 'panic', 'inside', 'nlp', 'orgs', 'big', 'tech', 'company', 'big', 'tech', 'company', 'working', 'along', 'side', 'science', 'team', 'product', 'youve', 'probably', 'used', 'year', 'long', 'initiative', 'productionalize', 'state', 'art', 'nlp', 'model', 'completely', 'obsolete', 'face', 'gpt', 'think', 'first', 'science', 'orgs', 'quietin', 'denial', 'obvious', 'basically', 'working', 'worthless', 'technology', 'mean', 'large', 'organization', 'score', 'team', 'anyone', 'else', 'seeing', 'long', 'term', 'effect', 'science', 'career', 'get', 'disrupted', 'like', 'whats', 'even', 'odd', 'ego', 'science', 'people', 'clearly', 'model', 'catch', 'still']",,,,
d7ad2y,"[D] Siraj Raval - Potentially exploiting students, banning students asking for refund. Thoughts?","I'm not a personal follower of Siraj, but this issue came up in a ML FBook group that I'm part of. I'm curious to hear what you all think.

It appears that Siraj recently offered a course ""Make Money with Machine Learning"" with a registration fee but did not follow through with promises made in the initial offering of the course. On top of that, he created a refund and warranty page with information regarding the course *after* people already paid. Here is a link to a WayBackMachine captures of u/klarken's documentation of Siraj's potential misdeeds: [case for a refund](https://web.archive.org/save/https://case-for-a-refund.s3.us-east-2.amazonaws.com/feedback.html), [discussion in course Discord](https://web.archive.org/web/20190923211614/https://case-for-a-refund.s3.us-east-2.amazonaws.com/reference_messages.png), [\~1200 individuals in the course](https://web.archive.org/web/20190923211815/https://case-for-a-refund.s3.us-east-2.amazonaws.com/members.png), [Multiple Slack channel discussion, students hidden from each other](https://web.archive.org/web/20190923211940/https://case-for-a-refund.s3.us-east-2.amazonaws.com/multiple_slack_channels.png), [""Hundreds refunded""](https://web.archive.org/web/20190923212113/https://case-for-a-refund.s3.us-east-2.amazonaws.com/hundreds_refunded.png)

According to Twitter threads, he has been banning anyone in his Discord/Slack that has been asking for refunds.

On top of this there are many Twitter threads regarding his behavior. A screenshot (bottom of post) of an account that has since been deactivated/deleted (he made the account to try and get Siraj's attention). Here is a Twitter WayBackMachine archive link of a search for the user in the screenshot: [https://web.archive.org/web/20190921130513/https:/twitter.com/search?q=safayet96434935&src=typed\_query](https://web.archive.org/web/20190921130513/https:/twitter.com/search?q=safayet96434935&src=typed_query). In the search results it is apparent that there are many students who have been impacted by Siraj.

UPDATE 1: Additional searching on Twitter has yielded many more posts, check out the tweets/retweets of these people: [student1](https://web.archive.org/save/https:/twitter.com/ReneeSLiu1) [student2](https://web.archive.org/web/20190921133155/https://twitter.com/Aravind56898077)

UPDATE 2: A user mentioned that I should ask a question on r/legaladvice regarding the legality of the refusal to refund and whatnot. I have done so [here](https://www.reddit.com/r/legaladvice/comments/d7gopa/independent_online_course_false_advertising_and/). It appears that per California commerce law (where the School of AI is registered) individuals have the right to ask for a refund for 30 days.

UPDATE 3: Siraj has replied to the post below, and on [Twitter](https://web.archive.org/web/20190922213957/https://twitter.com/sirajraval/status/1175864213916372992?s=09) (Way Back Machine capture)

UPDATE 4: Another student has shared their interactions via [this Imgur post](https://imgur.com/gallery/msAdqBn). And another recorded moderators actively suppressing any mentions of refunds [on a live stream](https://web.archive.org/save/https://imgur.com/a/o1TMRY2). [Here is an example](https://imgur.com/a/KhMV6Xo) of assignment quality, note that the assignment is to generate fashion designs not pneumonia prediction.

UPDATE5: Relevant Reddit posts: [Siraj response](https://www.reddit.com/r/MachineLearning/comments/d7vv1l/d_siraj_apologizes_and_promises_refunds_within_30/), [question about opinions on course two weeks before this](https://www.reddit.com/r/learnmachinelearning/comments/cp7kht/guys_what_do_you_think_about_siraj_ravals_new/ewnv00m/?utm_source=share&utm_medium=web2x), [Siraj-Udacity relationship](https://www.reddit.com/r/MachineLearning/comments/d8nlqf/n_udacity_had_an_interventional_meeting_with/)

UPDATE6: The Register has [published a piece on the debacle](https://www.theregister.co.uk/2019/09/27/youtube_ai_star/), Coffezilla [posted a video on all of this](https://www.youtube.com/watch?v=7jmBE4yPrOs)

UPDATE7: Example of blatant ripoff: GitHub user gregwchase [diabetic retinopathy](https://github.com/gregwchase/dsi-capstone), Siraj's [ripoff](https://web.archive.org/web/20190928160728/https://github.com/llSourcell/AI_in_Medicine_Clinical_Imaging_Classification)

UPDATE8: Siraj has a [new paper and it is plagiarized](https://www.reddit.com/r/MachineLearning/comments/dh2xfs/d_siraj_has_a_new_paper_the_neural_qubit_its/)

If you were/are a student in the course and have your own documentation of your interactions, please feel free to bring them to my attention either via DM or in the comments below and I will add them to the main body here.

&#x200B;

https://preview.redd.it/i75r44bku7o31.jpg?width=347&format=pjpg&auto=webp&s=ec2f02ee1998e27ea00d529ffb2086657dc60d77",1569071811.0,1354.0,468.0,/r/MachineLearning/comments/d7ad2y/d_siraj_raval_potentially_exploiting_students/,https://www.reddit.com/r/MachineLearning/comments/d7ad2y/d_siraj_raval_potentially_exploiting_students/,nord2rocks,MachineLearning,0.98,True,False,False,False,0.0,1745833790.572468,Tech & Programming,13.0,445.0,449.0,Saturday,9.0,September,2019.0,True,0.9648,0.06,0.012,0.928,positive,d siraj raval potentially exploiting students banning students asking for refund thoughts,im not a personal follower of siraj but this issue came up in a ml fbook group that im part of im curious to hear what you all think it appears that siraj recently offered a course make money with machine learning with a registration fee but did not follow through with promises made in the initial offering of the course on top of that he created a refund and warranty page with information regarding the course after people already paid here is a link to a waybackmachine captures of uklarkens documentation of sirajs potential misdeeds case for a refund discussion in course discord individuals in the course multiple slack channel discussion students hidden from each other hundreds refunded according to twitter threads he has been banning anyone in his discordslack that has been asking for refunds on top of this there are many twitter threads regarding his behavior a screenshot bottom of post of an account that has since been deactivateddeleted he made the account to try and get sirajs attention here is a twitter waybackmachine archive link of a search for the user in the screenshot in the search results it is apparent that there are many students who have been impacted by siraj update additional searching on twitter has yielded many more posts check out the tweetsretweets of these people student student update a user mentioned that i should ask a question on rlegaladvice regarding the legality of the refusal to refund and whatnot i have done so here it appears that per california commerce law where the school of ai is registered individuals have the right to ask for a refund for days update siraj has replied to the post below and on twitter way back machine capture update another student has shared their interactions via this imgur post and another recorded moderators actively suppressing any mentions of refunds on a live stream here is an example of assignment quality note that the assignment is to generate fashion designs not pneumonia prediction update relevant reddit posts siraj response question about opinions on course two weeks before this sirajudacity relationship update the register has published a piece on the debacle coffezilla posted a video on all of this update example of blatant ripoff github user gregwchase diabetic retinopathy sirajs ripoff update siraj has a new paper and it is plagiarized if you wereare a student in the course and have your own documentation of your interactions please feel free to bring them to my attention either via dm or in the comments below and i will add them to the main body here xb,d siraj raval potentially exploiting students banning students asking for refund thoughts im not a personal follower of siraj but this issue came up in a ml fbook group that im part of im curious to hear what you all think it appears that siraj recently offered a course make money with machine learning with a registration fee but did not follow through with promises made in the initial offering of the course on top of that he created a refund and warranty page with information regarding the course after people already paid here is a link to a waybackmachine captures of uklarkens documentation of sirajs potential misdeeds case for a refund discussion in course discord individuals in the course multiple slack channel discussion students hidden from each other hundreds refunded according to twitter threads he has been banning anyone in his discordslack that has been asking for refunds on top of this there are many twitter threads regarding his behavior a screenshot bottom of post of an account that has since been deactivateddeleted he made the account to try and get sirajs attention here is a twitter waybackmachine archive link of a search for the user in the screenshot in the search results it is apparent that there are many students who have been impacted by siraj update additional searching on twitter has yielded many more posts check out the tweetsretweets of these people student student update a user mentioned that i should ask a question on rlegaladvice regarding the legality of the refusal to refund and whatnot i have done so here it appears that per california commerce law where the school of ai is registered individuals have the right to ask for a refund for days update siraj has replied to the post below and on twitter way back machine capture update another student has shared their interactions via this imgur post and another recorded moderators actively suppressing any mentions of refunds on a live stream here is an example of assignment quality note that the assignment is to generate fashion designs not pneumonia prediction update relevant reddit posts siraj response question about opinions on course two weeks before this sirajudacity relationship update the register has published a piece on the debacle coffezilla posted a video on all of this update example of blatant ripoff github user gregwchase diabetic retinopathy sirajs ripoff update siraj has a new paper and it is plagiarized if you wereare a student in the course and have your own documentation of your interactions please feel free to bring them to my attention either via dm or in the comments below and i will add them to the main body here xb,"student, update, siraj, refund, course",2019-09-21 13:16:51,d siraj raval potentially exploiting students banning students asking for refund thoughts im not a personal follower of siraj but this issue came up in a ml fbook group that im part of im curious to hear what you all think it appears that siraj recently offered a course make money with machine learning with a registration fee but did not follow through with promises made in the initial offering of the course on top of that he created a refund and warranty page with information regarding the course after people already paid here is a link to a waybackmachine captures of uklarkens documentation of sirajs potential misdeeds case for a refund discussion in course discord individuals in the course multiple slack channel discussion students hidden from each other hundreds refunded according to twitter threads he has been banning anyone in his discordslack that has been asking for refunds on top of this there are many twitter threads regarding his behavior a screenshot bottom of post of an account that has since been deactivateddeleted he made the account to try and get sirajs attention here is a twitter waybackmachine archive link of a search for the user in the screenshot in the search results it is apparent that there are many students who have been impacted by siraj update additional searching on twitter has yielded many more posts check out the tweetsretweets of these people student student update a user mentioned that i should ask a question on rlegaladvice regarding the legality of the refusal to refund and whatnot i have done so here it appears that per california commerce law where the school of ai is registered individuals have the right to ask for a refund for days update siraj has replied to the post below and on twitter way back machine capture update another student has shared their interactions via this imgur post and another recorded moderators actively suppressing any mentions of refunds on a live stream here is an example of assignment quality note that the assignment is to generate fashion designs not pneumonia prediction update relevant reddit posts siraj response question about opinions on course two weeks before this sirajudacity relationship update the register has published a piece on the debacle coffezilla posted a video on all of this update example of blatant ripoff github user gregwchase diabetic retinopathy sirajs ripoff update siraj has a new paper and it is plagiarized if you wereare a student in the course and have your own documentation of your interactions please feel free to bring them to my attention either via dm or in the comments below and i will add them to the main body here xb,"['siraj', 'raval', 'potentially', 'exploiting', 'student', 'banning', 'student', 'asking', 'refund', 'thought', 'personal', 'follower', 'siraj', 'issue', 'came', 'fbook', 'group', 'part', 'curious', 'hear', 'think', 'appears', 'siraj', 'recently', 'offered', 'course', 'make', 'money', 'machine', 'learning', 'registration', 'fee', 'follow', 'promise', 'made', 'initial', 'offering', 'course', 'top', 'created', 'refund', 'warranty', 'page', 'information', 'regarding', 'course', 'people', 'already', 'paid', 'link', 'waybackmachine', 'capture', 'uklarkens', 'documentation', 'sirajs', 'potential', 'misdeed', 'case', 'refund', 'discussion', 'course', 'discord', 'individual', 'course', 'multiple', 'slack', 'channel', 'discussion', 'student', 'hidden', 'hundred', 'refunded', 'according', 'twitter', 'thread', 'banning', 'anyone', 'discordslack', 'asking', 'refund', 'top', 'many', 'twitter', 'thread', 'regarding', 'behavior', 'screenshot', 'bottom', 'post', 'account', 'since', 'deactivateddeleted', 'made', 'account', 'try', 'get', 'sirajs', 'attention', 'twitter', 'waybackmachine', 'archive', 'link', 'search', 'user', 'screenshot', 'search', 'result', 'apparent', 'many', 'student', 'impacted', 'siraj', 'update', 'additional', 'searching', 'twitter', 'yielded', 'many', 'post', 'check', 'tweetsretweets', 'people', 'student', 'student', 'update', 'user', 'mentioned', 'ask', 'question', 'rlegaladvice', 'regarding', 'legality', 'refusal', 'refund', 'whatnot', 'done', 'appears', 'per', 'california', 'commerce', 'law', 'school', 'registered', 'individual', 'right', 'ask', 'refund', 'day', 'update', 'siraj', 'replied', 'post', 'twitter', 'way', 'back', 'machine', 'capture', 'update', 'another', 'student', 'shared', 'interaction', 'via', 'imgur', 'post', 'another', 'recorded', 'moderator', 'actively', 'suppressing', 'mention', 'refund', 'live', 'stream', 'example', 'assignment', 'quality', 'note', 'assignment', 'generate', 'fashion', 'design', 'pneumonia', 'prediction', 'update', 'relevant', 'reddit', 'post', 'siraj', 'response', 'question', 'opinion', 'course', 'two', 'week', 'sirajudacity', 'relationship', 'update', 'register', 'published', 'piece', 'debacle', 'coffezilla', 'posted', 'video', 'update', 'example', 'blatant', 'ripoff', 'github', 'user', 'gregwchase', 'diabetic', 'retinopathy', 'sirajs', 'ripoff', 'update', 'siraj', 'new', 'paper', 'plagiarized', 'wereare', 'student', 'course', 'documentation', 'interaction', 'please', 'feel', 'free', 'bring', 'attention', 'either', 'via', 'comment', 'add', 'main', 'body']",,,,
jdeyp9,[P] Predict your political leaning from your reddit comment history! (Webapp linked in comments),,1603021585.0,1352.0,188.0,/r/MachineLearning/comments/jdeyp9/p_predict_your_political_leaning_from_your_reddit/,https://i.redd.it/7gh5ykmmcut51.gif,tigeer,MachineLearning,0.95,False,False,False,False,2.0,1745833792.763177,Tech & Programming,14.0,0.0,14.0,Sunday,7.0,October,2020.0,True,0.0,0.0,0.0,1.0,neutral,p predict your political leaning from your reddit comment history webapp linked in comments,,p predict your political leaning from your reddit comment history webapp linked in comments ,"comment, predict, political, leaning, reddit",2020-10-18 11:46:25,p predict your political leaning from your reddit comment history webapp linked in comments ,"['predict', 'political', 'leaning', 'reddit', 'comment', 'history', 'webapp', 'linked', 'comment']",,,,
14kv1ym,"So long r/MachineLearning, it's been an interesting few years","Some of you may recognize me, most of you probably don't. I've been the most active moderator of r/MachineLearning for a few years now, but on June 30th I'll be deleting my Reddit account.

I pretty much exclusively used Apollo to moderate. It would notify me of any new post, which allowed me to moderate from anywhere, anytime. That's how I stayed on top of moderating such a large sub.

When I stepped back on my moderation efforts a few months ago, [the effects](https://old.reddit.com/r/MachineLearning/comments/110swn2/d_quality_of_posts_in_this_sub_going_down) were quite apparent to [many of you](https://old.reddit.com/r/MachineLearning/comments/115ez2r/deleted_by_user).

Of course, this is the internet, and each of you have your own subjective view on moderation. Just know that it is a very time consuming task that I did for free because I genuinely cared about the community.

If you want to join me, I'll be moving on to kbin where I'm a moderator for [m/machinelearning](https://kbin.social/m/machinelearning). Otherwise, this is my farewell.

P.S. I'm sure there will be some who are sympathetic and some who just have an axe to grind and will complain about anything. I'm not a piñata; there's no prize inside if you bash me, but if you just can't help yourself, then have at it. I'll be gone soon anyway.",1687913569.0,1327.0,91.0,/r/MachineLearning/comments/14kv1ym/so_long_rmachinelearning_its_been_an_interesting/,https://www.reddit.com/r/MachineLearning/comments/14kv1ym/so_long_rmachinelearning_its_been_an_interesting/,,MachineLearning,0.92,True,False,False,False,0.0,1745833794.069436,Tech & Programming,9.0,205.0,214.0,Tuesday,20.0,June,2023.0,False,0.9523,0.153,0.078,0.768,positive,so long rmachinelearning its been an interesting few years,some of you may recognize me most of you probably dont ive been the most active moderator of rmachinelearning for a few years now but on june th ill be deleting my reddit account i pretty much exclusively used apollo to moderate it would notify me of any new post which allowed me to moderate from anywhere anytime thats how i stayed on top of moderating such a large sub when i stepped back on my moderation efforts a few months ago the effects were quite apparent to many of you of course this is the internet and each of you have your own subjective view on moderation just know that it is a very time consuming task that i did for free because i genuinely cared about the community if you want to join me ill be moving on to kbin where im a moderator for mmachinelearning otherwise this is my farewell ps im sure there will be some who are sympathetic and some who just have an axe to grind and will complain about anything im not a piñata theres no prize inside if you bash me but if you just cant help yourself then have at it ill be gone soon anyway,so long rmachinelearning its been an interesting few years some of you may recognize me most of you probably dont ive been the most active moderator of rmachinelearning for a few years now but on june th ill be deleting my reddit account i pretty much exclusively used apollo to moderate it would notify me of any new post which allowed me to moderate from anywhere anytime thats how i stayed on top of moderating such a large sub when i stepped back on my moderation efforts a few months ago the effects were quite apparent to many of you of course this is the internet and each of you have your own subjective view on moderation just know that it is a very time consuming task that i did for free because i genuinely cared about the community if you want to join me ill be moving on to kbin where im a moderator for mmachinelearning otherwise this is my farewell ps im sure there will be some who are sympathetic and some who just have an axe to grind and will complain about anything im not a piñata theres no prize inside if you bash me but if you just cant help yourself then have at it ill be gone soon anyway,"ill, rmachinelearning, year, moderator, moderate",2023-06-28 00:52:49,so long rmachinelearning its been an interesting few years some of you may recognize me most of you probably dont ive been the most active moderator of rmachinelearning for a few years now but on june th ill be deleting my reddit account i pretty much exclusively used apollo to moderate it would notify me of any new post which allowed me to moderate from anywhere anytime thats how i stayed on top of moderating such a large sub when i stepped back on my moderation efforts a few months ago the effects were quite apparent to many of you of course this is the internet and each of you have your own subjective view on moderation just know that it is a very time consuming task that i did for free because i genuinely cared about the community if you want to join me ill be moving on to kbin where im a moderator for mmachinelearning otherwise this is my farewell ps im sure there will be some who are sympathetic and some who just have an axe to grind and will complain about anything im not a piñata theres no prize inside if you bash me but if you just cant help yourself then have at it ill be gone soon anyway,"['long', 'rmachinelearning', 'interesting', 'year', 'may', 'recognize', 'probably', 'dont', 'ive', 'active', 'moderator', 'rmachinelearning', 'year', 'june', 'ill', 'deleting', 'reddit', 'account', 'pretty', 'much', 'exclusively', 'used', 'apollo', 'moderate', 'would', 'notify', 'new', 'post', 'allowed', 'moderate', 'anywhere', 'anytime', 'thats', 'stayed', 'top', 'moderating', 'large', 'sub', 'stepped', 'back', 'moderation', 'effort', 'month', 'ago', 'effect', 'quite', 'apparent', 'many', 'course', 'internet', 'subjective', 'view', 'moderation', 'know', 'time', 'consuming', 'task', 'free', 'genuinely', 'cared', 'community', 'want', 'join', 'ill', 'moving', 'kbin', 'moderator', 'mmachinelearning', 'otherwise', 'farewell', 'sure', 'sympathetic', 'axe', 'grind', 'complain', 'anything', 'piñata', 'there', 'prize', 'inside', 'bash', 'cant', 'help', 'ill', 'gone', 'soon', 'anyway']",,,,
k3ygrc,[R] AlphaFold 2,"Seems like DeepMind just caused the ImageNet moment for protein folding.

Blog post isn't that deeply informative yet (paper is promised to appear soonish). Seems like the improvement over the first version of AlphaFold is mostly usage of transformer/attention mechanisms applied to residue space and combining it with the working ideas from the first version. Compute budget is surprisingly moderate given how crazy the results are. Exciting times for people working in the intersection of molecular sciences and ML :)

Tweet by Mohammed AlQuraishi (well-known domain expert)  
[https://twitter.com/MoAlQuraishi/status/1333383634649313280](https://twitter.com/MoAlQuraishi/status/1333383634649313280)

DeepMind BlogPost  
[https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)  


UPDATE:   
Nature published a comment on it as well  
[https://www.nature.com/articles/d41586-020-03348-4](https://www.nature.com/articles/d41586-020-03348-4)",1606751771.0,1326.0,240.0,/r/MachineLearning/comments/k3ygrc/r_alphafold_2/,https://www.reddit.com/r/MachineLearning/comments/k3ygrc/r_alphafold_2/,konasj,MachineLearning,0.98,True,False,False,False,1.0,1745833794.518265,Tech & Programming,3.0,101.0,99.0,Monday,10.0,November,2020.0,False,0.9274,0.165,0.022,0.814,positive,r alphafold,seems like deepmind just caused the imagenet moment for protein folding blog post isnt that deeply informative yet paper is promised to appear soonish seems like the improvement over the first version of alphafold is mostly usage of transformerattention mechanisms applied to residue space and combining it with the working ideas from the first version compute budget is surprisingly moderate given how crazy the results are exciting times for people working in the intersection of molecular sciences and ml tweet by mohammed alquraishi wellknown domain expert deepmind blogpost update nature published a comment on it as well,r alphafold seems like deepmind just caused the imagenet moment for protein folding blog post isnt that deeply informative yet paper is promised to appear soonish seems like the improvement over the first version of alphafold is mostly usage of transformerattention mechanisms applied to residue space and combining it with the working ideas from the first version compute budget is surprisingly moderate given how crazy the results are exciting times for people working in the intersection of molecular sciences and ml tweet by mohammed alquraishi wellknown domain expert deepmind blogpost update nature published a comment on it as well,"alphafold, seems, like, deepmind, first",2020-11-30 15:56:11,r alphafold seems like deepmind just caused the imagenet moment for protein folding blog post isnt that deeply informative yet paper is promised to appear soonish seems like the improvement over the first version of alphafold is mostly usage of transformerattention mechanisms applied to residue space and combining it with the working ideas from the first version compute budget is surprisingly moderate given how crazy the results are exciting times for people working in the intersection of molecular sciences and ml tweet by mohammed alquraishi wellknown domain expert deepmind blogpost update nature published a comment on it as well,"['alphafold', 'seems', 'like', 'deepmind', 'caused', 'imagenet', 'moment', 'protein', 'folding', 'blog', 'post', 'isnt', 'deeply', 'informative', 'yet', 'paper', 'promised', 'appear', 'soonish', 'seems', 'like', 'improvement', 'first', 'version', 'alphafold', 'mostly', 'usage', 'transformerattention', 'mechanism', 'applied', 'residue', 'space', 'combining', 'working', 'idea', 'first', 'version', 'compute', 'budget', 'surprisingly', 'moderate', 'given', 'crazy', 'result', 'exciting', 'time', 'people', 'working', 'intersection', 'molecular', 'science', 'tweet', 'mohammed', 'alquraishi', 'wellknown', 'domain', 'expert', 'deepmind', 'blogpost', 'update', 'nature', 'published', 'comment', 'well']",,,,
8l5w56,[P] Generative Ramen,,1526950824.0,1312.0,76.0,/r/MachineLearning/comments/8l5w56/p_generative_ramen/,https://i.redd.it/la6q5y853bz01.gif,wei_jok,MachineLearning,0.95,False,False,False,False,0.0,1745833795.72995,Tech & Programming,3.0,0.0,3.0,Monday,21.0,May,2018.0,False,0.0,0.0,0.0,1.0,neutral,p generative ramen,,p generative ramen ,"generative, ramen",2018-05-22 01:00:24,p generative ramen ,"['generative', 'ramen']",,,,
1cjxh9u,"[D] The ""it"" in AI models is really just the dataset?",,1714819651.0,1313.0,272.0,/r/MachineLearning/comments/1cjxh9u/d_the_it_in_ai_models_is_really_just_the_dataset/,https://i.redd.it/uadactn53eyc1.png,vijayabhaskar96,MachineLearning,0.95,False,False,False,False,0.0,1745833796.399896,Tech & Programming,11.0,0.0,11.0,Saturday,6.0,May,2024.0,True,0.0,0.0,0.0,1.0,neutral,d the it in ai models is really just the dataset,,d the it in ai models is really just the dataset ,"model, really, dataset",2024-05-04 10:47:31,d the it in ai models is really just the dataset ,"['model', 'really', 'dataset']",,,,
wz68mz,[P] Run Stable Diffusion locally with a web UI + artist workflow video,,1661615696.0,1312.0,52.0,/r/MachineLearning/comments/wz68mz/p_run_stable_diffusion_locally_with_a_web_ui/,https://v.redd.it/djdpfsmy2ak91,Illustrious_Row_9971,MachineLearning,0.99,False,False,False,False,0.0,1745833797.789278,Tech & Programming,13.0,0.0,12.0,Saturday,11.0,August,2022.0,True,0.296,0.196,0.0,0.804,positive,p run stable diffusion locally with a web ui artist workflow video,,p run stable diffusion locally with a web ui artist workflow video ,"run, stable, diffusion, locally, web",2022-08-27 15:54:56,p run stable diffusion locally with a web ui artist workflow video ,"['run', 'stable', 'diffusion', 'locally', 'web', 'artist', 'workflow', 'video']",,,,
8kbmyn,"[D] If you had to show one paper to someone to show that machine learning is beautiful, what would you choose? (assuming they're equipped to understand it)",,1526632476.0,1308.0,276.0,/r/MachineLearning/comments/8kbmyn/d_if_you_had_to_show_one_paper_to_someone_to_show/,https://www.reddit.com/r/MachineLearning/comments/8kbmyn/d_if_you_had_to_show_one_paper_to_someone_to_show/,MTGTraner,MachineLearning,0.99,True,False,False,False,0.0,1745833798.185016,Tech & Programming,27.0,0.0,27.0,Friday,4.0,May,2018.0,False,0.5994,0.135,0.0,0.865,positive,d if you had to show one paper to someone to show that machine learning is beautiful what would you choose assuming theyre equipped to understand it,,d if you had to show one paper to someone to show that machine learning is beautiful what would you choose assuming theyre equipped to understand it ,"show, one, paper, someone, machine",2018-05-18 08:34:36,d if you had to show one paper to someone to show that machine learning is beautiful what would you choose assuming theyre equipped to understand it ,"['show', 'one', 'paper', 'someone', 'show', 'machine', 'learning', 'beautiful', 'would', 'choose', 'assuming', 'theyre', 'equipped', 'understand']",,,,
qjpcut,[Project] These plants do not exist - Using StyleGan2,,1635686392.0,1310.0,26.0,/r/MachineLearning/comments/qjpcut/project_these_plants_do_not_exist_using_stylegan2/,https://v.redd.it/jxy5m9bvcsw71,vadhavaniyafaijan,MachineLearning,0.99,False,False,False,False,0.0,1745833799.42502,Tech & Programming,9.0,0.0,8.0,Sunday,9.0,October,2021.0,True,0.0,0.0,0.0,1.0,neutral,project these plants do not exist using stylegan,,project these plants do not exist using stylegan ,"project, plant, exist, using, stylegan",2021-10-31 13:19:52,project these plants do not exist using stylegan ,"['project', 'plant', 'exist', 'using', 'stylegan']",,,,
4w6tsv,AMA: We are the Google Brain team. We'd love to answer your questions about machine learning.,"We’re a group of research scientists and engineers that work on the [Google Brain team](http://g.co/brain).  Our group’s mission is to make intelligent machines, and to use them to improve people’s lives.  For the last five years, we’ve conducted research and built systems to advance this mission.

We disseminate our work in multiple ways:

* By publishing papers about our research (see [publication list](https://research.google.com/pubs/BrainTeam.html))
* By building and open-sourcing software systems like TensorFlow (see [tensorflow.org](http://tensorflow.org) and [https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow))
* By working with other teams at Google and Alphabet to get our work into the hands of billions of people (some examples: [RankBrain for Google Search](https://en.wikipedia.org/wiki/RankBrain), [SmartReply for GMail](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html), [Google Photos](https://research.googleblog.com/2014/09/building-deeper-understanding-of-images.html), [Google Speech Recognition](https://research.googleblog.com/2012/08/speech-recognition-and-deep-learning.html), …)
* By training new researchers through internships and the [Google Brain Residency](http://g.co/brainresidency) program

We are:

* [Jeff Dean](http://research.google.com/people/jeff) (/u/jeffatgoogle)
* [Geoffrey Hinton](https://research.google.com/pubs/GeoffreyHinton.html) (/u/geoffhinton)
* [Vijay Vasudevan](http://research.google.com/pubs/VijayVasudevan.html) (/u/Spezzer)
* [Vincent Vanhoucke](http://research.google.com/pubs/VincentVanhoucke.html) (/u/vincentvanhoucke)
* [Chris Olah](http://research.google.com/pubs/ChristopherOlah.html) (/u/colah)
* [Rajat Monga](http://research.google.com/pubs/RajatMonga.html) (/u/rajatmonga)
* [Greg Corrado](http://research.google.com/pubs/GregCorrado.html) (/u/gcorrado)
* [George Dahl](https://scholar.google.com/citations?user=ghbWy-0AAAAJ&hl=en) (/u/gdahl)
* [Doug Eck](http://research.google.com/pubs/author39086.html) (/u/douglaseck)
* [Samy Bengio](http://research.google.com/pubs/bengio.html) (/u/samybengio)
* [Quoc Le](http://research.google.com/pubs/QuocLe.html) (/u/quocle)
* [Martin Abadi](http://research.google.com/pubs/abadi.html) (/u/martinabadi)
* [Claire Cui](https://www.linkedin.com/in/claire-cui-5021035) (/u/clairecui)
* [Anna Goldie](https://www.linkedin.com/in/adgoldie) (/u/anna_goldie)
* [Zak Stone](https://www.linkedin.com/in/zstone) (/u/poiguy)
* [Dan Mané](https://www.linkedin.com/in/danmane) (/u/danmane)
* [David Patterson](https://www2.eecs.berkeley.edu/Faculty/Homepages/patterson.html) (/u/pattrsn)
* [Maithra Raghu](http://maithraraghu.com/) (/u/mraghu)
* [Anelia Angelova](http://research.google.com/pubs/AneliaAngelova.html) (/u/aangelova)
* [Fernanda Viégas](http://hint.fm/) (/u/fernanda_viegas)
* [Martin Wattenberg](http://hint.fm/) (/u/martin_wattenberg)
* [David Ha](http://blog.otoro.net/) (/u/hardmaru)
* [Sherry Moore](https://www.linkedin.com/in/sherry-moore-38b3a32) (/u/sherryqmoore/)
* … and maybe others: we’ll update if others become involved.

We’re excited to answer your questions about the Brain team and/or machine learning!  (We’re gathering questions now and will be answering them on August 11, 2016).

Edit (~10 AM Pacific time): A number of us are gathered in Mountain View, San Francisco, Toronto, and Cambridge (MA), snacks close at hand.  Thanks for all the questions, and we're excited to get this started.

Edit2: We're back from lunch.  Here's [our AMA command center](http://imgur.com/gallery/zHkoC)

Edit3: (2:45 PM Pacific time): We're mostly done here.  Thanks for the questions, everyone!  We may continue to answer questions sporadically throughout the day.",1470345084.0,1311.0,791.0,/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/,https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/,jeffatgoogle,MachineLearning,0.95,True,False,False,False,0.0,1745833800.136622,Tech & Programming,16.0,326.0,307.0,Thursday,17.0,August,2016.0,False,0.9821,0.099,0.0,0.901,positive,ama we are the google brain team wed love to answer your questions about machine learning,were a group of research scientists and engineers that work on the google brain team our groups mission is to make intelligent machines and to use them to improve peoples lives for the last five years weve conducted research and built systems to advance this mission we disseminate our work in multiple ways by publishing papers about our research see publication list by building and opensourcing software systems like tensorflow see tensorfloworg and by working with other teams at google and alphabet to get our work into the hands of billions of people some examples rankbrain for google search smartreply for gmail google photos google speech recognition by training new researchers through internships and the google brain residency program we are jeff dean ujeffatgoogle geoffrey hinton ugeoffhinton vijay vasudevan uspezzer vincent vanhoucke uvincentvanhoucke chris olah ucolah rajat monga urajatmonga greg corrado ugcorrado george dahl ugdahl doug eck udouglaseck samy bengio usamybengio quoc le uquocle martin abadi umartinabadi claire cui uclairecui anna goldie uanna_goldie zak stone upoiguy dan mané udanmane david patterson upattrsn maithra raghu umraghu anelia angelova uaangelova fernanda viégas ufernanda_viegas martin wattenberg umartin_wattenberg david ha uhardmaru sherry moore usherryqmoore and maybe others well update if others become involved were excited to answer your questions about the brain team andor machine learning were gathering questions now and will be answering them on august edit am pacific time a number of us are gathered in mountain view san francisco toronto and cambridge ma snacks close at hand thanks for all the questions and were excited to get this started edit were back from lunch heres our ama command center edit pm pacific time were mostly done here thanks for the questions everyone we may continue to answer questions sporadically throughout the day,ama we are the google brain team wed love to answer your questions about machine learning were a group of research scientists and engineers that work on the google brain team our groups mission is to make intelligent machines and to use them to improve peoples lives for the last five years weve conducted research and built systems to advance this mission we disseminate our work in multiple ways by publishing papers about our research see publication list by building and opensourcing software systems like tensorflow see tensorfloworg and by working with other teams at google and alphabet to get our work into the hands of billions of people some examples rankbrain for google search smartreply for gmail google photos google speech recognition by training new researchers through internships and the google brain residency program we are jeff dean ujeffatgoogle geoffrey hinton ugeoffhinton vijay vasudevan uspezzer vincent vanhoucke uvincentvanhoucke chris olah ucolah rajat monga urajatmonga greg corrado ugcorrado george dahl ugdahl doug eck udouglaseck samy bengio usamybengio quoc le uquocle martin abadi umartinabadi claire cui uclairecui anna goldie uanna_goldie zak stone upoiguy dan mané udanmane david patterson upattrsn maithra raghu umraghu anelia angelova uaangelova fernanda viégas ufernanda_viegas martin wattenberg umartin_wattenberg david ha uhardmaru sherry moore usherryqmoore and maybe others well update if others become involved were excited to answer your questions about the brain team andor machine learning were gathering questions now and will be answering them on august edit am pacific time a number of us are gathered in mountain view san francisco toronto and cambridge ma snacks close at hand thanks for all the questions and were excited to get this started edit were back from lunch heres our ama command center edit pm pacific time were mostly done here thanks for the questions everyone we may continue to answer questions sporadically throughout the day,"google, question, brain, team, answer",2016-08-04 21:11:24,ama we are the google brain team wed love to answer your questions about machine learning were a group of research scientists and engineers that work on the google brain team our groups mission is to make intelligent machines and to use them to improve peoples lives for the last five years weve conducted research and built systems to advance this mission we disseminate our work in multiple ways by publishing papers about our research see publication list by building and opensourcing software systems like tensorflow see tensorfloworg and by working with other teams at google and alphabet to get our work into the hands of billions of people some examples rankbrain for google search smartreply for gmail google photos google speech recognition by training new researchers through internships and the google brain residency program we are jeff dean ujeffatgoogle geoffrey hinton ugeoffhinton vijay vasudevan uspezzer vincent vanhoucke uvincentvanhoucke chris olah ucolah rajat monga urajatmonga greg corrado ugcorrado george dahl ugdahl doug eck udouglaseck samy bengio usamybengio quoc le uquocle martin abadi umartinabadi claire cui uclairecui anna goldie uanna_goldie zak stone upoiguy dan mané udanmane david patterson upattrsn maithra raghu umraghu anelia angelova uaangelova fernanda viégas ufernanda_viegas martin wattenberg umartin_wattenberg david ha uhardmaru sherry moore usherryqmoore and maybe others well update if others become involved were excited to answer your questions about the brain team andor machine learning were gathering questions now and will be answering them on august edit am pacific time a number of us are gathered in mountain view san francisco toronto and cambridge ma snacks close at hand thanks for all the questions and were excited to get this started edit were back from lunch heres our ama command center edit pm pacific time were mostly done here thanks for the questions everyone we may continue to answer questions sporadically throughout the day,"['ama', 'google', 'brain', 'team', 'wed', 'love', 'answer', 'question', 'machine', 'learning', 'group', 'research', 'scientist', 'engineer', 'work', 'google', 'brain', 'team', 'group', 'mission', 'make', 'intelligent', 'machine', 'use', 'improve', 'people', 'life', 'last', 'five', 'year', 'weve', 'conducted', 'research', 'built', 'system', 'advance', 'mission', 'disseminate', 'work', 'multiple', 'way', 'publishing', 'paper', 'research', 'see', 'publication', 'list', 'building', 'opensourcing', 'software', 'system', 'like', 'tensorflow', 'see', 'tensorfloworg', 'working', 'team', 'google', 'alphabet', 'get', 'work', 'hand', 'billion', 'people', 'example', 'rankbrain', 'google', 'search', 'smartreply', 'gmail', 'google', 'photo', 'google', 'speech', 'recognition', 'training', 'new', 'researcher', 'internship', 'google', 'brain', 'residency', 'program', 'jeff', 'dean', 'ujeffatgoogle', 'geoffrey', 'hinton', 'ugeoffhinton', 'vijay', 'vasudevan', 'uspezzer', 'vincent', 'vanhoucke', 'uvincentvanhoucke', 'chris', 'olah', 'ucolah', 'rajat', 'monga', 'urajatmonga', 'greg', 'corrado', 'ugcorrado', 'george', 'dahl', 'ugdahl', 'doug', 'eck', 'udouglaseck', 'samy', 'bengio', 'usamybengio', 'quoc', 'uquocle', 'martin', 'abadi', 'umartinabadi', 'claire', 'cui', 'uclairecui', 'anna', 'goldie', 'uanna_goldie', 'zak', 'stone', 'upoiguy', 'dan', 'mané', 'udanmane', 'david', 'patterson', 'upattrsn', 'maithra', 'raghu', 'umraghu', 'anelia', 'angelova', 'uaangelova', 'fernanda', 'viégas', 'ufernanda_viegas', 'martin', 'wattenberg', 'umartin_wattenberg', 'david', 'uhardmaru', 'sherry', 'moore', 'usherryqmoore', 'maybe', 'others', 'well', 'update', 'others', 'become', 'involved', 'excited', 'answer', 'question', 'brain', 'team', 'andor', 'machine', 'learning', 'gathering', 'question', 'answering', 'august', 'edit', 'pacific', 'time', 'number', 'gathered', 'mountain', 'view', 'san', 'francisco', 'toronto', 'cambridge', 'snack', 'close', 'hand', 'thanks', 'question', 'excited', 'get', 'started', 'edit', 'back', 'lunch', 'here', 'ama', 'command', 'center', 'edit', 'pacific', 'time', 'mostly', 'done', 'thanks', 'question', 'everyone', 'may', 'continue', 'answer', 'question', 'sporadically', 'throughout', 'day']",,,,
10ujsk5,[P] I made a browser extension that uses ChatGPT to answer every StackOverflow question,,1675622354.0,1300.0,133.0,/r/MachineLearning/comments/10ujsk5/p_i_made_a_browser_extension_that_uses_chatgpt_to/,https://v.redd.it/ipqpfw7vzega1,jsonathan,MachineLearning,0.88,False,False,False,False,1.0,1745833802.470257,Tech & Programming,14.0,0.0,14.0,Sunday,13.0,February,2023.0,True,0.0,0.0,0.0,1.0,neutral,p i made a browser extension that uses chatgpt to answer every stackoverflow question,,p i made a browser extension that uses chatgpt to answer every stackoverflow question ,"made, browser, extension, us, chatgpt",2023-02-05 18:39:14,p i made a browser extension that uses chatgpt to answer every stackoverflow question ,"['made', 'browser', 'extension', 'us', 'chatgpt', 'answer', 'every', 'stackoverflow', 'question']",,,,
7y6g79,[P] Landing the Falcon booster with Reinforcement Learning in OpenAI,,1518871530.0,1290.0,55.0,/r/MachineLearning/comments/7y6g79/p_landing_the_falcon_booster_with_reinforcement/,https://gfycat.com/CoarseEmbellishedIsopod,EmbersArc,MachineLearning,0.95,False,False,False,False,0.0,1745833803.441501,Tech & Programming,10.0,0.0,10.0,Saturday,7.0,February,2018.0,True,0.0,0.0,0.0,1.0,neutral,p landing the falcon booster with reinforcement learning in openai,,p landing the falcon booster with reinforcement learning in openai ,"landing, falcon, booster, reinforcement, learning",2018-02-17 12:45:30,p landing the falcon booster with reinforcement learning in openai ,"['landing', 'falcon', 'booster', 'reinforcement', 'learning', 'openai']",,,,
zo2nl1,[P] Football Player 3D Pose Estimation using YOLOv7,,1671269271.0,1287.0,44.0,/r/MachineLearning/comments/zo2nl1/p_football_player_3d_pose_estimation_using_yolov7/,https://v.redd.it/wxi4sebsff6a1,RandomForests92,MachineLearning,0.98,False,False,False,False,0.0,1745833803.898134,Tech & Programming,8.0,0.0,8.0,Saturday,4.0,December,2022.0,True,0.0,0.0,0.0,1.0,neutral,p football player d pose estimation using yolov,,p football player d pose estimation using yolov ,"football, player, pose, estimation, using",2022-12-17 09:27:51,p football player d pose estimation using yolov ,"['football', 'player', 'pose', 'estimation', 'using', 'yolov']",,,,
eesoav,"[N] 4 Months after Siraj was caught scamming he has still not refunded any victims based in India, Philippines, or any other countries with no legal recourse. He makes an apology video, and when his victims ask for their refund, his followers respond with ""Be kind. He's asking for your forgiveness""","This is fucking sick..

People based in India, the Philippines, and other countries that do not have the resources to go after Siraj legally are those who need the money the most. 200$ could be a months worth of salary, or several months. And the types of people who get caught up in the scams are those who genuinely looking to improve their financial situation and work hard for it. This is fucking **cruel**. 

I'm having a hard time believing Siraj's followers are that brainwashed. Most likely alt accounts controlled by Siraj.

https://i.imgur.com/6cUhQDO.png

https://i.imgur.com/TDx5ELA.png",1577144539.0,1281.0,173.0,/r/MachineLearning/comments/eesoav/n_4_months_after_siraj_was_caught_scamming_he_has/,https://www.reddit.com/r/MachineLearning/comments/eesoav/n_4_months_after_siraj_was_caught_scamming_he_has/,RelevantMarketing,MachineLearning,0.96,True,False,False,False,0.0,1745833804.249015,Tech & Programming,51.0,94.0,141.0,Monday,18.0,December,2019.0,False,-0.2874,0.116,0.104,0.779,negative,n months after siraj was caught scamming he has still not refunded any victims based in india philippines or any other countries with no legal recourse he makes an apology video and when his victims ask for their refund his followers respond with be kind hes asking for your forgiveness,this is fucking sick people based in india the philippines and other countries that do not have the resources to go after siraj legally are those who need the money the most could be a months worth of salary or several months and the types of people who get caught up in the scams are those who genuinely looking to improve their financial situation and work hard for it this is fucking cruel im having a hard time believing sirajs followers are that brainwashed most likely alt accounts controlled by siraj,n months after siraj was caught scamming he has still not refunded any victims based in india philippines or any other countries with no legal recourse he makes an apology video and when his victims ask for their refund his followers respond with be kind hes asking for your forgiveness this is fucking sick people based in india the philippines and other countries that do not have the resources to go after siraj legally are those who need the money the most could be a months worth of salary or several months and the types of people who get caught up in the scams are those who genuinely looking to improve their financial situation and work hard for it this is fucking cruel im having a hard time believing sirajs followers are that brainwashed most likely alt accounts controlled by siraj,"month, siraj, caught, victim, based",2019-12-23 23:42:19,n months after siraj was caught scamming he has still not refunded any victims based in india philippines or any other countries with no legal recourse he makes an apology video and when his victims ask for their refund his followers respond with be kind hes asking for your forgiveness this is fucking sick people based in india the philippines and other countries that do not have the resources to go after siraj legally are those who need the money the most could be a months worth of salary or several months and the types of people who get caught up in the scams are those who genuinely looking to improve their financial situation and work hard for it this is fucking cruel im having a hard time believing sirajs followers are that brainwashed most likely alt accounts controlled by siraj,"['month', 'siraj', 'caught', 'scamming', 'still', 'refunded', 'victim', 'based', 'india', 'philippine', 'country', 'legal', 'recourse', 'make', 'apology', 'video', 'victim', 'ask', 'refund', 'follower', 'respond', 'kind', 'he', 'asking', 'forgiveness', 'fucking', 'sick', 'people', 'based', 'india', 'philippine', 'country', 'resource', 'siraj', 'legally', 'need', 'money', 'could', 'month', 'worth', 'salary', 'several', 'month', 'type', 'people', 'get', 'caught', 'scam', 'genuinely', 'looking', 'improve', 'financial', 'situation', 'work', 'hard', 'fucking', 'cruel', 'hard', 'time', 'believing', 'sirajs', 'follower', 'brainwashed', 'likely', 'alt', 'account', 'controlled', 'siraj']",,,,
u0o0yy,[N]: Dall-E 2 Explained,,1649616190.0,1270.0,68.0,/r/MachineLearning/comments/u0o0yy/n_dalle_2_explained/,https://v.redd.it/yubixbacyqs81,giugiacaglia,MachineLearning,0.94,False,False,False,False,0.0,1745833805.204521,Tech & Programming,4.0,0.0,3.0,Sunday,14.0,April,2022.0,True,0.0,0.0,0.0,1.0,neutral,n dalle explained,,n dalle explained ,"dalle, explained",2022-04-10 18:43:10,n dalle explained ,"['dalle', 'explained']",,,,
12nbixk,[P] OpenAssistant - The world's largest open-source replication of ChatGPT,"We’re excited to announce the release of OpenAssistant.

The future of AI development depends heavily on high quality datasets and models being made publicly available, and that’s exactly what this project does.

Watch the annoucement video:

[https://youtu.be/ddG2fM9i4Kk](https://youtu.be/ddG2fM9i4Kk)

&#x200B;

Our team has worked tirelessly over the past several months collecting large amounts of text-based input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other AI applications.

With over 600k human-generated data points covering a wide range of topics and styles of writing, our dataset will be an invaluable tool for any developer looking to create state-of-the-art instruction models!

To make things even better, we are making this entire dataset free and accessible to all who wish to use it. Check it out today at our HF org: OpenAssistant

On top of that, we've trained very powerful models that you can try right now at: [open-assistant.io/chat](https://open-assistant.io/chat) !",1681578898.0,1277.0,174.0,/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/,https://www.reddit.com/r/MachineLearning/comments/12nbixk/p_openassistant_the_worlds_largest_opensource/,ykilcher,MachineLearning,0.97,True,False,False,False,0.0,1745833805.636187,Tech & Programming,10.0,154.0,161.0,Saturday,13.0,April,2023.0,True,0.9545,0.12,0.0,0.88,positive,p openassistant the worlds largest opensource replication of chatgpt,were excited to announce the release of openassistant the future of ai development depends heavily on high quality datasets and models being made publicly available and thats exactly what this project does watch the annoucement video xb our team has worked tirelessly over the past several months collecting large amounts of textbased input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other ai applications with over k humangenerated data points covering a wide range of topics and styles of writing our dataset will be an invaluable tool for any developer looking to create stateoftheart instruction models to make things even better we are making this entire dataset free and accessible to all who wish to use it check it out today at our hf org openassistant on top of that weve trained very powerful models that you can try right now at openassistantiochat,p openassistant the worlds largest opensource replication of chatgpt were excited to announce the release of openassistant the future of ai development depends heavily on high quality datasets and models being made publicly available and thats exactly what this project does watch the annoucement video xb our team has worked tirelessly over the past several months collecting large amounts of textbased input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other ai applications with over k humangenerated data points covering a wide range of topics and styles of writing our dataset will be an invaluable tool for any developer looking to create stateoftheart instruction models to make things even better we are making this entire dataset free and accessible to all who wish to use it check it out today at our hf org openassistant on top of that weve trained very powerful models that you can try right now at openassistantiochat,"model, openassistant, dataset, create, world",2023-04-15 17:14:58,p openassistant the worlds largest opensource replication of chatgpt were excited to announce the release of openassistant the future of ai development depends heavily on high quality datasets and models being made publicly available and thats exactly what this project does watch the annoucement video xb our team has worked tirelessly over the past several months collecting large amounts of textbased input and feedback to create an incredibly diverse and unique dataset designed specifically for training language models or other ai applications with over k humangenerated data points covering a wide range of topics and styles of writing our dataset will be an invaluable tool for any developer looking to create stateoftheart instruction models to make things even better we are making this entire dataset free and accessible to all who wish to use it check it out today at our hf org openassistant on top of that weve trained very powerful models that you can try right now at openassistantiochat,"['openassistant', 'world', 'largest', 'opensource', 'replication', 'chatgpt', 'excited', 'announce', 'release', 'openassistant', 'future', 'development', 'depends', 'heavily', 'high', 'quality', 'datasets', 'model', 'made', 'publicly', 'available', 'thats', 'exactly', 'project', 'watch', 'annoucement', 'video', 'team', 'worked', 'tirelessly', 'past', 'several', 'month', 'collecting', 'large', 'amount', 'textbased', 'input', 'feedback', 'create', 'incredibly', 'diverse', 'unique', 'dataset', 'designed', 'specifically', 'training', 'language', 'model', 'application', 'humangenerated', 'data', 'point', 'covering', 'wide', 'range', 'topic', 'style', 'writing', 'dataset', 'invaluable', 'tool', 'developer', 'looking', 'create', 'stateoftheart', 'instruction', 'model', 'make', 'thing', 'even', 'better', 'making', 'entire', 'dataset', 'free', 'accessible', 'wish', 'use', 'check', 'today', 'org', 'openassistant', 'top', 'weve', 'trained', 'powerful', 'model', 'try', 'right', 'openassistantiochat']",,,,
gydxzd,[P] YOLOv4 — The most accurate real-time neural network on MS COCO Dataset,,1591542060.0,1258.0,73.0,/r/MachineLearning/comments/gydxzd/p_yolov4_the_most_accurate_realtime_neural/,https://v.redd.it/39iumy526i351,TheInsaneApp,MachineLearning,0.98,False,False,False,False,0.0,1745833806.65551,Tech & Programming,13.0,0.0,12.0,Sunday,11.0,June,2020.0,True,0.0,0.0,0.0,1.0,neutral,p yolov the most accurate realtime neural network on ms coco dataset,,p yolov the most accurate realtime neural network on ms coco dataset ,"yolov, accurate, realtime, neural, network",2020-06-07 15:01:00,p yolov the most accurate realtime neural network on ms coco dataset ,"['yolov', 'accurate', 'realtime', 'neural', 'network', 'coco', 'dataset']",,,,
7vuqvc,[P] Real-time Mask RCNN using Facebook Detectron,,1517992714.0,1253.0,84.0,/r/MachineLearning/comments/7vuqvc/p_realtime_mask_rcnn_using_facebook_detectron/,https://v.redd.it/0qkxi2r06re01,_sshin_,MachineLearning,0.97,False,False,False,False,0.0,1745833807.116863,Tech & Programming,7.0,0.0,7.0,Wednesday,3.0,February,2018.0,False,0.0,0.0,0.0,1.0,neutral,p realtime mask rcnn using facebook detectron,,p realtime mask rcnn using facebook detectron ,"realtime, mask, rcnn, using, facebook",2018-02-07 08:38:34,p realtime mask rcnn using facebook detectron ,"['realtime', 'mask', 'rcnn', 'using', 'facebook', 'detectron']",,,,
11vozd5,[R] First open source text to video 1.7 billion parameter diffusion model is out,,1679241616.0,1245.0,86.0,/r/MachineLearning/comments/11vozd5/r_first_open_source_text_to_video_17_billion/,https://v.redd.it/u5ytyd5mwpoa1,Illustrious_Row_9971,MachineLearning,0.99,False,False,False,False,0.0,1745833807.916092,Tech & Programming,14.0,0.0,13.0,Sunday,12.0,March,2023.0,True,0.0,0.0,0.0,1.0,neutral,r first open source text to video billion parameter diffusion model is out,,r first open source text to video billion parameter diffusion model is out ,"first, open, source, text, video",2023-03-19 16:00:16,r first open source text to video billion parameter diffusion model is out ,"['first', 'open', 'source', 'text', 'video', 'billion', 'parameter', 'diffusion', 'model']",,,,
yzap5b,[N] new SNAPCHAT feature transfers an image of an upper body garment in realtime on a person in AR,,1668860625.0,1243.0,46.0,/r/MachineLearning/comments/yzap5b/n_new_snapchat_feature_transfers_an_image_of_an/,https://i.redd.it/p38td2lbhw0a1.gif,SpatialComputing,MachineLearning,0.96,False,False,False,False,0.0,1745833808.509715,Tech & Programming,19.0,0.0,19.0,Saturday,7.0,November,2022.0,True,0.0,0.0,0.0,1.0,neutral,n new snapchat feature transfers an image of an upper body garment in realtime on a person in ar,,n new snapchat feature transfers an image of an upper body garment in realtime on a person in ar ,"new, snapchat, feature, transfer, image",2022-11-19 12:23:45,n new snapchat feature transfers an image of an upper body garment in realtime on a person in ar ,"['new', 'snapchat', 'feature', 'transfer', 'image', 'upper', 'body', 'garment', 'realtime', 'person']",,,,
qeihw2,[R] ByteTrack: Multi-Object Tracking by Associating Every Detection Box,,1635040318.0,1235.0,65.0,/r/MachineLearning/comments/qeihw2/r_bytetrack_multiobject_tracking_by_associating/,https://v.redd.it/sf125fyg0bv71,Illustrious_Row_9971,MachineLearning,0.98,False,False,False,False,0.0,1745833808.963167,Tech & Programming,9.0,0.0,9.0,Saturday,21.0,October,2021.0,True,0.0,0.0,0.0,1.0,neutral,r bytetrack multiobject tracking by associating every detection box,,r bytetrack multiobject tracking by associating every detection box ,"bytetrack, multiobject, tracking, associating, every",2021-10-24 01:51:58,r bytetrack multiobject tracking by associating every detection box ,"['bytetrack', 'multiobject', 'tracking', 'associating', 'every', 'detection', 'box']",,,,
ia93ao,[P] I made an AI that can drive in a real racing game (Trackmania),,1597504578.0,1227.0,85.0,/r/MachineLearning/comments/ia93ao/p_i_made_an_ai_that_can_drive_in_a_real_racing/,https://v.redd.it/c9o74p9mn6h51,yoshTM,MachineLearning,0.99,False,False,False,False,0.0,1745833826.242017,Tech & Programming,14.0,0.0,14.0,Saturday,11.0,August,2020.0,True,0.0,0.0,0.0,1.0,neutral,p i made an ai that can drive in a real racing game trackmania,,p i made an ai that can drive in a real racing game trackmania ,"made, drive, real, racing, game",2020-08-15 15:16:18,p i made an ai that can drive in a real racing game trackmania ,"['made', 'drive', 'real', 'racing', 'game', 'trackmania']",,,,
nnqjjc,[P] Tutorial: Real-time YOLOv3 on a Laptop Using Sparse Quantization,,1622304374.0,1216.0,70.0,/r/MachineLearning/comments/nnqjjc/p_tutorial_realtime_yolov3_on_a_laptop_using/,https://v.redd.it/39z4u6r523271,markurtz,MachineLearning,0.96,False,False,False,False,0.0,1745833826.751348,Tech & Programming,10.0,0.0,10.0,Saturday,12.0,May,2021.0,True,0.0,0.0,0.0,1.0,neutral,p tutorial realtime yolov on a laptop using sparse quantization,,p tutorial realtime yolov on a laptop using sparse quantization ,"tutorial, realtime, yolov, laptop, using",2021-05-29 16:06:14,p tutorial realtime yolov on a laptop using sparse quantization ,"['tutorial', 'realtime', 'yolov', 'laptop', 'using', 'sparse', 'quantization']",,,,
13ztppy,I Created an AI Basketball Referee [P],,1685835234.0,1208.0,58.0,/r/MachineLearning/comments/13ztppy/i_created_an_ai_basketball_referee_p/,https://v.redd.it/tgyre2in1w3b1,_ayushp_,MachineLearning,0.96,False,False,False,False,0.0,1745833827.184418,Tech & Programming,7.0,0.0,7.0,Saturday,19.0,June,2023.0,True,0.25,0.333,0.0,0.667,positive,i created an ai basketball referee p,,i created an ai basketball referee p ,"created, basketball, referee",2023-06-03 23:33:54,i created an ai basketball referee p ,"['created', 'basketball', 'referee']",,,,
ohk6b7,[R] RMA algorithm: Robots that learn to adapt instantly to changing real-world conditions (link in comments),,1625928955.0,1203.0,75.0,/r/MachineLearning/comments/ohk6b7/r_rma_algorithm_robots_that_learn_to_adapt/,https://v.redd.it/xok1j6cofea71,pathak22,MachineLearning,0.98,False,False,False,False,0.0,1745833827.591711,Tech & Programming,16.0,0.0,16.0,Saturday,10.0,July,2021.0,True,0.0,0.0,0.0,1.0,neutral,r rma algorithm robots that learn to adapt instantly to changing realworld conditions link in comments,,r rma algorithm robots that learn to adapt instantly to changing realworld conditions link in comments ,"rma, algorithm, robot, learn, adapt",2021-07-10 14:55:55,r rma algorithm robots that learn to adapt instantly to changing realworld conditions link in comments ,"['rma', 'algorithm', 'robot', 'learn', 'adapt', 'instantly', 'changing', 'realworld', 'condition', 'link', 'comment']",,,,
i5yres,[P] Trained a Sub-Zero bot for Mortal Kombat II using PPO2. Here's a single-player run against the first 5 opponents.,,1596891779.0,1204.0,78.0,/r/MachineLearning/comments/i5yres/p_trained_a_subzero_bot_for_mortal_kombat_ii/,https://v.redd.it/fhldbjcd1sf51,voidupdate,MachineLearning,0.98,False,False,False,False,0.0,1745833828.082126,Tech & Programming,20.0,0.0,19.0,Saturday,9.0,August,2020.0,True,0.0,0.0,0.0,1.0,neutral,p trained a subzero bot for mortal kombat ii using ppo heres a singleplayer run against the first opponents,,p trained a subzero bot for mortal kombat ii using ppo heres a singleplayer run against the first opponents ,"trained, subzero, bot, mortal, kombat",2020-08-08 13:02:59,p trained a subzero bot for mortal kombat ii using ppo heres a singleplayer run against the first opponents ,"['trained', 'subzero', 'bot', 'mortal', 'kombat', 'using', 'ppo', 'here', 'singleplayer', 'run', 'first', 'opponent']",,,,
8p169l,[D] Dedicated to all those researchers in fear of being scooped :),,1528296269.0,1196.0,118.0,/r/MachineLearning/comments/8p169l/d_dedicated_to_all_those_researchers_in_fear_of/,https://i.redd.it/8rwcis9t6e211.jpg,_gmark_,MachineLearning,0.94,False,False,False,False,0.0,1745833828.540764,Tech & Programming,12.0,0.0,11.0,Wednesday,10.0,June,2018.0,False,-0.0516,0.211,0.225,0.563,negative,d dedicated to all those researchers in fear of being scooped,,d dedicated to all those researchers in fear of being scooped ,"dedicated, researcher, fear, scooped",2018-06-06 14:44:29,d dedicated to all those researchers in fear of being scooped ,"['dedicated', 'researcher', 'fear', 'scooped']",,,,
137rxgw,"[D] Google ""We Have No Moat, And Neither Does OpenAI"": Leaked Internal Google Document Claims Open Source AI Will Outcompete Google and OpenAI",,1683216810.0,1190.0,206.0,/r/MachineLearning/comments/137rxgw/d_google_we_have_no_moat_and_neither_does_openai/,https://www.semianalysis.com/p/google-we-have-no-moat-and-neither,hardmaru,MachineLearning,0.98,False,False,False,False,0.0,1745833829.342022,Tech & Programming,23.0,0.0,23.0,Thursday,12.0,May,2023.0,False,-0.0613,0.081,0.091,0.828,negative,d google we have no moat and neither does openai leaked internal google document claims open source ai will outcompete google and openai,,d google we have no moat and neither does openai leaked internal google document claims open source ai will outcompete google and openai ,"google, openai, moat, neither, leaked",2023-05-04 16:13:30,d google we have no moat and neither does openai leaked internal google document claims open source ai will outcompete google and openai ,"['google', 'moat', 'neither', 'openai', 'leaked', 'internal', 'google', 'document', 'claim', 'open', 'source', 'outcompete', 'google', 'openai']",,,,
ex2sks,[D] Siraj is still plagiarizing,"Siraj's latest video on explainable computer vision is still using people's material without credit. In this week's video, the slides from 1:40 to 6:00 \[1\] are lifted verbatim from a 2018 tutorial \[2\], except that Siraj removed the footer saying it was from the Fraunhofer institute on all but one slide.

Maybe we should just ignore him at this point, but proper credit assignment really is the foundation of any discipline, and any plagiarism hurts it (even if he is being better about crediting others than before).

I mean, COME ON MAN.

\[1\] [https://www.youtube.com/watch?v=Y8mSngdQb9Q&feature=youtu.be](https://www.youtube.com/watch?v=Y8mSngdQb9Q&feature=youtu.be) 

\[2\]  [http://heatmapping.org/slides/2018\_MICCAI.pdf](http://heatmapping.org/slides/2018_MICCAI.pdf)",1580543333.0,1183.0,142.0,/r/MachineLearning/comments/ex2sks/d_siraj_is_still_plagiarizing/,https://www.reddit.com/r/MachineLearning/comments/ex2sks/d_siraj_is_still_plagiarizing/,AGI_aint_happening,MachineLearning,0.96,True,False,False,False,0.0,1745833831.045246,Tech & Programming,5.0,96.0,92.0,Saturday,2.0,February,2020.0,True,-0.6724,0.072,0.116,0.812,negative,d siraj is still plagiarizing,sirajs latest video on explainable computer vision is still using peoples material without credit in this weeks video the slides from to are lifted verbatim from a tutorial except that siraj removed the footer saying it was from the fraunhofer institute on all but one slide maybe we should just ignore him at this point but proper credit assignment really is the foundation of any discipline and any plagiarism hurts it even if he is being better about crediting others than before i mean come on man,d siraj is still plagiarizing sirajs latest video on explainable computer vision is still using peoples material without credit in this weeks video the slides from to are lifted verbatim from a tutorial except that siraj removed the footer saying it was from the fraunhofer institute on all but one slide maybe we should just ignore him at this point but proper credit assignment really is the foundation of any discipline and any plagiarism hurts it even if he is being better about crediting others than before i mean come on man,"siraj, still, video, credit, slide",2020-02-01 07:48:53,d siraj is still plagiarizing sirajs latest video on explainable computer vision is still using peoples material without credit in this weeks video the slides from to are lifted verbatim from a tutorial except that siraj removed the footer saying it was from the fraunhofer institute on all but one slide maybe we should just ignore him at this point but proper credit assignment really is the foundation of any discipline and any plagiarism hurts it even if he is being better about crediting others than before i mean come on man,"['siraj', 'still', 'plagiarizing', 'sirajs', 'latest', 'video', 'explainable', 'computer', 'vision', 'still', 'using', 'people', 'material', 'without', 'credit', 'week', 'video', 'slide', 'lifted', 'verbatim', 'tutorial', 'except', 'siraj', 'removed', 'footer', 'saying', 'fraunhofer', 'institute', 'one', 'slide', 'maybe', 'ignore', 'point', 'proper', 'credit', 'assignment', 'really', 'foundation', 'discipline', 'plagiarism', 'hurt', 'even', 'better', 'crediting', 'others', 'mean', 'come', 'man']",,,,
gpmbpl,[Project][Reinforcement Learning] Using DQN (Q-Learning) to play the Game 2048.,,1590309872.0,1178.0,38.0,/r/MachineLearning/comments/gpmbpl/projectreinforcement_learning_using_dqn_qlearning/,https://i.redd.it/re44c0twdo051.gif,FelipeMarcelino,MachineLearning,0.97,False,False,False,False,0.0,1745833832.04468,Tech & Programming,10.0,0.0,9.0,Sunday,4.0,May,2020.0,True,0.34,0.231,0.0,0.769,positive,projectreinforcement learning using dqn qlearning to play the game,,projectreinforcement learning using dqn qlearning to play the game ,"projectreinforcement, learning, using, dqn, qlearning",2020-05-24 08:44:32,projectreinforcement learning using dqn qlearning to play the game ,"['projectreinforcement', 'learning', 'using', 'dqn', 'qlearning', 'play', 'game']",,,,
if1sdg,[P] ObjectCut - API that removes automatically image backgrounds with DL (objectcut.com),,1598183093.0,1178.0,35.0,/r/MachineLearning/comments/if1sdg/p_objectcut_api_that_removes_automatically_image/,https://v.redd.it/6pri35sbpqi51,adriacabeza,MachineLearning,0.98,False,False,False,False,0.0,1745833832.38009,Tech & Programming,12.0,0.0,11.0,Sunday,7.0,August,2020.0,True,0.0,0.0,0.0,1.0,neutral,p objectcut api that removes automatically image backgrounds with dl objectcutcom,,p objectcut api that removes automatically image backgrounds with dl objectcutcom ,"objectcut, api, remove, automatically, image",2020-08-23 11:44:53,p objectcut api that removes automatically image backgrounds with dl objectcutcom ,"['objectcut', 'api', 'remove', 'automatically', 'image', 'background', 'objectcutcom']",,,,
wbwkwb,I created a CV-based automated basketball referee [P],,1659184637.0,1175.0,24.0,/r/MachineLearning/comments/wbwkwb/i_created_a_cvbased_automated_basketball_referee_p/,https://v.redd.it/ho5l6r95ape91,_ayushp_,MachineLearning,0.97,False,False,False,False,0.0,1745833832.662418,Tech & Programming,8.0,0.0,8.0,Saturday,8.0,July,2022.0,True,0.25,0.333,0.0,0.667,positive,i created a cvbased automated basketball referee p,,i created a cvbased automated basketball referee p ,"created, cvbased, automated, basketball, referee",2022-07-30 12:37:17,i created a cvbased automated basketball referee p ,"['created', 'cvbased', 'automated', 'basketball', 'referee']",,,,
ajgzoc,"We are Oriol Vinyals and David Silver from DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO and MaNa! Ask us anything","Hi there! We are Oriol Vinyals (/u/OriolVinyals) and David Silver (/u/David_Silver), lead researchers on DeepMind’s AlphaStar team, joined by StarCraft II pro players TLO, and MaNa.

This evening at DeepMind HQ we held a livestream demonstration of AlphaStar playing against TLO and MaNa - you can read more about the matches [here](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/) or re-watch the stream on YouTube [here](https://www.youtube.com/watch?v=cUTMhmVh1qs).

Now, we’re excited to talk with you about AlphaStar, the challenge of real-time strategy games for AI research, the matches themselves, and anything you’d like to know from TLO and MaNa about their experience playing against AlphaStar! :)

We are opening this thread now and will be here at **16:00 GMT / 11:00 ET / 08:00PT** on Friday, 25 January to answer your questions.

&#x200B;

EDIT: Thanks everyone for your great questions. It was a blast, hope you enjoyed it as well!",1548363323.0,1169.0,1003.0,/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/,https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/,OriolVinyals,MachineLearning,0.99,True,False,False,False,1.0,1745833832.873451,Tech & Programming,23.0,141.0,157.0,Thursday,15.0,January,2019.0,False,0.9702,0.155,0.0,0.845,positive,we are oriol vinyals and david silver from deepminds alphastar team joined by starcraft ii pro players tlo and mana ask us anything,hi there we are oriol vinyals uoriolvinyals and david silver udavid_silver lead researchers on deepminds alphastar team joined by starcraft ii pro players tlo and mana this evening at deepmind hq we held a livestream demonstration of alphastar playing against tlo and mana you can read more about the matches here or rewatch the stream on youtube here now were excited to talk with you about alphastar the challenge of realtime strategy games for ai research the matches themselves and anything youd like to know from tlo and mana about their experience playing against alphastar we are opening this thread now and will be here at gmt et pt on friday january to answer your questions xb edit thanks everyone for your great questions it was a blast hope you enjoyed it as well,we are oriol vinyals and david silver from deepminds alphastar team joined by starcraft ii pro players tlo and mana ask us anything hi there we are oriol vinyals uoriolvinyals and david silver udavid_silver lead researchers on deepminds alphastar team joined by starcraft ii pro players tlo and mana this evening at deepmind hq we held a livestream demonstration of alphastar playing against tlo and mana you can read more about the matches here or rewatch the stream on youtube here now were excited to talk with you about alphastar the challenge of realtime strategy games for ai research the matches themselves and anything youd like to know from tlo and mana about their experience playing against alphastar we are opening this thread now and will be here at gmt et pt on friday january to answer your questions xb edit thanks everyone for your great questions it was a blast hope you enjoyed it as well,"alphastar, tlo, mana, oriol, vinyals",2019-01-24 20:55:23,we are oriol vinyals and david silver from deepminds alphastar team joined by starcraft ii pro players tlo and mana ask us anything hi there we are oriol vinyals uoriolvinyals and david silver udavid_silver lead researchers on deepminds alphastar team joined by starcraft ii pro players tlo and mana this evening at deepmind hq we held a livestream demonstration of alphastar playing against tlo and mana you can read more about the matches here or rewatch the stream on youtube here now were excited to talk with you about alphastar the challenge of realtime strategy games for ai research the matches themselves and anything youd like to know from tlo and mana about their experience playing against alphastar we are opening this thread now and will be here at gmt et pt on friday january to answer your questions xb edit thanks everyone for your great questions it was a blast hope you enjoyed it as well,"['oriol', 'vinyals', 'david', 'silver', 'deepminds', 'alphastar', 'team', 'joined', 'starcraft', 'pro', 'player', 'tlo', 'mana', 'ask', 'anything', 'oriol', 'vinyals', 'uoriolvinyals', 'david', 'silver', 'udavid_silver', 'lead', 'researcher', 'deepminds', 'alphastar', 'team', 'joined', 'starcraft', 'pro', 'player', 'tlo', 'mana', 'evening', 'deepmind', 'held', 'livestream', 'demonstration', 'alphastar', 'playing', 'tlo', 'mana', 'read', 'match', 'rewatch', 'stream', 'youtube', 'excited', 'talk', 'alphastar', 'challenge', 'realtime', 'strategy', 'game', 'research', 'match', 'anything', 'youd', 'like', 'know', 'tlo', 'mana', 'experience', 'playing', 'alphastar', 'opening', 'thread', 'gmt', 'friday', 'january', 'answer', 'question', 'edit', 'thanks', 'everyone', 'great', 'question', 'blast', 'hope', 'enjoyed', 'well']",,,,
sroth8,[P] Stylegan Vintage-Style Portraits,,1644775591.0,1166.0,55.0,/r/MachineLearning/comments/sroth8/p_stylegan_vintagestyle_portraits/,https://www.reddit.com/gallery/sroth8,Illustrious_Row_9971,MachineLearning,0.96,False,False,False,False,0.0,1745833836.502293,Tech & Programming,4.0,0.0,4.0,Sunday,13.0,February,2022.0,True,0.0,0.0,0.0,1.0,neutral,p stylegan vintagestyle portraits,,p stylegan vintagestyle portraits ,"stylegan, vintagestyle, portrait",2022-02-13 18:06:31,p stylegan vintagestyle portraits ,"['stylegan', 'vintagestyle', 'portrait']",,,,
10nxqfg,[R] InstructPix2Pix: Learning to Follow Image Editing Instructions,,1674962898.0,1172.0,37.0,/r/MachineLearning/comments/10nxqfg/r_instructpix2pix_learning_to_follow_image/,https://i.redd.it/413x5q54jwea1.jpg,Illustrious_Row_9971,MachineLearning,0.98,False,False,False,False,0.0,1745833836.969398,Tech & Programming,8.0,0.0,8.0,Saturday,22.0,January,2023.0,True,0.0,0.0,0.0,1.0,neutral,r instructpixpix learning to follow image editing instructions,,r instructpixpix learning to follow image editing instructions ,"instructpixpix, learning, follow, image, editing",2023-01-29 03:28:18,r instructpixpix learning to follow image editing instructions ,"['instructpixpix', 'learning', 'follow', 'image', 'editing', 'instruction']",,,,
bvzc7w,[D] Has anyone noticed a lot of ML research into facial recognition of Uyghur people lately?,"[https://i.imgur.com/7lCmYQt.jpg](https://i.imgur.com/7lCmYQt.jpg)

[https://i.imgur.com/KSSVkGT.jpg](https://i.imgur.com/KSSVkGT.jpg)

This popped up on my feed this morning and I thought it was interesting/horrifying.",1559493858.0,1162.0,202.0,/r/MachineLearning/comments/bvzc7w/d_has_anyone_noticed_a_lot_of_ml_research_into/,https://www.reddit.com/r/MachineLearning/comments/bvzc7w/d_has_anyone_noticed_a_lot_of_ml_research_into/,,MachineLearning,0.97,True,False,False,False,1.0,1745833837.655329,Tech & Programming,16.0,16.0,30.0,Sunday,12.0,June,2019.0,True,0.0,0.0,0.0,1.0,neutral,d has anyone noticed a lot of ml research into facial recognition of uyghur people lately,this popped up on my feed this morning and i thought it was interestinghorrifying,d has anyone noticed a lot of ml research into facial recognition of uyghur people lately this popped up on my feed this morning and i thought it was interestinghorrifying,"anyone, noticed, lot, research, facial",2019-06-02 16:44:18,d has anyone noticed a lot of ml research into facial recognition of uyghur people lately this popped up on my feed this morning and i thought it was interestinghorrifying,"['anyone', 'noticed', 'lot', 'research', 'facial', 'recognition', 'uyghur', 'people', 'lately', 'popped', 'feed', 'morning', 'thought', 'interestinghorrifying']",,,,
1fywi9h,[N] 2024 Nobel Prize for Physics goes to ML and DNN researchers J. Hopfield and G. Hinton,"Announcement: https://x.com/NobelPrize/status/1843589140455272810

Our boys John Hopfield and Geoffrey Hinton were rewarded for their foundational contributions to machine learning and deep learning with the Nobel prize for physics 2024!

I hear furious Schmidhuber noises in the distance!

On a more serious note, despite the very surprising choice, I am generally happy - as a physicist myself with strong interest in ML, I love this physics-ML cinematic universe crossover.

The restriction to Hopfield and Hinton will probably spark discussions about the relative importance of {Hopfield, Hinton, LeCun, Schmidhuber, Bengio, Linnainmaa, ...} for the success of modern ML/DL/AI.
A discussion especially Schmidhuber very actively engages in.

The response from the core physics community however is rather mixed, as shown in the [/r/physics thread](https://www.reddit.com/r/Physics/comments/1fyw12p/the_2024_nobel_prize_in_physics_is_awarded_to/). There, the missing link/connection to physics research is noted and the concurrent ""loss"" of the '24 prize for physics researchers.",1728383190.0,1153.0,306.0,/r/MachineLearning/comments/1fywi9h/n_2024_nobel_prize_for_physics_goes_to_ml_and_dnn/,https://www.reddit.com/r/MachineLearning/comments/1fywi9h/n_2024_nobel_prize_for_physics_goes_to_ml_and_dnn/,PrittEnergizer,MachineLearning,0.97,True,False,False,False,0.0,1745833839.485284,Tech & Programming,17.0,140.0,151.0,Tuesday,6.0,October,2024.0,False,0.9811,0.228,0.078,0.693,positive,n nobel prize for physics goes to ml and dnn researchers j hopfield and g hinton,announcement our boys john hopfield and geoffrey hinton were rewarded for their foundational contributions to machine learning and deep learning with the nobel prize for physics i hear furious schmidhuber noises in the distance on a more serious note despite the very surprising choice i am generally happy as a physicist myself with strong interest in ml i love this physicsml cinematic universe crossover the restriction to hopfield and hinton will probably spark discussions about the relative importance of hopfield hinton lecun schmidhuber bengio linnainmaa for the success of modern mldlai a discussion especially schmidhuber very actively engages in the response from the core physics community however is rather mixed as shown in the rphysics thread there the missing linkconnection to physics research is noted and the concurrent loss of the prize for physics researchers,n nobel prize for physics goes to ml and dnn researchers j hopfield and g hinton announcement our boys john hopfield and geoffrey hinton were rewarded for their foundational contributions to machine learning and deep learning with the nobel prize for physics i hear furious schmidhuber noises in the distance on a more serious note despite the very surprising choice i am generally happy as a physicist myself with strong interest in ml i love this physicsml cinematic universe crossover the restriction to hopfield and hinton will probably spark discussions about the relative importance of hopfield hinton lecun schmidhuber bengio linnainmaa for the success of modern mldlai a discussion especially schmidhuber very actively engages in the response from the core physics community however is rather mixed as shown in the rphysics thread there the missing linkconnection to physics research is noted and the concurrent loss of the prize for physics researchers,"physic, hopfield, hinton, prize, schmidhuber",2024-10-08 10:26:30,n nobel prize for physics goes to ml and dnn researchers j hopfield and g hinton announcement our boys john hopfield and geoffrey hinton were rewarded for their foundational contributions to machine learning and deep learning with the nobel prize for physics i hear furious schmidhuber noises in the distance on a more serious note despite the very surprising choice i am generally happy as a physicist myself with strong interest in ml i love this physicsml cinematic universe crossover the restriction to hopfield and hinton will probably spark discussions about the relative importance of hopfield hinton lecun schmidhuber bengio linnainmaa for the success of modern mldlai a discussion especially schmidhuber very actively engages in the response from the core physics community however is rather mixed as shown in the rphysics thread there the missing linkconnection to physics research is noted and the concurrent loss of the prize for physics researchers,"['nobel', 'prize', 'physic', 'go', 'dnn', 'researcher', 'hopfield', 'hinton', 'announcement', 'boy', 'john', 'hopfield', 'geoffrey', 'hinton', 'rewarded', 'foundational', 'contribution', 'machine', 'learning', 'deep', 'learning', 'nobel', 'prize', 'physic', 'hear', 'furious', 'schmidhuber', 'noise', 'distance', 'serious', 'note', 'despite', 'surprising', 'choice', 'generally', 'happy', 'physicist', 'strong', 'interest', 'love', 'physicsml', 'cinematic', 'universe', 'crossover', 'restriction', 'hopfield', 'hinton', 'probably', 'spark', 'discussion', 'relative', 'importance', 'hopfield', 'hinton', 'lecun', 'schmidhuber', 'bengio', 'linnainmaa', 'success', 'modern', 'mldlai', 'discussion', 'especially', 'schmidhuber', 'actively', 'engages', 'response', 'core', 'physic', 'community', 'however', 'rather', 'mixed', 'shown', 'rphysics', 'thread', 'missing', 'linkconnection', 'physic', 'research', 'noted', 'concurrent', 'loss', 'prize', 'physic', 'researcher']",,,,
ymo07f,"[P] Finetuned Diffusion: multiple fine-tuned Stable Diffusion models, trained on different styles",,1667636231.0,1151.0,65.0,/r/MachineLearning/comments/ymo07f/p_finetuned_diffusion_multiple_finetuned_stable/,https://huggingface.co/spaces/anzorq/finetuned_diffusion,Illustrious_Row_9971,MachineLearning,0.96,False,False,False,False,0.0,1745833841.791889,Tech & Programming,12.0,0.0,12.0,Saturday,4.0,November,2022.0,True,0.296,0.18,0.0,0.82,positive,p finetuned diffusion multiple finetuned stable diffusion models trained on different styles,,p finetuned diffusion multiple finetuned stable diffusion models trained on different styles ,"finetuned, diffusion, multiple, stable, model",2022-11-05 08:17:11,p finetuned diffusion multiple finetuned stable diffusion models trained on different styles ,"['finetuned', 'diffusion', 'multiple', 'finetuned', 'stable', 'diffusion', 'model', 'trained', 'different', 'style']",,,,
yxzaz3,"[D] my PhD advisor ""machine learning researchers are like children, always re-discovering things that are already known and make a big deal out of it.""","So I was talking to my advisor on the topic of implicit regularization and he/she said told me, convergence of an algorithm to a *minimum norm solution* has been one of the most well-studied problem since the 70s, with hundreds of papers already published before ML people started talking about this so-called ""implicit regularization phenomenon"".

And then he/she said ""machine learning researchers are like children, always re-discovering things that are already known and make a big deal out of it.""

""the only mystery with implicit regularization is why these researchers are not digging into the literature.""

Do you agree/disagree?",1668713744.0,1135.0,205.0,/r/MachineLearning/comments/yxzaz3/d_my_phd_advisor_machine_learning_researchers_are/,https://www.reddit.com/r/MachineLearning/comments/yxzaz3/d_my_phd_advisor_machine_learning_researchers_are/,RandomProjections,MachineLearning,0.97,True,False,False,False,0.0,1745833842.293447,Tech & Programming,25.0,99.0,124.0,Thursday,14.0,November,2022.0,False,0.5141,0.059,0.024,0.917,positive,d my phd advisor machine learning researchers are like children always rediscovering things that are already known and make a big deal out of it,so i was talking to my advisor on the topic of implicit regularization and heshe said told me convergence of an algorithm to a minimum norm solution has been one of the most wellstudied problem since the s with hundreds of papers already published before ml people started talking about this socalled implicit regularization phenomenon and then heshe said machine learning researchers are like children always rediscovering things that are already known and make a big deal out of it the only mystery with implicit regularization is why these researchers are not digging into the literature do you agreedisagree,d my phd advisor machine learning researchers are like children always rediscovering things that are already known and make a big deal out of it so i was talking to my advisor on the topic of implicit regularization and heshe said told me convergence of an algorithm to a minimum norm solution has been one of the most wellstudied problem since the s with hundreds of papers already published before ml people started talking about this socalled implicit regularization phenomenon and then heshe said machine learning researchers are like children always rediscovering things that are already known and make a big deal out of it the only mystery with implicit regularization is why these researchers are not digging into the literature do you agreedisagree,"researcher, already, implicit, regularization, advisor",2022-11-17 19:35:44,d my phd advisor machine learning researchers are like children always rediscovering things that are already known and make a big deal out of it so i was talking to my advisor on the topic of implicit regularization and heshe said told me convergence of an algorithm to a minimum norm solution has been one of the most wellstudied problem since the s with hundreds of papers already published before ml people started talking about this socalled implicit regularization phenomenon and then heshe said machine learning researchers are like children always rediscovering things that are already known and make a big deal out of it the only mystery with implicit regularization is why these researchers are not digging into the literature do you agreedisagree,"['phd', 'advisor', 'machine', 'learning', 'researcher', 'like', 'child', 'always', 'rediscovering', 'thing', 'already', 'known', 'make', 'big', 'deal', 'talking', 'advisor', 'topic', 'implicit', 'regularization', 'heshe', 'said', 'told', 'convergence', 'algorithm', 'minimum', 'norm', 'solution', 'one', 'wellstudied', 'problem', 'since', 'hundred', 'paper', 'already', 'published', 'people', 'started', 'talking', 'socalled', 'implicit', 'regularization', 'phenomenon', 'heshe', 'said', 'machine', 'learning', 'researcher', 'like', 'child', 'always', 'rediscovering', 'thing', 'already', 'known', 'make', 'big', 'deal', 'mystery', 'implicit', 'regularization', 'researcher', 'digging', 'literature', 'agreedisagree']",,,,
n3b1m6,[R] Few-Shot Patch-Based Training (Siggraph 2020) - Dr. Ondřej Texler - Link to free zoom lecture by the author in comments,,1619975673.0,1136.0,23.0,/r/MachineLearning/comments/n3b1m6/r_fewshot_patchbased_training_siggraph_2020_dr/,https://i.redd.it/g7drgmkupqw61.gif,pinter69,MachineLearning,0.98,False,False,False,False,0.0,1745833843.509577,Tech & Programming,21.0,0.0,18.0,Sunday,13.0,May,2021.0,True,0.5106,0.171,0.0,0.829,positive,r fewshot patchbased training siggraph dr ondřej texler link to free zoom lecture by the author in comments,,r fewshot patchbased training siggraph dr ondřej texler link to free zoom lecture by the author in comments ,"fewshot, patchbased, training, siggraph, ondřej",2021-05-02 17:14:33,r fewshot patchbased training siggraph dr ondřej texler link to free zoom lecture by the author in comments ,"['fewshot', 'patchbased', 'training', 'siggraph', 'ondřej', 'texler', 'link', 'free', 'zoom', 'lecture', 'author', 'comment']",,,,
e1r0ou,"[D] Chinese government uses machine learning not only for surveillance, but also for predictive policing and for deciding who to arrest in Xinjiang","Link to **[story](https://www.icij.org/investigations/china-cables/exposed-chinas-operating-manuals-for-mass-internment-and-arrest-by-algorithm/)**

This post is not an ML *research* related post. I am posting this because I think it is important for the community to see how research is applied by authoritarian governments to achieve their goals. It is related to a few previous popular posts on this subreddit with high upvotes, which prompted me to post this [story](https://www.icij.org/investigations/china-cables/exposed-chinas-operating-manuals-for-mass-internment-and-arrest-by-algorithm/).

Previous related stories:

- [Is machine learning's killer app totalitarian surveillance and oppression?](https://redd.it/c9n1u2)

- [Using CV for surveillance and regression for threat scoring citizens in Xinjiang](https://redd.it/7kzflw)

- [ICCV 19: The state of some ethically questionable papers](https://redd.it/dp389c)

- [Hikvision marketed ML surveillance camera that automatically identifies Uyghurs](https://redd.it/dv5axp)

- [Working on an ethically questionnable project...](https://redd.it/dw7sms)

The **[story](https://www.icij.org/investigations/china-cables/exposed-chinas-operating-manuals-for-mass-internment-and-arrest-by-algorithm/)** reports the details of a new leak of highly classified Chinese government documents reveals the operations manual for running the mass detention camps in Xinjiang and exposed the mechanics of the region’s system of mass surveillance.

**The [lead journalist](https://twitter.com/BethanyAllenEbr/status/1198663008152621057)'s summary of findings**

The China Cables represent the first leak of a classified Chinese government document revealing the inner workings of the detention camps, as well as the first leak of classified government documents unveiling the predictive policing system in Xinjiang.

The leak features classified intelligence briefings that reveal, in the government’s own words, how Xinjiang police essentially take orders from a massive “cybernetic brain” known as IJOP, which flags entire categories of people for investigation & detention.

These secret intelligence briefings reveal the scope and ambition of the government’s AI-powered policing platform, which purports to predict crimes based on computer-generated findings alone. The result? Arrest by algorithm.

**The article describe methods used for algorithmic policing**

The classified intelligence briefings reveal the scope and ambition of the government’s artificial-intelligence-powered policing platform, which purports to predict crimes based on these computer-generated findings alone. Experts say the platform, which is used in both policing and military contexts, demonstrates the power of technology to help drive industrial-scale human rights abuses.

“The Chinese [government] have bought into a model of policing where they believe that through the collection of large-scale data run through artificial intelligence and machine learning that they can, in fact, predict ahead of time where possible incidents might take place, as well as identify possible populations that have the propensity to engage in anti-state anti-regime action,” said Mulvenon, the SOS International document expert and director of intelligence integration. “And then they are preemptively going after those people using that data.”

In addition to the predictive policing aspect of the article, there are side [articles](https://qz.com/1755018/chinas-manual-for-uighur-detention-camps-revealed-in-data-leak/) about the entire ML stack, including how [mobile apps](https://www.icij.org/investigations/china-cables/how-china-targets-uighurs-one-by-one-for-using-a-mobile-app/) are used to target Uighurs, and also how the inmates are [re-educated](https://www.bbc.com/news/world-asia-china-50511063) once inside the concentration camps. The documents reveal how every aspect of a detainee's life is monitored and controlled.

*Note: My motivation for posting this story is to raise ethical concerns and awareness in the research community. I do not want to heighten levels of racism towards the Chinese research community (not that it may matter, but I am Chinese). See this [thread](https://redd.it/e10b5x) for some context about what I don't want these discussions to become.*

*I am aware of the fact that the Chinese government's policy is to integrate the state and the people as one, so accusing the party is perceived domestically as insulting the Chinese people, but I also believe that we as a research community is intelligent enough to be able to separate government, and those in power, from individual researchers. We as a community should keep in mind that there are many Chinese researchers (in mainland and abroad) who are not supportive of the actions of the CCP, but they may not be able to voice their concerns due to personal risk.*

**Edit** Suggestion from /u/DunkelBeard:

When discussing issues relating to the Chinese government, try to use the term CCP, Chinese Communist Party, Chinese government, or Beijing. Try *not* to use only the term *Chinese* or *China* when describing the government, as it may be misinterpreted as referring to the Chinese people (either citizens of China, or people of Chinese ethnicity), if that is not your intention. As mentioned earlier, conflating China and the CCP is actually a tactic of the CCP.",1574734164.0,1131.0,191.0,/r/MachineLearning/comments/e1r0ou/d_chinese_government_uses_machine_learning_not/,https://www.reddit.com/r/MachineLearning/comments/e1r0ou/d_chinese_government_uses_machine_learning_not/,sensetime,MachineLearning,0.97,True,False,False,False,0.0,1745833843.77026,Tech & Programming,23.0,694.0,710.0,Monday,21.0,November,2019.0,False,-0.9608,0.075,0.102,0.823,negative,d chinese government uses machine learning not only for surveillance but also for predictive policing and for deciding who to arrest in xinjiang,link to story this post is not an ml research related post i am posting this because i think it is important for the community to see how research is applied by authoritarian governments to achieve their goals it is related to a few previous popular posts on this subreddit with high upvotes which prompted me to post this story previous related stories is machine learnings killer app totalitarian surveillance and oppression using cv for surveillance and regression for threat scoring citizens in xinjiang iccv the state of some ethically questionable papers hikvision marketed ml surveillance camera that automatically identifies uyghurs working on an ethically questionnable project the story reports the details of a new leak of highly classified chinese government documents reveals the operations manual for running the mass detention camps in xinjiang and exposed the mechanics of the regions system of mass surveillance the lead journalist summary of findings the china cables represent the first leak of a classified chinese government document revealing the inner workings of the detention camps as well as the first leak of classified government documents unveiling the predictive policing system in xinjiang the leak features classified intelligence briefings that reveal in the governments own words how xinjiang police essentially take orders from a massive cybernetic brain known as ijop which flags entire categories of people for investigation detention these secret intelligence briefings reveal the scope and ambition of the governments aipowered policing platform which purports to predict crimes based on computergenerated findings alone the result arrest by algorithm the article describe methods used for algorithmic policing the classified intelligence briefings reveal the scope and ambition of the governments artificialintelligencepowered policing platform which purports to predict crimes based on these computergenerated findings alone experts say the platform which is used in both policing and military contexts demonstrates the power of technology to help drive industrialscale human rights abuses the chinese government have bought into a model of policing where they believe that through the collection of largescale data run through artificial intelligence and machine learning that they can in fact predict ahead of time where possible incidents might take place as well as identify possible populations that have the propensity to engage in antistate antiregime action said mulvenon the sos international document expert and director of intelligence integration and then they are preemptively going after those people using that data in addition to the predictive policing aspect of the article there are side articles about the entire ml stack including how mobile apps are used to target uighurs and also how the inmates are reeducated once inside the concentration camps the documents reveal how every aspect of a detainees life is monitored and controlled note my motivation for posting this story is to raise ethical concerns and awareness in the research community i do not want to heighten levels of racism towards the chinese research community not that it may matter but i am chinese see this thread for some context about what i dont want these discussions to become i am aware of the fact that the chinese governments policy is to integrate the state and the people as one so accusing the party is perceived domestically as insulting the chinese people but i also believe that we as a research community is intelligent enough to be able to separate government and those in power from individual researchers we as a community should keep in mind that there are many chinese researchers in mainland and abroad who are not supportive of the actions of the ccp but they may not be able to voice their concerns due to personal risk edit suggestion from udunkelbeard when discussing issues relating to the chinese government try to use the term ccp chinese communist party chinese government or beijing try not to use only the term chinese or china when describing the government as it may be misinterpreted as referring to the chinese people either citizens of china or people of chinese ethnicity if that is not your intention as mentioned earlier conflating china and the ccp is actually a tactic of the ccp,d chinese government uses machine learning not only for surveillance but also for predictive policing and for deciding who to arrest in xinjiang link to story this post is not an ml research related post i am posting this because i think it is important for the community to see how research is applied by authoritarian governments to achieve their goals it is related to a few previous popular posts on this subreddit with high upvotes which prompted me to post this story previous related stories is machine learnings killer app totalitarian surveillance and oppression using cv for surveillance and regression for threat scoring citizens in xinjiang iccv the state of some ethically questionable papers hikvision marketed ml surveillance camera that automatically identifies uyghurs working on an ethically questionnable project the story reports the details of a new leak of highly classified chinese government documents reveals the operations manual for running the mass detention camps in xinjiang and exposed the mechanics of the regions system of mass surveillance the lead journalist summary of findings the china cables represent the first leak of a classified chinese government document revealing the inner workings of the detention camps as well as the first leak of classified government documents unveiling the predictive policing system in xinjiang the leak features classified intelligence briefings that reveal in the governments own words how xinjiang police essentially take orders from a massive cybernetic brain known as ijop which flags entire categories of people for investigation detention these secret intelligence briefings reveal the scope and ambition of the governments aipowered policing platform which purports to predict crimes based on computergenerated findings alone the result arrest by algorithm the article describe methods used for algorithmic policing the classified intelligence briefings reveal the scope and ambition of the governments artificialintelligencepowered policing platform which purports to predict crimes based on these computergenerated findings alone experts say the platform which is used in both policing and military contexts demonstrates the power of technology to help drive industrialscale human rights abuses the chinese government have bought into a model of policing where they believe that through the collection of largescale data run through artificial intelligence and machine learning that they can in fact predict ahead of time where possible incidents might take place as well as identify possible populations that have the propensity to engage in antistate antiregime action said mulvenon the sos international document expert and director of intelligence integration and then they are preemptively going after those people using that data in addition to the predictive policing aspect of the article there are side articles about the entire ml stack including how mobile apps are used to target uighurs and also how the inmates are reeducated once inside the concentration camps the documents reveal how every aspect of a detainees life is monitored and controlled note my motivation for posting this story is to raise ethical concerns and awareness in the research community i do not want to heighten levels of racism towards the chinese research community not that it may matter but i am chinese see this thread for some context about what i dont want these discussions to become i am aware of the fact that the chinese governments policy is to integrate the state and the people as one so accusing the party is perceived domestically as insulting the chinese people but i also believe that we as a research community is intelligent enough to be able to separate government and those in power from individual researchers we as a community should keep in mind that there are many chinese researchers in mainland and abroad who are not supportive of the actions of the ccp but they may not be able to voice their concerns due to personal risk edit suggestion from udunkelbeard when discussing issues relating to the chinese government try to use the term ccp chinese communist party chinese government or beijing try not to use only the term chinese or china when describing the government as it may be misinterpreted as referring to the chinese people either citizens of china or people of chinese ethnicity if that is not your intention as mentioned earlier conflating china and the ccp is actually a tactic of the ccp,"chinese, government, policing, people, surveillance",2019-11-26 02:09:24,d chinese government uses machine learning not only for surveillance but also for predictive policing and for deciding who to arrest in xinjiang link to story this post is not an ml research related post i am posting this because i think it is important for the community to see how research is applied by authoritarian governments to achieve their goals it is related to a few previous popular posts on this subreddit with high upvotes which prompted me to post this story previous related stories is machine learnings killer app totalitarian surveillance and oppression using cv for surveillance and regression for threat scoring citizens in xinjiang iccv the state of some ethically questionable papers hikvision marketed ml surveillance camera that automatically identifies uyghurs working on an ethically questionnable project the story reports the details of a new leak of highly classified chinese government documents reveals the operations manual for running the mass detention camps in xinjiang and exposed the mechanics of the regions system of mass surveillance the lead journalist summary of findings the china cables represent the first leak of a classified chinese government document revealing the inner workings of the detention camps as well as the first leak of classified government documents unveiling the predictive policing system in xinjiang the leak features classified intelligence briefings that reveal in the governments own words how xinjiang police essentially take orders from a massive cybernetic brain known as ijop which flags entire categories of people for investigation detention these secret intelligence briefings reveal the scope and ambition of the governments aipowered policing platform which purports to predict crimes based on computergenerated findings alone the result arrest by algorithm the article describe methods used for algorithmic policing the classified intelligence briefings reveal the scope and ambition of the governments artificialintelligencepowered policing platform which purports to predict crimes based on these computergenerated findings alone experts say the platform which is used in both policing and military contexts demonstrates the power of technology to help drive industrialscale human rights abuses the chinese government have bought into a model of policing where they believe that through the collection of largescale data run through artificial intelligence and machine learning that they can in fact predict ahead of time where possible incidents might take place as well as identify possible populations that have the propensity to engage in antistate antiregime action said mulvenon the sos international document expert and director of intelligence integration and then they are preemptively going after those people using that data in addition to the predictive policing aspect of the article there are side articles about the entire ml stack including how mobile apps are used to target uighurs and also how the inmates are reeducated once inside the concentration camps the documents reveal how every aspect of a detainees life is monitored and controlled note my motivation for posting this story is to raise ethical concerns and awareness in the research community i do not want to heighten levels of racism towards the chinese research community not that it may matter but i am chinese see this thread for some context about what i dont want these discussions to become i am aware of the fact that the chinese governments policy is to integrate the state and the people as one so accusing the party is perceived domestically as insulting the chinese people but i also believe that we as a research community is intelligent enough to be able to separate government and those in power from individual researchers we as a community should keep in mind that there are many chinese researchers in mainland and abroad who are not supportive of the actions of the ccp but they may not be able to voice their concerns due to personal risk edit suggestion from udunkelbeard when discussing issues relating to the chinese government try to use the term ccp chinese communist party chinese government or beijing try not to use only the term chinese or china when describing the government as it may be misinterpreted as referring to the chinese people either citizens of china or people of chinese ethnicity if that is not your intention as mentioned earlier conflating china and the ccp is actually a tactic of the ccp,"['chinese', 'government', 'us', 'machine', 'learning', 'surveillance', 'also', 'predictive', 'policing', 'deciding', 'arrest', 'xinjiang', 'link', 'story', 'post', 'research', 'related', 'post', 'posting', 'think', 'important', 'community', 'see', 'research', 'applied', 'authoritarian', 'government', 'achieve', 'goal', 'related', 'previous', 'popular', 'post', 'subreddit', 'high', 'upvotes', 'prompted', 'post', 'story', 'previous', 'related', 'story', 'machine', 'learning', 'killer', 'app', 'totalitarian', 'surveillance', 'oppression', 'using', 'surveillance', 'regression', 'threat', 'scoring', 'citizen', 'xinjiang', 'iccv', 'state', 'ethically', 'questionable', 'paper', 'hikvision', 'marketed', 'surveillance', 'camera', 'automatically', 'identifies', 'uyghurs', 'working', 'ethically', 'questionnable', 'project', 'story', 'report', 'detail', 'new', 'leak', 'highly', 'classified', 'chinese', 'government', 'document', 'reveals', 'operation', 'manual', 'running', 'mass', 'detention', 'camp', 'xinjiang', 'exposed', 'mechanic', 'region', 'system', 'mass', 'surveillance', 'lead', 'journalist', 'summary', 'finding', 'china', 'cable', 'represent', 'first', 'leak', 'classified', 'chinese', 'government', 'document', 'revealing', 'inner', 'working', 'detention', 'camp', 'well', 'first', 'leak', 'classified', 'government', 'document', 'unveiling', 'predictive', 'policing', 'system', 'xinjiang', 'leak', 'feature', 'classified', 'intelligence', 'briefing', 'reveal', 'government', 'word', 'xinjiang', 'police', 'essentially', 'take', 'order', 'massive', 'cybernetic', 'brain', 'known', 'ijop', 'flag', 'entire', 'category', 'people', 'investigation', 'detention', 'secret', 'intelligence', 'briefing', 'reveal', 'scope', 'ambition', 'government', 'aipowered', 'policing', 'platform', 'purport', 'predict', 'crime', 'based', 'computergenerated', 'finding', 'alone', 'result', 'arrest', 'algorithm', 'article', 'describe', 'method', 'used', 'algorithmic', 'policing', 'classified', 'intelligence', 'briefing', 'reveal', 'scope', 'ambition', 'government', 'artificialintelligencepowered', 'policing', 'platform', 'purport', 'predict', 'crime', 'based', 'computergenerated', 'finding', 'alone', 'expert', 'say', 'platform', 'used', 'policing', 'military', 'context', 'demonstrates', 'power', 'technology', 'help', 'drive', 'industrialscale', 'human', 'right', 'abuse', 'chinese', 'government', 'bought', 'model', 'policing', 'believe', 'collection', 'largescale', 'data', 'run', 'artificial', 'intelligence', 'machine', 'learning', 'fact', 'predict', 'ahead', 'time', 'possible', 'incident', 'might', 'take', 'place', 'well', 'identify', 'possible', 'population', 'propensity', 'engage', 'antistate', 'antiregime', 'action', 'said', 'mulvenon', 'so', 'international', 'document', 'expert', 'director', 'intelligence', 'integration', 'preemptively', 'going', 'people', 'using', 'data', 'addition', 'predictive', 'policing', 'aspect', 'article', 'side', 'article', 'entire', 'stack', 'including', 'mobile', 'apps', 'used', 'target', 'uighur', 'also', 'inmate', 'reeducated', 'inside', 'concentration', 'camp', 'document', 'reveal', 'every', 'aspect', 'detainee', 'life', 'monitored', 'controlled', 'note', 'motivation', 'posting', 'story', 'raise', 'ethical', 'concern', 'awareness', 'research', 'community', 'want', 'heighten', 'level', 'racism', 'towards', 'chinese', 'research', 'community', 'may', 'matter', 'chinese', 'see', 'thread', 'context', 'dont', 'want', 'discussion', 'become', 'aware', 'fact', 'chinese', 'government', 'policy', 'integrate', 'state', 'people', 'one', 'accusing', 'party', 'perceived', 'domestically', 'insulting', 'chinese', 'people', 'also', 'believe', 'research', 'community', 'intelligent', 'enough', 'able', 'separate', 'government', 'power', 'individual', 'researcher', 'community', 'keep', 'mind', 'many', 'chinese', 'researcher', 'mainland', 'abroad', 'supportive', 'action', 'ccp', 'may', 'able', 'voice', 'concern', 'due', 'personal', 'risk', 'edit', 'suggestion', 'udunkelbeard', 'discussing', 'issue', 'relating', 'chinese', 'government', 'try', 'use', 'term', 'ccp', 'chinese', 'communist', 'party', 'chinese', 'government', 'beijing', 'try', 'use', 'term', 'chinese', 'china', 'describing', 'government', 'may', 'misinterpreted', 'referring', 'chinese', 'people', 'either', 'citizen', 'china', 'people', 'chinese', 'ethnicity', 'intention', 'mentioned', 'earlier', 'conflating', 'china', 'ccp', 'actually', 'tactic', 'ccp']",,,,
zowhlo,[N] Neural Rendering: Reconstruct your city in 3D using only your mobile phone and CitySynth!,,1671362656.0,1133.0,66.0,/r/MachineLearning/comments/zowhlo/n_neural_rendering_reconstruct_your_city_in_3d/,https://v.redd.it/hoy9jldn5n6a1,ydrive-ai,MachineLearning,0.98,False,False,False,False,1.0,1745833844.771658,Tech & Programming,15.0,0.0,15.0,Sunday,6.0,December,2022.0,True,0.0,0.0,0.0,1.0,neutral,n neural rendering reconstruct your city in d using only your mobile phone and citysynth,,n neural rendering reconstruct your city in d using only your mobile phone and citysynth ,"neural, rendering, reconstruct, city, using",2022-12-18 11:24:16,n neural rendering reconstruct your city in d using only your mobile phone and citysynth ,"['neural', 'rendering', 'reconstruct', 'city', 'using', 'mobile', 'phone', 'citysynth']",,,,
7gls3j,"[R] ""Deep Image Prior"": deep super-resolution, inpainting, denoising without learning on a dataset and pretrained networks",,1512042224.0,1125.0,89.0,/r/MachineLearning/comments/7gls3j/r_deep_image_prior_deep_superresolution/,https://i.redd.it/a0bqopiwn3101.jpg,dmitry_ulyanov,MachineLearning,0.97,False,False,False,False,0.0,1745833845.204752,Tech & Programming,16.0,0.0,16.0,Thursday,6.0,November,2017.0,False,0.0,0.0,0.0,1.0,neutral,r deep image prior deep superresolution inpainting denoising without learning on a dataset and pretrained networks,,r deep image prior deep superresolution inpainting denoising without learning on a dataset and pretrained networks ,"deep, image, prior, superresolution, inpainting",2017-11-30 11:43:44,r deep image prior deep superresolution inpainting denoising without learning on a dataset and pretrained networks ,"['deep', 'image', 'prior', 'deep', 'superresolution', 'inpainting', 'denoising', 'without', 'learning', 'dataset', 'pretrained', 'network']",,,,
7fro3g,[R] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation,,1511747730.0,1125.0,85.0,/r/MachineLearning/comments/7fro3g/r_stargan_unified_generative_adversarial_networks/,https://i.redd.it/7805mzyjcf001.jpg,yunjey,MachineLearning,0.96,False,False,False,False,0.0,1745833845.699517,Tech & Programming,10.0,0.0,10.0,Sunday,20.0,November,2017.0,True,0.0258,0.215,0.207,0.579,neutral,r stargan unified generative adversarial networks for multidomain imagetoimage translation,,r stargan unified generative adversarial networks for multidomain imagetoimage translation ,"stargan, unified, generative, adversarial, network",2017-11-27 01:55:30,r stargan unified generative adversarial networks for multidomain imagetoimage translation ,"['stargan', 'unified', 'generative', 'adversarial', 'network', 'multidomain', 'imagetoimage', 'translation']",,,,
1g7dzkp,[D] Why do PhD Students in the US seem like overpowered final bosses ,"Hello,

I'm a PhD student in a European university, working on AI/ML/CV ..etc. my PhD is 4 years. The first year I literally just spent learning how to actually do research, teaching one course to learn how things work...etc. Second year, I published my first publication as a co-author in CVPR. By third year, I can manage research projects, I understand how to do grants applications, how funding works, the politics of it all ...etc. I added to my CV, 2 publications, one journal and another conference as first author. I'm very involved in industry and I also write a lot of production grade code in regard to AI, systems architecture, backend, cloud, deployment, etc for companies that have contracts with my lab.

The issue is when I see PhD students similar to me in the US, they be having 10 publications, 5 of them 1st author, all of them are either CVPR, ICML, ICLR, NeurIPS ...etc. I don't understand, do these people not sleep ? How are they able to achieve this crazy amount of work and still have 3 publications every year in A\* journals ?

I don't think these people are smarter than I, usually I get ideas and I look up if something exists, and I can see that something was just published by some PhD student in Stanford or DeepMind ..etc like 1 month ago, So I can see that my reasoning isn't late in regard to SOTA. but the concepts that you would need to grasp to just have one of those publications + the effort and the time you need to invest and the resources to get everything done, wouldn't be possible for 2\~3 months project. How is it possible for these people to do this ?

Thank you !",1729358853.0,1108.0,275.0,/r/MachineLearning/comments/1g7dzkp/d_why_do_phd_students_in_the_us_seem_like/,https://www.reddit.com/r/MachineLearning/comments/1g7dzkp/d_why_do_phd_students_in_the_us_seem_like/,,MachineLearning,0.95,True,False,False,False,0.0,1745833846.512002,Tech & Programming,13.0,297.0,298.0,Saturday,13.0,October,2024.0,True,0.7838,0.038,0.007,0.956,positive,d why do phd students in the us seem like overpowered final bosses,hello im a phd student in a european university working on aimlcv etc my phd is years the first year i literally just spent learning how to actually do research teaching one course to learn how things worketc second year i published my first publication as a coauthor in cvpr by third year i can manage research projects i understand how to do grants applications how funding works the politics of it all etc i added to my cv publications one journal and another conference as first author im very involved in industry and i also write a lot of production grade code in regard to ai systems architecture backend cloud deployment etc for companies that have contracts with my lab the issue is when i see phd students similar to me in the us they be having publications of them st author all of them are either cvpr icml iclr neurips etc i dont understand do these people not sleep how are they able to achieve this crazy amount of work and still have publications every year in a journals i dont think these people are smarter than i usually i get ideas and i look up if something exists and i can see that something was just published by some phd student in stanford or deepmind etc like month ago so i can see that my reasoning isnt late in regard to sota but the concepts that you would need to grasp to just have one of those publications the effort and the time you need to invest and the resources to get everything done wouldnt be possible for months project how is it possible for these people to do this thank you,d why do phd students in the us seem like overpowered final bosses hello im a phd student in a european university working on aimlcv etc my phd is years the first year i literally just spent learning how to actually do research teaching one course to learn how things worketc second year i published my first publication as a coauthor in cvpr by third year i can manage research projects i understand how to do grants applications how funding works the politics of it all etc i added to my cv publications one journal and another conference as first author im very involved in industry and i also write a lot of production grade code in regard to ai systems architecture backend cloud deployment etc for companies that have contracts with my lab the issue is when i see phd students similar to me in the us they be having publications of them st author all of them are either cvpr icml iclr neurips etc i dont understand do these people not sleep how are they able to achieve this crazy amount of work and still have publications every year in a journals i dont think these people are smarter than i usually i get ideas and i look up if something exists and i can see that something was just published by some phd student in stanford or deepmind etc like month ago so i can see that my reasoning isnt late in regard to sota but the concepts that you would need to grasp to just have one of those publications the effort and the time you need to invest and the resources to get everything done wouldnt be possible for months project how is it possible for these people to do this thank you,"phd, etc, year, publication, student",2024-10-19 17:27:33,d why do phd students in the us seem like overpowered final bosses hello im a phd student in a european university working on aimlcv etc my phd is years the first year i literally just spent learning how to actually do research teaching one course to learn how things worketc second year i published my first publication as a coauthor in cvpr by third year i can manage research projects i understand how to do grants applications how funding works the politics of it all etc i added to my cv publications one journal and another conference as first author im very involved in industry and i also write a lot of production grade code in regard to ai systems architecture backend cloud deployment etc for companies that have contracts with my lab the issue is when i see phd students similar to me in the us they be having publications of them st author all of them are either cvpr icml iclr neurips etc i dont understand do these people not sleep how are they able to achieve this crazy amount of work and still have publications every year in a journals i dont think these people are smarter than i usually i get ideas and i look up if something exists and i can see that something was just published by some phd student in stanford or deepmind etc like month ago so i can see that my reasoning isnt late in regard to sota but the concepts that you would need to grasp to just have one of those publications the effort and the time you need to invest and the resources to get everything done wouldnt be possible for months project how is it possible for these people to do this thank you,"['phd', 'student', 'seem', 'like', 'overpowered', 'final', 'boss', 'hello', 'phd', 'student', 'european', 'university', 'working', 'aimlcv', 'etc', 'phd', 'year', 'first', 'year', 'literally', 'spent', 'learning', 'actually', 'research', 'teaching', 'one', 'course', 'learn', 'thing', 'worketc', 'second', 'year', 'published', 'first', 'publication', 'coauthor', 'cvpr', 'third', 'year', 'manage', 'research', 'project', 'understand', 'grant', 'application', 'funding', 'work', 'politics', 'etc', 'added', 'publication', 'one', 'journal', 'another', 'conference', 'first', 'author', 'involved', 'industry', 'also', 'write', 'lot', 'production', 'grade', 'code', 'regard', 'system', 'architecture', 'backend', 'cloud', 'deployment', 'etc', 'company', 'contract', 'lab', 'issue', 'see', 'phd', 'student', 'similar', 'publication', 'author', 'either', 'cvpr', 'icml', 'iclr', 'neurips', 'etc', 'dont', 'understand', 'people', 'sleep', 'able', 'achieve', 'crazy', 'amount', 'work', 'still', 'publication', 'every', 'year', 'journal', 'dont', 'think', 'people', 'smarter', 'usually', 'get', 'idea', 'look', 'something', 'exists', 'see', 'something', 'published', 'phd', 'student', 'stanford', 'deepmind', 'etc', 'like', 'month', 'ago', 'see', 'reasoning', 'isnt', 'late', 'regard', 'sota', 'concept', 'would', 'need', 'grasp', 'one', 'publication', 'effort', 'time', 'need', 'invest', 'resource', 'get', 'everything', 'done', 'wouldnt', 'possible', 'month', 'project', 'possible', 'people', 'thank']",,,,
fni5ow,[D] Why is the AI Hype Absolutely Bonkers,"**Edit 2:** Both the repo and the post were deleted. Redacting identifying information as the author has appeared to make rectifications, and it’d be pretty damaging if this is what came up when googling their name / GitHub (hopefully they’ve learned a career lesson and can move on). 

**TL;DR:** A PhD candidate claimed to have achieved 97% accuracy for coronavirus from chest x-rays. Their post gathered thousands of reactions, and the candidate was quick to recruit branding, marketing, frontend, and backend developers for the project. Heaps of praise all around. He listed himself as a Director of XXXX (redacted), the new name for his project. 

The accuracy was based on a training dataset of ~30 images of lesion / healthy lungs, sharing of data between test / train / validation, and code to train ResNet50 from a PyTorch tutorial.   Nonetheless, thousands of reactions and praise from the “AI | Data Science | Entrepreneur” community. 

**Original Post:**

I saw this post circulating on LinkedIn: https://www.linkedin.com/posts/activity-6645711949554425856-9Dhm

Here, a PhD candidate claims to achieve great performance with “ARTIFICIAL INTELLIGENCE” to predict coronavirus, asks for more help, and garners tens of thousands of views. The repo housing this ARTIFICIAL INTELLIGENCE solution already has a backend, front end, *branding*, a README translated in 6 languages, and a call to spread the word for this wonderful technology. Surely, I thought, this researcher has some great and novel tech for all of this hype? I mean dear god, we have *branding*, and the author has listed himself as the *founder of an organization* based on this project. Anything with this much attention, with dozens of “AI | Data Scientist | Entrepreneur” members of LinkedIn praising it, must have some great merit, right? 

Lo and behold, we have ResNet50, from torchvision.models import resnet50, with its linear layer replaced. We have a training dataset of 30 images. This should’ve taken at MAX 3 hours to put together - 1 hour for following a tutorial, and 2 for obfuscating the training with unnecessary code. 

I genuinely don’t know what to think other than this is bonkers. I hope I’m wrong, and there’s some secret model this author is hiding? If so, I’ll delete this post, but I looked through the repo and (REPO link redacted) that’s all I could find. 

I’m at a loss for thoughts. Can someone explain why this stuff trends on LinkedIn, gets thousands of views and reactions, and gets loads of praise from “expert data scientists”? It’s almost offensive to people who are like ... actually working to treat coronavirus and develop real solutions. It also seriously turns me off from pursuing an MS in CV as opposed to CS.

Edit: It turns out there were duplicate images between test / val / training, as if ResNet50 on 30 images wasn’t enough already. 

He’s also posted an update signed as “Director of XXXX (redacted)”. This seems like a straight up sleazy way to capitalize on the pandemic by advertising himself to be the head of a made up organization, pulling resources away from real biomedical researchers.",1584961524.0,1103.0,226.0,/r/MachineLearning/comments/fni5ow/d_why_is_the_ai_hype_absolutely_bonkers/,https://www.reddit.com/r/MachineLearning/comments/fni5ow/d_why_is_the_ai_hype_absolutely_bonkers/,good_rice,MachineLearning,0.98,True,False,False,False,1.0,1745833848.448851,Tech & Programming,8.0,510.0,496.0,Monday,7.0,March,2020.0,False,0.9899,0.124,0.032,0.844,positive,d why is the ai hype absolutely bonkers,edit both the repo and the post were deleted redacting identifying information as the author has appeared to make rectifications and itd be pretty damaging if this is what came up when googling their name github hopefully theyve learned a career lesson and can move on tldr a phd candidate claimed to have achieved accuracy for coronavirus from chest xrays their post gathered thousands of reactions and the candidate was quick to recruit branding marketing frontend and backend developers for the project heaps of praise all around he listed himself as a director of xxxx redacted the new name for his project the accuracy was based on a training dataset of images of lesion healthy lungs sharing of data between test train validation and code to train resnet from a pytorch tutorial nonetheless thousands of reactions and praise from the ai data science entrepreneur community original post i saw this post circulating on linkedin here a phd candidate claims to achieve great performance with artificial intelligence to predict coronavirus asks for more help and garners tens of thousands of views the repo housing this artificial intelligence solution already has a backend front end branding a readme translated in languages and a call to spread the word for this wonderful technology surely i thought this researcher has some great and novel tech for all of this hype i mean dear god we have branding and the author has listed himself as the founder of an organization based on this project anything with this much attention with dozens of ai data scientist entrepreneur members of linkedin praising it must have some great merit right lo and behold we have resnet from torchvisionmodels import resnet with its linear layer replaced we have a training dataset of images this shouldve taken at max hours to put together hour for following a tutorial and for obfuscating the training with unnecessary code i genuinely dont know what to think other than this is bonkers i hope im wrong and theres some secret model this author is hiding if so ill delete this post but i looked through the repo and repo link redacted thats all i could find im at a loss for thoughts can someone explain why this stuff trends on linkedin gets thousands of views and reactions and gets loads of praise from expert data scientists its almost offensive to people who are like actually working to treat coronavirus and develop real solutions it also seriously turns me off from pursuing an ms in cv as opposed to cs edit it turns out there were duplicate images between test val training as if resnet on images wasnt enough already hes also posted an update signed as director of xxxx redacted this seems like a straight up sleazy way to capitalize on the pandemic by advertising himself to be the head of a made up organization pulling resources away from real biomedical researchers,d why is the ai hype absolutely bonkers edit both the repo and the post were deleted redacting identifying information as the author has appeared to make rectifications and itd be pretty damaging if this is what came up when googling their name github hopefully theyve learned a career lesson and can move on tldr a phd candidate claimed to have achieved accuracy for coronavirus from chest xrays their post gathered thousands of reactions and the candidate was quick to recruit branding marketing frontend and backend developers for the project heaps of praise all around he listed himself as a director of xxxx redacted the new name for his project the accuracy was based on a training dataset of images of lesion healthy lungs sharing of data between test train validation and code to train resnet from a pytorch tutorial nonetheless thousands of reactions and praise from the ai data science entrepreneur community original post i saw this post circulating on linkedin here a phd candidate claims to achieve great performance with artificial intelligence to predict coronavirus asks for more help and garners tens of thousands of views the repo housing this artificial intelligence solution already has a backend front end branding a readme translated in languages and a call to spread the word for this wonderful technology surely i thought this researcher has some great and novel tech for all of this hype i mean dear god we have branding and the author has listed himself as the founder of an organization based on this project anything with this much attention with dozens of ai data scientist entrepreneur members of linkedin praising it must have some great merit right lo and behold we have resnet from torchvisionmodels import resnet with its linear layer replaced we have a training dataset of images this shouldve taken at max hours to put together hour for following a tutorial and for obfuscating the training with unnecessary code i genuinely dont know what to think other than this is bonkers i hope im wrong and theres some secret model this author is hiding if so ill delete this post but i looked through the repo and repo link redacted thats all i could find im at a loss for thoughts can someone explain why this stuff trends on linkedin gets thousands of views and reactions and gets loads of praise from expert data scientists its almost offensive to people who are like actually working to treat coronavirus and develop real solutions it also seriously turns me off from pursuing an ms in cv as opposed to cs edit it turns out there were duplicate images between test val training as if resnet on images wasnt enough already hes also posted an update signed as director of xxxx redacted this seems like a straight up sleazy way to capitalize on the pandemic by advertising himself to be the head of a made up organization pulling resources away from real biomedical researchers,"post, repo, thousand, training, image",2020-03-23 11:05:24,d why is the ai hype absolutely bonkers edit both the repo and the post were deleted redacting identifying information as the author has appeared to make rectifications and itd be pretty damaging if this is what came up when googling their name github hopefully theyve learned a career lesson and can move on tldr a phd candidate claimed to have achieved accuracy for coronavirus from chest xrays their post gathered thousands of reactions and the candidate was quick to recruit branding marketing frontend and backend developers for the project heaps of praise all around he listed himself as a director of xxxx redacted the new name for his project the accuracy was based on a training dataset of images of lesion healthy lungs sharing of data between test train validation and code to train resnet from a pytorch tutorial nonetheless thousands of reactions and praise from the ai data science entrepreneur community original post i saw this post circulating on linkedin here a phd candidate claims to achieve great performance with artificial intelligence to predict coronavirus asks for more help and garners tens of thousands of views the repo housing this artificial intelligence solution already has a backend front end branding a readme translated in languages and a call to spread the word for this wonderful technology surely i thought this researcher has some great and novel tech for all of this hype i mean dear god we have branding and the author has listed himself as the founder of an organization based on this project anything with this much attention with dozens of ai data scientist entrepreneur members of linkedin praising it must have some great merit right lo and behold we have resnet from torchvisionmodels import resnet with its linear layer replaced we have a training dataset of images this shouldve taken at max hours to put together hour for following a tutorial and for obfuscating the training with unnecessary code i genuinely dont know what to think other than this is bonkers i hope im wrong and theres some secret model this author is hiding if so ill delete this post but i looked through the repo and repo link redacted thats all i could find im at a loss for thoughts can someone explain why this stuff trends on linkedin gets thousands of views and reactions and gets loads of praise from expert data scientists its almost offensive to people who are like actually working to treat coronavirus and develop real solutions it also seriously turns me off from pursuing an ms in cv as opposed to cs edit it turns out there were duplicate images between test val training as if resnet on images wasnt enough already hes also posted an update signed as director of xxxx redacted this seems like a straight up sleazy way to capitalize on the pandemic by advertising himself to be the head of a made up organization pulling resources away from real biomedical researchers,"['hype', 'absolutely', 'bonkers', 'edit', 'repo', 'post', 'deleted', 'redacting', 'identifying', 'information', 'author', 'appeared', 'make', 'rectification', 'itd', 'pretty', 'damaging', 'came', 'googling', 'name', 'github', 'hopefully', 'theyve', 'learned', 'career', 'lesson', 'move', 'tldr', 'phd', 'candidate', 'claimed', 'achieved', 'accuracy', 'coronavirus', 'chest', 'xrays', 'post', 'gathered', 'thousand', 'reaction', 'candidate', 'quick', 'recruit', 'branding', 'marketing', 'frontend', 'backend', 'developer', 'project', 'heap', 'praise', 'around', 'listed', 'director', 'xxxx', 'redacted', 'new', 'name', 'project', 'accuracy', 'based', 'training', 'dataset', 'image', 'lesion', 'healthy', 'lung', 'sharing', 'data', 'test', 'train', 'validation', 'code', 'train', 'resnet', 'pytorch', 'tutorial', 'nonetheless', 'thousand', 'reaction', 'praise', 'data', 'science', 'entrepreneur', 'community', 'original', 'post', 'saw', 'post', 'circulating', 'linkedin', 'phd', 'candidate', 'claim', 'achieve', 'great', 'performance', 'artificial', 'intelligence', 'predict', 'coronavirus', 'asks', 'help', 'garner', 'ten', 'thousand', 'view', 'repo', 'housing', 'artificial', 'intelligence', 'solution', 'already', 'backend', 'front', 'end', 'branding', 'readme', 'translated', 'language', 'call', 'spread', 'word', 'wonderful', 'technology', 'surely', 'thought', 'researcher', 'great', 'novel', 'tech', 'hype', 'mean', 'dear', 'god', 'branding', 'author', 'listed', 'founder', 'organization', 'based', 'project', 'anything', 'much', 'attention', 'dozen', 'data', 'scientist', 'entrepreneur', 'member', 'linkedin', 'praising', 'must', 'great', 'merit', 'right', 'behold', 'resnet', 'torchvisionmodels', 'import', 'resnet', 'linear', 'layer', 'replaced', 'training', 'dataset', 'image', 'shouldve', 'taken', 'max', 'hour', 'put', 'together', 'hour', 'following', 'tutorial', 'obfuscating', 'training', 'unnecessary', 'code', 'genuinely', 'dont', 'know', 'think', 'bonkers', 'hope', 'wrong', 'there', 'secret', 'model', 'author', 'hiding', 'ill', 'delete', 'post', 'looked', 'repo', 'repo', 'link', 'redacted', 'thats', 'could', 'find', 'loss', 'thought', 'someone', 'explain', 'stuff', 'trend', 'linkedin', 'get', 'thousand', 'view', 'reaction', 'get', 'load', 'praise', 'expert', 'data', 'scientist', 'almost', 'offensive', 'people', 'like', 'actually', 'working', 'treat', 'coronavirus', 'develop', 'real', 'solution', 'also', 'seriously', 'turn', 'pursuing', 'opposed', 'edit', 'turn', 'duplicate', 'image', 'test', 'val', 'training', 'resnet', 'image', 'wasnt', 'enough', 'already', 'he', 'also', 'posted', 'update', 'signed', 'director', 'xxxx', 'redacted', 'seems', 'like', 'straight', 'sleazy', 'way', 'capitalize', 'pandemic', 'advertising', 'head', 'made', 'organization', 'pulling', 'resource', 'away', 'real', 'biomedical', 'researcher']",,,,
xgnt6k,"[R] GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",,1663424507.0,1106.0,50.0,/r/MachineLearning/comments/xgnt6k/r_gans_n_roses_stable_controllable_diverse_image/,https://i.redd.it/hc7h0vzihfo91.gif,No-Challenge-4770,MachineLearning,0.91,False,False,False,False,0.0,1745833849.442121,Tech & Programming,15.0,0.0,15.0,Saturday,10.0,September,2022.0,True,0.296,0.155,0.0,0.845,positive,r gans n roses stable controllable diverse image to image translation works for videos too,,r gans n roses stable controllable diverse image to image translation works for videos too ,"image, gans, rose, stable, controllable",2022-09-17 14:21:47,r gans n roses stable controllable diverse image to image translation works for videos too ,"['gans', 'rose', 'stable', 'controllable', 'diverse', 'image', 'image', 'translation', 'work', 'video']",,,,
xslpwt,"[P] Pokémon text to image, fine tuned stable diffusion model with Gradio UI",,1664597581.0,1100.0,31.0,/r/MachineLearning/comments/xslpwt/p_pokémon_text_to_image_fine_tuned_stable/,https://www.reddit.com/gallery/xslpwt,Illustrious_Row_9971,MachineLearning,0.98,False,False,False,False,0.0,1745833849.815481,Tech & Programming,13.0,0.0,13.0,Saturday,0.0,October,2022.0,True,0.4588,0.286,0.0,0.714,positive,p pokémon text to image fine tuned stable diffusion model with gradio ui,,p pokémon text to image fine tuned stable diffusion model with gradio ui ,"pokémon, text, image, fine, tuned",2022-10-01 04:13:01,p pokémon text to image fine tuned stable diffusion model with gradio ui ,"['pokémon', 'text', 'image', 'fine', 'tuned', 'stable', 'diffusion', 'model', 'gradio']",,,,
w759hp,"[R] Generative Multiplane Images: Making a 2D GAN 3D-Aware (ECCV 2022, Oral presentation). Paper and code available","Paper: https://arxiv.org/abs/2207.10642
Code: https://github.com/apple/ml-gmpi
Webpage: https://xiaoming-zhao.github.io/projects/gmpi/",1658694999.0,1106.0,36.0,/r/MachineLearning/comments/w759hp/r_generative_multiplane_images_making_a_2d_gan/,https://v.redd.it/2px9z8trbmd91,NoisesMaker,MachineLearning,0.99,False,False,False,False,0.0,1745833850.094735,Tech & Programming,17.0,6.0,19.0,Sunday,16.0,July,2022.0,True,0.0,0.0,0.0,1.0,neutral,r generative multiplane images making a d gan daware eccv oral presentation paper and code available,paper code webpage,r generative multiplane images making a d gan daware eccv oral presentation paper and code available paper code webpage,"paper, code, generative, multiplane, image",2022-07-24 20:36:39,r generative multiplane images making a d gan daware eccv oral presentation paper and code available paper code webpage,"['generative', 'multiplane', 'image', 'making', 'gan', 'daware', 'eccv', 'oral', 'presentation', 'paper', 'code', 'available', 'paper', 'code', 'webpage']",,,,
vapbkh,[P] The easiest way to process and tag video data - update,,1655050532.0,1102.0,31.0,/r/MachineLearning/comments/vapbkh/p_the_easiest_way_to_process_and_tag_video_data/,https://v.redd.it/13ji5z4ct7591,happybirthday290,MachineLearning,0.97,False,False,False,False,0.0,1745833850.437931,Tech & Programming,12.0,0.0,11.0,Sunday,12.0,June,2022.0,True,0.4215,0.237,0.0,0.763,positive,p the easiest way to process and tag video data update,,p the easiest way to process and tag video data update ,"easiest, way, process, tag, video",2022-06-12 16:15:32,p the easiest way to process and tag video data update ,"['easiest', 'way', 'process', 'tag', 'video', 'data', 'update']",,,,
8hdby5,[D] Overview of Machine Learning for newcomers,,1525586408.0,1086.0,51.0,/r/MachineLearning/comments/8hdby5/d_overview_of_machine_learning_for_newcomers/,https://i.redd.it/udk71f8496w01.png,undefdev,MachineLearning,0.9,False,False,False,False,0.0,1745833850.769392,Tech & Programming,7.0,0.0,7.0,Sunday,2.0,May,2018.0,True,0.0,0.0,0.0,1.0,neutral,d overview of machine learning for newcomers,,d overview of machine learning for newcomers ,"overview, machine, learning, newcomer",2018-05-06 06:00:08,d overview of machine learning for newcomers ,"['overview', 'machine', 'learning', 'newcomer']",,,,
fvwwzj,"[Project] If gpt-2 read erotica, what would be its take on the Holy scriptures?","**The Orange Erotic Bible**  
I fine-tuned a 117M gpt-2 model on a bdsm dataset scraped from literotica. Then I used conditional generation with sliding window prompts from [The Bible, King James Version](http://www.gutenberg.org/ebooks/30).

The result is delirious and somewhat funny. Semantic consistency is lacking, but it retains a lot of its entertainment value and metaphorical power. Needless to say, the Orange Erotic Bible is NSFW. Reader discretion and humour is advised.

Read it on [write.as](https://write.as/409j3pqk81dazkla.md)  
Code available on [github](https://github.com/orange-erotic-bible/orange-erotic-bible)  
This was my [entry](https://github.com/NaNoGenMo/2019/issues/18) to the 2019 edition of [NaNoGenMo](https://nanogenmo.github.io/)

Feedback very welcome :) send me your favourite quote!",1586171517.0,1071.0,151.0,/r/MachineLearning/comments/fvwwzj/project_if_gpt2_read_erotica_what_would_be_its/,https://www.reddit.com/r/MachineLearning/comments/fvwwzj/project_if_gpt2_read_erotica_what_would_be_its/,orange-erotic-bible,MachineLearning,0.95,True,True,False,False,2.0,1745833851.225311,Tech & Programming,14.0,97.0,109.0,Monday,7.0,April,2020.0,False,0.9531,0.149,0.0,0.851,positive,project if gpt read erotica what would be its take on the holy scriptures,the orange erotic bible i finetuned a m gpt model on a bdsm dataset scraped from literotica then i used conditional generation with sliding window prompts from the bible king james version the result is delirious and somewhat funny semantic consistency is lacking but it retains a lot of its entertainment value and metaphorical power needless to say the orange erotic bible is nsfw reader discretion and humour is advised read it on writeas code available on github this was my entry to the edition of nanogenmo feedback very welcome send me your favourite quote,project if gpt read erotica what would be its take on the holy scriptures the orange erotic bible i finetuned a m gpt model on a bdsm dataset scraped from literotica then i used conditional generation with sliding window prompts from the bible king james version the result is delirious and somewhat funny semantic consistency is lacking but it retains a lot of its entertainment value and metaphorical power needless to say the orange erotic bible is nsfw reader discretion and humour is advised read it on writeas code available on github this was my entry to the edition of nanogenmo feedback very welcome send me your favourite quote,"bible, gpt, read, orange, erotic",2020-04-06 11:11:57,project if gpt read erotica what would be its take on the holy scriptures the orange erotic bible i finetuned a m gpt model on a bdsm dataset scraped from literotica then i used conditional generation with sliding window prompts from the bible king james version the result is delirious and somewhat funny semantic consistency is lacking but it retains a lot of its entertainment value and metaphorical power needless to say the orange erotic bible is nsfw reader discretion and humour is advised read it on writeas code available on github this was my entry to the edition of nanogenmo feedback very welcome send me your favourite quote,"['project', 'gpt', 'read', 'erotica', 'would', 'take', 'holy', 'scripture', 'orange', 'erotic', 'bible', 'finetuned', 'gpt', 'model', 'bdsm', 'dataset', 'scraped', 'literotica', 'used', 'conditional', 'generation', 'sliding', 'window', 'prompt', 'bible', 'king', 'james', 'version', 'result', 'delirious', 'somewhat', 'funny', 'semantic', 'consistency', 'lacking', 'retains', 'lot', 'entertainment', 'value', 'metaphorical', 'power', 'needless', 'say', 'orange', 'erotic', 'bible', 'nsfw', 'reader', 'discretion', 'humour', 'advised', 'read', 'writeas', 'code', 'available', 'github', 'entry', 'edition', 'nanogenmo', 'feedback', 'welcome', 'send', 'favourite', 'quote']",,,,
8rdpwy,[P]I made a GPU cluster and free website to help detecting and classifying breast mammogram lesions for general public,,1529091412.0,1071.0,103.0,/r/MachineLearning/comments/8rdpwy/pi_made_a_gpu_cluster_and_free_website_to_help/,https://imgur.com/gallery/PuWx39O,coolwulf,MachineLearning,0.97,False,False,False,False,0.0,1745833852.137906,Tech & Programming,19.0,0.0,19.0,Friday,15.0,June,2018.0,False,0.7184,0.273,0.0,0.727,positive,pi made a gpu cluster and free website to help detecting and classifying breast mammogram lesions for general public,,pi made a gpu cluster and free website to help detecting and classifying breast mammogram lesions for general public ,"made, gpu, cluster, free, website",2018-06-15 19:36:52,pi made a gpu cluster and free website to help detecting and classifying breast mammogram lesions for general public ,"['made', 'gpu', 'cluster', 'free', 'website', 'help', 'detecting', 'classifying', 'breast', 'mammogram', 'lesion', 'general', 'public']",,,,
12v0vda,[P] I built a tool that auto-generates scrapers for any website with GPT,,1682156612.0,1071.0,90.0,/r/MachineLearning/comments/12v0vda/p_i_built_a_tool_that_autogenerates_scrapers_for/,https://v.redd.it/tgl8gqowoeva1,madredditscientist,MachineLearning,0.96,False,False,False,False,0.0,1745833853.029557,Tech & Programming,13.0,0.0,13.0,Saturday,5.0,April,2023.0,True,0.0,0.0,0.0,1.0,neutral,p i built a tool that autogenerates scrapers for any website with gpt,,p i built a tool that autogenerates scrapers for any website with gpt ,"built, tool, autogenerates, scraper, website",2023-04-22 09:43:32,p i built a tool that autogenerates scrapers for any website with gpt ,"['built', 'tool', 'autogenerates', 'scraper', 'website', 'gpt']",,,,
q97fpv,[R] Resolution-robust Large Mask Inpainting with Fourier Convolutions,,1634370452.0,1067.0,37.0,/r/MachineLearning/comments/q97fpv/r_resolutionrobust_large_mask_inpainting_with/,https://i.redd.it/3xsy3gttort71.gif,Illustrious_Row_9971,MachineLearning,0.99,False,False,False,False,0.0,1745833853.526578,Tech & Programming,8.0,0.0,8.0,Saturday,3.0,October,2021.0,True,0.0,0.0,0.0,1.0,neutral,r resolutionrobust large mask inpainting with fourier convolutions,,r resolutionrobust large mask inpainting with fourier convolutions ,"resolutionrobust, large, mask, inpainting, fourier",2021-10-16 07:47:32,r resolutionrobust large mask inpainting with fourier convolutions ,"['resolutionrobust', 'large', 'mask', 'inpainting', 'fourier', 'convolution']",,,,
kibblu,[P] NumPy Illustrated. The Visual Guide to NumPy,"Hi, r/MachineLearning,

I've built a (more or less) complete guide to numpy by taking ""Visual Intro to NumPy"" by Jay Alammar as a starting point and significantly expanding the coverage.

Here's the [link](https://medium.com/better-programming/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d?source=friends_link&sk=57b908a77aa44075a49293fa1631dd9b).",1608662668.0,1066.0,53.0,/r/MachineLearning/comments/kibblu/p_numpy_illustrated_the_visual_guide_to_numpy/,https://www.reddit.com/r/MachineLearning/comments/kibblu/p_numpy_illustrated_the_visual_guide_to_numpy/,jettico,MachineLearning,0.98,True,False,False,False,1.0,1745833853.866494,Tech & Programming,8.0,33.0,41.0,Tuesday,13.0,December,2020.0,False,0.0,0.0,0.0,1.0,neutral,p numpy illustrated the visual guide to numpy,hi rmachinelearning ive built a more or less complete guide to numpy by taking visual intro to numpy by jay alammar as a starting point and significantly expanding the coverage heres the link,p numpy illustrated the visual guide to numpy hi rmachinelearning ive built a more or less complete guide to numpy by taking visual intro to numpy by jay alammar as a starting point and significantly expanding the coverage heres the link,"numpy, visual, guide, illustrated, rmachinelearning",2020-12-22 18:44:28,p numpy illustrated the visual guide to numpy hi rmachinelearning ive built a more or less complete guide to numpy by taking visual intro to numpy by jay alammar as a starting point and significantly expanding the coverage heres the link,"['numpy', 'illustrated', 'visual', 'guide', 'numpy', 'rmachinelearning', 'ive', 'built', 'less', 'complete', 'guide', 'numpy', 'taking', 'visual', 'intro', 'numpy', 'jay', 'alammar', 'starting', 'point', 'significantly', 'expanding', 'coverage', 'here', 'link']",,,,
x5dwm5,[P] Apple pencil with the power of Local Stable Diffusion using Gradio Web UI running off a 3090,,1662265777.0,1065.0,44.0,/r/MachineLearning/comments/x5dwm5/p_apple_pencil_with_the_power_of_local_stable/,https://v.redd.it/qct942lxrrl91,Illustrious_Row_9971,MachineLearning,0.96,False,False,False,False,0.0,1745833854.236479,Tech & Programming,18.0,0.0,17.0,Sunday,0.0,September,2022.0,True,0.296,0.136,0.0,0.864,positive,p apple pencil with the power of local stable diffusion using gradio web ui running off a,,p apple pencil with the power of local stable diffusion using gradio web ui running off a ,"apple, pencil, power, local, stable",2022-09-04 04:29:37,p apple pencil with the power of local stable diffusion using gradio web ui running off a ,"['apple', 'pencil', 'power', 'local', 'stable', 'diffusion', 'using', 'gradio', 'web', 'running']",,,,
121t6tp,[P] A 'ChatGPT Interface' to Explore Your ML Datasets -> app.activeloop.ai,,1679766080.0,1062.0,38.0,/r/MachineLearning/comments/121t6tp/p_a_chatgpt_interface_to_explore_your_ml_datasets/,https://v.redd.it/n5l842qa9xpa1,davidbun,MachineLearning,0.95,False,False,False,False,0.0,1745833854.619105,Tech & Programming,11.0,0.0,10.0,Saturday,13.0,March,2023.0,True,0.0,0.0,0.0,1.0,neutral,p a chatgpt interface to explore your ml datasets appactiveloopai,,p a chatgpt interface to explore your ml datasets appactiveloopai ,"chatgpt, interface, explore, datasets, appactiveloopai",2023-03-25 17:41:20,p a chatgpt interface to explore your ml datasets appactiveloopai ,"['chatgpt', 'interface', 'explore', 'datasets', 'appactiveloopai']",,,,
7b7ghl,"[P] I trained a RNN to play Super Mario Kart, human-style",,1509996341.0,1049.0,75.0,/r/MachineLearning/comments/7b7ghl/p_i_trained_a_rnn_to_play_super_mario_kart/,https://www.youtube.com/watch?v=Ipi40cb_RsI,SethBling,MachineLearning,0.95,False,False,False,False,0.0,1745833854.928574,Tech & Programming,11.0,0.0,11.0,Monday,14.0,November,2017.0,False,0.743,0.512,0.0,0.488,positive,p i trained a rnn to play super mario kart humanstyle,,p i trained a rnn to play super mario kart humanstyle ,"trained, rnn, play, super, mario",2017-11-06 19:25:41,p i trained a rnn to play super mario kart humanstyle ,"['trained', 'rnn', 'play', 'super', 'mario', 'kart', 'humanstyle']",,,,
6se5zj,[N] Andrew Ng announces new Deep Learning specialization on Coursera,,1502205642.0,1043.0,186.0,/r/MachineLearning/comments/6se5zj/n_andrew_ng_announces_new_deep_learning/,https://medium.com/@andrewng/deeplearning-ai-announcing-new-deep-learning-courses-on-coursera-43af0a368116,a19n,MachineLearning,0.94,False,False,False,False,0.0,1745833855.414128,Tech & Programming,10.0,0.0,10.0,Tuesday,11.0,August,2017.0,False,0.0,0.0,0.0,1.0,neutral,n andrew ng announces new deep learning specialization on coursera,,n andrew ng announces new deep learning specialization on coursera ,"andrew, announces, new, deep, learning",2017-08-08 15:20:42,n andrew ng announces new deep learning specialization on coursera ,"['andrew', 'announces', 'new', 'deep', 'learning', 'specialization', 'coursera']",,,,
yh3gmq,"[P][R] Modern Disney Diffusion, dreambooth model trained using the diffusers implementation",,1667100686.0,1040.0,56.0,/r/MachineLearning/comments/yh3gmq/pr_modern_disney_diffusion_dreambooth_model/,https://huggingface.co/nitrosocke/mo-di-diffusion,Illustrious_Row_9971,MachineLearning,0.96,False,False,False,False,0.0,1745833856.327355,Tech & Programming,11.0,0.0,11.0,Saturday,23.0,October,2022.0,True,0.0,0.0,0.0,1.0,neutral,pr modern disney diffusion dreambooth model trained using the diffusers implementation,,pr modern disney diffusion dreambooth model trained using the diffusers implementation ,"modern, disney, diffusion, dreambooth, model",2022-10-30 03:31:26,pr modern disney diffusion dreambooth model trained using the diffusers implementation ,"['modern', 'disney', 'diffusion', 'dreambooth', 'model', 'trained', 'using', 'diffuser', 'implementation']",,,,
r3c970,"[P] From shapes to ""faces"" - shape abstraction using neural networks for differentiable 2D rendering",,1638014654.0,1032.0,38.0,/r/MachineLearning/comments/r3c970/p_from_shapes_to_faces_shape_abstraction_using/,https://v.redd.it/m0i799yyo4281,zimonitrome,MachineLearning,0.96,False,False,False,False,0.0,1745833856.742494,Tech & Programming,15.0,0.0,14.0,Saturday,7.0,November,2021.0,True,0.0,0.0,0.0,1.0,neutral,p from shapes to faces shape abstraction using neural networks for differentiable d rendering,,p from shapes to faces shape abstraction using neural networks for differentiable d rendering ,"shape, face, abstraction, using, neural",2021-11-27 12:04:14,p from shapes to faces shape abstraction using neural networks for differentiable d rendering ,"['shape', 'face', 'shape', 'abstraction', 'using', 'neural', 'network', 'differentiable', 'rendering']",,,,
ktnwcv,[P] [D] ML algorithm that can morph any two images without reference points.,,1610184716.0,1025.0,64.0,/r/MachineLearning/comments/ktnwcv/p_d_ml_algorithm_that_can_morph_any_two_images/,https://v.redd.it/wr8preja0aa61,Another__one,MachineLearning,0.95,False,False,False,False,0.0,1745833857.056156,Tech & Programming,13.0,0.0,13.0,Saturday,4.0,January,2021.0,True,0.0,0.0,0.0,1.0,neutral,p d ml algorithm that can morph any two images without reference points,,p d ml algorithm that can morph any two images without reference points ,"algorithm, morph, two, image, without",2021-01-09 09:31:56,p d ml algorithm that can morph any two images without reference points ,"['algorithm', 'morph', 'two', 'image', 'without', 'reference', 'point']",,,,
6z51xb,We are the Google Brain team. We’d love to answer your questions (again),"We had so much fun at our [2016 AMA](https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/) that we’re back again!

We are a group of research scientists and engineers that work on the Google Brain team. You can learn more about us and our work at [g.co/brain](http://g.co/brain), including a [list of our publications](https://research.google.com/pubs/BrainTeam.html), our [blog posts](https://research.googleblog.com/search/label/Google%20Brain), our [team's mission and culture](https://research.google.com/teams/brain/about.html), some of our particular areas of research, and can read about the experiences of our first cohort of [Google Brain Residents](http://g.co/brainresidency) who “graduated” in June of 2017.

You can also learn more about the TensorFlow system that our group open-sourced at [tensorflow.org](http://tensorflow.org) in November, 2015.  In less than two years since its open-source release, TensorFlow has attracted a vibrant community of developers, machine learning researchers and practitioners from all across the globe.

We’re excited to talk to you about our work, including topics like creating machines that [learn how to learn](https://research.google.com/pubs/pub45826.html), enabling people to [explore deep learning right in their browsers](https://research.googleblog.com/2017/08/harness-power-of-machine-learning-in.html), Google's custom machine learning TPU chips  and systems ([TPUv1](https://arxiv.org/abs/1704.04760) and [TPUv2](http://g.co/tpu)), use of machine learning for [robotics](http://g.co/brain/robotics) and [healthcare](http://g.co/brain/healthcare), our papers accepted to [ICLR 2017](https://research.googleblog.com/2017/04/research-at-google-and-iclr-2017.html), [ICML 2017](https://research.googleblog.com/2017/08/google-at-icml-2017.html) and NIPS 2017 (public list to be posted soon), and anything else you all want to discuss.

We're posting this a few days early to collect your questions here, and we’ll be online for much of the day on September 13, 2017, starting at around 9 AM PDT to answer your questions.

Edit: 9:05 AM PDT: A number of us have gathered across many locations including Mountain View, Montreal, Toronto, Cambridge (MA), and San Francisco.  Let's get this going!

Edit 2: 1:49 PM PDT: We've mostly finished our large group question answering session.  Thanks for the great questions, everyone!  A few of us might continue to answer a few more questions throughout the day.

We are:

* [Jeff](http://research.google.com/people/jeff) [Dean](https://scholar.google.com/citations?user=NMS69lQAAAAJ) (/u/jeffatgoogle)
* [George](https://scholar.google.com/citations?user=ghbWy-0AAAAJ&hl=en) [Dahl](https://research.google.com/pubs/104884.html) (/u/gdahl)
* [Samy Bengio](http://research.google.com/pubs/bengio.html) (/u/samybengio)
* [Prajit Ramachandran](https://scholar.google.com/citations?user=ktKXDuMAAAAJ&hl=en) (/u/prajit)
* [Alexandre Passos](https://scholar.google.com/citations?user=P3ER6nYAAAAJ&hl=en) (/u/alextp)
* [Nicolas Le Roux](https://scholar.google.com/citations?user=LmKtwk8AAAAJ&hl=en) (/u/Nicolas_LeRoux)
* [Sally Jesmonth](https://www.linkedin.com/in/sally-jesmonth-853b9624/) (/u/sallyjesm)
* [Irwan Bello] (https://scholar.google.com/citations?user=mY6p8gcAAAAJ&hl=en) /u/irwan_brain)
* [Danny Tarlow](https://scholar.google.com/citations?hl=en&user=oavgGaMAAAAJ&view_op=list_works&sortby=pubdate) (/u/dtarlow)
* [Jasmine Hsu](https://scholar.google.com/citations?hl=en&user=WcXt6YQAAAAJ) (/u/hellojas)
* [Vincent Vanhoucke](http://vincent.vanhoucke.com) (/u/vincentvanhoucke)
* [Dumitru Erhan](https://scholar.google.com/citations?user=wfGiqXEAAAAJ&hl=en&oi=ao) (/u/doomie)
* [Jascha Sohl-Dickstein](https://research.google.com/pubs/JaschaSohldickstein.html) (/u/jaschasd)
* [Pi-Chuan Chang](https://scholar.google.com/citations?user=8_8omVoAAAAJ&hl=en) (/u/pichuan)
* [Nick Frosst](https://scholar.google.ca/citations?user=1yVnaTgAAAAJ&hl=en) (/u/nick_frosst)
* [Colin Raffel](https://scholar.google.com/citations?user=I66ZBYwAAAAJ&hl=en&oi=ao) (/u/craffel)
* [Sara Hooker](https://www.linkedin.com/in/sararosehooker/) (/u/sara_brain)
* [Greg Corrado](https://scholar.google.com/citations?user=HBtozdUAAAAJ&hl=en) (/u/gcorrado)
* [Fernanda Viégas](http://hint.fm/) (/u/fernanda_viegas)
* [Martin Wattenberg](http://hint.fm/) (/u/martin_wattenberg)
* [Rajat Monga](https://research.google.com/pubs/RajatMonga.html) (/u/rajatmonga)
* [Katherine Chou] (https://www.linkedin.com/in/katherinechou) (/u/katherinechou)
* [Douglas Eck] (https://research.google.com/pubs/author39086.html) (/u/douglaseck)
* [Jonathan Hseu] (https://www.linkedin.com/in/jonathan-hseu-38088521/) (/u/jhseu)
* [David Dohan] (https://www.linkedin.com/in/ddohan) (/u/ddohan)
* … and maybe others: we’ll update if others become involved.",1505000459.0,1026.0,522.0,/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/,https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/,jeffatgoogle,MachineLearning,0.94,True,False,False,False,0.0,1745833857.524618,Tech & Programming,13.0,415.0,384.0,Saturday,19.0,September,2017.0,True,0.9861,0.092,0.0,0.908,positive,we are the google brain team wed love to answer your questions again,we had so much fun at our ama that were back again we are a group of research scientists and engineers that work on the google brain team you can learn more about us and our work at gcobrain including a list of our publications our blog posts our teams mission and culture some of our particular areas of research and can read about the experiences of our first cohort of google brain residents who graduated in june of you can also learn more about the tensorflow system that our group opensourced at tensorfloworg in november in less than two years since its opensource release tensorflow has attracted a vibrant community of developers machine learning researchers and practitioners from all across the globe were excited to talk to you about our work including topics like creating machines that learn how to learn enabling people to explore deep learning right in their browsers googles custom machine learning tpu chips and systems tpuv and tpuv use of machine learning for robotics and healthcare our papers accepted to iclr icml and nips public list to be posted soon and anything else you all want to discuss were posting this a few days early to collect your questions here and well be online for much of the day on september starting at around am pdt to answer your questions edit am pdt a number of us have gathered across many locations including mountain view montreal toronto cambridge ma and san francisco lets get this going edit pm pdt weve mostly finished our large group question answering session thanks for the great questions everyone a few of us might continue to answer a few more questions throughout the day we are jeff dean ujeffatgoogle george dahl ugdahl samy bengio usamybengio prajit ramachandran uprajit alexandre passos ualextp nicolas le roux unicolas_leroux sally jesmonth usallyjesm irwan bello uirwan_brain danny tarlow udtarlow jasmine hsu uhellojas vincent vanhoucke uvincentvanhoucke dumitru erhan udoomie jascha sohldickstein ujaschasd pichuan chang upichuan nick frosst unick_frosst colin raffel ucraffel sara hooker usara_brain greg corrado ugcorrado fernanda viégas ufernanda_viegas martin wattenberg umartin_wattenberg rajat monga urajatmonga katherine chou ukatherinechou douglas eck udouglaseck jonathan hseu ujhseu david dohan uddohan and maybe others well update if others become involved,we are the google brain team wed love to answer your questions again we had so much fun at our ama that were back again we are a group of research scientists and engineers that work on the google brain team you can learn more about us and our work at gcobrain including a list of our publications our blog posts our teams mission and culture some of our particular areas of research and can read about the experiences of our first cohort of google brain residents who graduated in june of you can also learn more about the tensorflow system that our group opensourced at tensorfloworg in november in less than two years since its opensource release tensorflow has attracted a vibrant community of developers machine learning researchers and practitioners from all across the globe were excited to talk to you about our work including topics like creating machines that learn how to learn enabling people to explore deep learning right in their browsers googles custom machine learning tpu chips and systems tpuv and tpuv use of machine learning for robotics and healthcare our papers accepted to iclr icml and nips public list to be posted soon and anything else you all want to discuss were posting this a few days early to collect your questions here and well be online for much of the day on september starting at around am pdt to answer your questions edit am pdt a number of us have gathered across many locations including mountain view montreal toronto cambridge ma and san francisco lets get this going edit pm pdt weve mostly finished our large group question answering session thanks for the great questions everyone a few of us might continue to answer a few more questions throughout the day we are jeff dean ujeffatgoogle george dahl ugdahl samy bengio usamybengio prajit ramachandran uprajit alexandre passos ualextp nicolas le roux unicolas_leroux sally jesmonth usallyjesm irwan bello uirwan_brain danny tarlow udtarlow jasmine hsu uhellojas vincent vanhoucke uvincentvanhoucke dumitru erhan udoomie jascha sohldickstein ujaschasd pichuan chang upichuan nick frosst unick_frosst colin raffel ucraffel sara hooker usara_brain greg corrado ugcorrado fernanda viégas ufernanda_viegas martin wattenberg umartin_wattenberg rajat monga urajatmonga katherine chou ukatherinechou douglas eck udouglaseck jonathan hseu ujhseu david dohan uddohan and maybe others well update if others become involved,"question, google, learn, machine, learning",2017-09-09 23:40:59,we are the google brain team wed love to answer your questions again we had so much fun at our ama that were back again we are a group of research scientists and engineers that work on the google brain team you can learn more about us and our work at gcobrain including a list of our publications our blog posts our teams mission and culture some of our particular areas of research and can read about the experiences of our first cohort of google brain residents who graduated in june of you can also learn more about the tensorflow system that our group opensourced at tensorfloworg in november in less than two years since its opensource release tensorflow has attracted a vibrant community of developers machine learning researchers and practitioners from all across the globe were excited to talk to you about our work including topics like creating machines that learn how to learn enabling people to explore deep learning right in their browsers googles custom machine learning tpu chips and systems tpuv and tpuv use of machine learning for robotics and healthcare our papers accepted to iclr icml and nips public list to be posted soon and anything else you all want to discuss were posting this a few days early to collect your questions here and well be online for much of the day on september starting at around am pdt to answer your questions edit am pdt a number of us have gathered across many locations including mountain view montreal toronto cambridge ma and san francisco lets get this going edit pm pdt weve mostly finished our large group question answering session thanks for the great questions everyone a few of us might continue to answer a few more questions throughout the day we are jeff dean ujeffatgoogle george dahl ugdahl samy bengio usamybengio prajit ramachandran uprajit alexandre passos ualextp nicolas le roux unicolas_leroux sally jesmonth usallyjesm irwan bello uirwan_brain danny tarlow udtarlow jasmine hsu uhellojas vincent vanhoucke uvincentvanhoucke dumitru erhan udoomie jascha sohldickstein ujaschasd pichuan chang upichuan nick frosst unick_frosst colin raffel ucraffel sara hooker usara_brain greg corrado ugcorrado fernanda viégas ufernanda_viegas martin wattenberg umartin_wattenberg rajat monga urajatmonga katherine chou ukatherinechou douglas eck udouglaseck jonathan hseu ujhseu david dohan uddohan and maybe others well update if others become involved,"['google', 'brain', 'team', 'wed', 'love', 'answer', 'question', 'much', 'fun', 'ama', 'back', 'group', 'research', 'scientist', 'engineer', 'work', 'google', 'brain', 'team', 'learn', 'work', 'gcobrain', 'including', 'list', 'publication', 'blog', 'post', 'team', 'mission', 'culture', 'particular', 'area', 'research', 'read', 'experience', 'first', 'cohort', 'google', 'brain', 'resident', 'graduated', 'june', 'also', 'learn', 'tensorflow', 'system', 'group', 'opensourced', 'tensorfloworg', 'november', 'less', 'two', 'year', 'since', 'opensource', 'release', 'tensorflow', 'attracted', 'vibrant', 'community', 'developer', 'machine', 'learning', 'researcher', 'practitioner', 'across', 'globe', 'excited', 'talk', 'work', 'including', 'topic', 'like', 'creating', 'machine', 'learn', 'learn', 'enabling', 'people', 'explore', 'deep', 'learning', 'right', 'browser', 'google', 'custom', 'machine', 'learning', 'tpu', 'chip', 'system', 'tpuv', 'tpuv', 'use', 'machine', 'learning', 'robotics', 'healthcare', 'paper', 'accepted', 'iclr', 'icml', 'nip', 'public', 'list', 'posted', 'soon', 'anything', 'else', 'want', 'discus', 'posting', 'day', 'early', 'collect', 'question', 'well', 'online', 'much', 'day', 'september', 'starting', 'around', 'pdt', 'answer', 'question', 'edit', 'pdt', 'number', 'gathered', 'across', 'many', 'location', 'including', 'mountain', 'view', 'montreal', 'toronto', 'cambridge', 'san', 'francisco', 'let', 'get', 'going', 'edit', 'pdt', 'weve', 'mostly', 'finished', 'large', 'group', 'question', 'answering', 'session', 'thanks', 'great', 'question', 'everyone', 'might', 'continue', 'answer', 'question', 'throughout', 'day', 'jeff', 'dean', 'ujeffatgoogle', 'george', 'dahl', 'ugdahl', 'samy', 'bengio', 'usamybengio', 'prajit', 'ramachandran', 'uprajit', 'alexandre', 'passos', 'ualextp', 'nicolas', 'roux', 'unicolas_leroux', 'sally', 'jesmonth', 'usallyjesm', 'irwan', 'bello', 'uirwan_brain', 'danny', 'tarlow', 'udtarlow', 'jasmine', 'hsu', 'uhellojas', 'vincent', 'vanhoucke', 'uvincentvanhoucke', 'dumitru', 'erhan', 'udoomie', 'jascha', 'sohldickstein', 'ujaschasd', 'pichuan', 'chang', 'upichuan', 'nick', 'frosst', 'unick_frosst', 'colin', 'raffel', 'ucraffel', 'sara', 'hooker', 'usara_brain', 'greg', 'corrado', 'ugcorrado', 'fernanda', 'viégas', 'ufernanda_viegas', 'martin', 'wattenberg', 'umartin_wattenberg', 'rajat', 'monga', 'urajatmonga', 'katherine', 'chou', 'ukatherinechou', 'douglas', 'eck', 'udouglaseck', 'jonathan', 'hseu', 'ujhseu', 'david', 'dohan', 'uddohan', 'maybe', 'others', 'well', 'update', 'others', 'become', 'involved']",,,,
uzt23p,[R] OnePose can estimate 6D poses of arbitrary household objects without instance/category-specific training or CAD models,,1653762044.0,1022.0,35.0,/r/MachineLearning/comments/uzt23p/r_onepose_can_estimate_6d_poses_of_arbitrary/,https://v.redd.it/4q2slhcjv8291,SpatialComputing,MachineLearning,0.98,False,False,False,False,0.0,1745833860.308894,Tech & Programming,16.0,0.0,16.0,Saturday,14.0,May,2022.0,True,0.0,0.0,0.0,1.0,neutral,r onepose can estimate d poses of arbitrary household objects without instancecategoryspecific training or cad models,,r onepose can estimate d poses of arbitrary household objects without instancecategoryspecific training or cad models ,"onepose, estimate, pose, arbitrary, household",2022-05-28 18:20:44,r onepose can estimate d poses of arbitrary household objects without instancecategoryspecific training or cad models ,"['onepose', 'estimate', 'pose', 'arbitrary', 'household', 'object', 'without', 'instancecategoryspecific', 'training', 'cad', 'model']",,,,
146ue8q,r/MachineLearning is joining the Reddit Blackout starting June 12th,"Hi folks,

At this point you all are probably well aware of the shenanigans Reddit has been pulling regarding their [announced API changes](https://old.reddit.com/r/modnews/comments/13wshdp/api_update_continued_access_to_our_api_for/). These changes [are forcing many third party apps to shutdown](https://old.reddit.com/r/Save3rdPartyApps/comments/13yh0jf/dont_let_reddit_kill_3rd_party_apps/), including [Apollo](https://old.reddit.com/r/apolloapp/comments/144f6xm/apollo_will_close_down_on_june_30th_reddits/), [Reddit is Fun](https://old.reddit.com/r/redditisfun/comments/13wxepd/rif_dev_here_reddits_api_changes_will_likely_kill/), [Sync](https://old.reddit.com/r/redditsync/comments/144jp3w/sync_will_shut_down_on_june_30_2023/), [Narwhal](https://old.reddit.com/r/getnarwhal/comments/13wv038/reddit_have_quoted_the_apollo_devs_a_ridiculous/jmdqtyt/), and [many more](https://old.reddit.com/r/technology/comments/144o0cs/its_not_just_apollo_other_reddit_apps_are/). Many of the mods here, including me, use one of these apps to help moderate the sub.

Furthermore, it's now clear that Reddit is not acting in good faith. This includes [falsely accusing the creator of Apollo of extortion](https://old.reddit.com/r/reddit/comments/145bram/addressing_the_community_about_changes_to_our_api/jnk45rr/?context=3), [ignoring app developers](https://old.reddit.com/r/reddit/comments/145bram/addressing_the_community_about_changes_to_our_api/jnk2pp3/) requests to communicate while [saying they are working devs](https://old.reddit.com/r/reddit/comments/145bram/addressing_the_community_about_changes_to_our_api/jnk647a/), and [requiring devs who make accessibility-focused apps to do so for free](https://old.reddit.com/r/reddit/comments/145bram/addressing_the_community_about_changes_to_our_api/jnk5jfh/)! This mirrors the philosophy they have for moderation: have unpaid volunteers provide millions of hours of unpaid labor for Reddit.

We [previously asked the community](https://old.reddit.com/r/MachineLearning/comments/14265di/should_rmachinelearning_join_the_reddit_blackout/) if we should join [the planned Reddit blackout](https://old.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/) and the answer was a resounding yes. So, that's what we plan to do. We feel there are enough other platforms for machine learning discussion (Hacker News, Twitter, Mastodon, etc), that people can migrate there in the meantime until Reddit reassesses their latest policy decisions. We hope to see you all on the other side.

Sincerely,
Your r/MachineLearning moderators",1686491301.0,1012.0,67.0,/r/MachineLearning/comments/146ue8q/rmachinelearning_is_joining_the_reddit_blackout/,https://www.reddit.com/r/MachineLearning/comments/146ue8q/rmachinelearning_is_joining_the_reddit_blackout/,,MachineLearning,0.95,True,False,False,False,0.0,1745833860.768948,Tech & Programming,9.0,198.0,207.0,Sunday,9.0,June,2023.0,True,0.9715,0.134,0.03,0.837,positive,rmachinelearning is joining the reddit blackout starting june th,hi folks at this point you all are probably well aware of the shenanigans reddit has been pulling regarding their announced api changes these changes are forcing many third party apps to shutdown including apollo reddit is fun sync narwhal and many more many of the mods here including me use one of these apps to help moderate the sub furthermore its now clear that reddit is not acting in good faith this includes falsely accusing the creator of apollo of extortion ignoring app developers requests to communicate while saying they are working devs and requiring devs who make accessibilityfocused apps to do so for free this mirrors the philosophy they have for moderation have unpaid volunteers provide millions of hours of unpaid labor for reddit we previously asked the community if we should join the planned reddit blackout and the answer was a resounding yes so thats what we plan to do we feel there are enough other platforms for machine learning discussion hacker news twitter mastodon etc that people can migrate there in the meantime until reddit reassesses their latest policy decisions we hope to see you all on the other side sincerely your rmachinelearning moderators,rmachinelearning is joining the reddit blackout starting june th hi folks at this point you all are probably well aware of the shenanigans reddit has been pulling regarding their announced api changes these changes are forcing many third party apps to shutdown including apollo reddit is fun sync narwhal and many more many of the mods here including me use one of these apps to help moderate the sub furthermore its now clear that reddit is not acting in good faith this includes falsely accusing the creator of apollo of extortion ignoring app developers requests to communicate while saying they are working devs and requiring devs who make accessibilityfocused apps to do so for free this mirrors the philosophy they have for moderation have unpaid volunteers provide millions of hours of unpaid labor for reddit we previously asked the community if we should join the planned reddit blackout and the answer was a resounding yes so thats what we plan to do we feel there are enough other platforms for machine learning discussion hacker news twitter mastodon etc that people can migrate there in the meantime until reddit reassesses their latest policy decisions we hope to see you all on the other side sincerely your rmachinelearning moderators,"reddit, many, apps, rmachinelearning, blackout",2023-06-11 13:48:21,rmachinelearning is joining the reddit blackout starting june th hi folks at this point you all are probably well aware of the shenanigans reddit has been pulling regarding their announced api changes these changes are forcing many third party apps to shutdown including apollo reddit is fun sync narwhal and many more many of the mods here including me use one of these apps to help moderate the sub furthermore its now clear that reddit is not acting in good faith this includes falsely accusing the creator of apollo of extortion ignoring app developers requests to communicate while saying they are working devs and requiring devs who make accessibilityfocused apps to do so for free this mirrors the philosophy they have for moderation have unpaid volunteers provide millions of hours of unpaid labor for reddit we previously asked the community if we should join the planned reddit blackout and the answer was a resounding yes so thats what we plan to do we feel there are enough other platforms for machine learning discussion hacker news twitter mastodon etc that people can migrate there in the meantime until reddit reassesses their latest policy decisions we hope to see you all on the other side sincerely your rmachinelearning moderators,"['rmachinelearning', 'joining', 'reddit', 'blackout', 'starting', 'june', 'folk', 'point', 'probably', 'well', 'aware', 'shenanigan', 'reddit', 'pulling', 'regarding', 'announced', 'api', 'change', 'change', 'forcing', 'many', 'third', 'party', 'apps', 'shutdown', 'including', 'apollo', 'reddit', 'fun', 'sync', 'narwhal', 'many', 'many', 'mod', 'including', 'use', 'one', 'apps', 'help', 'moderate', 'sub', 'furthermore', 'clear', 'reddit', 'acting', 'good', 'faith', 'includes', 'falsely', 'accusing', 'creator', 'apollo', 'extortion', 'ignoring', 'app', 'developer', 'request', 'communicate', 'saying', 'working', 'devs', 'requiring', 'devs', 'make', 'accessibilityfocused', 'apps', 'free', 'mirror', 'philosophy', 'moderation', 'unpaid', 'volunteer', 'provide', 'million', 'hour', 'unpaid', 'labor', 'reddit', 'previously', 'asked', 'community', 'join', 'planned', 'reddit', 'blackout', 'answer', 'resounding', 'yes', 'thats', 'plan', 'feel', 'enough', 'platform', 'machine', 'learning', 'discussion', 'hacker', 'news', 'twitter', 'mastodon', 'etc', 'people', 'migrate', 'meantime', 'reddit', 'reassesses', 'latest', 'policy', 'decision', 'hope', 'see', 'side', 'sincerely', 'rmachinelearning', 'moderator']",,,,
kbnlte,[P] paperai: AI-powered literature discovery and review engine for medical/scientific papers,,1607772209.0,1010.0,39.0,/r/MachineLearning/comments/kbnlte/p_paperai_aipowered_literature_discovery_and/,https://i.redd.it/p5niv90oqq461.png,davidmezzetti,MachineLearning,0.99,False,False,False,False,1.0,1745833861.190081,Tech & Programming,11.0,0.0,11.0,Saturday,6.0,December,2020.0,True,0.0,0.0,0.0,1.0,neutral,p paperai aipowered literature discovery and review engine for medicalscientific papers,,p paperai aipowered literature discovery and review engine for medicalscientific papers ,"paperai, aipowered, literature, discovery, review",2020-12-12 11:23:29,p paperai aipowered literature discovery and review engine for medicalscientific papers ,"['paperai', 'aipowered', 'literature', 'discovery', 'review', 'engine', 'medicalscientific', 'paper']",,,,
124eyso,[N] OpenAI may have benchmarked GPT-4’s coding ability on it’s own training data,"[GPT-4 and professional benchmarks: the wrong answer to the wrong question](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)

*OpenAI may have tested on the training data. Besides, human benchmarks are meaningless for bots.*

 **Problem 1: training data contamination**

To benchmark GPT-4’s coding ability, OpenAI evaluated it on problems from Codeforces, a website that hosts coding competitions. Surprisingly, Horace He pointed out that GPT-4 solved 10/10 pre-2021 problems and 0/10 recent problems in the easy category. The training data cutoff for GPT-4 is September 2021. This strongly suggests that the model is able to memorize solutions from its training set — or at least partly memorize them, enough that it can fill in what it can’t recall.

As further evidence for this hypothesis, we tested it on Codeforces problems from different times in 2021. We found that it could regularly solve problems in the easy category before September 5, but none of the problems after September 12.

In fact, we can definitively show that it has memorized problems in its training set: when prompted with the title of a Codeforces problem, GPT-4 includes a link to the exact contest where the problem appears (and the round number is almost correct: it is off by one). Note that GPT-4 cannot access the Internet, so memorization is the only explanation.",1679983023.0,1002.0,134.0,/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/,https://www.reddit.com/r/MachineLearning/comments/124eyso/n_openai_may_have_benchmarked_gpt4s_coding/,Balance-,MachineLearning,0.97,True,False,False,False,0.0,1745833861.513022,Tech & Programming,13.0,210.0,215.0,Tuesday,1.0,March,2023.0,False,-0.9525,0.069,0.133,0.798,negative,n openai may have benchmarked gpts coding ability on its own training data,gpt and professional benchmarks the wrong answer to the wrong question openai may have tested on the training data besides human benchmarks are meaningless for bots problem training data contamination to benchmark gpts coding ability openai evaluated it on problems from codeforces a website that hosts coding competitions surprisingly horace he pointed out that gpt solved pre problems and recent problems in the easy category the training data cutoff for gpt is september this strongly suggests that the model is able to memorize solutions from its training set or at least partly memorize them enough that it can fill in what it cant recall as further evidence for this hypothesis we tested it on codeforces problems from different times in we found that it could regularly solve problems in the easy category before september but none of the problems after september in fact we can definitively show that it has memorized problems in its training set when prompted with the title of a codeforces problem gpt includes a link to the exact contest where the problem appears and the round number is almost correct it is off by one note that gpt cannot access the internet so memorization is the only explanation,n openai may have benchmarked gpts coding ability on its own training data gpt and professional benchmarks the wrong answer to the wrong question openai may have tested on the training data besides human benchmarks are meaningless for bots problem training data contamination to benchmark gpts coding ability openai evaluated it on problems from codeforces a website that hosts coding competitions surprisingly horace he pointed out that gpt solved pre problems and recent problems in the easy category the training data cutoff for gpt is september this strongly suggests that the model is able to memorize solutions from its training set or at least partly memorize them enough that it can fill in what it cant recall as further evidence for this hypothesis we tested it on codeforces problems from different times in we found that it could regularly solve problems in the easy category before september but none of the problems after september in fact we can definitively show that it has memorized problems in its training set when prompted with the title of a codeforces problem gpt includes a link to the exact contest where the problem appears and the round number is almost correct it is off by one note that gpt cannot access the internet so memorization is the only explanation,"problem, training, gpt, data, openai",2023-03-28 05:57:03,n openai may have benchmarked gpts coding ability on its own training data gpt and professional benchmarks the wrong answer to the wrong question openai may have tested on the training data besides human benchmarks are meaningless for bots problem training data contamination to benchmark gpts coding ability openai evaluated it on problems from codeforces a website that hosts coding competitions surprisingly horace he pointed out that gpt solved pre problems and recent problems in the easy category the training data cutoff for gpt is september this strongly suggests that the model is able to memorize solutions from its training set or at least partly memorize them enough that it can fill in what it cant recall as further evidence for this hypothesis we tested it on codeforces problems from different times in we found that it could regularly solve problems in the easy category before september but none of the problems after september in fact we can definitively show that it has memorized problems in its training set when prompted with the title of a codeforces problem gpt includes a link to the exact contest where the problem appears and the round number is almost correct it is off by one note that gpt cannot access the internet so memorization is the only explanation,"['openai', 'may', 'benchmarked', 'gpts', 'coding', 'ability', 'training', 'data', 'gpt', 'professional', 'benchmark', 'wrong', 'answer', 'wrong', 'question', 'openai', 'may', 'tested', 'training', 'data', 'besides', 'human', 'benchmark', 'meaningless', 'bot', 'problem', 'training', 'data', 'contamination', 'benchmark', 'gpts', 'coding', 'ability', 'openai', 'evaluated', 'problem', 'codeforces', 'website', 'host', 'coding', 'competition', 'surprisingly', 'horace', 'pointed', 'gpt', 'solved', 'pre', 'problem', 'recent', 'problem', 'easy', 'category', 'training', 'data', 'cutoff', 'gpt', 'september', 'strongly', 'suggests', 'model', 'able', 'memorize', 'solution', 'training', 'set', 'least', 'partly', 'memorize', 'enough', 'fill', 'cant', 'recall', 'evidence', 'hypothesis', 'tested', 'codeforces', 'problem', 'different', 'time', 'found', 'could', 'regularly', 'solve', 'problem', 'easy', 'category', 'september', 'none', 'problem', 'september', 'fact', 'definitively', 'show', 'memorized', 'problem', 'training', 'set', 'prompted', 'title', 'codeforces', 'problem', 'gpt', 'includes', 'link', 'exact', 'contest', 'problem', 'appears', 'round', 'number', 'almost', 'correct', 'one', 'note', 'gpt', 'access', 'internet', 'memorization', 'explanation']",,,,
1alxv3l,"[D] Off my chest. I'm doing PhD in ML, and I'm a failure."," I'm halfway through my ML PhD.

I was quite lucky and got into a good program, especially in a good lab where students are superstars and get fancy jobs upon graduation. I'm not one of them. I have one crappy, not-so-technical publication and I'm struggling to find a new problem that is solvable within my capacity. I've tried hard. I've been doing research throughout my undergrad and masters, doing everything I could – doing projects, reading papers, taking ML and math courses, writing grants for professors...

The thing is, I just can't reach the level of generating new ideas. No matter how hard I try, it just ain't my thing. I think why. I begin to wonder if STEM wasn't my thing in the first place. I look around and there are people whose brain simply ""gets"" things easier. For me, it requires extra hard working and extra time. During undergrad, I could get away with studying harder and longer. Well, not for PhD. Especially not in this fast-paced, crowded field where I need to take in new stuff and publish quickly.

I'm an imposter, and this is not a syndrome. I'm getting busted. Everybody else is getting multiple internship offers and all that. I'm getting rejected from everywhere. It seems now they know. They know I'm useless. Would like to say this to my advisor but he's such a genius that he doesn't get the mind of the commoner. All my senior labmates are full-time employed, so practically I'm the most senior in my lab right now.",1707405042.0,999.0,327.0,/r/MachineLearning/comments/1alxv3l/d_off_my_chest_im_doing_phd_in_ml_and_im_a_failure/,https://www.reddit.com/r/MachineLearning/comments/1alxv3l/d_off_my_chest_im_doing_phd_in_ml_and_im_a_failure/,rsfhuose,MachineLearning,0.96,True,False,False,False,0.0,1745833862.195116,Tech & Programming,13.0,258.0,270.0,Thursday,10.0,February,2024.0,False,-0.4292,0.051,0.069,0.879,negative,d off my chest im doing phd in ml and im a failure,im halfway through my ml phd i was quite lucky and got into a good program especially in a good lab where students are superstars and get fancy jobs upon graduation im not one of them i have one crappy notsotechnical publication and im struggling to find a new problem that is solvable within my capacity ive tried hard ive been doing research throughout my undergrad and masters doing everything i could doing projects reading papers taking ml and math courses writing grants for professors the thing is i just cant reach the level of generating new ideas no matter how hard i try it just aint my thing i think why i begin to wonder if stem wasnt my thing in the first place i look around and there are people whose brain simply gets things easier for me it requires extra hard working and extra time during undergrad i could get away with studying harder and longer well not for phd especially not in this fastpaced crowded field where i need to take in new stuff and publish quickly im an imposter and this is not a syndrome im getting busted everybody else is getting multiple internship offers and all that im getting rejected from everywhere it seems now they know they know im useless would like to say this to my advisor but hes such a genius that he doesnt get the mind of the commoner all my senior labmates are fulltime employed so practically im the most senior in my lab right now,d off my chest im doing phd in ml and im a failure im halfway through my ml phd i was quite lucky and got into a good program especially in a good lab where students are superstars and get fancy jobs upon graduation im not one of them i have one crappy notsotechnical publication and im struggling to find a new problem that is solvable within my capacity ive tried hard ive been doing research throughout my undergrad and masters doing everything i could doing projects reading papers taking ml and math courses writing grants for professors the thing is i just cant reach the level of generating new ideas no matter how hard i try it just aint my thing i think why i begin to wonder if stem wasnt my thing in the first place i look around and there are people whose brain simply gets things easier for me it requires extra hard working and extra time during undergrad i could get away with studying harder and longer well not for phd especially not in this fastpaced crowded field where i need to take in new stuff and publish quickly im an imposter and this is not a syndrome im getting busted everybody else is getting multiple internship offers and all that im getting rejected from everywhere it seems now they know they know im useless would like to say this to my advisor but hes such a genius that he doesnt get the mind of the commoner all my senior labmates are fulltime employed so practically im the most senior in my lab right now,"get, thing, phd, new, hard",2024-02-08 15:10:42,d off my chest im doing phd in ml and im a failure im halfway through my ml phd i was quite lucky and got into a good program especially in a good lab where students are superstars and get fancy jobs upon graduation im not one of them i have one crappy notsotechnical publication and im struggling to find a new problem that is solvable within my capacity ive tried hard ive been doing research throughout my undergrad and masters doing everything i could doing projects reading papers taking ml and math courses writing grants for professors the thing is i just cant reach the level of generating new ideas no matter how hard i try it just aint my thing i think why i begin to wonder if stem wasnt my thing in the first place i look around and there are people whose brain simply gets things easier for me it requires extra hard working and extra time during undergrad i could get away with studying harder and longer well not for phd especially not in this fastpaced crowded field where i need to take in new stuff and publish quickly im an imposter and this is not a syndrome im getting busted everybody else is getting multiple internship offers and all that im getting rejected from everywhere it seems now they know they know im useless would like to say this to my advisor but hes such a genius that he doesnt get the mind of the commoner all my senior labmates are fulltime employed so practically im the most senior in my lab right now,"['chest', 'phd', 'failure', 'halfway', 'phd', 'quite', 'lucky', 'got', 'good', 'program', 'especially', 'good', 'lab', 'student', 'superstar', 'get', 'fancy', 'job', 'upon', 'graduation', 'one', 'one', 'crappy', 'notsotechnical', 'publication', 'struggling', 'find', 'new', 'problem', 'solvable', 'within', 'capacity', 'ive', 'tried', 'hard', 'ive', 'research', 'throughout', 'undergrad', 'master', 'everything', 'could', 'project', 'reading', 'paper', 'taking', 'math', 'course', 'writing', 'grant', 'professor', 'thing', 'cant', 'reach', 'level', 'generating', 'new', 'idea', 'matter', 'hard', 'try', 'aint', 'thing', 'think', 'begin', 'wonder', 'stem', 'wasnt', 'thing', 'first', 'place', 'look', 'around', 'people', 'whose', 'brain', 'simply', 'get', 'thing', 'easier', 'requires', 'extra', 'hard', 'working', 'extra', 'time', 'undergrad', 'could', 'get', 'away', 'studying', 'harder', 'longer', 'well', 'phd', 'especially', 'fastpaced', 'crowded', 'field', 'need', 'take', 'new', 'stuff', 'publish', 'quickly', 'imposter', 'syndrome', 'getting', 'busted', 'everybody', 'else', 'getting', 'multiple', 'internship', 'offer', 'getting', 'rejected', 'everywhere', 'seems', 'know', 'know', 'useless', 'would', 'like', 'say', 'advisor', 'he', 'genius', 'doesnt', 'get', 'mind', 'commoner', 'senior', 'labmates', 'fulltime', 'employed', 'practically', 'senior', 'lab', 'right']",,,,
w1ybgk,[R] Unicorn: 🦄 : Towards Grand Unification of Object Tracking(Video Demo),,1658147871.0,998.0,37.0,/r/MachineLearning/comments/w1ybgk/r_unicorn_towards_grand_unification_of_object/,https://v.redd.it/vdwwncw9nbc91,iFighting,MachineLearning,0.98,False,False,False,False,0.0,1745833864.356532,Tech & Programming,11.0,0.0,9.0,Monday,8.0,July,2022.0,False,0.4588,0.3,0.0,0.7,positive,r unicorn towards grand unification of object trackingvideo demo,,r unicorn towards grand unification of object trackingvideo demo ,"unicorn, towards, grand, unification, object",2022-07-18 12:37:51,r unicorn towards grand unification of object trackingvideo demo ,"['unicorn', 'towards', 'grand', 'unification', 'object', 'trackingvideo', 'demo']",,,,
zvbjot,Trippy Inkpunk Style animation using Stable Diffusion [P],,1672017287.0,1001.0,31.0,/r/MachineLearning/comments/zvbjot/trippy_inkpunk_style_animation_using_stable/,https://v.redd.it/nya12m82858a1,oridnary_artist,MachineLearning,0.93,False,False,False,False,0.0,1745833864.628978,Tech & Programming,8.0,0.0,8.0,Sunday,20.0,December,2022.0,True,0.296,0.268,0.0,0.732,positive,trippy inkpunk style animation using stable diffusion p,,trippy inkpunk style animation using stable diffusion p ,"trippy, inkpunk, style, animation, using",2022-12-26 01:14:47,trippy inkpunk style animation using stable diffusion p ,"['trippy', 'inkpunk', 'style', 'animation', 'using', 'stable', 'diffusion']",,,,
1cbhec7,Meta does everything OpenAI should be [D]," I'm surprised (or maybe not) to say this, but Meta (or Facebook) democratises AI/ML much more than OpenAI, which was originally founded and primarily funded for this purpose. OpenAI has largely become a commercial project for profit only. Although as far as Llama models go, they don't yet reach GPT4 capabilities for me, but I believe it's only a matter of time. What do you guys think about this?",1713909800.0,985.0,257.0,/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/,https://www.reddit.com/r/MachineLearning/comments/1cbhec7/meta_does_everything_openai_should_be_d/,ReputationMindless32,MachineLearning,0.96,True,False,False,False,0.0,1745833886.242102,Tech & Programming,7.0,69.0,76.0,Tuesday,18.0,April,2024.0,False,0.653,0.085,0.015,0.9,positive,meta does everything openai should be d,im surprised or maybe not to say this but meta or facebook democratises aiml much more than openai which was originally founded and primarily funded for this purpose openai has largely become a commercial project for profit only although as far as llama models go they dont yet reach gpt capabilities for me but i believe its only a matter of time what do you guys think about this,meta does everything openai should be d im surprised or maybe not to say this but meta or facebook democratises aiml much more than openai which was originally founded and primarily funded for this purpose openai has largely become a commercial project for profit only although as far as llama models go they dont yet reach gpt capabilities for me but i believe its only a matter of time what do you guys think about this,"openai, meta, everything, surprised, maybe",2024-04-23 22:03:20,meta does everything openai should be d im surprised or maybe not to say this but meta or facebook democratises aiml much more than openai which was originally founded and primarily funded for this purpose openai has largely become a commercial project for profit only although as far as llama models go they dont yet reach gpt capabilities for me but i believe its only a matter of time what do you guys think about this,"['meta', 'everything', 'openai', 'surprised', 'maybe', 'say', 'meta', 'facebook', 'democratises', 'aiml', 'much', 'openai', 'originally', 'founded', 'primarily', 'funded', 'purpose', 'openai', 'largely', 'become', 'commercial', 'project', 'profit', 'although', 'far', 'llama', 'model', 'dont', 'yet', 'reach', 'gpt', 'capability', 'believe', 'matter', 'time', 'guy', 'think']",,,,
xhahv5,[P] Stable Diffusion web ui + IMG2IMG + After Effects + artist workflow,,1663487364.0,979.0,24.0,/r/MachineLearning/comments/xhahv5/p_stable_diffusion_web_ui_img2img_after_effects/,https://v.redd.it/dswwh3dynko91,Illustrious_Row_9971,MachineLearning,0.98,False,False,False,False,0.0,1745833887.413392,Tech & Programming,13.0,0.0,10.0,Sunday,3.0,September,2022.0,True,0.296,0.216,0.0,0.784,positive,p stable diffusion web ui imgimg after effects artist workflow,,p stable diffusion web ui imgimg after effects artist workflow ,"stable, diffusion, web, imgimg, effect",2022-09-18 07:49:24,p stable diffusion web ui imgimg after effects artist workflow ,"['stable', 'diffusion', 'web', 'imgimg', 'effect', 'artist', 'workflow']",,,,
mocpgj,[P] Using PyTorch + NumPy? A bug that plagues thousands of open-source ML projects.,"Using NumPy’s random number generator with multi-process data loading in PyTorch causes identical augmentations unless you specifically set seeds using the worker\_init\_fn option in the DataLoader. I didn’t and this bug silently regressed my model’s accuracy.

How many others has this bug done damage to? Curious, I downloaded over a hundred thousand repositories from GitHub that import PyTorch, and analysed their source code. I kept projects that define a custom dataset, use NumPy’s random number generator with multi-process data loading, and are more-or-less straightforward to analyse using abstract syntax trees. Out of these, over 95% of the repositories are plagued by this problem. It’s inside PyTorch's official tutorial, OpenAI’s code, and NVIDIA’s projects. Even Karpathy admitted falling prey to it.

For example, the following image shows the duplicated random crop augmentations you get when you blindly follow the official PyTorch tutorial on custom datasets:

https://preview.redd.it/pccy5wskpes61.png?width=1652&format=png&auto=webp&s=f292d0282ad954cbac2c693a9656d62fa0dd9682

You can read more details [here](https://tanelp.github.io/posts/a-bug-that-plagues-thousands-of-open-source-ml-projects/).",1618087578.0,974.0,159.0,/r/MachineLearning/comments/mocpgj/p_using_pytorch_numpy_a_bug_that_plagues/,https://www.reddit.com/r/MachineLearning/comments/mocpgj/p_using_pytorch_numpy_a_bug_that_plagues/,tanelai,MachineLearning,0.98,True,False,False,False,0.0,1745833887.70015,Tech & Programming,14.0,151.0,162.0,Saturday,16.0,April,2021.0,True,-0.561,0.039,0.049,0.912,negative,p using pytorch numpy a bug that plagues thousands of opensource ml projects,using numpys random number generator with multiprocess data loading in pytorch causes identical augmentations unless you specifically set seeds using the worker_init_fn option in the dataloader i didnt and this bug silently regressed my models accuracy how many others has this bug done damage to curious i downloaded over a hundred thousand repositories from github that import pytorch and analysed their source code i kept projects that define a custom dataset use numpys random number generator with multiprocess data loading and are moreorless straightforward to analyse using abstract syntax trees out of these over of the repositories are plagued by this problem its inside pytorchs official tutorial openais code and nvidias projects even karpathy admitted falling prey to it for example the following image shows the duplicated random crop augmentations you get when you blindly follow the official pytorch tutorial on custom datasets you can read more details here,p using pytorch numpy a bug that plagues thousands of opensource ml projects using numpys random number generator with multiprocess data loading in pytorch causes identical augmentations unless you specifically set seeds using the worker_init_fn option in the dataloader i didnt and this bug silently regressed my models accuracy how many others has this bug done damage to curious i downloaded over a hundred thousand repositories from github that import pytorch and analysed their source code i kept projects that define a custom dataset use numpys random number generator with multiprocess data loading and are moreorless straightforward to analyse using abstract syntax trees out of these over of the repositories are plagued by this problem its inside pytorchs official tutorial openais code and nvidias projects even karpathy admitted falling prey to it for example the following image shows the duplicated random crop augmentations you get when you blindly follow the official pytorch tutorial on custom datasets you can read more details here,"using, pytorch, bug, project, random",2021-04-10 20:46:18,p using pytorch numpy a bug that plagues thousands of opensource ml projects using numpys random number generator with multiprocess data loading in pytorch causes identical augmentations unless you specifically set seeds using the worker_init_fn option in the dataloader i didnt and this bug silently regressed my models accuracy how many others has this bug done damage to curious i downloaded over a hundred thousand repositories from github that import pytorch and analysed their source code i kept projects that define a custom dataset use numpys random number generator with multiprocess data loading and are moreorless straightforward to analyse using abstract syntax trees out of these over of the repositories are plagued by this problem its inside pytorchs official tutorial openais code and nvidias projects even karpathy admitted falling prey to it for example the following image shows the duplicated random crop augmentations you get when you blindly follow the official pytorch tutorial on custom datasets you can read more details here,"['using', 'pytorch', 'numpy', 'bug', 'plague', 'thousand', 'opensource', 'project', 'using', 'numpys', 'random', 'number', 'generator', 'multiprocess', 'data', 'loading', 'pytorch', 'cause', 'identical', 'augmentation', 'unless', 'specifically', 'set', 'seed', 'using', 'worker_init_fn', 'option', 'dataloader', 'didnt', 'bug', 'silently', 'regressed', 'model', 'accuracy', 'many', 'others', 'bug', 'done', 'damage', 'curious', 'downloaded', 'hundred', 'thousand', 'repository', 'github', 'import', 'pytorch', 'analysed', 'source', 'code', 'kept', 'project', 'define', 'custom', 'dataset', 'use', 'numpys', 'random', 'number', 'generator', 'multiprocess', 'data', 'loading', 'moreorless', 'straightforward', 'analyse', 'using', 'abstract', 'syntax', 'tree', 'repository', 'plagued', 'problem', 'inside', 'pytorchs', 'official', 'tutorial', 'openais', 'code', 'nvidias', 'project', 'even', 'karpathy', 'admitted', 'falling', 'prey', 'example', 'following', 'image', 'show', 'duplicated', 'random', 'crop', 'augmentation', 'get', 'blindly', 'follow', 'official', 'pytorch', 'tutorial', 'custom', 'datasets', 'read', 'detail']",,,,
wcalkv,[R] Highly Accurate Dichotomous Image Segmentation + Gradio Web Demo,,1659224084.0,970.0,23.0,/r/MachineLearning/comments/wcalkv/r_highly_accurate_dichotomous_image_segmentation/,https://v.redd.it/6azot5l6jse91,Illustrious_Row_9971,MachineLearning,0.99,False,False,False,False,0.0,1745833888.570732,Tech & Programming,10.0,0.0,9.0,Saturday,19.0,July,2022.0,True,0.0,0.0,0.0,1.0,neutral,r highly accurate dichotomous image segmentation gradio web demo,,r highly accurate dichotomous image segmentation gradio web demo ,"highly, accurate, dichotomous, image, segmentation",2022-07-30 23:34:44,r highly accurate dichotomous image segmentation gradio web demo ,"['highly', 'accurate', 'dichotomous', 'image', 'segmentation', 'gradio', 'web', 'demo']",,,,
ssfijc,"[P] Database for AI: Visualize, version-control & explore image, video and audio datasets",,1644858237.0,966.0,52.0,/r/MachineLearning/comments/ssfijc/p_database_for_ai_visualize_versioncontrol/,https://v.redd.it/sn45ektcyth81,davidbun,MachineLearning,0.95,False,False,False,False,0.0,1745833888.773936,Tech & Programming,13.0,0.0,12.0,Monday,12.0,February,2022.0,False,0.0,0.0,0.0,1.0,neutral,p database for ai visualize versioncontrol explore image video and audio datasets,,p database for ai visualize versioncontrol explore image video and audio datasets ,"database, visualize, versioncontrol, explore, image",2022-02-14 17:03:57,p database for ai visualize versioncontrol explore image video and audio datasets ,"['database', 'visualize', 'versioncontrol', 'explore', 'image', 'video', 'audio', 'datasets']",,,,
ab4207,"UC Berkeley and Berkeley AI Research published all materials of CS 188: Introduction to Artificial Intelligence, Fall 2018",,1546233422.0,958.0,56.0,/r/MachineLearning/comments/ab4207/uc_berkeley_and_berkeley_ai_research_published/,https://inst.eecs.berkeley.edu/~cs188/fa18/,dronecub,MachineLearning,0.99,False,False,False,False,0.0,1745833889.136225,Tech & Programming,18.0,0.0,16.0,Monday,0.0,December,2018.0,False,0.4767,0.171,0.0,0.829,positive,uc berkeley and berkeley ai research published all materials of cs introduction to artificial intelligence fall,,uc berkeley and berkeley ai research published all materials of cs introduction to artificial intelligence fall ,"berkeley, research, published, material, introduction",2018-12-31 05:17:02,uc berkeley and berkeley ai research published all materials of cs introduction to artificial intelligence fall ,"['berkeley', 'berkeley', 'research', 'published', 'material', 'introduction', 'artificial', 'intelligence', 'fall']",,,,
ngn6at,"[N] Pornhub uses machine learning to re-colour 20 historic erotic films (1890 to 1940, even some by Thomas Eddison)","As a data scientist, got to say it was pretty interesting to read about the use of machine learning to ""train"" an AI with 100,000 nudey videos and images to help it know how to colour films that were never in colour in the first place.

Safe for work (non-Porhub) link -> https://itwire.com/business-it-news/data/pornhub-uses-ai-to-restore-century-old-erotic-films-to-titillating-technicolour.html",1621474436.0,954.0,108.0,/r/MachineLearning/comments/ngn6at/n_pornhub_uses_machine_learning_to_recolour_20/,https://www.reddit.com/r/MachineLearning/comments/ngn6at/n_pornhub_uses_machine_learning_to_recolour_20/,mgdmw,MachineLearning,0.94,True,False,False,False,0.0,1745833889.59518,Tech & Programming,19.0,53.0,66.0,Wednesday,21.0,May,2021.0,False,0.8885,0.161,0.0,0.839,positive,n pornhub uses machine learning to recolour historic erotic films to even some by thomas eddison,as a data scientist got to say it was pretty interesting to read about the use of machine learning to train an ai with nudey videos and images to help it know how to colour films that were never in colour in the first place safe for work nonporhub link,n pornhub uses machine learning to recolour historic erotic films to even some by thomas eddison as a data scientist got to say it was pretty interesting to read about the use of machine learning to train an ai with nudey videos and images to help it know how to colour films that were never in colour in the first place safe for work nonporhub link,"machine, learning, film, colour, pornhub",2021-05-20 01:33:56,n pornhub uses machine learning to recolour historic erotic films to even some by thomas eddison as a data scientist got to say it was pretty interesting to read about the use of machine learning to train an ai with nudey videos and images to help it know how to colour films that were never in colour in the first place safe for work nonporhub link,"['pornhub', 'us', 'machine', 'learning', 'recolour', 'historic', 'erotic', 'film', 'even', 'thomas', 'eddison', 'data', 'scientist', 'got', 'say', 'pretty', 'interesting', 'read', 'use', 'machine', 'learning', 'train', 'nudey', 'video', 'image', 'help', 'know', 'colour', 'film', 'never', 'colour', 'first', 'place', 'safe', 'work', 'nonporhub', 'link']",,,,
lcuq4b,[D] Anyone else find themselves rolling their eyes at a lot of mainstream articles that talk about “AI”?,"I’m not talking about papers, or articles from more scientific publications, but mainstream stuff that gets published on the BBC, CNN, etc. Stuff that makes it to Reddit front pages. 

There’s so much misinformation out there, it’s honestly nauseating. AI is doom and gloom nonsense ranging from racist AIs to the extinction of human kind. 

I just wish people would understand that we are so incomprehensibly far away from a true, thinking machine. The stuff we have now that is called “ai” are just fancy classification/regression models that rely on huge amounts of data to train. The applications are awesome, no doubt, but ultimately AI in its current state is just another tool in the belt of a researcher/engineer. AI itself is neither good, or bad, in the same way that a chainsaw is neither good or bad. It’s just another tool.  

Tldr: I rant about the misinformation regarding AI in its current state.",1612485007.0,955.0,231.0,/r/MachineLearning/comments/lcuq4b/d_anyone_else_find_themselves_rolling_their_eyes/,https://www.reddit.com/r/MachineLearning/comments/lcuq4b/d_anyone_else_find_themselves_rolling_their_eyes/,,MachineLearning,0.95,True,False,False,False,0.0,1745833890.224156,Tech & Programming,18.0,154.0,172.0,Thursday,19.0,February,2021.0,False,-0.7652,0.147,0.182,0.671,negative,d anyone else find themselves rolling their eyes at a lot of mainstream articles that talk about ai,im not talking about papers or articles from more scientific publications but mainstream stuff that gets published on the bbc cnn etc stuff that makes it to reddit front pages theres so much misinformation out there its honestly nauseating ai is doom and gloom nonsense ranging from racist ais to the extinction of human kind i just wish people would understand that we are so incomprehensibly far away from a true thinking machine the stuff we have now that is called ai are just fancy classificationregression models that rely on huge amounts of data to train the applications are awesome no doubt but ultimately ai in its current state is just another tool in the belt of a researcherengineer ai itself is neither good or bad in the same way that a chainsaw is neither good or bad its just another tool tldr i rant about the misinformation regarding ai in its current state,d anyone else find themselves rolling their eyes at a lot of mainstream articles that talk about ai im not talking about papers or articles from more scientific publications but mainstream stuff that gets published on the bbc cnn etc stuff that makes it to reddit front pages theres so much misinformation out there its honestly nauseating ai is doom and gloom nonsense ranging from racist ais to the extinction of human kind i just wish people would understand that we are so incomprehensibly far away from a true thinking machine the stuff we have now that is called ai are just fancy classificationregression models that rely on huge amounts of data to train the applications are awesome no doubt but ultimately ai in its current state is just another tool in the belt of a researcherengineer ai itself is neither good or bad in the same way that a chainsaw is neither good or bad its just another tool tldr i rant about the misinformation regarding ai in its current state,"stuff, mainstream, article, misinformation, current",2021-02-05 00:30:07,d anyone else find themselves rolling their eyes at a lot of mainstream articles that talk about ai im not talking about papers or articles from more scientific publications but mainstream stuff that gets published on the bbc cnn etc stuff that makes it to reddit front pages theres so much misinformation out there its honestly nauseating ai is doom and gloom nonsense ranging from racist ais to the extinction of human kind i just wish people would understand that we are so incomprehensibly far away from a true thinking machine the stuff we have now that is called ai are just fancy classificationregression models that rely on huge amounts of data to train the applications are awesome no doubt but ultimately ai in its current state is just another tool in the belt of a researcherengineer ai itself is neither good or bad in the same way that a chainsaw is neither good or bad its just another tool tldr i rant about the misinformation regarding ai in its current state,"['anyone', 'else', 'find', 'rolling', 'eye', 'lot', 'mainstream', 'article', 'talk', 'talking', 'paper', 'article', 'scientific', 'publication', 'mainstream', 'stuff', 'get', 'published', 'bbc', 'cnn', 'etc', 'stuff', 'make', 'reddit', 'front', 'page', 'there', 'much', 'misinformation', 'honestly', 'nauseating', 'doom', 'gloom', 'nonsense', 'ranging', 'racist', 'ai', 'extinction', 'human', 'kind', 'wish', 'people', 'would', 'understand', 'incomprehensibly', 'far', 'away', 'true', 'thinking', 'machine', 'stuff', 'called', 'fancy', 'classificationregression', 'model', 'rely', 'huge', 'amount', 'data', 'train', 'application', 'awesome', 'doubt', 'ultimately', 'current', 'state', 'another', 'tool', 'belt', 'researcherengineer', 'neither', 'good', 'bad', 'way', 'chainsaw', 'neither', 'good', 'bad', 'another', 'tool', 'tldr', 'rant', 'misinformation', 'regarding', 'current', 'state']",,,,
1ib2vtx,[D] Why did DeepSeek open-source their work?,"If their training is 45x more efficient, they could have dominated the LLM market. Why do you think they chose to open-source their work? How is this a net gain for their company? Now the big labs in the US can say: ""we'll take their *excellent* ideas and we'll just combine them with our *secret* ideas, and we'll still be ahead""

---

*Edit:* `DeepSeek-R1` is now ranked #1 in the LLM Arena (with `StyleCtrl`). They share this rank with 3 other models: `Gemini-Exp-1206`, `4o-latest` and `o1-2024-12-17`.",1737964108.0,952.0,331.0,/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/,https://www.reddit.com/r/MachineLearning/comments/1ib2vtx/d_why_did_deepseek_opensource_their_work/,we_are_mammals,MachineLearning,0.94,True,False,False,False,0.0,1745833891.389951,Tech & Programming,7.0,86.0,90.0,Monday,2.0,January,2025.0,False,0.9493,0.191,0.0,0.809,positive,d why did deepseek opensource their work,if their training is x more efficient they could have dominated the llm market why do you think they chose to opensource their work how is this a net gain for their company now the big labs in the us can say well take their excellent ideas and well just combine them with our secret ideas and well still be ahead edit deepseekr is now ranked in the llm arena with stylectrl they share this rank with other models geminiexp olatest and o,d why did deepseek opensource their work if their training is x more efficient they could have dominated the llm market why do you think they chose to opensource their work how is this a net gain for their company now the big labs in the us can say well take their excellent ideas and well just combine them with our secret ideas and well still be ahead edit deepseekr is now ranked in the llm arena with stylectrl they share this rank with other models geminiexp olatest and o,"well, opensource, work, llm, idea",2025-01-27 07:48:28,d why did deepseek opensource their work if their training is x more efficient they could have dominated the llm market why do you think they chose to opensource their work how is this a net gain for their company now the big labs in the us can say well take their excellent ideas and well just combine them with our secret ideas and well still be ahead edit deepseekr is now ranked in the llm arena with stylectrl they share this rank with other models geminiexp olatest and o,"['deepseek', 'opensource', 'work', 'training', 'efficient', 'could', 'dominated', 'llm', 'market', 'think', 'chose', 'opensource', 'work', 'net', 'gain', 'company', 'big', 'lab', 'say', 'well', 'take', 'excellent', 'idea', 'well', 'combine', 'secret', 'idea', 'well', 'still', 'ahead', 'edit', 'deepseekr', 'ranked', 'llm', 'arena', 'stylectrl', 'share', 'rank', 'model', 'geminiexp', 'olatest']",,,,
hzdiru,"[D] If you say in a paper you provide code, it should be required to be available at time of publication","TL;DR: The only thing worse than not providing code is saying you did and not following through.

I'm frustrated, so this might be a little bit of a rant but here goes: I cannot believe that it is acceptable in highly ranked conferences to straight-up lie about the availability of code. Firstly, obviously it would be great if everyone released their code all the time because repeatability in ML is pretty dismal at times. But if you're not going to publish your code, then don't say you are. Especially when you're leaving details out of the paper and referring the reader to said ""published"" code.

Take for example [this paper](https://arxiv.org/abs/2004.04725), coming out of NVIDIA's research lab and published in CVPR2020. It is fairly detail-sparse, and nigh on impossible to reproduce in its current state as a result. It refers the reader to [this repository](https://github.com/NVlabs/wetectron) which has been a single readme since its creation. It is simply unacceptable for this when the paper directly says the code has been released.

As top conferences are starting to encourage the release of code, I think there needs to be another component: the code must actually be available. Papers that link to empty or missing repositories within some kind of reasonable timeframe of publication should be withdrawn. It should be unacceptable to direct readers to code that doesn't exist for details, and similarly for deleting repositories shortly after publication. I get that this is logistically a little tough, because it has to be done after publication, but still we can't let this be considered okay

EDIT: To repeat the TL;DR again and highlight the key point - There won't always be code, that's frustrating but tolerable. There is no excuse for claiming to have code available, but not actually making it available. Code should be required to be up at time of publication, and kept up for some duration, if a paper wishes to claim to have released their code.",1595938168.0,956.0,134.0,/r/MachineLearning/comments/hzdiru/d_if_you_say_in_a_paper_you_provide_code_it/,https://www.reddit.com/r/MachineLearning/comments/hzdiru/d_if_you_say_in_a_paper_you_provide_code_it/,chatterbox272,MachineLearning,0.97,True,False,False,False,0.0,1745833892.781881,Tech & Programming,21.0,326.0,346.0,Tuesday,8.0,July,2020.0,False,-0.0718,0.082,0.086,0.832,negative,d if you say in a paper you provide code it should be required to be available at time of publication,tldr the only thing worse than not providing code is saying you did and not following through im frustrated so this might be a little bit of a rant but here goes i cannot believe that it is acceptable in highly ranked conferences to straightup lie about the availability of code firstly obviously it would be great if everyone released their code all the time because repeatability in ml is pretty dismal at times but if youre not going to publish your code then dont say you are especially when youre leaving details out of the paper and referring the reader to said published code take for example this paper coming out of nvidias research lab and published in cvpr it is fairly detailsparse and nigh on impossible to reproduce in its current state as a result it refers the reader to this repository which has been a single readme since its creation it is simply unacceptable for this when the paper directly says the code has been released as top conferences are starting to encourage the release of code i think there needs to be another component the code must actually be available papers that link to empty or missing repositories within some kind of reasonable timeframe of publication should be withdrawn it should be unacceptable to direct readers to code that doesnt exist for details and similarly for deleting repositories shortly after publication i get that this is logistically a little tough because it has to be done after publication but still we cant let this be considered okay edit to repeat the tldr again and highlight the key point there wont always be code thats frustrating but tolerable there is no excuse for claiming to have code available but not actually making it available code should be required to be up at time of publication and kept up for some duration if a paper wishes to claim to have released their code,d if you say in a paper you provide code it should be required to be available at time of publication tldr the only thing worse than not providing code is saying you did and not following through im frustrated so this might be a little bit of a rant but here goes i cannot believe that it is acceptable in highly ranked conferences to straightup lie about the availability of code firstly obviously it would be great if everyone released their code all the time because repeatability in ml is pretty dismal at times but if youre not going to publish your code then dont say you are especially when youre leaving details out of the paper and referring the reader to said published code take for example this paper coming out of nvidias research lab and published in cvpr it is fairly detailsparse and nigh on impossible to reproduce in its current state as a result it refers the reader to this repository which has been a single readme since its creation it is simply unacceptable for this when the paper directly says the code has been released as top conferences are starting to encourage the release of code i think there needs to be another component the code must actually be available papers that link to empty or missing repositories within some kind of reasonable timeframe of publication should be withdrawn it should be unacceptable to direct readers to code that doesnt exist for details and similarly for deleting repositories shortly after publication i get that this is logistically a little tough because it has to be done after publication but still we cant let this be considered okay edit to repeat the tldr again and highlight the key point there wont always be code thats frustrating but tolerable there is no excuse for claiming to have code available but not actually making it available code should be required to be up at time of publication and kept up for some duration if a paper wishes to claim to have released their code,"code, paper, publication, available, time",2020-07-28 12:09:28,d if you say in a paper you provide code it should be required to be available at time of publication tldr the only thing worse than not providing code is saying you did and not following through im frustrated so this might be a little bit of a rant but here goes i cannot believe that it is acceptable in highly ranked conferences to straightup lie about the availability of code firstly obviously it would be great if everyone released their code all the time because repeatability in ml is pretty dismal at times but if youre not going to publish your code then dont say you are especially when youre leaving details out of the paper and referring the reader to said published code take for example this paper coming out of nvidias research lab and published in cvpr it is fairly detailsparse and nigh on impossible to reproduce in its current state as a result it refers the reader to this repository which has been a single readme since its creation it is simply unacceptable for this when the paper directly says the code has been released as top conferences are starting to encourage the release of code i think there needs to be another component the code must actually be available papers that link to empty or missing repositories within some kind of reasonable timeframe of publication should be withdrawn it should be unacceptable to direct readers to code that doesnt exist for details and similarly for deleting repositories shortly after publication i get that this is logistically a little tough because it has to be done after publication but still we cant let this be considered okay edit to repeat the tldr again and highlight the key point there wont always be code thats frustrating but tolerable there is no excuse for claiming to have code available but not actually making it available code should be required to be up at time of publication and kept up for some duration if a paper wishes to claim to have released their code,"['say', 'paper', 'provide', 'code', 'required', 'available', 'time', 'publication', 'tldr', 'thing', 'worse', 'providing', 'code', 'saying', 'following', 'frustrated', 'might', 'little', 'bit', 'rant', 'go', 'believe', 'acceptable', 'highly', 'ranked', 'conference', 'straightup', 'lie', 'availability', 'code', 'firstly', 'obviously', 'would', 'great', 'everyone', 'released', 'code', 'time', 'repeatability', 'pretty', 'dismal', 'time', 'youre', 'going', 'publish', 'code', 'dont', 'say', 'especially', 'youre', 'leaving', 'detail', 'paper', 'referring', 'reader', 'said', 'published', 'code', 'take', 'example', 'paper', 'coming', 'nvidias', 'research', 'lab', 'published', 'cvpr', 'fairly', 'detailsparse', 'nigh', 'impossible', 'reproduce', 'current', 'state', 'result', 'refers', 'reader', 'repository', 'single', 'readme', 'since', 'creation', 'simply', 'unacceptable', 'paper', 'directly', 'say', 'code', 'released', 'top', 'conference', 'starting', 'encourage', 'release', 'code', 'think', 'need', 'another', 'component', 'code', 'must', 'actually', 'available', 'paper', 'link', 'empty', 'missing', 'repository', 'within', 'kind', 'reasonable', 'timeframe', 'publication', 'withdrawn', 'unacceptable', 'direct', 'reader', 'code', 'doesnt', 'exist', 'detail', 'similarly', 'deleting', 'repository', 'shortly', 'publication', 'get', 'logistically', 'little', 'tough', 'done', 'publication', 'still', 'cant', 'let', 'considered', 'okay', 'edit', 'repeat', 'tldr', 'highlight', 'key', 'point', 'wont', 'always', 'code', 'thats', 'frustrating', 'tolerable', 'excuse', 'claiming', 'code', 'available', 'actually', 'making', 'available', 'code', 'required', 'time', 'publication', 'kept', 'duration', 'paper', 'wish', 'claim', 'released', 'code']",,,,
y89xqw,[D] Call for questions for Andrej Karpathy from Lex Fridman,"Hi, my name is Lex Fridman. I host a [podcast](https://www.youtube.com/c/lexfridman). I'm talking to Andrej Karpathy on it soon. To me, Andrej is one of the best researchers and educators in the history of the machine learning field. If you have questions/topic suggestions you'd like us to discuss, including technical and philosophical ones, please let me know.

**EDIT**: Here's [the resulting published episode](https://www.youtube.com/watch?v=cdiD-9MMpb0). Thank you for the questions!",1666203260.0,946.0,346.0,/r/MachineLearning/comments/y89xqw/d_call_for_questions_for_andrej_karpathy_from_lex/,https://www.reddit.com/r/MachineLearning/comments/y89xqw/d_call_for_questions_for_andrej_karpathy_from_lex/,lexfridman,MachineLearning,0.94,True,False,False,False,0.0,1745833893.44651,Tech & Programming,10.0,67.0,77.0,Wednesday,14.0,October,2022.0,False,0.8885,0.141,0.0,0.859,positive,d call for questions for andrej karpathy from lex fridman,hi my name is lex fridman i host a podcast im talking to andrej karpathy on it soon to me andrej is one of the best researchers and educators in the history of the machine learning field if you have questionstopic suggestions youd like us to discuss including technical and philosophical ones please let me know edit heres the resulting published episode thank you for the questions,d call for questions for andrej karpathy from lex fridman hi my name is lex fridman i host a podcast im talking to andrej karpathy on it soon to me andrej is one of the best researchers and educators in the history of the machine learning field if you have questionstopic suggestions youd like us to discuss including technical and philosophical ones please let me know edit heres the resulting published episode thank you for the questions,"andrej, question, karpathy, lex, fridman",2022-10-19 18:14:20,d call for questions for andrej karpathy from lex fridman hi my name is lex fridman i host a podcast im talking to andrej karpathy on it soon to me andrej is one of the best researchers and educators in the history of the machine learning field if you have questionstopic suggestions youd like us to discuss including technical and philosophical ones please let me know edit heres the resulting published episode thank you for the questions,"['call', 'question', 'andrej', 'karpathy', 'lex', 'fridman', 'name', 'lex', 'fridman', 'host', 'podcast', 'talking', 'andrej', 'karpathy', 'soon', 'andrej', 'one', 'best', 'researcher', 'educator', 'history', 'machine', 'learning', 'field', 'questionstopic', 'suggestion', 'youd', 'like', 'discus', 'including', 'technical', 'philosophical', 'one', 'please', 'let', 'know', 'edit', 'here', 'resulting', 'published', 'episode', 'thank', 'question']",,,,
xnbv8e,[P] Enhancing local detail and cohesion by mosaicing with stable diffusion Gradio Web UI,,1664075225.0,951.0,29.0,/r/MachineLearning/comments/xnbv8e/p_enhancing_local_detail_and_cohesion_by/,https://v.redd.it/d7xx4fpc8xp91,Illustrious_Row_9971,MachineLearning,0.99,False,False,False,False,0.0,1745833895.02518,Tech & Programming,14.0,0.0,14.0,Saturday,23.0,September,2022.0,True,0.296,0.155,0.0,0.845,positive,p enhancing local detail and cohesion by mosaicing with stable diffusion gradio web ui,,p enhancing local detail and cohesion by mosaicing with stable diffusion gradio web ui ,"enhancing, local, detail, cohesion, mosaicing",2022-09-25 03:07:05,p enhancing local detail and cohesion by mosaicing with stable diffusion gradio web ui ,"['enhancing', 'local', 'detail', 'cohesion', 'mosaicing', 'stable', 'diffusion', 'gradio', 'web']",,,,
w5w0jq,"[P] We have developed CVEDIA-RT as a free tool to help companies and hobbyist interactively play with, and deploy their AI models on the edge or cloud. We're in early beta and are looking for feedback.",,1658554413.0,933.0,24.0,/r/MachineLearning/comments/w5w0jq/p_we_have_developed_cvediart_as_a_free_tool_to/,https://v.redd.it/ilqobrg689d91,ajcvedia,MachineLearning,0.98,False,False,False,False,0.0,1745833895.383007,Tech & Programming,36.0,0.0,36.0,Saturday,1.0,July,2022.0,True,0.8126,0.213,0.0,0.787,positive,p we have developed cvediart as a free tool to help companies and hobbyist interactively play with and deploy their ai models on the edge or cloud were in early beta and are looking for feedback,,p we have developed cvediart as a free tool to help companies and hobbyist interactively play with and deploy their ai models on the edge or cloud were in early beta and are looking for feedback ,"developed, cvediart, free, tool, help",2022-07-23 05:33:33,p we have developed cvediart as a free tool to help companies and hobbyist interactively play with and deploy their ai models on the edge or cloud were in early beta and are looking for feedback ,"['developed', 'cvediart', 'free', 'tool', 'help', 'company', 'hobbyist', 'interactively', 'play', 'deploy', 'model', 'edge', 'cloud', 'early', 'beta', 'looking', 'feedback']",,,,
hpajb2,[R] One Policy to Control Them All: Shared Modular Policies for Agent-Agnostic Control (Link in Comments),,1594476388.0,931.0,24.0,/r/MachineLearning/comments/hpajb2/r_one_policy_to_control_them_all_shared_modular/,https://v.redd.it/g2002fw8j8a51,hardmaru,MachineLearning,0.98,False,False,False,False,0.0,1745833895.624107,Tech & Programming,16.0,0.0,16.0,Saturday,10.0,July,2020.0,True,0.34,0.146,0.0,0.854,positive,r one policy to control them all shared modular policies for agentagnostic control link in comments,,r one policy to control them all shared modular policies for agentagnostic control link in comments ,"policy, control, one, shared, modular",2020-07-11 14:06:28,r one policy to control them all shared modular policies for agentagnostic control link in comments ,"['one', 'policy', 'control', 'shared', 'modular', 'policy', 'agentagnostic', 'control', 'link', 'comment']",,,,
8qh7e5,[P] Simple Tensorflow implementation of StarGAN (CVPR 2018 Oral),,1528790599.0,926.0,57.0,/r/MachineLearning/comments/8qh7e5/p_simple_tensorflow_implementation_of_stargan/,https://i.redd.it/ctjls7zr1j311.png,taki0112,MachineLearning,0.97,False,False,False,False,0.0,1745833895.951758,Tech & Programming,9.0,0.0,8.0,Tuesday,4.0,June,2018.0,False,0.0,0.0,0.0,1.0,neutral,p simple tensorflow implementation of stargan cvpr oral,,p simple tensorflow implementation of stargan cvpr oral ,"simple, tensorflow, implementation, stargan, cvpr",2018-06-12 08:03:19,p simple tensorflow implementation of stargan cvpr oral ,"['simple', 'tensorflow', 'implementation', 'stargan', 'cvpr', 'oral']",,,,
di2fez,[N] Netflix and European Space Agency no longer working with Siraj Raval,"*According to article in [The Register](https://www.theregister.co.uk/2019/10/14/ravel_ai_youtube/)*:

A Netflix spokesperson confirmed to The Register it wasn’t working with Raval, and the ESA has cancelled the whole workshop altogether.

“The situation is as it is. The workshop is cancelled, and that’s all,” Guillaume Belanger, an astrophysicist and the INTEGRAL Science Operations Coordinator at the ESA, told The Register on Monday.

Raval isn’t about to quit his work any time soon, however. He promised students who graduated from his course that they would be referred to recruiters at Nvidia, Intel, Google and Amazon for engineering positions, or matched with a startup co-founder or a consulting client.

In an unlisted YouTube video recorded live for his students discussing week eight of his course, and seen by El Reg, he read out a question posed to him: “Will your referrals hold any value now?”

“Um, yeah they’re going to hold value. I don’t see why they wouldn’t. I mean, yes, some people on Twitter were angry but that has nothing to do with… I mean… I’ve also had tons of support, you know. I’ve had tons of support from people, who, uh, you know, support me, who work at these companies.

*He continues to justify his actions:*

“Public figures called me in private to remind me that this happens. You know, people make mistakes. You just have to keep going. They’re basically just telling me to not to stop. Of course, you make mistakes but you just keep going,” he claimed.

*When The Register asked Raval for comment, he responded:*

**I've hardly taken any time off to relax since I first started my YouTube channel almost four years ago. And despite the enormous amount of work it takes to release two high quality videos a week for my audience, I progressively started to take on multiple other projects simultaneously by myself – a book, a docu-series, podcasts, YouTube videos, the course, the school of AI. Basically, these past few weeks, I've been experiencing a burnout unlike anything I've felt before. As a result, all of my output has been subpar.**

**I made the [neural qubits] video and paper in one week. I remember wishing I had three to six months to really dive into quantum machine-learning and make something awesome, but telling myself I couldn't take that long as it would hinder my other projects. I plagiarized large chunks of the paper to meet my self-imposed one-week deadline. The associated video with animations took a lot more work to make. I didn't expect the paper to be cited as serious research, I considered it an additional reading resource for people who enjoyed the associated video to learn more about quantum machine learning. If I had a second chance, I'd definitely take way more time to write the paper, and in my own words.**

**I've given refunds to every student who's asked so far, and the majority of students are still enrolled in the course. There are many happy students, they're just not as vocal on social media. We're on week 8 of 10 of my course, fully committed to student success.**

“And, no, I haven't plagiarized research for any other paper,” he added.

https://www.theregister.co.uk/2019/10/14/ravel_ai_youtube/",1571112550.0,919.0,251.0,/r/MachineLearning/comments/di2fez/n_netflix_and_european_space_agency_no_longer/,https://www.reddit.com/r/MachineLearning/comments/di2fez/n_netflix_and_european_space_agency_no_longer/,inarrears,MachineLearning,0.97,True,False,False,False,0.0,1745833896.72595,Tech & Programming,12.0,529.0,537.0,Tuesday,0.0,October,2019.0,False,0.9909,0.101,0.034,0.865,positive,n netflix and european space agency no longer working with siraj raval,according to article in the register a netflix spokesperson confirmed to the register it wasnt working with raval and the esa has cancelled the whole workshop altogether the situation is as it is the workshop is cancelled and thats all guillaume belanger an astrophysicist and the integral science operations coordinator at the esa told the register on monday raval isnt about to quit his work any time soon however he promised students who graduated from his course that they would be referred to recruiters at nvidia intel google and amazon for engineering positions or matched with a startup cofounder or a consulting client in an unlisted youtube video recorded live for his students discussing week eight of his course and seen by el reg he read out a question posed to him will your referrals hold any value now um yeah theyre going to hold value i dont see why they wouldnt i mean yes some people on twitter were angry but that has nothing to do with i mean ive also had tons of support you know ive had tons of support from people who uh you know support me who work at these companies he continues to justify his actions public figures called me in private to remind me that this happens you know people make mistakes you just have to keep going theyre basically just telling me to not to stop of course you make mistakes but you just keep going he claimed when the register asked raval for comment he responded ive hardly taken any time off to relax since i first started my youtube channel almost four years ago and despite the enormous amount of work it takes to release two high quality videos a week for my audience i progressively started to take on multiple other projects simultaneously by myself a book a docuseries podcasts youtube videos the course the school of ai basically these past few weeks ive been experiencing a burnout unlike anything ive felt before as a result all of my output has been subpar i made the neural qubits video and paper in one week i remember wishing i had three to six months to really dive into quantum machinelearning and make something awesome but telling myself i couldnt take that long as it would hinder my other projects i plagiarized large chunks of the paper to meet my selfimposed oneweek deadline the associated video with animations took a lot more work to make i didnt expect the paper to be cited as serious research i considered it an additional reading resource for people who enjoyed the associated video to learn more about quantum machine learning if i had a second chance id definitely take way more time to write the paper and in my own words ive given refunds to every student whos asked so far and the majority of students are still enrolled in the course there are many happy students theyre just not as vocal on social media were on week of of my course fully committed to student success and no i havent plagiarized research for any other paper he added,n netflix and european space agency no longer working with siraj raval according to article in the register a netflix spokesperson confirmed to the register it wasnt working with raval and the esa has cancelled the whole workshop altogether the situation is as it is the workshop is cancelled and thats all guillaume belanger an astrophysicist and the integral science operations coordinator at the esa told the register on monday raval isnt about to quit his work any time soon however he promised students who graduated from his course that they would be referred to recruiters at nvidia intel google and amazon for engineering positions or matched with a startup cofounder or a consulting client in an unlisted youtube video recorded live for his students discussing week eight of his course and seen by el reg he read out a question posed to him will your referrals hold any value now um yeah theyre going to hold value i dont see why they wouldnt i mean yes some people on twitter were angry but that has nothing to do with i mean ive also had tons of support you know ive had tons of support from people who uh you know support me who work at these companies he continues to justify his actions public figures called me in private to remind me that this happens you know people make mistakes you just have to keep going theyre basically just telling me to not to stop of course you make mistakes but you just keep going he claimed when the register asked raval for comment he responded ive hardly taken any time off to relax since i first started my youtube channel almost four years ago and despite the enormous amount of work it takes to release two high quality videos a week for my audience i progressively started to take on multiple other projects simultaneously by myself a book a docuseries podcasts youtube videos the course the school of ai basically these past few weeks ive been experiencing a burnout unlike anything ive felt before as a result all of my output has been subpar i made the neural qubits video and paper in one week i remember wishing i had three to six months to really dive into quantum machinelearning and make something awesome but telling myself i couldnt take that long as it would hinder my other projects i plagiarized large chunks of the paper to meet my selfimposed oneweek deadline the associated video with animations took a lot more work to make i didnt expect the paper to be cited as serious research i considered it an additional reading resource for people who enjoyed the associated video to learn more about quantum machine learning if i had a second chance id definitely take way more time to write the paper and in my own words ive given refunds to every student whos asked so far and the majority of students are still enrolled in the course there are many happy students theyre just not as vocal on social media were on week of of my course fully committed to student success and no i havent plagiarized research for any other paper he added,"student, course, video, ive, week",2019-10-15 04:09:10,n netflix and european space agency no longer working with siraj raval according to article in the register a netflix spokesperson confirmed to the register it wasnt working with raval and the esa has cancelled the whole workshop altogether the situation is as it is the workshop is cancelled and thats all guillaume belanger an astrophysicist and the integral science operations coordinator at the esa told the register on monday raval isnt about to quit his work any time soon however he promised students who graduated from his course that they would be referred to recruiters at nvidia intel google and amazon for engineering positions or matched with a startup cofounder or a consulting client in an unlisted youtube video recorded live for his students discussing week eight of his course and seen by el reg he read out a question posed to him will your referrals hold any value now um yeah theyre going to hold value i dont see why they wouldnt i mean yes some people on twitter were angry but that has nothing to do with i mean ive also had tons of support you know ive had tons of support from people who uh you know support me who work at these companies he continues to justify his actions public figures called me in private to remind me that this happens you know people make mistakes you just have to keep going theyre basically just telling me to not to stop of course you make mistakes but you just keep going he claimed when the register asked raval for comment he responded ive hardly taken any time off to relax since i first started my youtube channel almost four years ago and despite the enormous amount of work it takes to release two high quality videos a week for my audience i progressively started to take on multiple other projects simultaneously by myself a book a docuseries podcasts youtube videos the course the school of ai basically these past few weeks ive been experiencing a burnout unlike anything ive felt before as a result all of my output has been subpar i made the neural qubits video and paper in one week i remember wishing i had three to six months to really dive into quantum machinelearning and make something awesome but telling myself i couldnt take that long as it would hinder my other projects i plagiarized large chunks of the paper to meet my selfimposed oneweek deadline the associated video with animations took a lot more work to make i didnt expect the paper to be cited as serious research i considered it an additional reading resource for people who enjoyed the associated video to learn more about quantum machine learning if i had a second chance id definitely take way more time to write the paper and in my own words ive given refunds to every student whos asked so far and the majority of students are still enrolled in the course there are many happy students theyre just not as vocal on social media were on week of of my course fully committed to student success and no i havent plagiarized research for any other paper he added,"['netflix', 'european', 'space', 'agency', 'longer', 'working', 'siraj', 'raval', 'according', 'article', 'register', 'netflix', 'spokesperson', 'confirmed', 'register', 'wasnt', 'working', 'raval', 'esa', 'cancelled', 'whole', 'workshop', 'altogether', 'situation', 'workshop', 'cancelled', 'thats', 'guillaume', 'belanger', 'astrophysicist', 'integral', 'science', 'operation', 'coordinator', 'esa', 'told', 'register', 'monday', 'raval', 'isnt', 'quit', 'work', 'time', 'soon', 'however', 'promised', 'student', 'graduated', 'course', 'would', 'referred', 'recruiter', 'nvidia', 'intel', 'google', 'amazon', 'engineering', 'position', 'matched', 'startup', 'cofounder', 'consulting', 'client', 'unlisted', 'youtube', 'video', 'recorded', 'live', 'student', 'discussing', 'week', 'eight', 'course', 'seen', 'reg', 'read', 'question', 'posed', 'referral', 'hold', 'value', 'yeah', 'theyre', 'going', 'hold', 'value', 'dont', 'see', 'wouldnt', 'mean', 'yes', 'people', 'twitter', 'angry', 'nothing', 'mean', 'ive', 'also', 'ton', 'support', 'know', 'ive', 'ton', 'support', 'people', 'know', 'support', 'work', 'company', 'continues', 'justify', 'action', 'public', 'figure', 'called', 'private', 'remind', 'happens', 'know', 'people', 'make', 'mistake', 'keep', 'going', 'theyre', 'basically', 'telling', 'stop', 'course', 'make', 'mistake', 'keep', 'going', 'claimed', 'register', 'asked', 'raval', 'comment', 'responded', 'ive', 'hardly', 'taken', 'time', 'relax', 'since', 'first', 'started', 'youtube', 'channel', 'almost', 'four', 'year', 'ago', 'despite', 'enormous', 'amount', 'work', 'take', 'release', 'two', 'high', 'quality', 'video', 'week', 'audience', 'progressively', 'started', 'take', 'multiple', 'project', 'simultaneously', 'book', 'docuseries', 'podcasts', 'youtube', 'video', 'course', 'school', 'basically', 'past', 'week', 'ive', 'experiencing', 'burnout', 'unlike', 'anything', 'ive', 'felt', 'result', 'output', 'subpar', 'made', 'neural', 'qubits', 'video', 'paper', 'one', 'week', 'remember', 'wishing', 'three', 'six', 'month', 'really', 'dive', 'quantum', 'machinelearning', 'make', 'something', 'awesome', 'telling', 'couldnt', 'take', 'long', 'would', 'hinder', 'project', 'plagiarized', 'large', 'chunk', 'paper', 'meet', 'selfimposed', 'oneweek', 'deadline', 'associated', 'video', 'animation', 'took', 'lot', 'work', 'make', 'didnt', 'expect', 'paper', 'cited', 'serious', 'research', 'considered', 'additional', 'reading', 'resource', 'people', 'enjoyed', 'associated', 'video', 'learn', 'quantum', 'machine', 'learning', 'second', 'chance', 'definitely', 'take', 'way', 'time', 'write', 'paper', 'word', 'ive', 'given', 'refund', 'every', 'student', 'who', 'asked', 'far', 'majority', 'student', 'still', 'enrolled', 'course', 'many', 'happy', 'student', 'theyre', 'vocal', 'social', 'medium', 'week', 'course', 'fully', 'committed', 'student', 'success', 'havent', 'plagiarized', 'research', 'paper', 'added']",,,,
k8nyf8,data siens,,1607370595.0,4106.0,72.0,/r/datascience/comments/k8nyf8/data_siens/,https://dslntlv9vhjr4.cloudfront.net/posts_images/EcY6g2neQEaIi.png,,datascience,0.97,False,False,False,False,0.0,1745834581.940793,Tech & Programming,2.0,0.0,2.0,Monday,14.0,December,2020.0,False,0.0,0.0,0.0,1.0,neutral,data siens,,data siens ,"data, siens",2020-12-07 19:49:55,data siens ,"['data', 'siens']",,,,
oeg6nl,The pain and excitement,,1625518640.0,3916.0,175.0,/r/datascience/comments/oeg6nl/the_pain_and_excitement/,https://i.redd.it/yqnunwryjg971.jpg,Kent-Clark-,datascience,0.97,False,False,False,False,0.0,1745834582.429945,Tech & Programming,4.0,0.0,4.0,Monday,16.0,July,2021.0,False,-0.0258,0.376,0.388,0.235,neutral,the pain and excitement,,the pain and excitement ,"pain, excitement",2021-07-05 20:57:20,the pain and excitement ,"['pain', 'excitement']",,,,
hohvgq,Shout Out to All the Mediocre Data Scientists Out There,"I've been lurking on this sub for a while now and all too often I see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience. That's great and all but I'd like to move the spotlight to the rest of us for just a minute. Cheers to my fellow mediocre data scientists who don't work at FAANG companies, aren't pursing a PhD, don't publish papers, haven't won Kaggle competitions, and don't spend every waking hour improving their portfolio.  Even though we're nothing special, we still deserve some appreciation every once in a while.

/rant I'll hand it back over to the smart people now",1594352731.0,3632.0,267.0,/r/datascience/comments/hohvgq/shout_out_to_all_the_mediocre_data_scientists_out/,https://www.reddit.com/r/datascience/comments/hohvgq/shout_out_to_all_the_mediocre_data_scientists_out/,MrBurritoQuest,datascience,0.99,True,False,False,False,1.0,1745834583.603374,Tech & Programming,10.0,115.0,125.0,Thursday,23.0,July,2020.0,False,0.9025,0.185,0.125,0.69,positive,shout out to all the mediocre data scientists out there,ive been lurking on this sub for a while now and all too often i see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience thats great and all but id like to move the spotlight to the rest of us for just a minute cheers to my fellow mediocre data scientists who dont work at faang companies arent pursing a phd dont publish papers havent won kaggle competitions and dont spend every waking hour improving their portfolio even though were nothing special we still deserve some appreciation every once in a while rant ill hand it back over to the smart people now,shout out to all the mediocre data scientists out there ive been lurking on this sub for a while now and all too often i see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience thats great and all but id like to move the spotlight to the rest of us for just a minute cheers to my fellow mediocre data scientists who dont work at faang companies arent pursing a phd dont publish papers havent won kaggle competitions and dont spend every waking hour improving their portfolio even though were nothing special we still deserve some appreciation every once in a while rant ill hand it back over to the smart people now,"dont, mediocre, data, scientist, people",2020-07-10 03:45:31,shout out to all the mediocre data scientists out there ive been lurking on this sub for a while now and all too often i see posts from people claiming they feel inadequate and then they go on to describe their stupid impressive background and experience thats great and all but id like to move the spotlight to the rest of us for just a minute cheers to my fellow mediocre data scientists who dont work at faang companies arent pursing a phd dont publish papers havent won kaggle competitions and dont spend every waking hour improving their portfolio even though were nothing special we still deserve some appreciation every once in a while rant ill hand it back over to the smart people now,"['shout', 'mediocre', 'data', 'scientist', 'ive', 'lurking', 'sub', 'often', 'see', 'post', 'people', 'claiming', 'feel', 'inadequate', 'describe', 'stupid', 'impressive', 'background', 'experience', 'thats', 'great', 'like', 'move', 'spotlight', 'rest', 'minute', 'cheer', 'fellow', 'mediocre', 'data', 'scientist', 'dont', 'work', 'faang', 'company', 'arent', 'pursing', 'phd', 'dont', 'publish', 'paper', 'havent', 'kaggle', 'competition', 'dont', 'spend', 'every', 'waking', 'hour', 'improving', 'portfolio', 'even', 'though', 'nothing', 'special', 'still', 'deserve', 'appreciation', 'every', 'rant', 'ill', 'hand', 'back', 'smart', 'people']",,,,
xdv6nz,Let's keep this on...,,1663139475.0,3599.0,121.0,/r/datascience/comments/xdv6nz/lets_keep_this_on/,https://i.redd.it/k102dyo0yrn91.jpg,CompetitivePlastic67,datascience,0.97,False,False,False,False,0.0,1745834584.892702,Tech & Programming,4.0,0.0,4.0,Wednesday,3.0,September,2022.0,False,0.0,0.0,0.0,1.0,neutral,lets keep this on,,lets keep this on ,"let, keep",2022-09-14 07:11:15,lets keep this on ,"['let', 'keep']",,,,
tj3kek,"Guys, we’ve been doing it wrong this whole time",,1647837277.0,3467.0,386.0,/r/datascience/comments/tj3kek/guys_weve_been_doing_it_wrong_this_whole_time/,https://i.imgur.com/TAex5zG.jpg,,datascience,0.96,False,False,False,False,0.0,1745834585.506464,Tech & Programming,9.0,0.0,9.0,Monday,0.0,March,2022.0,False,-0.4767,0.0,0.279,0.721,negative,guys weve been doing it wrong this whole time,,guys weve been doing it wrong this whole time ,"guy, weve, wrong, whole, time",2022-03-21 04:34:37,guys weve been doing it wrong this whole time ,"['guy', 'weve', 'wrong', 'whole', 'time']",,,,
fg73za,It’s never too early,,1583808989.0,3413.0,67.0,/r/datascience/comments/fg73za/its_never_too_early/,https://i.redd.it/0c9louclfrl41.jpg,da_chosen1,datascience,0.98,False,False,False,False,0.0,1745834587.745591,Tech & Programming,4.0,0.0,4.0,Monday,22.0,March,2020.0,False,0.0,0.0,0.0,1.0,neutral,its never too early,,its never too early ,"never, early",2020-03-10 02:56:29,its never too early ,"['never', 'early']",,,,
oisl3e,how about that data integrity yo,,1626100778.0,3320.0,121.0,/r/datascience/comments/oisl3e/how_about_that_data_integrity_yo/,https://i.redd.it/x5hj821ilsa71.jpg,Kickass_Wizard,datascience,0.98,False,False,False,False,0.0,1745834588.172172,Tech & Programming,6.0,0.0,6.0,Monday,10.0,July,2021.0,False,0.3818,0.342,0.0,0.658,positive,how about that data integrity yo,,how about that data integrity yo ,"data, integrity",2021-07-12 14:39:38,how about that data integrity yo ,"['data', 'integrity']",,,,
xit874,Didn’t have to chart this one 🔥,,1663632440.0,3314.0,58.0,/r/datascience/comments/xit874/didnt_have_to_chart_this_one/,https://i.redd.it/s0s0x37zzto91.jpg,Lynx-Sure,datascience,0.98,False,False,False,False,0.0,1745834588.814205,Tech & Programming,7.0,0.0,6.0,Monday,20.0,September,2022.0,False,0.0,0.0,0.0,1.0,neutral,didnt have to chart this one,,didnt have to chart this one ,"didnt, chart, one",2022-09-20 00:07:20,didnt have to chart this one ,"['didnt', 'chart', 'one']",,,,
wp2vqk,Wait until you see the data in hospitals...,,1660578282.0,3258.0,105.0,/r/datascience/comments/wp2vqk/wait_until_you_see_the_data_in_hospitals/,https://i.redd.it/uwrv5tu2ewh91.png,forbiscuit,datascience,0.99,False,False,False,False,0.0,1745834589.235181,Tech & Programming,8.0,0.0,8.0,Monday,11.0,August,2022.0,False,0.0,0.0,0.0,1.0,neutral,wait until you see the data in hospitals,,wait until you see the data in hospitals ,"wait, see, data, hospital",2022-08-15 15:44:42,wait until you see the data in hospitals ,"['wait', 'see', 'data', 'hospital']",,,,
e6iy5o,Imposter Syndrome is a problem for me and I think this is the main contributor,,1575560765.0,3213.0,133.0,/r/datascience/comments/e6iy5o/imposter_syndrome_is_a_problem_for_me_and_i_think/,https://i.redd.it/e292g50m4u241.jpg,ExecutiveFingerblast,datascience,0.98,False,False,False,False,0.0,1745834589.948392,Tech & Programming,15.0,0.0,15.0,Thursday,10.0,December,2019.0,False,-0.4019,0.0,0.184,0.816,negative,imposter syndrome is a problem for me and i think this is the main contributor,,imposter syndrome is a problem for me and i think this is the main contributor ,"imposter, syndrome, problem, think, main",2019-12-05 15:46:05,imposter syndrome is a problem for me and i think this is the main contributor ,"['imposter', 'syndrome', 'problem', 'think', 'main', 'contributor']",,,,
1f6ztk4,How to avoid 1/2-assed data analysis,,1725257884.0,3179.0,71.0,/r/datascience/comments/1f6ztk4/how_to_avoid_12assed_data_analysis/,https://i.redd.it/l6zd3zsa9cmd1.jpeg,BdR76,datascience,0.98,False,False,False,False,0.0,1745834590.620086,Tech & Programming,6.0,0.0,6.0,Monday,2.0,September,2024.0,False,-0.296,0.0,0.306,0.694,negative,how to avoid assed data analysis,,how to avoid assed data analysis ,"avoid, assed, data, analysis",2024-09-02 06:18:04,how to avoid assed data analysis ,"['avoid', 'assed', 'data', 'analysis']",,,,
dudedh,DS at a glance,,1573402538.0,2911.0,92.0,/r/datascience/comments/dudedh/ds_at_a_glance/,https://i.redd.it/mdlja2h1wvx31.jpg,Siba911,datascience,0.98,False,False,False,False,1.0,1745834590.945467,Tech & Programming,4.0,0.0,4.0,Sunday,11.0,November,2019.0,True,0.0,0.0,0.0,1.0,neutral,ds at a glance,,ds at a glance ,glance,2019-11-10 16:15:38,ds at a glance ,['glance'],,,,
peremu,Remember it always.,,1630358182.0,2869.0,53.0,/r/datascience/comments/peremu/remember_it_always/,https://i.redd.it/kgomawneakk71.jpg,the_last_crusaderr,datascience,0.95,False,False,False,False,0.0,1745834591.518373,Tech & Programming,3.0,0.0,3.0,Monday,17.0,August,2021.0,False,0.0,0.0,0.0,1.0,neutral,remember it always,,remember it always ,"remember, always",2021-08-30 21:16:22,remember it always ,"['remember', 'always']",,,,
1feyx6h,Favourite piece of code 🤣,What's your favourite one line code.,1726135600.0,2841.0,103.0,/r/datascience/comments/1feyx6h/favourite_piece_of_code/,https://i.redd.it/jqvbe1ycrcod1.jpeg,nobody_undefined,datascience,0.98,False,False,False,False,0.0,1745834591.870503,Tech & Programming,5.0,6.0,10.0,Thursday,6.0,September,2024.0,False,0.0,0.0,0.0,1.0,neutral,favourite piece of code,whats your favourite one line code,favourite piece of code whats your favourite one line code,"favourite, code, piece, whats, one",2024-09-12 10:06:40,favourite piece of code whats your favourite one line code,"['favourite', 'piece', 'code', 'whats', 'favourite', 'one', 'line', 'code']",,,,
ljftgi,"I created a four-page Data Science Cheatsheet to assist with exam reviews, interview prep, and anything in-between","Hey guys, I’ve been doing a lot of preparation for interviews lately, and thought I’d compile a document of theories, algorithms, and models I found helpful during this time. Originally, I was just keeping notes in a Google Doc, but figured I could create something more permanent and aesthetic.

It covers topics (some more in-depth than others), such as:

* Distributions
* Linear and Logistic Regression
* Decision Trees and Random Forest
* SVM
* KNN
* Clustering
* Boosting
* Dimension Reduction (PCA, LDA, Factor Analysis)
* NLP
* Neural Networks
* Recommender Systems
* Reinforcement Learning
* Anomaly Detection

The four-page Data Science Cheatsheet can be found [here](https://github.com/aaronwangy/Data-Science-Cheatsheet/blob/main/Data_Science_Cheatsheet.pdf), and I hope it's helpful to those looking to review or brush up on machine learning concepts. Feel free to leave any suggestions and star/save the PDF for reference.

Cheers!

Github Repo: [https://github.com/aaronwangy/Data-Science-Cheatsheet](https://github.com/aaronwangy/Data-Science-Cheatsheet)

Edit - Thanks for the awards! However, I don't have much need for internet points and much rather we help out local charities in need :) Some highly rated Covid relief projects listed [here](https://www.charitynavigator.org/index.cfm?bay=content.view&cpid=7779).",1613271603.0,2772.0,102.0,/r/datascience/comments/ljftgi/i_created_a_fourpage_data_science_cheatsheet_to/,https://www.reddit.com/r/datascience/comments/ljftgi/i_created_a_fourpage_data_science_cheatsheet_to/,WirelessSushi,datascience,0.99,True,False,False,False,1.0,1745834592.480728,Tech & Programming,17.0,177.0,178.0,Saturday,22.0,February,2021.0,True,0.9929,0.227,0.006,0.767,positive,i created a fourpage data science cheatsheet to assist with exam reviews interview prep and anything inbetween,hey guys ive been doing a lot of preparation for interviews lately and thought id compile a document of theories algorithms and models i found helpful during this time originally i was just keeping notes in a google doc but figured i could create something more permanent and aesthetic it covers topics some more indepth than others such as distributions linear and logistic regression decision trees and random forest svm knn clustering boosting dimension reduction pca lda factor analysis nlp neural networks recommender systems reinforcement learning anomaly detection the fourpage data science cheatsheet can be found here and i hope its helpful to those looking to review or brush up on machine learning concepts feel free to leave any suggestions and starsave the pdf for reference cheers github repo edit thanks for the awards however i dont have much need for internet points and much rather we help out local charities in need some highly rated covid relief projects listed here,i created a fourpage data science cheatsheet to assist with exam reviews interview prep and anything inbetween hey guys ive been doing a lot of preparation for interviews lately and thought id compile a document of theories algorithms and models i found helpful during this time originally i was just keeping notes in a google doc but figured i could create something more permanent and aesthetic it covers topics some more indepth than others such as distributions linear and logistic regression decision trees and random forest svm knn clustering boosting dimension reduction pca lda factor analysis nlp neural networks recommender systems reinforcement learning anomaly detection the fourpage data science cheatsheet can be found here and i hope its helpful to those looking to review or brush up on machine learning concepts feel free to leave any suggestions and starsave the pdf for reference cheers github repo edit thanks for the awards however i dont have much need for internet points and much rather we help out local charities in need some highly rated covid relief projects listed here,"fourpage, data, science, cheatsheet, review",2021-02-14 03:00:03,i created a fourpage data science cheatsheet to assist with exam reviews interview prep and anything inbetween hey guys ive been doing a lot of preparation for interviews lately and thought id compile a document of theories algorithms and models i found helpful during this time originally i was just keeping notes in a google doc but figured i could create something more permanent and aesthetic it covers topics some more indepth than others such as distributions linear and logistic regression decision trees and random forest svm knn clustering boosting dimension reduction pca lda factor analysis nlp neural networks recommender systems reinforcement learning anomaly detection the fourpage data science cheatsheet can be found here and i hope its helpful to those looking to review or brush up on machine learning concepts feel free to leave any suggestions and starsave the pdf for reference cheers github repo edit thanks for the awards however i dont have much need for internet points and much rather we help out local charities in need some highly rated covid relief projects listed here,"['created', 'fourpage', 'data', 'science', 'cheatsheet', 'assist', 'exam', 'review', 'interview', 'prep', 'anything', 'inbetween', 'hey', 'guy', 'ive', 'lot', 'preparation', 'interview', 'lately', 'thought', 'compile', 'document', 'theory', 'algorithm', 'model', 'found', 'helpful', 'time', 'originally', 'keeping', 'note', 'google', 'doc', 'figured', 'could', 'create', 'something', 'permanent', 'aesthetic', 'cover', 'topic', 'indepth', 'others', 'distribution', 'linear', 'logistic', 'regression', 'decision', 'tree', 'random', 'forest', 'svm', 'knn', 'clustering', 'boosting', 'dimension', 'reduction', 'pca', 'lda', 'factor', 'analysis', 'nlp', 'neural', 'network', 'recommender', 'system', 'reinforcement', 'learning', 'anomaly', 'detection', 'fourpage', 'data', 'science', 'cheatsheet', 'found', 'hope', 'helpful', 'looking', 'review', 'brush', 'machine', 'learning', 'concept', 'feel', 'free', 'leave', 'suggestion', 'starsave', 'pdf', 'reference', 'cheer', 'github', 'repo', 'edit', 'thanks', 'award', 'however', 'dont', 'much', 'need', 'internet', 'point', 'much', 'rather', 'help', 'local', 'charity', 'need', 'highly', 'rated', 'covid', 'relief', 'project', 'listed']",,,,
uqzrul,I want to be free of this pain.,,1652718187.0,2684.0,87.0,/r/datascience/comments/uqzrul/i_want_to_be_free_of_this_pain/,https://i.redd.it/o89y3eq36vz81.png,Kickass_Wizard,datascience,0.98,False,False,False,False,0.0,1745834593.001462,Tech & Programming,8.0,0.0,8.0,Monday,12.0,May,2022.0,False,0.0772,0.387,0.277,0.336,positive,i want to be free of this pain,,i want to be free of this pain ,"want, free, pain",2022-05-16 16:23:07,i want to be free of this pain ,"['want', 'free', 'pain']",,,,
ejvao9,True that,,1578135230.0,2656.0,218.0,/r/datascience/comments/ejvao9/true_that/,https://i.redd.it/vh0ey1fgsm841.jpg,,datascience,0.97,False,False,False,False,0.0,1745834593.427864,Tech & Programming,2.0,0.0,2.0,Saturday,5.0,January,2020.0,True,0.4215,0.737,0.0,0.263,positive,true that,,true that ,true,2020-01-04 10:53:50,true that ,['true'],,,,
10mmm38,"As a hiring manager - this, this right here",,1674830901.0,2642.0,135.0,/r/datascience/comments/10mmm38/as_a_hiring_manager_this_this_right_here/,https://i.redd.it/fk95v2ghilea1.png,cardsfan314,datascience,0.97,False,False,False,False,0.0,1745834594.81068,Tech & Programming,9.0,0.0,8.0,Friday,9.0,January,2023.0,False,0.0,0.0,0.0,1.0,neutral,as a hiring manager this this right here,,as a hiring manager this this right here ,"hiring, manager, right",2023-01-27 14:48:21,as a hiring manager this this right here ,"['hiring', 'manager', 'right']",,,,
vwlmoo,Imposter Detected,,1657554677.0,2572.0,121.0,/r/datascience/comments/vwlmoo/imposter_detected/,https://i.imgur.com/pr09q68.png,tits_mcgee_92,datascience,0.98,False,False,False,False,0.0,1745834595.806888,Tech & Programming,2.0,0.0,2.0,Monday,11.0,July,2022.0,False,0.0,0.0,0.0,1.0,neutral,imposter detected,,imposter detected ,"imposter, detected",2022-07-11 15:51:17,imposter detected ,"['imposter', 'detected']",,,,
frkgr7,Graph of graph analysis,,1585543660.0,2574.0,41.0,/r/datascience/comments/frkgr7/graph_of_graph_analysis/,https://i.redd.it/m99e3svtpqp41.jpg,VeryOddEvey,datascience,0.98,False,False,False,False,0.0,1745834596.432822,Tech & Programming,4.0,0.0,4.0,Monday,0.0,March,2020.0,False,0.0,0.0,0.0,1.0,neutral,graph of graph analysis,,graph of graph analysis ,"graph, analysis",2020-03-30 04:47:40,graph of graph analysis ,"['graph', 'graph', 'analysis']",,,,
qzluvi,Selling my own damn data (cartoon by artist Jeremy Nguyen),,1637589084.0,2562.0,46.0,/r/datascience/comments/qzluvi/selling_my_own_damn_data_cartoon_by_artist_jeremy/,https://i.redd.it/i0iafeelj5181.jpg,rotterdamn8,datascience,0.98,False,False,False,False,0.0,1745834596.738699,Tech & Programming,10.0,0.0,10.0,Monday,8.0,November,2021.0,False,-0.4019,0.0,0.231,0.769,negative,selling my own damn data cartoon by artist jeremy nguyen,,selling my own damn data cartoon by artist jeremy nguyen ,"selling, damn, data, cartoon, artist",2021-11-22 13:51:24,selling my own damn data cartoon by artist jeremy nguyen ,"['selling', 'damn', 'data', 'cartoon', 'artist', 'jeremy', 'nguyen']",,,,
tw7kc0,Me trying to switch careers after getting a Master’s degree in Data Science,,1649092885.0,2484.0,272.0,/r/datascience/comments/tw7kc0/me_trying_to_switch_careers_after_getting_a/,https://i.redd.it/ohprn1taqjr81.jpg,malmcb,datascience,0.97,False,False,False,False,0.0,1745834597.070321,Tech & Programming,13.0,0.0,13.0,Monday,13.0,April,2022.0,False,0.0,0.0,0.0,1.0,neutral,me trying to switch careers after getting a masters degree in data science,,me trying to switch careers after getting a masters degree in data science ,"trying, switch, career, getting, master",2022-04-04 17:21:25,me trying to switch careers after getting a masters degree in data science ,"['trying', 'switch', 'career', 'getting', 'master', 'degree', 'data', 'science']",,,,
eb240z,When the boss doesn’t like your charts,,1576432616.0,2343.0,73.0,/r/datascience/comments/eb240z/when_the_boss_doesnt_like_your_charts/,https://i.redd.it/cyg4vip06u441.jpg,,datascience,0.99,False,False,False,False,0.0,1745834598.970054,Tech & Programming,7.0,0.0,7.0,Sunday,12.0,December,2019.0,True,-0.2755,0.0,0.26,0.74,negative,when the boss doesnt like your charts,,when the boss doesnt like your charts ,"bos, doesnt, like, chart",2019-12-15 17:56:56,when the boss doesnt like your charts ,"['bos', 'doesnt', 'like', 'chart']",,,,
xcdnd8,Data Science in 2022,,1662991336.0,2339.0,139.0,/r/datascience/comments/xcdnd8/data_science_in_2022/,https://i.imgur.com/60Vnj0X.png,tits_mcgee_92,datascience,0.97,False,False,False,False,0.0,1745834599.389703,Tech & Programming,4.0,0.0,3.0,Monday,10.0,September,2022.0,False,0.0,0.0,0.0,1.0,neutral,data science in,,data science in ,"data, science",2022-09-12 14:02:16,data science in ,"['data', 'science']",,,,
qrjmge,Stop asking data scientist riddles in interviews!,,1636631533.0,2328.0,266.0,/r/datascience/comments/qrjmge/stop_asking_data_scientist_riddles_in_interviews/,https://i.redd.it/jjtjirwagyy71.jpg,harsh5161,datascience,0.94,False,False,False,False,0.0,1745834600.502568,Tech & Programming,7.0,0.0,7.0,Thursday,6.0,November,2021.0,False,-0.296,0.0,0.268,0.732,negative,stop asking data scientist riddles in interviews,,stop asking data scientist riddles in interviews ,"stop, asking, data, scientist, riddle",2021-11-11 11:52:13,stop asking data scientist riddles in interviews ,"['stop', 'asking', 'data', 'scientist', 'riddle', 'interview']",,,,
tjfxtx,Feeling starting out,,1647880596.0,2262.0,88.0,/r/datascience/comments/tjfxtx/feeling_starting_out/,https://i.redd.it/pilz06fjlro81.jpg,unknown777,datascience,0.98,False,False,False,False,0.0,1745834602.147065,Tech & Programming,3.0,0.0,3.0,Monday,12.0,March,2022.0,False,0.128,0.429,0.0,0.571,positive,feeling starting out,,feeling starting out ,"feeling, starting",2022-03-21 16:36:36,feeling starting out ,"['feeling', 'starting']",,,,
f6xk72,"For any python & pandas users out there, here's a free tool to visualize your dataframes",,1582224233.0,2244.0,190.0,/r/datascience/comments/f6xk72/for_any_python_pandas_users_out_there_heres_a/,https://v.redd.it/2u0skf49j4i41,aschonfe,datascience,0.99,False,False,False,False,2.0,1745834602.651428,Tech & Programming,16.0,0.0,15.0,Thursday,13.0,February,2020.0,False,0.5106,0.202,0.0,0.798,positive,for any python pandas users out there heres a free tool to visualize your dataframes,,for any python pandas users out there heres a free tool to visualize your dataframes ,"python, panda, user, here, free",2020-02-20 18:43:53,for any python pandas users out there heres a free tool to visualize your dataframes ,"['python', 'panda', 'user', 'here', 'free', 'tool', 'visualize', 'dataframes']",,,,
rozxuk,What Companies think AI looks like vs What Actually it is,,1640535235.0,2186.0,67.0,/r/datascience/comments/rozxuk/what_companies_think_ai_looks_like_vs_what/,https://i.redd.it/mu7cm5ztvw781.jpg,harsh5161,datascience,0.96,False,False,False,False,0.0,1745834603.498398,Tech & Programming,11.0,0.0,11.0,Sunday,11.0,December,2021.0,True,0.3612,0.2,0.0,0.8,positive,what companies think ai looks like vs what actually it is,,what companies think ai looks like vs what actually it is ,"company, think, look, like, actually",2021-12-26 16:13:55,what companies think ai looks like vs what actually it is ,"['company', 'think', 'look', 'like', 'actually']",,,,
zw9mtn,Pre screening tests be like,,1672125307.0,2175.0,115.0,/r/datascience/comments/zw9mtn/pre_screening_tests_be_like/,https://i.redd.it/ntqdnbd1nf8a1.jpg,Gagan_Ku2905,datascience,0.97,False,False,False,False,0.0,1745834604.008609,Tech & Programming,5.0,0.0,5.0,Tuesday,2.0,December,2022.0,False,0.3612,0.385,0.0,0.615,positive,pre screening tests be like,,pre screening tests be like ,"pre, screening, test, like",2022-12-27 07:15:07,pre screening tests be like ,"['pre', 'screening', 'test', 'like']",,,,
p59a8u,That's true,,1629089555.0,2153.0,131.0,/r/datascience/comments/p59a8u/thats_true/,https://i.redd.it/59v75in4inh71.jpg,Kent-Clark-,datascience,0.94,False,False,False,False,0.0,1745834604.564057,Tech & Programming,2.0,0.0,2.0,Monday,0.0,August,2021.0,False,0.4215,0.737,0.0,0.263,positive,thats true,,thats true ,"thats, true",2021-08-16 04:52:35,thats true ,"['thats', 'true']",,,,
uw2a27,When a non-technical manager wants details behind your model.,,1653318273.0,2117.0,83.0,/r/datascience/comments/uw2a27/when_a_nontechnical_manager_wants_details_behind/,https://i.imgur.com/0hMDEK1.jpeg,tits_mcgee_92,datascience,0.95,False,False,False,False,0.0,1745834605.091698,Tech & Programming,9.0,0.0,9.0,Monday,11.0,May,2022.0,False,0.0,0.0,0.0,1.0,neutral,when a nontechnical manager wants details behind your model,,when a nontechnical manager wants details behind your model ,"nontechnical, manager, want, detail, behind",2022-05-23 15:04:33,when a nontechnical manager wants details behind your model ,"['nontechnical', 'manager', 'want', 'detail', 'behind', 'model']",,,,
yik3k5,"Happy Halloween, Pandas! 🎃🤓",,1667240441.0,2088.0,58.0,/r/datascience/comments/yik3k5/happy_halloween_pandas/,https://i.redd.it/g2ukf6e2o6x91.jpg,aplarsen,datascience,0.97,False,False,False,False,0.0,1745834605.68294,Tech & Programming,4.0,0.0,3.0,Monday,14.0,October,2022.0,False,0.5719,0.649,0.0,0.351,positive,happy halloween pandas,,happy halloween pandas ,"happy, halloween, panda",2022-10-31 18:20:41,happy halloween pandas ,"['happy', 'halloween', 'panda']",,,,
g8v44c,"It's Meme Monday, so here's a python meme for DS folks",,1587968470.0,2082.0,83.0,/r/datascience/comments/g8v44c/its_meme_monday_so_heres_a_python_meme_for_ds/,https://i.redd.it/nklty63uzav41.png,rajeshbhat_ds,datascience,0.96,False,False,False,False,0.0,1745834606.02885,Tech & Programming,11.0,0.0,11.0,Monday,2.0,April,2020.0,False,0.0,0.0,0.0,1.0,neutral,its meme monday so heres a python meme for ds folks,,its meme monday so heres a python meme for ds folks ,"meme, monday, here, python, folk",2020-04-27 06:21:10,its meme monday so heres a python meme for ds folks ,"['meme', 'monday', 'here', 'python', 'meme', 'folk']",,,,
1hp7pim,My Data Science Manifesto from a Self Taught Data Scientist,"**Background**

I’m a self-taught data scientist, with about 5 years of data analyst experience and now about 5 years as a Data Scientist. I’m more math minded than the average person, but I’m not special. I have a bachelor’s degree in mechanical engineering, and have worked alongside 6 data scientists, 4 of which have PHDs and the other 2 have a masters. Despite being probably, the 6th out of 7 in natural ability, I have been the 2nd most productive data scientist out of the group.


**Gatekeeping**

Every day someone on this subreddit asks some derivative of “what do I need to know to get started in ML/DS?” The answers are always smug and give some insane list of courses and topics one must master. As someone who’s been on both sides, this is attitude extremely annoying and rampart in the industry. I don’t think you can be bad at math and have no pre-requisite knowledge, and be successful, but the levels needed are greatly exaggerated. Most of the people telling you these things are just posturing due to insecurity.



As a mechanical engineering student, I had at least 3 calculus courses, a linear algebra course, and a probability course, but it was 10+ years before I attempted to become a DS, and I didn’t remember much at all. This sub, and others like it, made me think I had to be an expert in all these topics and many more to even think about trying to become a data scientist. 



When I started my journey, I would take coding, calculus, stats, linear algebra, etc. courses. I’d take a course, do OK in it, and move onto the next thing. However, eventually I’d get defeated because I realized I couldn’t remember much from the courses I took 3 months prior. It just felt like too much information for me to hold at a single time while working a full-time job. I never got started on actually solving problems because the internet and industry told me I needed to be an expert in all these things.


**What you actually need**

The reality is, 95% of the time you only need a basic understanding of these topics. Projects often require a deeper dive into something else, but that's a case by case basis, and you figure that out as you go.


For calculus, you don't need to know how to integrate multivariable functions by hand. You need to know that derivatives create a function that represents the slope of the original function, and that where the derivative = 0 is a local min/max. You need to know integrals are area under the curve.



For stats, you need to understand what a p value represents. You don't need to know all the different tests, and when to use them. You need to know that they exist and why you need them. When it's time to use one, just google it, and figure out which one best suits your use case.



For linear algebra, you don't need to know how to solve for eigenvectors by hand, or whatever other specific things you do in that class. You need to know how to ‘read’ it. It is also helpful to know properties of linear algebra. Like the cross product of 2 vectors yields a vector perpendicular to both.



For probability, you need to understand basic things, but again, just google your specific problem.



You don't need to be an expert software dev. You need to write ok code, and be able to use chatGPT to help you improve it little by little.



You don't need to know how to build all the algorithms by hand. A general understanding of how they work is enough in 95% of cases.



Of all of those things, the only thing you absolutely NEED to get started is basic coding ability. 



By far the number one technical ability needed to 'master' is understanding how to ""frame"" your problem, and how to test and evaluate and interpret performance. If you can ensure that you're accurately framing the problem and evaluating the model or alogithm, with metrics that correctly align with the use case, that's enough to start providing some real value. I often see people asking things like ""should I do this feature engineering technique for this problem?"" or “which of these algorithms will perform best?”. The answer should usually be, ""I don't know, try it, measure it, and see"". Understanding how the algorithms work can give you clues into what you should try, but at the end of the day, you should just try it and see.   



Despite the posturing in the industry, very few people are actually experts in all these domains. Some people are better at talking the talk than others, but at the end of the day, you WILL have to constantly research and learn on a project by project basis. That’s what makes it fun and interesting. As you gain PRACTICAL experience, you will grow, you will learn, you will improve beyond what you could've ever imagined. Just get the basics down and get started, don't spin your wheels trying and failing to nail all these disciplines before ever applying anything.



The reason I’m near the top in productivity while being near the bottom in natural and technical ability is my 5 years of experience as a data analyst at my company. During this time, I got really good at exploring my companies’ data. When you are stumped on problem, intelligently visualizing the data often reveals the solution. I’ve also had the luxury of analyzing our data from all different perspectives. I’d have assignments from marketing, product, tech support, customer service, software, firmware, and other technical teams. I understand the complete company better than the other data scientists. I’m also just aware of more ‘tips and tricks’ than anyone else.  



Good domain knowledge and data exploration skills with average technical skills will outperform good technical skills with average domain knowledge and data exploration almost every time. 


**Advice for those self taught**


I’ve been on the hiring side of things a few times now, and the market is certainly difficult. I think it would be very difficult for someone to online course and side project themselves directly into a DS job. The side project would have to be EXTREMELY impressive to be considered. However, I think my path is repeatable.



I taught myself basic SQL and Tableau and completed a few side projects. I accepted a job as a data analyst, in a medium sized (100-200 total employees) on a team where DS and DA shared the same boss. The barrier to DA is likely higher than it was ~10 years ago, but it's definitely something achievable. My advice would be to find roles that you have some sort of unique experience with, and tailor your resume to that connection. No connection is too small. For example, my DA role required working with a lot of accelerometer data. In my previous job as a test engineer, I sometimes helped set up accelerometers to record data from the tests. This experience barely helped me at all when actually on the job, but it helped my resume actually get looked at. For entry level jobs employers are looking for ANY connection, because most entry level resumes all look the same.


The first year or two I excelled at my role as a DA. I made my boss aware that I wanted to become a DS eventually. He started to make me a small part of some DS projects, running queries, building dashboards to track performance and things like that. I was also a part of some of the meetings, so I got some insight into how certain problems were approached. 



My boss made me aware that I would need to teach myself to code and machine learning. My role in the data science projects grew over time, but I was ultimately blocked from becoming a DS because I kept trying and failing to learn to code and the 25 areas of expertise reddit tells you that you need by taking MOOCs. 

  

Eventually, I paid up for DataQuest. I naively thought the course would teach me everything I needed to know. While you will not be proficient in anything DS upon completing, the interactive format made it easy to jump into 30-60 minutes of structured coding every day. Like a real language consistency is vital. 



Once I got to the point where I could do some basic coding, I began my own side project. THIS IS THE MOST IMPORTANT THING. ONCE YOU GET THE BASELINE KNOWLEDGE, JUST GET STARTED WORKING ON THINGS. This is where the real learning began. You'll screw things up, and that's ok. Titanic problem is fine for day 1, but you really need a project of your own. I picked a project that I was interested in and had a function that I would personally use (I'm on V3 of this project and it's grown to a level that I never could've dreamed of at the time). This was crucial in ensuring that I stuck with the project, and had real investment in doing it correctly. When I didn’t know how to do something in the project, I would research it and figure it out. This is how it works in the real world.



After 3 months of Dataquest and another 3 of a project (along with 4 years of being a data analyst) I convinced my boss to assign me DS project. I worked alongside another data scientist, but I owned the project, and they were mostly there for guidance, and coded some of the more complex things. I excelled at that project, and was promoted to data scientist, and began getting projects of my own, with less and less oversight. We have a very collaborative work environment, and the data scientists are truly out to help each other. We present our progress to each other often which allows us all to learn and improve. I have been promoted twice since I began DS work.



I'd like to add that you can almost certainly do all this in less time than it took me. I wasted a lot of time spinning my wheels. ChatGPT is also a great resource that could also increase your learning speed. Don't blindly use it, but it's a great resource.


**Tldr:** Sir this is Wendy’s.

**Edit:** I’m not saying to never go deeper into things, I’m literally always learning. I go deeper into things all the time. Often in very niche domains, but you don't need to be a master in all things get started or even excel. Be able to understand generalities of those domains, and dig deeper when the problem calls for it. Learning a concept when you have a direct application is much more likely to stick.


I thought it went without saying, but I’m not saying those things I listed are literally the only things you need to know about those topics, I was just giving examples of where relatively simple concepts were way more important than specifics.

**Edit #2:** I'm not saying schooling is bad. Yes obviously having a masters and/or PhD is better than not. I'm directing this to those who are working a full time job who want to break into the field, but taking years getting a masters while working full time and going another 50K into debt is unrealistic",1735511285.0,2054.0,178.0,/r/datascience/comments/1hp7pim/my_data_science_manifesto_from_a_self_taught_data/,https://www.reddit.com/r/datascience/comments/1hp7pim/my_data_science_manifesto_from_a_self_taught_data/,irndk10,datascience,0.96,True,False,False,False,0.0,1745834606.593991,Tech & Programming,10.0,1908.0,1894.0,Sunday,17.0,December,2024.0,True,0.9995,0.137,0.049,0.814,positive,my data science manifesto from a self taught data scientist,background im a selftaught data scientist with about years of data analyst experience and now about years as a data scientist im more math minded than the average person but im not special i have a bachelors degree in mechanical engineering and have worked alongside data scientists of which have phds and the other have a masters despite being probably the th out of in natural ability i have been the nd most productive data scientist out of the group gatekeeping every day someone on this subreddit asks some derivative of what do i need to know to get started in mlds the answers are always smug and give some insane list of courses and topics one must master as someone whos been on both sides this is attitude extremely annoying and rampart in the industry i dont think you can be bad at math and have no prerequisite knowledge and be successful but the levels needed are greatly exaggerated most of the people telling you these things are just posturing due to insecurity as a mechanical engineering student i had at least calculus courses a linear algebra course and a probability course but it was years before i attempted to become a ds and i didnt remember much at all this sub and others like it made me think i had to be an expert in all these topics and many more to even think about trying to become a data scientist when i started my journey i would take coding calculus stats linear algebra etc courses id take a course do ok in it and move onto the next thing however eventually id get defeated because i realized i couldnt remember much from the courses i took months prior it just felt like too much information for me to hold at a single time while working a fulltime job i never got started on actually solving problems because the internet and industry told me i needed to be an expert in all these things what you actually need the reality is of the time you only need a basic understanding of these topics projects often require a deeper dive into something else but thats a case by case basis and you figure that out as you go for calculus you dont need to know how to integrate multivariable functions by hand you need to know that derivatives create a function that represents the slope of the original function and that where the derivative is a local minmax you need to know integrals are area under the curve for stats you need to understand what a p value represents you dont need to know all the different tests and when to use them you need to know that they exist and why you need them when its time to use one just google it and figure out which one best suits your use case for linear algebra you dont need to know how to solve for eigenvectors by hand or whatever other specific things you do in that class you need to know how to read it it is also helpful to know properties of linear algebra like the cross product of vectors yields a vector perpendicular to both for probability you need to understand basic things but again just google your specific problem you dont need to be an expert software dev you need to write ok code and be able to use chatgpt to help you improve it little by little you dont need to know how to build all the algorithms by hand a general understanding of how they work is enough in of cases of all of those things the only thing you absolutely need to get started is basic coding ability by far the number one technical ability needed to master is understanding how to frame your problem and how to test and evaluate and interpret performance if you can ensure that youre accurately framing the problem and evaluating the model or alogithm with metrics that correctly align with the use case thats enough to start providing some real value i often see people asking things like should i do this feature engineering technique for this problem or which of these algorithms will perform best the answer should usually be i dont know try it measure it and see understanding how the algorithms work can give you clues into what you should try but at the end of the day you should just try it and see despite the posturing in the industry very few people are actually experts in all these domains some people are better at talking the talk than others but at the end of the day you will have to constantly research and learn on a project by project basis thats what makes it fun and interesting as you gain practical experience you will grow you will learn you will improve beyond what you couldve ever imagined just get the basics down and get started dont spin your wheels trying and failing to nail all these disciplines before ever applying anything the reason im near the top in productivity while being near the bottom in natural and technical ability is my years of experience as a data analyst at my company during this time i got really good at exploring my companies data when you are stumped on problem intelligently visualizing the data often reveals the solution ive also had the luxury of analyzing our data from all different perspectives id have assignments from marketing product tech support customer service software firmware and other technical teams i understand the complete company better than the other data scientists im also just aware of more tips and tricks than anyone else good domain knowledge and data exploration skills with average technical skills will outperform good technical skills with average domain knowledge and data exploration almost every time advice for those self taught ive been on the hiring side of things a few times now and the market is certainly difficult i think it would be very difficult for someone to online course and side project themselves directly into a ds job the side project would have to be extremely impressive to be considered however i think my path is repeatable i taught myself basic sql and tableau and completed a few side projects i accepted a job as a data analyst in a medium sized total employees on a team where ds and da shared the same boss the barrier to da is likely higher than it was years ago but its definitely something achievable my advice would be to find roles that you have some sort of unique experience with and tailor your resume to that connection no connection is too small for example my da role required working with a lot of accelerometer data in my previous job as a test engineer i sometimes helped set up accelerometers to record data from the tests this experience barely helped me at all when actually on the job but it helped my resume actually get looked at for entry level jobs employers are looking for any connection because most entry level resumes all look the same the first year or two i excelled at my role as a da i made my boss aware that i wanted to become a ds eventually he started to make me a small part of some ds projects running queries building dashboards to track performance and things like that i was also a part of some of the meetings so i got some insight into how certain problems were approached my boss made me aware that i would need to teach myself to code and machine learning my role in the data science projects grew over time but i was ultimately blocked from becoming a ds because i kept trying and failing to learn to code and the areas of expertise reddit tells you that you need by taking moocs eventually i paid up for dataquest i naively thought the course would teach me everything i needed to know while you will not be proficient in anything ds upon completing the interactive format made it easy to jump into minutes of structured coding every day like a real language consistency is vital once i got to the point where i could do some basic coding i began my own side project this is the most important thing once you get the baseline knowledge just get started working on things this is where the real learning began youll screw things up and thats ok titanic problem is fine for day but you really need a project of your own i picked a project that i was interested in and had a function that i would personally use im on v of this project and its grown to a level that i never couldve dreamed of at the time this was crucial in ensuring that i stuck with the project and had real investment in doing it correctly when i didnt know how to do something in the project i would research it and figure it out this is how it works in the real world after months of dataquest and another of a project along with years of being a data analyst i convinced my boss to assign me ds project i worked alongside another data scientist but i owned the project and they were mostly there for guidance and coded some of the more complex things i excelled at that project and was promoted to data scientist and began getting projects of my own with less and less oversight we have a very collaborative work environment and the data scientists are truly out to help each other we present our progress to each other often which allows us all to learn and improve i have been promoted twice since i began ds work id like to add that you can almost certainly do all this in less time than it took me i wasted a lot of time spinning my wheels chatgpt is also a great resource that could also increase your learning speed dont blindly use it but its a great resource tldr sir this is wendys edit im not saying to never go deeper into things im literally always learning i go deeper into things all the time often in very niche domains but you dont need to be a master in all things get started or even excel be able to understand generalities of those domains and dig deeper when the problem calls for it learning a concept when you have a direct application is much more likely to stick i thought it went without saying but im not saying those things i listed are literally the only things you need to know about those topics i was just giving examples of where relatively simple concepts were way more important than specifics edit im not saying schooling is bad yes obviously having a masters andor phd is better than not im directing this to those who are working a full time job who want to break into the field but taking years getting a masters while working full time and going another k into debt is unrealistic,my data science manifesto from a self taught data scientist background im a selftaught data scientist with about years of data analyst experience and now about years as a data scientist im more math minded than the average person but im not special i have a bachelors degree in mechanical engineering and have worked alongside data scientists of which have phds and the other have a masters despite being probably the th out of in natural ability i have been the nd most productive data scientist out of the group gatekeeping every day someone on this subreddit asks some derivative of what do i need to know to get started in mlds the answers are always smug and give some insane list of courses and topics one must master as someone whos been on both sides this is attitude extremely annoying and rampart in the industry i dont think you can be bad at math and have no prerequisite knowledge and be successful but the levels needed are greatly exaggerated most of the people telling you these things are just posturing due to insecurity as a mechanical engineering student i had at least calculus courses a linear algebra course and a probability course but it was years before i attempted to become a ds and i didnt remember much at all this sub and others like it made me think i had to be an expert in all these topics and many more to even think about trying to become a data scientist when i started my journey i would take coding calculus stats linear algebra etc courses id take a course do ok in it and move onto the next thing however eventually id get defeated because i realized i couldnt remember much from the courses i took months prior it just felt like too much information for me to hold at a single time while working a fulltime job i never got started on actually solving problems because the internet and industry told me i needed to be an expert in all these things what you actually need the reality is of the time you only need a basic understanding of these topics projects often require a deeper dive into something else but thats a case by case basis and you figure that out as you go for calculus you dont need to know how to integrate multivariable functions by hand you need to know that derivatives create a function that represents the slope of the original function and that where the derivative is a local minmax you need to know integrals are area under the curve for stats you need to understand what a p value represents you dont need to know all the different tests and when to use them you need to know that they exist and why you need them when its time to use one just google it and figure out which one best suits your use case for linear algebra you dont need to know how to solve for eigenvectors by hand or whatever other specific things you do in that class you need to know how to read it it is also helpful to know properties of linear algebra like the cross product of vectors yields a vector perpendicular to both for probability you need to understand basic things but again just google your specific problem you dont need to be an expert software dev you need to write ok code and be able to use chatgpt to help you improve it little by little you dont need to know how to build all the algorithms by hand a general understanding of how they work is enough in of cases of all of those things the only thing you absolutely need to get started is basic coding ability by far the number one technical ability needed to master is understanding how to frame your problem and how to test and evaluate and interpret performance if you can ensure that youre accurately framing the problem and evaluating the model or alogithm with metrics that correctly align with the use case thats enough to start providing some real value i often see people asking things like should i do this feature engineering technique for this problem or which of these algorithms will perform best the answer should usually be i dont know try it measure it and see understanding how the algorithms work can give you clues into what you should try but at the end of the day you should just try it and see despite the posturing in the industry very few people are actually experts in all these domains some people are better at talking the talk than others but at the end of the day you will have to constantly research and learn on a project by project basis thats what makes it fun and interesting as you gain practical experience you will grow you will learn you will improve beyond what you couldve ever imagined just get the basics down and get started dont spin your wheels trying and failing to nail all these disciplines before ever applying anything the reason im near the top in productivity while being near the bottom in natural and technical ability is my years of experience as a data analyst at my company during this time i got really good at exploring my companies data when you are stumped on problem intelligently visualizing the data often reveals the solution ive also had the luxury of analyzing our data from all different perspectives id have assignments from marketing product tech support customer service software firmware and other technical teams i understand the complete company better than the other data scientists im also just aware of more tips and tricks than anyone else good domain knowledge and data exploration skills with average technical skills will outperform good technical skills with average domain knowledge and data exploration almost every time advice for those self taught ive been on the hiring side of things a few times now and the market is certainly difficult i think it would be very difficult for someone to online course and side project themselves directly into a ds job the side project would have to be extremely impressive to be considered however i think my path is repeatable i taught myself basic sql and tableau and completed a few side projects i accepted a job as a data analyst in a medium sized total employees on a team where ds and da shared the same boss the barrier to da is likely higher than it was years ago but its definitely something achievable my advice would be to find roles that you have some sort of unique experience with and tailor your resume to that connection no connection is too small for example my da role required working with a lot of accelerometer data in my previous job as a test engineer i sometimes helped set up accelerometers to record data from the tests this experience barely helped me at all when actually on the job but it helped my resume actually get looked at for entry level jobs employers are looking for any connection because most entry level resumes all look the same the first year or two i excelled at my role as a da i made my boss aware that i wanted to become a ds eventually he started to make me a small part of some ds projects running queries building dashboards to track performance and things like that i was also a part of some of the meetings so i got some insight into how certain problems were approached my boss made me aware that i would need to teach myself to code and machine learning my role in the data science projects grew over time but i was ultimately blocked from becoming a ds because i kept trying and failing to learn to code and the areas of expertise reddit tells you that you need by taking moocs eventually i paid up for dataquest i naively thought the course would teach me everything i needed to know while you will not be proficient in anything ds upon completing the interactive format made it easy to jump into minutes of structured coding every day like a real language consistency is vital once i got to the point where i could do some basic coding i began my own side project this is the most important thing once you get the baseline knowledge just get started working on things this is where the real learning began youll screw things up and thats ok titanic problem is fine for day but you really need a project of your own i picked a project that i was interested in and had a function that i would personally use im on v of this project and its grown to a level that i never couldve dreamed of at the time this was crucial in ensuring that i stuck with the project and had real investment in doing it correctly when i didnt know how to do something in the project i would research it and figure it out this is how it works in the real world after months of dataquest and another of a project along with years of being a data analyst i convinced my boss to assign me ds project i worked alongside another data scientist but i owned the project and they were mostly there for guidance and coded some of the more complex things i excelled at that project and was promoted to data scientist and began getting projects of my own with less and less oversight we have a very collaborative work environment and the data scientists are truly out to help each other we present our progress to each other often which allows us all to learn and improve i have been promoted twice since i began ds work id like to add that you can almost certainly do all this in less time than it took me i wasted a lot of time spinning my wheels chatgpt is also a great resource that could also increase your learning speed dont blindly use it but its a great resource tldr sir this is wendys edit im not saying to never go deeper into things im literally always learning i go deeper into things all the time often in very niche domains but you dont need to be a master in all things get started or even excel be able to understand generalities of those domains and dig deeper when the problem calls for it learning a concept when you have a direct application is much more likely to stick i thought it went without saying but im not saying those things i listed are literally the only things you need to know about those topics i was just giving examples of where relatively simple concepts were way more important than specifics edit im not saying schooling is bad yes obviously having a masters andor phd is better than not im directing this to those who are working a full time job who want to break into the field but taking years getting a masters while working full time and going another k into debt is unrealistic,"data, need, thing, project, know",2024-12-29 22:28:05,my data science manifesto from a self taught data scientist background im a selftaught data scientist with about years of data analyst experience and now about years as a data scientist im more math minded than the average person but im not special i have a bachelors degree in mechanical engineering and have worked alongside data scientists of which have phds and the other have a masters despite being probably the th out of in natural ability i have been the nd most productive data scientist out of the group gatekeeping every day someone on this subreddit asks some derivative of what do i need to know to get started in mlds the answers are always smug and give some insane list of courses and topics one must master as someone whos been on both sides this is attitude extremely annoying and rampart in the industry i dont think you can be bad at math and have no prerequisite knowledge and be successful but the levels needed are greatly exaggerated most of the people telling you these things are just posturing due to insecurity as a mechanical engineering student i had at least calculus courses a linear algebra course and a probability course but it was years before i attempted to become a ds and i didnt remember much at all this sub and others like it made me think i had to be an expert in all these topics and many more to even think about trying to become a data scientist when i started my journey i would take coding calculus stats linear algebra etc courses id take a course do ok in it and move onto the next thing however eventually id get defeated because i realized i couldnt remember much from the courses i took months prior it just felt like too much information for me to hold at a single time while working a fulltime job i never got started on actually solving problems because the internet and industry told me i needed to be an expert in all these things what you actually need the reality is of the time you only need a basic understanding of these topics projects often require a deeper dive into something else but thats a case by case basis and you figure that out as you go for calculus you dont need to know how to integrate multivariable functions by hand you need to know that derivatives create a function that represents the slope of the original function and that where the derivative is a local minmax you need to know integrals are area under the curve for stats you need to understand what a p value represents you dont need to know all the different tests and when to use them you need to know that they exist and why you need them when its time to use one just google it and figure out which one best suits your use case for linear algebra you dont need to know how to solve for eigenvectors by hand or whatever other specific things you do in that class you need to know how to read it it is also helpful to know properties of linear algebra like the cross product of vectors yields a vector perpendicular to both for probability you need to understand basic things but again just google your specific problem you dont need to be an expert software dev you need to write ok code and be able to use chatgpt to help you improve it little by little you dont need to know how to build all the algorithms by hand a general understanding of how they work is enough in of cases of all of those things the only thing you absolutely need to get started is basic coding ability by far the number one technical ability needed to master is understanding how to frame your problem and how to test and evaluate and interpret performance if you can ensure that youre accurately framing the problem and evaluating the model or alogithm with metrics that correctly align with the use case thats enough to start providing some real value i often see people asking things like should i do this feature engineering technique for this problem or which of these algorithms will perform best the answer should usually be i dont know try it measure it and see understanding how the algorithms work can give you clues into what you should try but at the end of the day you should just try it and see despite the posturing in the industry very few people are actually experts in all these domains some people are better at talking the talk than others but at the end of the day you will have to constantly research and learn on a project by project basis thats what makes it fun and interesting as you gain practical experience you will grow you will learn you will improve beyond what you couldve ever imagined just get the basics down and get started dont spin your wheels trying and failing to nail all these disciplines before ever applying anything the reason im near the top in productivity while being near the bottom in natural and technical ability is my years of experience as a data analyst at my company during this time i got really good at exploring my companies data when you are stumped on problem intelligently visualizing the data often reveals the solution ive also had the luxury of analyzing our data from all different perspectives id have assignments from marketing product tech support customer service software firmware and other technical teams i understand the complete company better than the other data scientists im also just aware of more tips and tricks than anyone else good domain knowledge and data exploration skills with average technical skills will outperform good technical skills with average domain knowledge and data exploration almost every time advice for those self taught ive been on the hiring side of things a few times now and the market is certainly difficult i think it would be very difficult for someone to online course and side project themselves directly into a ds job the side project would have to be extremely impressive to be considered however i think my path is repeatable i taught myself basic sql and tableau and completed a few side projects i accepted a job as a data analyst in a medium sized total employees on a team where ds and da shared the same boss the barrier to da is likely higher than it was years ago but its definitely something achievable my advice would be to find roles that you have some sort of unique experience with and tailor your resume to that connection no connection is too small for example my da role required working with a lot of accelerometer data in my previous job as a test engineer i sometimes helped set up accelerometers to record data from the tests this experience barely helped me at all when actually on the job but it helped my resume actually get looked at for entry level jobs employers are looking for any connection because most entry level resumes all look the same the first year or two i excelled at my role as a da i made my boss aware that i wanted to become a ds eventually he started to make me a small part of some ds projects running queries building dashboards to track performance and things like that i was also a part of some of the meetings so i got some insight into how certain problems were approached my boss made me aware that i would need to teach myself to code and machine learning my role in the data science projects grew over time but i was ultimately blocked from becoming a ds because i kept trying and failing to learn to code and the areas of expertise reddit tells you that you need by taking moocs eventually i paid up for dataquest i naively thought the course would teach me everything i needed to know while you will not be proficient in anything ds upon completing the interactive format made it easy to jump into minutes of structured coding every day like a real language consistency is vital once i got to the point where i could do some basic coding i began my own side project this is the most important thing once you get the baseline knowledge just get started working on things this is where the real learning began youll screw things up and thats ok titanic problem is fine for day but you really need a project of your own i picked a project that i was interested in and had a function that i would personally use im on v of this project and its grown to a level that i never couldve dreamed of at the time this was crucial in ensuring that i stuck with the project and had real investment in doing it correctly when i didnt know how to do something in the project i would research it and figure it out this is how it works in the real world after months of dataquest and another of a project along with years of being a data analyst i convinced my boss to assign me ds project i worked alongside another data scientist but i owned the project and they were mostly there for guidance and coded some of the more complex things i excelled at that project and was promoted to data scientist and began getting projects of my own with less and less oversight we have a very collaborative work environment and the data scientists are truly out to help each other we present our progress to each other often which allows us all to learn and improve i have been promoted twice since i began ds work id like to add that you can almost certainly do all this in less time than it took me i wasted a lot of time spinning my wheels chatgpt is also a great resource that could also increase your learning speed dont blindly use it but its a great resource tldr sir this is wendys edit im not saying to never go deeper into things im literally always learning i go deeper into things all the time often in very niche domains but you dont need to be a master in all things get started or even excel be able to understand generalities of those domains and dig deeper when the problem calls for it learning a concept when you have a direct application is much more likely to stick i thought it went without saying but im not saying those things i listed are literally the only things you need to know about those topics i was just giving examples of where relatively simple concepts were way more important than specifics edit im not saying schooling is bad yes obviously having a masters andor phd is better than not im directing this to those who are working a full time job who want to break into the field but taking years getting a masters while working full time and going another k into debt is unrealistic,"['data', 'science', 'manifesto', 'self', 'taught', 'data', 'scientist', 'background', 'selftaught', 'data', 'scientist', 'year', 'data', 'analyst', 'experience', 'year', 'data', 'scientist', 'math', 'minded', 'average', 'person', 'special', 'bachelor', 'degree', 'mechanical', 'engineering', 'worked', 'alongside', 'data', 'scientist', 'phd', 'master', 'despite', 'probably', 'natural', 'ability', 'productive', 'data', 'scientist', 'group', 'gatekeeping', 'every', 'day', 'someone', 'subreddit', 'asks', 'derivative', 'need', 'know', 'get', 'started', 'mlds', 'answer', 'always', 'smug', 'give', 'insane', 'list', 'course', 'topic', 'one', 'must', 'master', 'someone', 'who', 'side', 'attitude', 'extremely', 'annoying', 'rampart', 'industry', 'dont', 'think', 'bad', 'math', 'prerequisite', 'knowledge', 'successful', 'level', 'needed', 'greatly', 'exaggerated', 'people', 'telling', 'thing', 'posturing', 'due', 'insecurity', 'mechanical', 'engineering', 'student', 'least', 'calculus', 'course', 'linear', 'algebra', 'course', 'probability', 'course', 'year', 'attempted', 'become', 'didnt', 'remember', 'much', 'sub', 'others', 'like', 'made', 'think', 'expert', 'topic', 'many', 'even', 'think', 'trying', 'become', 'data', 'scientist', 'started', 'journey', 'would', 'take', 'coding', 'calculus', 'stats', 'linear', 'algebra', 'etc', 'course', 'take', 'course', 'move', 'onto', 'next', 'thing', 'however', 'eventually', 'get', 'defeated', 'realized', 'couldnt', 'remember', 'much', 'course', 'took', 'month', 'prior', 'felt', 'like', 'much', 'information', 'hold', 'single', 'time', 'working', 'fulltime', 'job', 'never', 'got', 'started', 'actually', 'solving', 'problem', 'internet', 'industry', 'told', 'needed', 'expert', 'thing', 'actually', 'need', 'reality', 'time', 'need', 'basic', 'understanding', 'topic', 'project', 'often', 'require', 'deeper', 'dive', 'something', 'else', 'thats', 'case', 'case', 'basis', 'figure', 'calculus', 'dont', 'need', 'know', 'integrate', 'multivariable', 'function', 'hand', 'need', 'know', 'derivative', 'create', 'function', 'represents', 'slope', 'original', 'function', 'derivative', 'local', 'minmax', 'need', 'know', 'integral', 'area', 'curve', 'stats', 'need', 'understand', 'value', 'represents', 'dont', 'need', 'know', 'different', 'test', 'use', 'need', 'know', 'exist', 'need', 'time', 'use', 'one', 'google', 'figure', 'one', 'best', 'suit', 'use', 'case', 'linear', 'algebra', 'dont', 'need', 'know', 'solve', 'eigenvectors', 'hand', 'whatever', 'specific', 'thing', 'class', 'need', 'know', 'read', 'also', 'helpful', 'know', 'property', 'linear', 'algebra', 'like', 'cross', 'product', 'vector', 'yield', 'vector', 'perpendicular', 'probability', 'need', 'understand', 'basic', 'thing', 'google', 'specific', 'problem', 'dont', 'need', 'expert', 'software', 'dev', 'need', 'write', 'code', 'able', 'use', 'chatgpt', 'help', 'improve', 'little', 'little', 'dont', 'need', 'know', 'build', 'algorithm', 'hand', 'general', 'understanding', 'work', 'enough', 'case', 'thing', 'thing', 'absolutely', 'need', 'get', 'started', 'basic', 'coding', 'ability', 'far', 'number', 'one', 'technical', 'ability', 'needed', 'master', 'understanding', 'frame', 'problem', 'test', 'evaluate', 'interpret', 'performance', 'ensure', 'youre', 'accurately', 'framing', 'problem', 'evaluating', 'model', 'alogithm', 'metric', 'correctly', 'align', 'use', 'case', 'thats', 'enough', 'start', 'providing', 'real', 'value', 'often', 'see', 'people', 'asking', 'thing', 'like', 'feature', 'engineering', 'technique', 'problem', 'algorithm', 'perform', 'best', 'answer', 'usually', 'dont', 'know', 'try', 'measure', 'see', 'understanding', 'algorithm', 'work', 'give', 'clue', 'try', 'end', 'day', 'try', 'see', 'despite', 'posturing', 'industry', 'people', 'actually', 'expert', 'domain', 'people', 'better', 'talking', 'talk', 'others', 'end', 'day', 'constantly', 'research', 'learn', 'project', 'project', 'basis', 'thats', 'make', 'fun', 'interesting', 'gain', 'practical', 'experience', 'grow', 'learn', 'improve', 'beyond', 'couldve', 'ever', 'imagined', 'get', 'basic', 'get', 'started', 'dont', 'spin', 'wheel', 'trying', 'failing', 'nail', 'discipline', 'ever', 'applying', 'anything', 'reason', 'near', 'top', 'productivity', 'near', 'bottom', 'natural', 'technical', 'ability', 'year', 'experience', 'data', 'analyst', 'company', 'time', 'got', 'really', 'good', 'exploring', 'company', 'data', 'stumped', 'problem', 'intelligently', 'visualizing', 'data', 'often', 'reveals', 'solution', 'ive', 'also', 'luxury', 'analyzing', 'data', 'different', 'perspective', 'assignment', 'marketing', 'product', 'tech', 'support', 'customer', 'service', 'software', 'firmware', 'technical', 'team', 'understand', 'complete', 'company', 'better', 'data', 'scientist', 'also', 'aware', 'tip', 'trick', 'anyone', 'else', 'good', 'domain', 'knowledge', 'data', 'exploration', 'skill', 'average', 'technical', 'skill', 'outperform', 'good', 'technical', 'skill', 'average', 'domain', 'knowledge', 'data', 'exploration', 'almost', 'every', 'time', 'advice', 'self', 'taught', 'ive', 'hiring', 'side', 'thing', 'time', 'market', 'certainly', 'difficult', 'think', 'would', 'difficult', 'someone', 'online', 'course', 'side', 'project', 'directly', 'job', 'side', 'project', 'would', 'extremely', 'impressive', 'considered', 'however', 'think', 'path', 'repeatable', 'taught', 'basic', 'sql', 'tableau', 'completed', 'side', 'project', 'accepted', 'job', 'data', 'analyst', 'medium', 'sized', 'total', 'employee', 'team', 'shared', 'bos', 'barrier', 'likely', 'higher', 'year', 'ago', 'definitely', 'something', 'achievable', 'advice', 'would', 'find', 'role', 'sort', 'unique', 'experience', 'tailor', 'resume', 'connection', 'connection', 'small', 'example', 'role', 'required', 'working', 'lot', 'accelerometer', 'data', 'previous', 'job', 'test', 'engineer', 'sometimes', 'helped', 'set', 'accelerometer', 'record', 'data', 'test', 'experience', 'barely', 'helped', 'actually', 'job', 'helped', 'resume', 'actually', 'get', 'looked', 'entry', 'level', 'job', 'employer', 'looking', 'connection', 'entry', 'level', 'resume', 'look', 'first', 'year', 'two', 'excelled', 'role', 'made', 'bos', 'aware', 'wanted', 'become', 'eventually', 'started', 'make', 'small', 'part', 'project', 'running', 'query', 'building', 'dashboard', 'track', 'performance', 'thing', 'like', 'also', 'part', 'meeting', 'got', 'insight', 'certain', 'problem', 'approached', 'bos', 'made', 'aware', 'would', 'need', 'teach', 'code', 'machine', 'learning', 'role', 'data', 'science', 'project', 'grew', 'time', 'ultimately', 'blocked', 'becoming', 'kept', 'trying', 'failing', 'learn', 'code', 'area', 'expertise', 'reddit', 'tell', 'need', 'taking', 'moocs', 'eventually', 'paid', 'dataquest', 'naively', 'thought', 'course', 'would', 'teach', 'everything', 'needed', 'know', 'proficient', 'anything', 'upon', 'completing', 'interactive', 'format', 'made', 'easy', 'jump', 'minute', 'structured', 'coding', 'every', 'day', 'like', 'real', 'language', 'consistency', 'vital', 'got', 'point', 'could', 'basic', 'coding', 'began', 'side', 'project', 'important', 'thing', 'get', 'baseline', 'knowledge', 'get', 'started', 'working', 'thing', 'real', 'learning', 'began', 'youll', 'screw', 'thing', 'thats', 'titanic', 'problem', 'fine', 'day', 'really', 'need', 'project', 'picked', 'project', 'interested', 'function', 'would', 'personally', 'use', 'project', 'grown', 'level', 'never', 'couldve', 'dreamed', 'time', 'crucial', 'ensuring', 'stuck', 'project', 'real', 'investment', 'correctly', 'didnt', 'know', 'something', 'project', 'would', 'research', 'figure', 'work', 'real', 'world', 'month', 'dataquest', 'another', 'project', 'along', 'year', 'data', 'analyst', 'convinced', 'bos', 'assign', 'project', 'worked', 'alongside', 'another', 'data', 'scientist', 'owned', 'project', 'mostly', 'guidance', 'coded', 'complex', 'thing', 'excelled', 'project', 'promoted', 'data', 'scientist', 'began', 'getting', 'project', 'less', 'less', 'oversight', 'collaborative', 'work', 'environment', 'data', 'scientist', 'truly', 'help', 'present', 'progress', 'often', 'allows', 'learn', 'improve', 'promoted', 'twice', 'since', 'began', 'work', 'like', 'add', 'almost', 'certainly', 'less', 'time', 'took', 'wasted', 'lot', 'time', 'spinning', 'wheel', 'chatgpt', 'also', 'great', 'resource', 'could', 'also', 'increase', 'learning', 'speed', 'dont', 'blindly', 'use', 'great', 'resource', 'tldr', 'sir', 'wendys', 'edit', 'saying', 'never', 'deeper', 'thing', 'literally', 'always', 'learning', 'deeper', 'thing', 'time', 'often', 'niche', 'domain', 'dont', 'need', 'master', 'thing', 'get', 'started', 'even', 'excel', 'able', 'understand', 'generality', 'domain', 'dig', 'deeper', 'problem', 'call', 'learning', 'concept', 'direct', 'application', 'much', 'likely', 'stick', 'thought', 'went', 'without', 'saying', 'saying', 'thing', 'listed', 'literally', 'thing', 'need', 'know', 'topic', 'giving', 'example', 'relatively', 'simple', 'concept', 'way', 'important', 'specific', 'edit', 'saying', 'schooling', 'bad', 'yes', 'obviously', 'master', 'andor', 'phd', 'better', 'directing', 'working', 'full', 'time', 'job', 'want', 'break', 'field', 'taking', 'year', 'getting', 'master', 'working', 'full', 'time', 'going', 'another', 'debt', 'unrealistic']",,,,
fvu3qu,Fit an exponential curve to anything...,,1586157028.0,2008.0,88.0,/r/datascience/comments/fvu3qu/fit_an_exponential_curve_to_anything/,https://i.redd.it/y9u0j7ggd5r41.png,JustGlowing,datascience,0.98,False,False,False,False,0.0,1745834607.777325,Tech & Programming,6.0,0.0,6.0,Monday,3.0,April,2020.0,False,0.3612,0.333,0.0,0.667,positive,fit an exponential curve to anything,,fit an exponential curve to anything ,"fit, exponential, curve, anything",2020-04-06 07:10:28,fit an exponential curve to anything ,"['fit', 'exponential', 'curve', 'anything']",,,,
g4jc29,The next time my coworkers ask what metrics I used for my model.,,1587344725.0,2007.0,64.0,/r/datascience/comments/g4jc29/the_next_time_my_coworkers_ask_what_metrics_i/,https://v.redd.it/ijncrmm5hvt41,shreddit47,datascience,0.98,False,False,False,False,1.0,1745834608.391916,Tech & Programming,13.0,0.0,13.0,Sunday,21.0,April,2020.0,True,0.0,0.0,0.0,1.0,neutral,the next time my coworkers ask what metrics i used for my model,,the next time my coworkers ask what metrics i used for my model ,"next, time, coworkers, ask, metric",2020-04-20 01:05:25,the next time my coworkers ask what metrics i used for my model ,"['next', 'time', 'coworkers', 'ask', 'metric', 'used', 'model']",,,,
ah0q69,:),,1547749323.0,1994.0,83.0,/r/datascience/comments/ah0q69/_/,https://i.redd.it/2qsivs4vz0b21.jpg,keymado,datascience,0.97,False,False,False,False,1.0,1745834608.845312,Tech & Programming,1.0,0.0,0.0,Thursday,13.0,January,2019.0,False,0.0,0.0,0.0,0.0,neutral,,, ,,2019-01-17 18:22:03, ,[],,,,
tq93vt,Data without context is noise! (With Zoom),,1648473464.0,1958.0,46.0,/r/datascience/comments/tq93vt/data_without_context_is_noise_with_zoom/,https://i.redd.it/k2lcid5ek4q81.jpg,Anxious_City_7864,datascience,0.98,False,False,False,False,0.0,1745834609.369149,Tech & Programming,7.0,0.0,7.0,Monday,9.0,March,2022.0,False,0.0,0.0,0.0,1.0,neutral,data without context is noise with zoom,,data without context is noise with zoom ,"data, without, context, noise, zoom",2022-03-28 13:17:44,data without context is noise with zoom ,"['data', 'without', 'context', 'noise', 'zoom']",,,,
ja54n9,Data Engineering,,1602557381.0,1921.0,47.0,/r/datascience/comments/ja54n9/data_engineering/,https://media.makeameme.org/created/we-should-take-bdc76d06df.jpg,Kickass_Wizard,datascience,0.97,False,False,False,False,0.0,1745834609.676005,Tech & Programming,2.0,0.0,2.0,Monday,22.0,October,2020.0,False,0.0,0.0,0.0,1.0,neutral,data engineering,,data engineering ,"data, engineering",2020-10-13 02:49:41,data engineering ,"['data', 'engineering']",,,,
eiiv4u,Beware of today's data,,1577888941.0,1905.0,49.0,/r/datascience/comments/eiiv4u/beware_of_todays_data/,https://i.redd.it/6mi8w52fg6841.jpg,postal__dude,datascience,0.96,False,False,False,False,0.0,1745834610.056311,Tech & Programming,4.0,0.0,4.0,Wednesday,9.0,January,2020.0,False,0.0,0.0,0.0,1.0,neutral,beware of todays data,,beware of todays data ,"beware, today, data",2020-01-01 14:29:01,beware of todays data ,"['beware', 'today', 'data']",,,,
vbcfpg,When you get your first DS role but they hit you with the mix.,,1655127515.0,1897.0,152.0,/r/datascience/comments/vbcfpg/when_you_get_your_first_ds_role_but_they_hit_you/,https://i.imgur.com/zQCpCOl.png,tits_mcgee_92,datascience,0.98,False,False,False,False,0.0,1745834610.417906,Tech & Programming,14.0,0.0,14.0,Monday,9.0,June,2022.0,False,0.0,0.0,0.0,1.0,neutral,when you get your first ds role but they hit you with the mix,,when you get your first ds role but they hit you with the mix ,"get, first, role, hit, mix",2022-06-13 13:38:35,when you get your first ds role but they hit you with the mix ,"['get', 'first', 'role', 'hit', 'mix']",,,,
mmzbgq,I just got offered a data science internship with Amazon. I've been lurking on the sub for 3 years and just wanted to thank the folks who put together stats/ml cheat sheets.,"This sub really motivated me to take my undergraduate degree in biomathematics/statistics and turn it into a masters in data science. I use to think I wouldn't have the programing background or that I wouldn't have the technical skills people wanted. It took a lot of my moving past my imposter syndrome as a woman in stem and working on my skill set but I've gotten this far. Thank you all so much.

Edit: Just came back to this post and saw all the support. For any one interested i have been applying since September to internships and have since then applied to 83 positions, reworked my resume twice, ended up making my own website for my projects just to look better on paper, and got 5 interviews at the end of March. I have gotten offers so far from every place I interviewed at and used the smaller offers to ask Amazon to give me a decision earlier, which ended up working. I only did 2 interviews with Amazon before I got my team and offer, which from reading online isn't common as they usually have a 3rd or 4th interview for interns. Its been a long process and a battle at every stage. Just 2 weeks ago I was resigned to the idea of a summer with no internship, but here we are now.",1617909736.0,1888.0,89.0,/r/datascience/comments/mmzbgq/i_just_got_offered_a_data_science_internship_with/,https://www.reddit.com/r/datascience/comments/mmzbgq/i_just_got_offered_a_data_science_internship_with/,BluntButter,datascience,0.97,True,False,False,False,1.0,1745834611.33162,Tech & Programming,32.0,226.0,253.0,Thursday,15.0,April,2021.0,False,0.8909,0.092,0.047,0.861,positive,i just got offered a data science internship with amazon ive been lurking on the sub for years and just wanted to thank the folks who put together statsml cheat sheets,this sub really motivated me to take my undergraduate degree in biomathematicsstatistics and turn it into a masters in data science i use to think i wouldnt have the programing background or that i wouldnt have the technical skills people wanted it took a lot of my moving past my imposter syndrome as a woman in stem and working on my skill set but ive gotten this far thank you all so much edit just came back to this post and saw all the support for any one interested i have been applying since september to internships and have since then applied to positions reworked my resume twice ended up making my own website for my projects just to look better on paper and got interviews at the end of march i have gotten offers so far from every place i interviewed at and used the smaller offers to ask amazon to give me a decision earlier which ended up working i only did interviews with amazon before i got my team and offer which from reading online isnt common as they usually have a rd or th interview for interns its been a long process and a battle at every stage just weeks ago i was resigned to the idea of a summer with no internship but here we are now,i just got offered a data science internship with amazon ive been lurking on the sub for years and just wanted to thank the folks who put together statsml cheat sheets this sub really motivated me to take my undergraduate degree in biomathematicsstatistics and turn it into a masters in data science i use to think i wouldnt have the programing background or that i wouldnt have the technical skills people wanted it took a lot of my moving past my imposter syndrome as a woman in stem and working on my skill set but ive gotten this far thank you all so much edit just came back to this post and saw all the support for any one interested i have been applying since september to internships and have since then applied to positions reworked my resume twice ended up making my own website for my projects just to look better on paper and got interviews at the end of march i have gotten offers so far from every place i interviewed at and used the smaller offers to ask amazon to give me a decision earlier which ended up working i only did interviews with amazon before i got my team and offer which from reading online isnt common as they usually have a rd or th interview for interns its been a long process and a battle at every stage just weeks ago i was resigned to the idea of a summer with no internship but here we are now,"got, internship, amazon, interview, offer",2021-04-08 19:22:16,i just got offered a data science internship with amazon ive been lurking on the sub for years and just wanted to thank the folks who put together statsml cheat sheets this sub really motivated me to take my undergraduate degree in biomathematicsstatistics and turn it into a masters in data science i use to think i wouldnt have the programing background or that i wouldnt have the technical skills people wanted it took a lot of my moving past my imposter syndrome as a woman in stem and working on my skill set but ive gotten this far thank you all so much edit just came back to this post and saw all the support for any one interested i have been applying since september to internships and have since then applied to positions reworked my resume twice ended up making my own website for my projects just to look better on paper and got interviews at the end of march i have gotten offers so far from every place i interviewed at and used the smaller offers to ask amazon to give me a decision earlier which ended up working i only did interviews with amazon before i got my team and offer which from reading online isnt common as they usually have a rd or th interview for interns its been a long process and a battle at every stage just weeks ago i was resigned to the idea of a summer with no internship but here we are now,"['got', 'offered', 'data', 'science', 'internship', 'amazon', 'ive', 'lurking', 'sub', 'year', 'wanted', 'thank', 'folk', 'put', 'together', 'statsml', 'cheat', 'sheet', 'sub', 'really', 'motivated', 'take', 'undergraduate', 'degree', 'biomathematicsstatistics', 'turn', 'master', 'data', 'science', 'use', 'think', 'wouldnt', 'programing', 'background', 'wouldnt', 'technical', 'skill', 'people', 'wanted', 'took', 'lot', 'moving', 'past', 'imposter', 'syndrome', 'woman', 'stem', 'working', 'skill', 'set', 'ive', 'gotten', 'far', 'thank', 'much', 'edit', 'came', 'back', 'post', 'saw', 'support', 'one', 'interested', 'applying', 'since', 'september', 'internship', 'since', 'applied', 'position', 'reworked', 'resume', 'twice', 'ended', 'making', 'website', 'project', 'look', 'better', 'paper', 'got', 'interview', 'end', 'march', 'gotten', 'offer', 'far', 'every', 'place', 'interviewed', 'used', 'smaller', 'offer', 'ask', 'amazon', 'give', 'decision', 'earlier', 'ended', 'working', 'interview', 'amazon', 'got', 'team', 'offer', 'reading', 'online', 'isnt', 'common', 'usually', 'interview', 'intern', 'long', 'process', 'battle', 'every', 'stage', 'week', 'ago', 'resigned', 'idea', 'summer', 'internship']",,,,
zo5bwf,Offend a data scientist in one tweet,,1671280215.0,1880.0,161.0,/r/datascience/comments/zo5bwf/offend_a_data_scientist_in_one_tweet/,https://i.redd.it/t7n4hi55uh6a1.jpg,datasciencepro,datascience,0.94,False,False,False,False,0.0,1745834611.809117,Tech & Programming,7.0,0.0,7.0,Saturday,7.0,December,2022.0,True,-0.296,0.0,0.306,0.694,negative,offend a data scientist in one tweet,,offend a data scientist in one tweet ,"offend, data, scientist, one, tweet",2022-12-17 12:30:15,offend a data scientist in one tweet ,"['offend', 'data', 'scientist', 'one', 'tweet']",,,,
umse6v,"I got 4 Data Science job offers with salaries between $100k - $150k in a single week, and I have a degree in English Literature","I have 3 years experience as a Data Analyst and a certificate (not a degree) an online Data Science program. Those are pretty weak credentials, and I'm sure I'm not the only person with that kind of background that starts the job search thinking there's no chance anyone would ever hire me.

I wanted to share what worked for me, just in case it can work for anybody else.

Basically, it's this:

**Treat the job interview like you're selling a service**

What worked for me was to stop thinking of it as a job interview.

Instead, imagine that you're the sales rep for a Data company answering an RFP. A client has a problem and they need a solution. You're just there to demonstrate that you can implement it.

Try to figure out what problem they're trying to solve with this role before the interview begins. That might be something like: ""We have data but we don't know how to get meaning out of it"" or ""We need to re-architect our data"" or even just: ""We have a guy who does a great job, but we need two of him.""

Center everything you say around the key message of: ""I know what your problem is and I know how to solve it.""

When they ask you to tell them about yourself:

1. Focus your answer on demonstrating that you have experience solving problems like theirs
2. Wrap it up by saying you were interested in the job because you got the impression that they need that problem solved, and you have a lot of experience solving that problem
3. Ask the interviewer if you're on the right about what problem they need solved

It's fine if you've totally misread the company. The point is that, when you ask that question, early in the interview, you force the interviewer to explain what they want the person who takes the role to be able to do.

It also switches the whole dynamic of the interview. Instead of them asking you questions, it's now about you troubleshooting that problem.

Respond by:

1. Asking clarifying questions about the problem they have
2. Explaining how you would approach the problem
3. Describing past similar projects you've worked on and how you solved them
4. Highlighting the business impact of your solutions

Doing this made a *massive* difference in my job search. I didn't hear back from any job I applied to until I tried this approach, but I heard back from everybody after I did.",1652215748.0,1861.0,288.0,/r/datascience/comments/umse6v/i_got_4_data_science_job_offers_with_salaries/,https://www.reddit.com/r/datascience/comments/umse6v/i_got_4_data_science_job_offers_with_salaries/,takenorinvalid,datascience,0.95,True,False,False,False,0.0,1745834612.574003,Tech & Programming,25.0,420.0,435.0,Tuesday,16.0,May,2022.0,False,0.8866,0.124,0.086,0.79,positive,i got data science job offers with salaries between k k in a single week and i have a degree in english literature,i have years experience as a data analyst and a certificate not a degree an online data science program those are pretty weak credentials and im sure im not the only person with that kind of background that starts the job search thinking theres no chance anyone would ever hire me i wanted to share what worked for me just in case it can work for anybody else basically its this treat the job interview like youre selling a service what worked for me was to stop thinking of it as a job interview instead imagine that youre the sales rep for a data company answering an rfp a client has a problem and they need a solution youre just there to demonstrate that you can implement it try to figure out what problem theyre trying to solve with this role before the interview begins that might be something like we have data but we dont know how to get meaning out of it or we need to rearchitect our data or even just we have a guy who does a great job but we need two of him center everything you say around the key message of i know what your problem is and i know how to solve it when they ask you to tell them about yourself focus your answer on demonstrating that you have experience solving problems like theirs wrap it up by saying you were interested in the job because you got the impression that they need that problem solved and you have a lot of experience solving that problem ask the interviewer if youre on the right about what problem they need solved its fine if youve totally misread the company the point is that when you ask that question early in the interview you force the interviewer to explain what they want the person who takes the role to be able to do it also switches the whole dynamic of the interview instead of them asking you questions its now about you troubleshooting that problem respond by asking clarifying questions about the problem they have explaining how you would approach the problem describing past similar projects youve worked on and how you solved them highlighting the business impact of your solutions doing this made a massive difference in my job search i didnt hear back from any job i applied to until i tried this approach but i heard back from everybody after i did,i got data science job offers with salaries between k k in a single week and i have a degree in english literature i have years experience as a data analyst and a certificate not a degree an online data science program those are pretty weak credentials and im sure im not the only person with that kind of background that starts the job search thinking theres no chance anyone would ever hire me i wanted to share what worked for me just in case it can work for anybody else basically its this treat the job interview like youre selling a service what worked for me was to stop thinking of it as a job interview instead imagine that youre the sales rep for a data company answering an rfp a client has a problem and they need a solution youre just there to demonstrate that you can implement it try to figure out what problem theyre trying to solve with this role before the interview begins that might be something like we have data but we dont know how to get meaning out of it or we need to rearchitect our data or even just we have a guy who does a great job but we need two of him center everything you say around the key message of i know what your problem is and i know how to solve it when they ask you to tell them about yourself focus your answer on demonstrating that you have experience solving problems like theirs wrap it up by saying you were interested in the job because you got the impression that they need that problem solved and you have a lot of experience solving that problem ask the interviewer if youre on the right about what problem they need solved its fine if youve totally misread the company the point is that when you ask that question early in the interview you force the interviewer to explain what they want the person who takes the role to be able to do it also switches the whole dynamic of the interview instead of them asking you questions its now about you troubleshooting that problem respond by asking clarifying questions about the problem they have explaining how you would approach the problem describing past similar projects youve worked on and how you solved them highlighting the business impact of your solutions doing this made a massive difference in my job search i didnt hear back from any job i applied to until i tried this approach but i heard back from everybody after i did,"problem, job, data, interview, need",2022-05-10 20:49:08,i got data science job offers with salaries between k k in a single week and i have a degree in english literature i have years experience as a data analyst and a certificate not a degree an online data science program those are pretty weak credentials and im sure im not the only person with that kind of background that starts the job search thinking theres no chance anyone would ever hire me i wanted to share what worked for me just in case it can work for anybody else basically its this treat the job interview like youre selling a service what worked for me was to stop thinking of it as a job interview instead imagine that youre the sales rep for a data company answering an rfp a client has a problem and they need a solution youre just there to demonstrate that you can implement it try to figure out what problem theyre trying to solve with this role before the interview begins that might be something like we have data but we dont know how to get meaning out of it or we need to rearchitect our data or even just we have a guy who does a great job but we need two of him center everything you say around the key message of i know what your problem is and i know how to solve it when they ask you to tell them about yourself focus your answer on demonstrating that you have experience solving problems like theirs wrap it up by saying you were interested in the job because you got the impression that they need that problem solved and you have a lot of experience solving that problem ask the interviewer if youre on the right about what problem they need solved its fine if youve totally misread the company the point is that when you ask that question early in the interview you force the interviewer to explain what they want the person who takes the role to be able to do it also switches the whole dynamic of the interview instead of them asking you questions its now about you troubleshooting that problem respond by asking clarifying questions about the problem they have explaining how you would approach the problem describing past similar projects youve worked on and how you solved them highlighting the business impact of your solutions doing this made a massive difference in my job search i didnt hear back from any job i applied to until i tried this approach but i heard back from everybody after i did,"['got', 'data', 'science', 'job', 'offer', 'salary', 'single', 'week', 'degree', 'english', 'literature', 'year', 'experience', 'data', 'analyst', 'certificate', 'degree', 'online', 'data', 'science', 'program', 'pretty', 'weak', 'credential', 'sure', 'person', 'kind', 'background', 'start', 'job', 'search', 'thinking', 'there', 'chance', 'anyone', 'would', 'ever', 'hire', 'wanted', 'share', 'worked', 'case', 'work', 'anybody', 'else', 'basically', 'treat', 'job', 'interview', 'like', 'youre', 'selling', 'service', 'worked', 'stop', 'thinking', 'job', 'interview', 'instead', 'imagine', 'youre', 'sale', 'rep', 'data', 'company', 'answering', 'rfp', 'client', 'problem', 'need', 'solution', 'youre', 'demonstrate', 'implement', 'try', 'figure', 'problem', 'theyre', 'trying', 'solve', 'role', 'interview', 'begin', 'might', 'something', 'like', 'data', 'dont', 'know', 'get', 'meaning', 'need', 'rearchitect', 'data', 'even', 'guy', 'great', 'job', 'need', 'two', 'center', 'everything', 'say', 'around', 'key', 'message', 'know', 'problem', 'know', 'solve', 'ask', 'tell', 'focus', 'answer', 'demonstrating', 'experience', 'solving', 'problem', 'like', 'wrap', 'saying', 'interested', 'job', 'got', 'impression', 'need', 'problem', 'solved', 'lot', 'experience', 'solving', 'problem', 'ask', 'interviewer', 'youre', 'right', 'problem', 'need', 'solved', 'fine', 'youve', 'totally', 'misread', 'company', 'point', 'ask', 'question', 'early', 'interview', 'force', 'interviewer', 'explain', 'want', 'person', 'take', 'role', 'able', 'also', 'switch', 'whole', 'dynamic', 'interview', 'instead', 'asking', 'question', 'troubleshooting', 'problem', 'respond', 'asking', 'clarifying', 'question', 'problem', 'explaining', 'would', 'approach', 'problem', 'describing', 'past', 'similar', 'project', 'youve', 'worked', 'solved', 'highlighting', 'business', 'impact', 'solution', 'made', 'massive', 'difference', 'job', 'search', 'didnt', 'hear', 'back', 'job', 'applied', 'tried', 'approach', 'heard', 'back', 'everybody']",,,,
w2282t,Thank you to the recruiters that define Data Science as building pretty visualizations and querying some,,1658158252.0,1851.0,123.0,/r/datascience/comments/w2282t/thank_you_to_the_recruiters_that_define_data/,https://i.imgur.com/ETKlQcd.png,tits_mcgee_92,datascience,0.96,False,False,False,False,0.0,1745834614.022431,Tech & Programming,16.0,0.0,16.0,Monday,11.0,July,2022.0,False,0.6908,0.289,0.0,0.711,positive,thank you to the recruiters that define data science as building pretty visualizations and querying some,,thank you to the recruiters that define data science as building pretty visualizations and querying some ,"thank, recruiter, define, data, science",2022-07-18 15:30:52,thank you to the recruiters that define data science as building pretty visualizations and querying some ,"['thank', 'recruiter', 'define', 'data', 'science', 'building', 'pretty', 'visualization', 'querying']",,,,
da5mhe,Found this,,1569614141.0,1835.0,42.0,/r/datascience/comments/da5mhe/found_this/,https://i.redd.it/itul8iw6z6p31.jpg,Sir-_-Butters22,datascience,0.99,False,False,False,False,0.0,1745834614.974774,Tech & Programming,2.0,0.0,2.0,Friday,15.0,September,2019.0,False,0.0,0.0,0.0,1.0,neutral,found this,,found this ,found,2019-09-27 19:55:41,found this ,['found'],,,,
1dsnbww,"You're not helping, Excel! please STOP HELPING!!!",,1719819987.0,1814.0,152.0,/r/datascience/comments/1dsnbww/youre_not_helping_excel_please_stop_helping/,https://i.redd.it/ccxo0ajs3v9d1.jpeg,BdR76,datascience,0.97,False,False,False,False,0.0,1745834615.380509,Tech & Programming,7.0,0.0,7.0,Monday,3.0,July,2024.0,False,-0.8135,0.0,0.839,0.161,negative,youre not helping excel please stop helping,,youre not helping excel please stop helping ,"helping, youre, excel, please, stop",2024-07-01 07:46:27,youre not helping excel please stop helping ,"['youre', 'helping', 'excel', 'please', 'stop', 'helping']",,,,
tag8l5,My Guide To Writing A Killer Cover Letter,"Most people think a cover letter is about themselves. This isn’t true.

A cover letter is a marketing tool. Treat it like one and you’ll see it do wonders. Treat it like an autobiography and you’ll wonder why no one gets back to you.

Here’s the cover letter formula that got me my current job:

1. **Analyzing the job description**
2. **Identifying what to include in your cover letter**
3. **Why do you want to work here?**
4. **Writing the cover letter**

**Before we get started:** this is a long post (\~3000 words). If you'd rather get a free PDF copy of it, feel free to [drop your email](https://www.careerfair.io/subscribe) here and I'll be sending it next week. 

**1/ Analyzing the job description**

Always write a cover letter from scratch. It's better to apply for five relevant positions with a complementing cover letter than to apply for fifty positions without any background research.

The best way to do this is to start by analyzing the job description.

A job description is composed of two parts:

1. What you’ll do
2. What the company is looking for (i.e qualifications)

First, focus on the “what you’ll do” portion. The first few bullets are the most important. And we need to make sure that they’re addressed in our cover letter. Start highlighting the ones you have experience carrying out.

https://preview.redd.it/pbakyc28yem81.png?width=2600&format=png&auto=webp&s=ee3a2be51ee0c9d009f81068868ee28064271904

Next, take a look at the qualifications. Note down the ones you can comfortably meet and ignore any you don’t. We also want to highlight the ‘preferred’ or ‘nice-to-have’ items listed in the job posting if you satisfy those.

*Quick note: Qualifications are always negotiable and should never deter you from applying if you think you’re almost there but missing a few requirements.*

https://preview.redd.it/s1yfj6n9yem81.png?width=3424&format=png&auto=webp&s=282abefe6281837a26d748131dbb9aca1daba54d

Make sure to note all these skills you’ve highlighted in the job description down. We’re now ready to move onto our next step.

**2/ Identifying what to include in your cover letter**

Create a table with two columns. In the left column jot down the highlighted skills you identified in the above section. And now in the right column, start writing down how you can match up to the advertised qualifications.

Here’s an example for my latest role. Notice how I try to use as many of the same words as the job description:

https://preview.redd.it/xhalvb7byem81.png?width=3200&format=png&auto=webp&s=76992f4e46b66a259504c8fb0bcc2f1ec6fca3ab

For now, just put down the qualifications without any regard for style. Also, you don’t need qualifications for all the requirements. We’re only going to use the top two anyway.

Struggling to come up with qualifications? Try to ask your co-workers or peers about projects they’ve enjoyed working with you on. Keeping a [brag document](https://www.careerfair.io/reviews/howtobragatwork) can also be really helpful.

And try to speak the employer’s language. So if a job description mentions “QuickBooks,” don’t just say you’ve used “accounting software”.

**3/ Why do you want to work here?**

You’re a great fit for the role. Now you have to convince them that you want to work there.

Realize that this is just a research based question. If you do enough research, you will find information about the company that you can link back to your own interests and goals.

To help you do research, ask yourself the following questions:

* What is the company’s mission?
* What problem are they trying to solve?
* What’s the product?
* What’s unique about this company compared to its competitors?
* What are some policies or values that the company has that they feature on their homepage?
* Describe any of the organization’s community engagement projects or employee development programs.

A great place to find more info is to look at interviews that their founders or executives have done. Another is the company’s blog.

Once you’ve done your research, list out *why* you find each answer to the above questions appealing. What is it about rockets that appeals to you? Why is a video messaging platform one you can connect with?

And if you’ve been using their product, that enthusiasm will shine through. It’s not mandatory and it’s not even common, but when it does happen, you have a great reason for why you want to work at the company.

*Sidenote: I'm going to release a complete guide on researching companies before the interview soon. If you'd like to read that you can* [*subscribe*](https://www.careerfair.io/subscribe) *here* *and get it when it's released.*

**4/ Writing the cover letter**

We’re going to use the following format for your cover letter:

*(i) Who you are, what you want, and what you believe in.*

*(ii) Transition*

*(iii). Skill & Qualification Match*

*(vi) Why do you want to work there?*

*(v) Conclusion*

***(i) Who you are, what you want, and what you believe in***

Use the first one or two sentences to make some statements about who you are, what you want, and what you believe in. Here are some good examples:

https://preview.redd.it/7tjx90ueyem81.png?width=2600&format=png&auto=webp&s=7c769a4c46e74c14d1b52b995177237b3569ba76

Emphasize your strengths and also ideally mention something specific to the company.

***(ii) Transition***

I like to link the intro in my cover letter to the first skill-qualification match by having a summary statement and attaching it to a generic sentence:

https://preview.redd.it/65imjsigyem81.png?width=2600&format=png&auto=webp&s=edfa8b0ec98b32708cca1db7b2c56c1b46b6fde5

The first sentence summarizes what you will bring to the company. The second helps flow into the experiences you’re about to write about.

Mine would be:

*Over the last 12 months, I’ve helped my company generate over $X in revenue by leading meetings with executive leaders and also built a variety of web applications on the side.*

*And now I’m excited to continue my journey by contributing and growing at Adyen. There are three things that make me the perfect fit for this position:*

Here are some examples that differentiate weak and better summary statements:

https://preview.redd.it/2hssbb2iyem81.png?width=3200&format=png&auto=webp&s=09585eef6003225bfc97c0cd38d5dc122af93b0a

Avoid jargon and get specific. Half the words, twice the examples. Ideally with a few numbers sprinkled in.

*Quick Note: The summary statement is also great to add to the top of your Linkedin bio.*

***(ii) Skill & Qualification Match***

Go back to your table matching your qualifications to the requirements. Pick the two most important ones.

We’re going to link your qualifications to a theme. And then use that to transform your boring bullet points into exciting sentences.

Here are eight common interview story themes:

1. Leading People
2. Taking initiative
3. Affinity for challenging work
4. Affinity for different types of work
5. Affinity for specific work
6. Dealing with failure
7. Managing conflict
8. Driven by curiosity

Let's say we ended up with the below table when analyzing a specific job description.

https://preview.redd.it/5zl2adfkyem81.png?width=3200&format=png&auto=webp&s=da38789ff4180a422a237027d1dd4827993f1dca

And let’s take our first qualification:

*Conducted Feature-Mapping and Requirements Gathering sessions with prospective and existing clients to formulate Scope and Backlog. Responsible for managing and creating backlog, writing stories and acceptance criteria for all managed projects.*

Let’s figure out how we can link this to one of the interview story themes:

https://preview.redd.it/mikhhw0myem81.png?width=3200&format=png&auto=webp&s=8057bf24031ebb66a10d21aac45f5f5836bf6ed8

And here's another example:

https://preview.redd.it/otukv2rnyem81.png?width=3200&format=png&auto=webp&s=d242ebd6f3764b64ce49d530a8a22df03ddfad97

So what we’ve done here is abstracted some themes from this person’s actual qualifications.

I know this isn't super scientific. More themes than just one work for most qualifications. But the goal is to help you solidify the type of story you want to tell.

And now that you have your theme, you can use it to guide your body paragraphs using this format:

https://preview.redd.it/hkdahc9pyem81.png?width=3200&format=png&auto=webp&s=7003513dacbe9704ed3a8b8c430f1932d4d0706a

Some more examples:

https://preview.redd.it/cql1thksyem81.png?width=3200&format=png&auto=webp&s=663d5c64f7cc9d4e63fcd37fdf0bda1358ebbdfc

***(vi) Why do you want to work there?***

Pick your two most favorite aspects about the company that you already found when doing your research. I like to pick one value driven one and one industry or current topic related. If you use their product, though, that should be first on your list.

If you want to check out some examples for this, you can do that [here](https://careerfairss.s3.us-east-2.amazonaws.com/cover_letter_guide/Screenshot+2022-03-07+at+23.30.32.png), [here](https://careerfairss.s3.us-east-2.amazonaws.com/cover_letter_guide/Screenshot+2022-03-07+at+23.30.40.png), and [here](https://careerfairss.s3.us-east-2.amazonaws.com/cover_letter_guide/Screenshot+2022-03-07+at+23.30.48.png).

Now that you’ve got two reasons, it’s time to craft together a simple paragraph that weaves them together:

*Third, I’ve been following \[COMPANY\] for a couple of months now and I resonate with both the company’s values and its general direction. The \[Insert Value\] really stands out to me because \[Insert Reason\]. I also recently read that \[Insert topical reason\] and this appeals to me because \[Why it appeals to you\].*

Realize that this part is your chance to bring out what you like about the company. And if you can’t really think of anything, maybe you need to rethink why you’re actually applying.

***(vi) Conclusion***

Simply state what you want and why you want it:

*I think you’ll find that my experience is a really good fit for \[COMPANY\] and specifically this position. I’m ready to take my skills to the next level with your team and look forward to hearing back.*

*Thanks,*

*Your name*

**Putting it together**

Combing everything, here’s what my cover letter for my current job looked like:

https://preview.redd.it/i4whem84zem81.png?width=4236&format=png&auto=webp&s=60072e121835415cbfa0f3706c91ad2faad5b1bf

And voila. You now have all the tools to write a killer cover letter.

\*\*\*

**Credit**

Thanks for reading. There’s great information available on this topic out there. The Princeton University cover letter guide is good as is the University of Washington's. Any questions feel free to DM me too.

*I’d love for you to* [*subscribe*](https://www.careerfair.io/subscribe) *to my newsletter. Each week I spend 20 hours analyzing a tech career topic that’s going to help you level up. I share what I learnt in a 5 minute email report like this one.*

Over and out -

Shikhar",1646856194.0,1813.0,148.0,/r/datascience/comments/tag8l5/my_guide_to_writing_a_killer_cover_letter/,https://www.reddit.com/r/datascience/comments/tag8l5/my_guide_to_writing_a_killer_cover_letter/,ibsurvivors,datascience,0.98,True,False,False,False,0.0,1745834616.073168,Tech & Programming,8.0,1551.0,1515.0,Wednesday,15.0,March,2022.0,False,0.9996,0.156,0.029,0.814,positive,my guide to writing a killer cover letter,most people think a cover letter is about themselves this isnt true a cover letter is a marketing tool treat it like one and youll see it do wonders treat it like an autobiography and youll wonder why no one gets back to you heres the cover letter formula that got me my current job analyzing the job description identifying what to include in your cover letter why do you want to work here writing the cover letter before we get started this is a long post words if youd rather get a free pdf copy of it feel free to drop your email here and ill be sending it next week analyzing the job description always write a cover letter from scratch its better to apply for five relevant positions with a complementing cover letter than to apply for fifty positions without any background research the best way to do this is to start by analyzing the job description a job description is composed of two parts what youll do what the company is looking for ie qualifications first focus on the what youll do portion the first few bullets are the most important and we need to make sure that theyre addressed in our cover letter start highlighting the ones you have experience carrying out next take a look at the qualifications note down the ones you can comfortably meet and ignore any you dont we also want to highlight the preferred or nicetohave items listed in the job posting if you satisfy those quick note qualifications are always negotiable and should never deter you from applying if you think youre almost there but missing a few requirements make sure to note all these skills youve highlighted in the job description down were now ready to move onto our next step identifying what to include in your cover letter create a table with two columns in the left column jot down the highlighted skills you identified in the above section and now in the right column start writing down how you can match up to the advertised qualifications heres an example for my latest role notice how i try to use as many of the same words as the job description for now just put down the qualifications without any regard for style also you dont need qualifications for all the requirements were only going to use the top two anyway struggling to come up with qualifications try to ask your coworkers or peers about projects theyve enjoyed working with you on keeping a brag document can also be really helpful and try to speak the employers language so if a job description mentions quickbooks dont just say youve used accounting software why do you want to work here youre a great fit for the role now you have to convince them that you want to work there realize that this is just a research based question if you do enough research you will find information about the company that you can link back to your own interests and goals to help you do research ask yourself the following questions what is the companys mission what problem are they trying to solve whats the product whats unique about this company compared to its competitors what are some policies or values that the company has that they feature on their homepage describe any of the organizations community engagement projects or employee development programs a great place to find more info is to look at interviews that their founders or executives have done another is the companys blog once youve done your research list out why you find each answer to the above questions appealing what is it about rockets that appeals to you why is a video messaging platform one you can connect with and if youve been using their product that enthusiasm will shine through its not mandatory and its not even common but when it does happen you have a great reason for why you want to work at the company sidenote im going to release a complete guide on researching companies before the interview soon if youd like to read that you can subscribe here and get it when its released writing the cover letter were going to use the following format for your cover letter i who you are what you want and what you believe in ii transition iii skill qualification match vi why do you want to work there v conclusion i who you are what you want and what you believe in use the first one or two sentences to make some statements about who you are what you want and what you believe in here are some good examples emphasize your strengths and also ideally mention something specific to the company ii transition i like to link the intro in my cover letter to the first skillqualification match by having a summary statement and attaching it to a generic sentence the first sentence summarizes what you will bring to the company the second helps flow into the experiences youre about to write about mine would be over the last months ive helped my company generate over x in revenue by leading meetings with executive leaders and also built a variety of web applications on the side and now im excited to continue my journey by contributing and growing at adyen there are three things that make me the perfect fit for this position here are some examples that differentiate weak and better summary statements avoid jargon and get specific half the words twice the examples ideally with a few numbers sprinkled in quick note the summary statement is also great to add to the top of your linkedin bio ii skill qualification match go back to your table matching your qualifications to the requirements pick the two most important ones were going to link your qualifications to a theme and then use that to transform your boring bullet points into exciting sentences here are eight common interview story themes leading people taking initiative affinity for challenging work affinity for different types of work affinity for specific work dealing with failure managing conflict driven by curiosity lets say we ended up with the below table when analyzing a specific job description and lets take our first qualification conducted featuremapping and requirements gathering sessions with prospective and existing clients to formulate scope and backlog responsible for managing and creating backlog writing stories and acceptance criteria for all managed projects lets figure out how we can link this to one of the interview story themes and heres another example so what weve done here is abstracted some themes from this persons actual qualifications i know this isnt super scientific more themes than just one work for most qualifications but the goal is to help you solidify the type of story you want to tell and now that you have your theme you can use it to guide your body paragraphs using this format some more examples vi why do you want to work there pick your two most favorite aspects about the company that you already found when doing your research i like to pick one value driven one and one industry or current topic related if you use their product though that should be first on your list if you want to check out some examples for this you can do that here here and here now that youve got two reasons its time to craft together a simple paragraph that weaves them together third ive been following company for a couple of months now and i resonate with both the companys values and its general direction the insert value really stands out to me because insert reason i also recently read that insert topical reason and this appeals to me because why it appeals to you realize that this part is your chance to bring out what you like about the company and if you cant really think of anything maybe you need to rethink why youre actually applying vi conclusion simply state what you want and why you want it i think youll find that my experience is a really good fit for company and specifically this position im ready to take my skills to the next level with your team and look forward to hearing back thanks your name putting it together combing everything heres what my cover letter for my current job looked like and voila you now have all the tools to write a killer cover letter credit thanks for reading theres great information available on this topic out there the princeton university cover letter guide is good as is the university of washingtons any questions feel free to dm me too id love for you to subscribe to my newsletter each week i spend hours analyzing a tech career topic thats going to help you level up i share what i learnt in a minute email report like this one over and out shikhar,my guide to writing a killer cover letter most people think a cover letter is about themselves this isnt true a cover letter is a marketing tool treat it like one and youll see it do wonders treat it like an autobiography and youll wonder why no one gets back to you heres the cover letter formula that got me my current job analyzing the job description identifying what to include in your cover letter why do you want to work here writing the cover letter before we get started this is a long post words if youd rather get a free pdf copy of it feel free to drop your email here and ill be sending it next week analyzing the job description always write a cover letter from scratch its better to apply for five relevant positions with a complementing cover letter than to apply for fifty positions without any background research the best way to do this is to start by analyzing the job description a job description is composed of two parts what youll do what the company is looking for ie qualifications first focus on the what youll do portion the first few bullets are the most important and we need to make sure that theyre addressed in our cover letter start highlighting the ones you have experience carrying out next take a look at the qualifications note down the ones you can comfortably meet and ignore any you dont we also want to highlight the preferred or nicetohave items listed in the job posting if you satisfy those quick note qualifications are always negotiable and should never deter you from applying if you think youre almost there but missing a few requirements make sure to note all these skills youve highlighted in the job description down were now ready to move onto our next step identifying what to include in your cover letter create a table with two columns in the left column jot down the highlighted skills you identified in the above section and now in the right column start writing down how you can match up to the advertised qualifications heres an example for my latest role notice how i try to use as many of the same words as the job description for now just put down the qualifications without any regard for style also you dont need qualifications for all the requirements were only going to use the top two anyway struggling to come up with qualifications try to ask your coworkers or peers about projects theyve enjoyed working with you on keeping a brag document can also be really helpful and try to speak the employers language so if a job description mentions quickbooks dont just say youve used accounting software why do you want to work here youre a great fit for the role now you have to convince them that you want to work there realize that this is just a research based question if you do enough research you will find information about the company that you can link back to your own interests and goals to help you do research ask yourself the following questions what is the companys mission what problem are they trying to solve whats the product whats unique about this company compared to its competitors what are some policies or values that the company has that they feature on their homepage describe any of the organizations community engagement projects or employee development programs a great place to find more info is to look at interviews that their founders or executives have done another is the companys blog once youve done your research list out why you find each answer to the above questions appealing what is it about rockets that appeals to you why is a video messaging platform one you can connect with and if youve been using their product that enthusiasm will shine through its not mandatory and its not even common but when it does happen you have a great reason for why you want to work at the company sidenote im going to release a complete guide on researching companies before the interview soon if youd like to read that you can subscribe here and get it when its released writing the cover letter were going to use the following format for your cover letter i who you are what you want and what you believe in ii transition iii skill qualification match vi why do you want to work there v conclusion i who you are what you want and what you believe in use the first one or two sentences to make some statements about who you are what you want and what you believe in here are some good examples emphasize your strengths and also ideally mention something specific to the company ii transition i like to link the intro in my cover letter to the first skillqualification match by having a summary statement and attaching it to a generic sentence the first sentence summarizes what you will bring to the company the second helps flow into the experiences youre about to write about mine would be over the last months ive helped my company generate over x in revenue by leading meetings with executive leaders and also built a variety of web applications on the side and now im excited to continue my journey by contributing and growing at adyen there are three things that make me the perfect fit for this position here are some examples that differentiate weak and better summary statements avoid jargon and get specific half the words twice the examples ideally with a few numbers sprinkled in quick note the summary statement is also great to add to the top of your linkedin bio ii skill qualification match go back to your table matching your qualifications to the requirements pick the two most important ones were going to link your qualifications to a theme and then use that to transform your boring bullet points into exciting sentences here are eight common interview story themes leading people taking initiative affinity for challenging work affinity for different types of work affinity for specific work dealing with failure managing conflict driven by curiosity lets say we ended up with the below table when analyzing a specific job description and lets take our first qualification conducted featuremapping and requirements gathering sessions with prospective and existing clients to formulate scope and backlog responsible for managing and creating backlog writing stories and acceptance criteria for all managed projects lets figure out how we can link this to one of the interview story themes and heres another example so what weve done here is abstracted some themes from this persons actual qualifications i know this isnt super scientific more themes than just one work for most qualifications but the goal is to help you solidify the type of story you want to tell and now that you have your theme you can use it to guide your body paragraphs using this format some more examples vi why do you want to work there pick your two most favorite aspects about the company that you already found when doing your research i like to pick one value driven one and one industry or current topic related if you use their product though that should be first on your list if you want to check out some examples for this you can do that here here and here now that youve got two reasons its time to craft together a simple paragraph that weaves them together third ive been following company for a couple of months now and i resonate with both the companys values and its general direction the insert value really stands out to me because insert reason i also recently read that insert topical reason and this appeals to me because why it appeals to you realize that this part is your chance to bring out what you like about the company and if you cant really think of anything maybe you need to rethink why youre actually applying vi conclusion simply state what you want and why you want it i think youll find that my experience is a really good fit for company and specifically this position im ready to take my skills to the next level with your team and look forward to hearing back thanks your name putting it together combing everything heres what my cover letter for my current job looked like and voila you now have all the tools to write a killer cover letter credit thanks for reading theres great information available on this topic out there the princeton university cover letter guide is good as is the university of washingtons any questions feel free to dm me too id love for you to subscribe to my newsletter each week i spend hours analyzing a tech career topic thats going to help you level up i share what i learnt in a minute email report like this one over and out shikhar,"cover, letter, company, want, qualification",2022-03-09 20:03:14,my guide to writing a killer cover letter most people think a cover letter is about themselves this isnt true a cover letter is a marketing tool treat it like one and youll see it do wonders treat it like an autobiography and youll wonder why no one gets back to you heres the cover letter formula that got me my current job analyzing the job description identifying what to include in your cover letter why do you want to work here writing the cover letter before we get started this is a long post words if youd rather get a free pdf copy of it feel free to drop your email here and ill be sending it next week analyzing the job description always write a cover letter from scratch its better to apply for five relevant positions with a complementing cover letter than to apply for fifty positions without any background research the best way to do this is to start by analyzing the job description a job description is composed of two parts what youll do what the company is looking for ie qualifications first focus on the what youll do portion the first few bullets are the most important and we need to make sure that theyre addressed in our cover letter start highlighting the ones you have experience carrying out next take a look at the qualifications note down the ones you can comfortably meet and ignore any you dont we also want to highlight the preferred or nicetohave items listed in the job posting if you satisfy those quick note qualifications are always negotiable and should never deter you from applying if you think youre almost there but missing a few requirements make sure to note all these skills youve highlighted in the job description down were now ready to move onto our next step identifying what to include in your cover letter create a table with two columns in the left column jot down the highlighted skills you identified in the above section and now in the right column start writing down how you can match up to the advertised qualifications heres an example for my latest role notice how i try to use as many of the same words as the job description for now just put down the qualifications without any regard for style also you dont need qualifications for all the requirements were only going to use the top two anyway struggling to come up with qualifications try to ask your coworkers or peers about projects theyve enjoyed working with you on keeping a brag document can also be really helpful and try to speak the employers language so if a job description mentions quickbooks dont just say youve used accounting software why do you want to work here youre a great fit for the role now you have to convince them that you want to work there realize that this is just a research based question if you do enough research you will find information about the company that you can link back to your own interests and goals to help you do research ask yourself the following questions what is the companys mission what problem are they trying to solve whats the product whats unique about this company compared to its competitors what are some policies or values that the company has that they feature on their homepage describe any of the organizations community engagement projects or employee development programs a great place to find more info is to look at interviews that their founders or executives have done another is the companys blog once youve done your research list out why you find each answer to the above questions appealing what is it about rockets that appeals to you why is a video messaging platform one you can connect with and if youve been using their product that enthusiasm will shine through its not mandatory and its not even common but when it does happen you have a great reason for why you want to work at the company sidenote im going to release a complete guide on researching companies before the interview soon if youd like to read that you can subscribe here and get it when its released writing the cover letter were going to use the following format for your cover letter i who you are what you want and what you believe in ii transition iii skill qualification match vi why do you want to work there v conclusion i who you are what you want and what you believe in use the first one or two sentences to make some statements about who you are what you want and what you believe in here are some good examples emphasize your strengths and also ideally mention something specific to the company ii transition i like to link the intro in my cover letter to the first skillqualification match by having a summary statement and attaching it to a generic sentence the first sentence summarizes what you will bring to the company the second helps flow into the experiences youre about to write about mine would be over the last months ive helped my company generate over x in revenue by leading meetings with executive leaders and also built a variety of web applications on the side and now im excited to continue my journey by contributing and growing at adyen there are three things that make me the perfect fit for this position here are some examples that differentiate weak and better summary statements avoid jargon and get specific half the words twice the examples ideally with a few numbers sprinkled in quick note the summary statement is also great to add to the top of your linkedin bio ii skill qualification match go back to your table matching your qualifications to the requirements pick the two most important ones were going to link your qualifications to a theme and then use that to transform your boring bullet points into exciting sentences here are eight common interview story themes leading people taking initiative affinity for challenging work affinity for different types of work affinity for specific work dealing with failure managing conflict driven by curiosity lets say we ended up with the below table when analyzing a specific job description and lets take our first qualification conducted featuremapping and requirements gathering sessions with prospective and existing clients to formulate scope and backlog responsible for managing and creating backlog writing stories and acceptance criteria for all managed projects lets figure out how we can link this to one of the interview story themes and heres another example so what weve done here is abstracted some themes from this persons actual qualifications i know this isnt super scientific more themes than just one work for most qualifications but the goal is to help you solidify the type of story you want to tell and now that you have your theme you can use it to guide your body paragraphs using this format some more examples vi why do you want to work there pick your two most favorite aspects about the company that you already found when doing your research i like to pick one value driven one and one industry or current topic related if you use their product though that should be first on your list if you want to check out some examples for this you can do that here here and here now that youve got two reasons its time to craft together a simple paragraph that weaves them together third ive been following company for a couple of months now and i resonate with both the companys values and its general direction the insert value really stands out to me because insert reason i also recently read that insert topical reason and this appeals to me because why it appeals to you realize that this part is your chance to bring out what you like about the company and if you cant really think of anything maybe you need to rethink why youre actually applying vi conclusion simply state what you want and why you want it i think youll find that my experience is a really good fit for company and specifically this position im ready to take my skills to the next level with your team and look forward to hearing back thanks your name putting it together combing everything heres what my cover letter for my current job looked like and voila you now have all the tools to write a killer cover letter credit thanks for reading theres great information available on this topic out there the princeton university cover letter guide is good as is the university of washingtons any questions feel free to dm me too id love for you to subscribe to my newsletter each week i spend hours analyzing a tech career topic thats going to help you level up i share what i learnt in a minute email report like this one over and out shikhar,"['guide', 'writing', 'killer', 'cover', 'letter', 'people', 'think', 'cover', 'letter', 'isnt', 'true', 'cover', 'letter', 'marketing', 'tool', 'treat', 'like', 'one', 'youll', 'see', 'wonder', 'treat', 'like', 'autobiography', 'youll', 'wonder', 'one', 'get', 'back', 'here', 'cover', 'letter', 'formula', 'got', 'current', 'job', 'analyzing', 'job', 'description', 'identifying', 'include', 'cover', 'letter', 'want', 'work', 'writing', 'cover', 'letter', 'get', 'started', 'long', 'post', 'word', 'youd', 'rather', 'get', 'free', 'pdf', 'copy', 'feel', 'free', 'drop', 'email', 'ill', 'sending', 'next', 'week', 'analyzing', 'job', 'description', 'always', 'write', 'cover', 'letter', 'scratch', 'better', 'apply', 'five', 'relevant', 'position', 'complementing', 'cover', 'letter', 'apply', 'fifty', 'position', 'without', 'background', 'research', 'best', 'way', 'start', 'analyzing', 'job', 'description', 'job', 'description', 'composed', 'two', 'part', 'youll', 'company', 'looking', 'qualification', 'first', 'focus', 'youll', 'portion', 'first', 'bullet', 'important', 'need', 'make', 'sure', 'theyre', 'addressed', 'cover', 'letter', 'start', 'highlighting', 'one', 'experience', 'carrying', 'next', 'take', 'look', 'qualification', 'note', 'one', 'comfortably', 'meet', 'ignore', 'dont', 'also', 'want', 'highlight', 'preferred', 'nicetohave', 'item', 'listed', 'job', 'posting', 'satisfy', 'quick', 'note', 'qualification', 'always', 'negotiable', 'never', 'deter', 'applying', 'think', 'youre', 'almost', 'missing', 'requirement', 'make', 'sure', 'note', 'skill', 'youve', 'highlighted', 'job', 'description', 'ready', 'move', 'onto', 'next', 'step', 'identifying', 'include', 'cover', 'letter', 'create', 'table', 'two', 'column', 'left', 'column', 'jot', 'highlighted', 'skill', 'identified', 'section', 'right', 'column', 'start', 'writing', 'match', 'advertised', 'qualification', 'here', 'example', 'latest', 'role', 'notice', 'try', 'use', 'many', 'word', 'job', 'description', 'put', 'qualification', 'without', 'regard', 'style', 'also', 'dont', 'need', 'qualification', 'requirement', 'going', 'use', 'top', 'two', 'anyway', 'struggling', 'come', 'qualification', 'try', 'ask', 'coworkers', 'peer', 'project', 'theyve', 'enjoyed', 'working', 'keeping', 'brag', 'document', 'also', 'really', 'helpful', 'try', 'speak', 'employer', 'language', 'job', 'description', 'mention', 'quickbooks', 'dont', 'say', 'youve', 'used', 'accounting', 'software', 'want', 'work', 'youre', 'great', 'fit', 'role', 'convince', 'want', 'work', 'realize', 'research', 'based', 'question', 'enough', 'research', 'find', 'information', 'company', 'link', 'back', 'interest', 'goal', 'help', 'research', 'ask', 'following', 'question', 'company', 'mission', 'problem', 'trying', 'solve', 'whats', 'product', 'whats', 'unique', 'company', 'compared', 'competitor', 'policy', 'value', 'company', 'feature', 'homepage', 'describe', 'organization', 'community', 'engagement', 'project', 'employee', 'development', 'program', 'great', 'place', 'find', 'info', 'look', 'interview', 'founder', 'executive', 'done', 'another', 'company', 'blog', 'youve', 'done', 'research', 'list', 'find', 'answer', 'question', 'appealing', 'rocket', 'appeal', 'video', 'messaging', 'platform', 'one', 'connect', 'youve', 'using', 'product', 'enthusiasm', 'shine', 'mandatory', 'even', 'common', 'happen', 'great', 'reason', 'want', 'work', 'company', 'sidenote', 'going', 'release', 'complete', 'guide', 'researching', 'company', 'interview', 'soon', 'youd', 'like', 'read', 'subscribe', 'get', 'released', 'writing', 'cover', 'letter', 'going', 'use', 'following', 'format', 'cover', 'letter', 'want', 'believe', 'transition', 'iii', 'skill', 'qualification', 'match', 'want', 'work', 'conclusion', 'want', 'believe', 'use', 'first', 'one', 'two', 'sentence', 'make', 'statement', 'want', 'believe', 'good', 'example', 'emphasize', 'strength', 'also', 'ideally', 'mention', 'something', 'specific', 'company', 'transition', 'like', 'link', 'intro', 'cover', 'letter', 'first', 'skillqualification', 'match', 'summary', 'statement', 'attaching', 'generic', 'sentence', 'first', 'sentence', 'summarizes', 'bring', 'company', 'second', 'help', 'flow', 'experience', 'youre', 'write', 'mine', 'would', 'last', 'month', 'ive', 'helped', 'company', 'generate', 'revenue', 'leading', 'meeting', 'executive', 'leader', 'also', 'built', 'variety', 'web', 'application', 'side', 'excited', 'continue', 'journey', 'contributing', 'growing', 'adyen', 'three', 'thing', 'make', 'perfect', 'fit', 'position', 'example', 'differentiate', 'weak', 'better', 'summary', 'statement', 'avoid', 'jargon', 'get', 'specific', 'half', 'word', 'twice', 'example', 'ideally', 'number', 'sprinkled', 'quick', 'note', 'summary', 'statement', 'also', 'great', 'add', 'top', 'linkedin', 'bio', 'skill', 'qualification', 'match', 'back', 'table', 'matching', 'qualification', 'requirement', 'pick', 'two', 'important', 'one', 'going', 'link', 'qualification', 'theme', 'use', 'transform', 'boring', 'bullet', 'point', 'exciting', 'sentence', 'eight', 'common', 'interview', 'story', 'theme', 'leading', 'people', 'taking', 'initiative', 'affinity', 'challenging', 'work', 'affinity', 'different', 'type', 'work', 'affinity', 'specific', 'work', 'dealing', 'failure', 'managing', 'conflict', 'driven', 'curiosity', 'let', 'say', 'ended', 'table', 'analyzing', 'specific', 'job', 'description', 'let', 'take', 'first', 'qualification', 'conducted', 'featuremapping', 'requirement', 'gathering', 'session', 'prospective', 'existing', 'client', 'formulate', 'scope', 'backlog', 'responsible', 'managing', 'creating', 'backlog', 'writing', 'story', 'acceptance', 'criterion', 'managed', 'project', 'let', 'figure', 'link', 'one', 'interview', 'story', 'theme', 'here', 'another', 'example', 'weve', 'done', 'abstracted', 'theme', 'person', 'actual', 'qualification', 'know', 'isnt', 'super', 'scientific', 'theme', 'one', 'work', 'qualification', 'goal', 'help', 'solidify', 'type', 'story', 'want', 'tell', 'theme', 'use', 'guide', 'body', 'paragraph', 'using', 'format', 'example', 'want', 'work', 'pick', 'two', 'favorite', 'aspect', 'company', 'already', 'found', 'research', 'like', 'pick', 'one', 'value', 'driven', 'one', 'one', 'industry', 'current', 'topic', 'related', 'use', 'product', 'though', 'first', 'list', 'want', 'check', 'example', 'youve', 'got', 'two', 'reason', 'time', 'craft', 'together', 'simple', 'paragraph', 'weave', 'together', 'third', 'ive', 'following', 'company', 'couple', 'month', 'resonate', 'company', 'value', 'general', 'direction', 'insert', 'value', 'really', 'stand', 'insert', 'reason', 'also', 'recently', 'read', 'insert', 'topical', 'reason', 'appeal', 'appeal', 'realize', 'part', 'chance', 'bring', 'like', 'company', 'cant', 'really', 'think', 'anything', 'maybe', 'need', 'rethink', 'youre', 'actually', 'applying', 'conclusion', 'simply', 'state', 'want', 'want', 'think', 'youll', 'find', 'experience', 'really', 'good', 'fit', 'company', 'specifically', 'position', 'ready', 'take', 'skill', 'next', 'level', 'team', 'look', 'forward', 'hearing', 'back', 'thanks', 'name', 'putting', 'together', 'combing', 'everything', 'here', 'cover', 'letter', 'current', 'job', 'looked', 'like', 'voila', 'tool', 'write', 'killer', 'cover', 'letter', 'credit', 'thanks', 'reading', 'there', 'great', 'information', 'available', 'topic', 'princeton', 'university', 'cover', 'letter', 'guide', 'good', 'university', 'washington', 'question', 'feel', 'free', 'love', 'subscribe', 'newsletter', 'week', 'spend', 'hour', 'analyzing', 'tech', 'career', 'topic', 'thats', 'going', 'help', 'level', 'share', 'learnt', 'minute', 'email', 'report', 'like', 'one', 'shikhar']",,,,
cqffii,Expectation vs reality,,1565814706.0,1781.0,93.0,/r/datascience/comments/cqffii/expectation_vs_reality/,https://i.redd.it/4f71u8ti5hg31.jpg,da_chosen1,datascience,0.96,False,False,False,False,0.0,1745834616.956123,Tech & Programming,3.0,0.0,3.0,Wednesday,16.0,August,2019.0,False,0.0,0.0,0.0,1.0,neutral,expectation vs reality,,expectation vs reality ,"expectation, reality",2019-08-14 20:31:46,expectation vs reality ,"['expectation', 'reality']",,,,
orybjg,Me showing off a suspiciously well-performing model [OC],,1627304783.0,1773.0,27.0,/r/datascience/comments/orybjg/me_showing_off_a_suspiciously_wellperforming/,https://i.redd.it/u3ngf9tw2kd71.png,LudwigTheBear,datascience,0.98,False,False,False,False,0.0,1745834617.547564,Tech & Programming,8.0,0.0,8.0,Monday,9.0,July,2021.0,False,-0.4019,0.0,0.31,0.69,negative,me showing off a suspiciously wellperforming model oc,,me showing off a suspiciously wellperforming model oc ,"showing, suspiciously, wellperforming, model",2021-07-26 13:06:23,me showing off a suspiciously wellperforming model oc ,"['showing', 'suspiciously', 'wellperforming', 'model']",,,,
10y2rrx,Thoughts?,,1675968872.0,1724.0,188.0,/r/datascience/comments/10y2rrx/thoughts/,https://i.redd.it/l269tf8x39ha1.jpg,Gentlecriminal14,datascience,0.97,False,False,False,False,0.0,1745834640.76048,Tech & Programming,1.0,0.0,1.0,Thursday,13.0,February,2023.0,False,0.0,0.0,0.0,1.0,neutral,thoughts,,thoughts ,thought,2023-02-09 18:54:32,thoughts ,['thought'],,,,
179huzu,Meme Mondays,,1697493093.0,1701.0,110.0,/r/datascience/comments/179huzu/meme_mondays/,https://i.redd.it/zxdz4pm6ymub1.png,softwareitcounts,datascience,0.98,False,False,False,False,0.0,1745834641.544167,Tech & Programming,2.0,0.0,2.0,Monday,17.0,October,2023.0,False,0.0,0.0,0.0,1.0,neutral,meme mondays,,meme mondays ,"meme, monday",2023-10-16 21:51:33,meme mondays ,"['meme', 'monday']",,,,
1afgvv9,Friendly reminder not to work too hard. You'll just get fired,"The year just started and there are already over 50K layoffs. The latest one is UPS, including some data professionals at corporate. These are people who worked hard, built a career with the company over extremely long period of time, stayed loyal, 3% merit increases, worked extra hours because they believed that they were contributing to a better future for the company and themselves.... And they were laid off without a second thought for cost saving. Yeah, Because that makes so much sense, right? Record-breaking profits every year is an unattainable goal, and it's stupid that here in the USA, we are one of the only countries that keeps pushing for this while other countries are leaving us in the dust with their quality of life....


So just remember. If you're thinking about doing some overtime for free, or going above and beyond just for a pat on the back, don't do it. You only have so many years on Earth. Focus on your own life and prioritize yourself, always",1706704645.0,1705.0,204.0,/r/datascience/comments/1afgvv9/friendly_reminder_not_to_work_too_hard_youll_just/,https://www.reddit.com/r/datascience/comments/1afgvv9/friendly_reminder_not_to_work_too_hard_youll_just/,,datascience,0.93,True,False,False,False,0.0,1745834642.257352,Tech & Programming,11.0,170.0,180.0,Wednesday,7.0,January,2024.0,False,0.891,0.105,0.05,0.844,positive,friendly reminder not to work too hard youll just get fired,the year just started and there are already over k layoffs the latest one is ups including some data professionals at corporate these are people who worked hard built a career with the company over extremely long period of time stayed loyal merit increases worked extra hours because they believed that they were contributing to a better future for the company and themselves and they were laid off without a second thought for cost saving yeah because that makes so much sense right recordbreaking profits every year is an unattainable goal and its stupid that here in the usa we are one of the only countries that keeps pushing for this while other countries are leaving us in the dust with their quality of life so just remember if youre thinking about doing some overtime for free or going above and beyond just for a pat on the back dont do it you only have so many years on earth focus on your own life and prioritize yourself always,friendly reminder not to work too hard youll just get fired the year just started and there are already over k layoffs the latest one is ups including some data professionals at corporate these are people who worked hard built a career with the company over extremely long period of time stayed loyal merit increases worked extra hours because they believed that they were contributing to a better future for the company and themselves and they were laid off without a second thought for cost saving yeah because that makes so much sense right recordbreaking profits every year is an unattainable goal and its stupid that here in the usa we are one of the only countries that keeps pushing for this while other countries are leaving us in the dust with their quality of life so just remember if youre thinking about doing some overtime for free or going above and beyond just for a pat on the back dont do it you only have so many years on earth focus on your own life and prioritize yourself always,"year, hard, one, worked, company",2024-01-31 12:37:25,friendly reminder not to work too hard youll just get fired the year just started and there are already over k layoffs the latest one is ups including some data professionals at corporate these are people who worked hard built a career with the company over extremely long period of time stayed loyal merit increases worked extra hours because they believed that they were contributing to a better future for the company and themselves and they were laid off without a second thought for cost saving yeah because that makes so much sense right recordbreaking profits every year is an unattainable goal and its stupid that here in the usa we are one of the only countries that keeps pushing for this while other countries are leaving us in the dust with their quality of life so just remember if youre thinking about doing some overtime for free or going above and beyond just for a pat on the back dont do it you only have so many years on earth focus on your own life and prioritize yourself always,"['friendly', 'reminder', 'work', 'hard', 'youll', 'get', 'fired', 'year', 'started', 'already', 'layoff', 'latest', 'one', 'ups', 'including', 'data', 'professional', 'corporate', 'people', 'worked', 'hard', 'built', 'career', 'company', 'extremely', 'long', 'period', 'time', 'stayed', 'loyal', 'merit', 'increase', 'worked', 'extra', 'hour', 'believed', 'contributing', 'better', 'future', 'company', 'laid', 'without', 'second', 'thought', 'cost', 'saving', 'yeah', 'make', 'much', 'sense', 'right', 'recordbreaking', 'profit', 'every', 'year', 'unattainable', 'goal', 'stupid', 'usa', 'one', 'country', 'keep', 'pushing', 'country', 'leaving', 'dust', 'quality', 'life', 'remember', 'youre', 'thinking', 'overtime', 'free', 'going', 'beyond', 'pat', 'back', 'dont', 'many', 'year', 'earth', 'focus', 'life', 'prioritize', 'always']",,,,
ylfpqx,"Add it to the training set, Walmart",,1667511110.0,1692.0,53.0,/r/datascience/comments/ylfpqx/add_it_to_the_training_set_walmart/,https://i.redd.it/irkcbvz41tx91.jpg,ljh78,datascience,0.98,False,False,False,False,0.0,1745834643.271404,Tech & Programming,7.0,0.0,7.0,Thursday,17.0,November,2022.0,False,0.0,0.0,0.0,1.0,neutral,add it to the training set walmart,,add it to the training set walmart ,"add, training, set, walmart",2022-11-03 21:31:50,add it to the training set walmart ,"['add', 'training', 'set', 'walmart']",,,,
uls349,"When you tell people what you do for a living, but they don't think it's cool or ask any follow-up questions.",,1652105307.0,1699.0,131.0,/r/datascience/comments/uls349/when_you_tell_people_what_you_do_for_a_living_but/,https://i.imgur.com/MtE7xpH.png,tits_mcgee_92,datascience,0.94,False,False,False,False,0.0,1745834643.603425,Tech & Programming,21.0,0.0,21.0,Monday,10.0,May,2022.0,False,-0.3491,0.0,0.114,0.886,negative,when you tell people what you do for a living but they dont think its cool or ask any followup questions,,when you tell people what you do for a living but they dont think its cool or ask any followup questions ,"tell, people, living, dont, think",2022-05-09 14:08:27,when you tell people what you do for a living but they dont think its cool or ask any followup questions ,"['tell', 'people', 'living', 'dont', 'think', 'cool', 'ask', 'followup', 'question']",,,,
cb0gte,The formatting struggle.,,1562676698.0,1696.0,95.0,/r/datascience/comments/cb0gte/the_formatting_struggle/,https://i.redd.it/yjm3620my9931.jpg,postal__dude,datascience,0.95,False,False,False,False,0.0,1745834644.281372,Tech & Programming,3.0,0.0,3.0,Tuesday,8.0,July,2019.0,False,-0.3182,0.0,0.535,0.465,negative,the formatting struggle,,the formatting struggle ,"formatting, struggle",2019-07-09 12:51:38,the formatting struggle ,"['formatting', 'struggle']",,,,
ey8icu,Recruiters be like,,1580742782.0,1690.0,97.0,/r/datascience/comments/ey8icu/recruiters_be_like/,https://i.redd.it/j5mx9ulc6qe41.jpg,smurfin101,datascience,0.97,False,False,False,False,0.0,1745834644.884257,Tech & Programming,3.0,0.0,3.0,Monday,10.0,February,2020.0,False,0.3612,0.556,0.0,0.444,positive,recruiters be like,,recruiters be like ,"recruiter, like",2020-02-03 15:13:02,recruiters be like ,"['recruiter', 'like']",,,,
1jr1tsv,I dare someone to drop this into a stakeholder presentation,"From source: https://ustr.gov/issue-areas/reciprocal-tariff-calculations

> “Parameter values for ε and φ were selected. The price elasticity of import demand, ε, was set at 4… The elasticity of import prices with respect to tariffs, φ, is 0.25.“",1743735580.0,1679.0,136.0,/r/datascience/comments/1jr1tsv/i_dare_someone_to_drop_this_into_a_stakeholder/,https://i.redd.it/vanv2v55hqse1.jpeg,brianckeegan,datascience,0.98,False,False,False,False,0.0,1745834645.687023,Tech & Programming,10.0,35.0,41.0,Thursday,22.0,April,2025.0,False,0.4939,0.144,0.089,0.767,positive,i dare someone to drop this into a stakeholder presentation,from source parameter values for ε and φ were selected the price elasticity of import demand ε was set at the elasticity of import prices with respect to tariffs φ is,i dare someone to drop this into a stakeholder presentation from source parameter values for ε and φ were selected the price elasticity of import demand ε was set at the elasticity of import prices with respect to tariffs φ is,"price, elasticity, import, dare, someone",2025-04-04 02:59:40,i dare someone to drop this into a stakeholder presentation from source parameter values for ε and φ were selected the price elasticity of import demand ε was set at the elasticity of import prices with respect to tariffs φ is,"['dare', 'someone', 'drop', 'stakeholder', 'presentation', 'source', 'parameter', 'value', 'selected', 'price', 'elasticity', 'import', 'demand', 'set', 'elasticity', 'import', 'price', 'respect', 'tariff']",,,,
e9cdf3,"When you get an Excel Sheet of 1000x5 and your clients ask you to do ""Data Science"" on this with ""AI""",,1576094988.0,1682.0,232.0,/r/datascience/comments/e9cdf3/when_you_get_an_excel_sheet_of_1000x5_and_your/,https://i.redd.it/hl8wcciu92441.jpg,Roger20Federer,datascience,0.97,False,False,False,False,0.0,1745834646.265985,Tech & Programming,21.0,0.0,21.0,Wednesday,15.0,December,2019.0,False,0.4588,0.136,0.0,0.864,positive,when you get an excel sheet of x and your clients ask you to do data science on this with ai,,when you get an excel sheet of x and your clients ask you to do data science on this with ai ,"get, excel, sheet, client, ask",2019-12-11 20:09:48,when you get an excel sheet of x and your clients ask you to do data science on this with ai ,"['get', 'excel', 'sheet', 'client', 'ask', 'data', 'science']",,,,
qbnf3s,Today’s edition of unreasonable job descriptions…,,1634684935.0,1672.0,247.0,/r/datascience/comments/qbnf3s/todays_edition_of_unreasonable_job_descriptions/,https://i.redd.it/x772dpg2ohu71.jpg,,datascience,0.99,False,False,False,False,0.0,1745834647.508691,Tech & Programming,6.0,0.0,6.0,Tuesday,19.0,October,2021.0,False,0.0,0.0,0.0,1.0,neutral,todays edition of unreasonable job descriptions,,todays edition of unreasonable job descriptions ,"today, edition, unreasonable, job, description",2021-10-19 23:08:55,todays edition of unreasonable job descriptions ,"['today', 'edition', 'unreasonable', 'job', 'description']",,,,
tq5i58,When you raise your polynomial to a degree of 11 in excel and get an R^2 of 0.99,,1648460039.0,1645.0,44.0,/r/datascience/comments/tq5i58/when_you_raise_your_polynomial_to_a_degree_of_11/,https://i.redd.it/qi0ufe42g3q81.png,Steingar,datascience,0.96,False,False,False,False,0.0,1745834648.69588,Tech & Programming,18.0,0.0,16.0,Monday,5.0,March,2022.0,False,0.4588,0.188,0.0,0.812,positive,when you raise your polynomial to a degree of in excel and get an r of,,when you raise your polynomial to a degree of in excel and get an r of ,"raise, polynomial, degree, excel, get",2022-03-28 09:33:59,when you raise your polynomial to a degree of in excel and get an r of ,"['raise', 'polynomial', 'degree', 'excel', 'get']",,,,
qph4tx,How to get a job in data science - a semi-harsh Q/A guide.,"**HOW DO I GET A JOB IN DATA SCIENCE?**

Hey you. Yes you, person asking ""how do I get a job in data science/analytics/MLE/AI whatever BS job with data in the title?"". I got news for you. There are two simple rules to getting one of these jobs.

1. Have experience.

2. Don't have no experience.

There are approximately 1000 entry level candidates who think they're qualified because they did a 24 week bootcamp for every entry level job. I don't need to be a statistician to tell you your odds of landing one of these aren't great.

**HOW DO I GET EXPERIENCE?**

Are you currently employed? If not, get a job. If you are, figure out a way to apply data science in your job, then put it on your resume. Mega bonus points here if you can figure out a way to attribute a dollar value to your contribution. Talk to your supervisor about career aspirations at year-end/mid-year reviews. Maybe you'll find a way to transfer to a role internally and skip the whole resume ignoring phase. Alternatively, network. Be friends with people who are in the roles you want to be in, maybe they'll help you find a job at their company.

**WHY AM I NOT GETTING INTERVIEWS?**

IDK. Maybe you don't have the required experience. Maybe there are 500+ other people applying for the same position. Maybe your resume stinks. If you're getting 1/20 response rate, you're doing great. Quit whining. 

**IS XYZ DEGREE GOOD FOR DATA SCIENCE?**

Does your degree involve some sort of non-remedial math higher than college algebra? Does your degree involve taking any sort of programming classes? If yes, congratulations, your degree will pass most base requirements for data science. Is it the best? Probably not, unless you're CS or some really heavy math degree where half your classes are taught in Greek letters. Don't come at me with those art history and underwater basket weaving degrees unless you have multiple years experience doing something else.

**SHOULD I DO XYZ BOOTCAMP/MICROMASTERS?**

Do you have experience? No? This ain't gonna help you as much as you think it might. Are you experienced and want to learn more about how data science works? This could be helpful.

**SHOULD I DO XYZ MASTER'S IN DATA SCIENCE PROGRAM?**

Congratulations, doing a Master's is usually a good idea and will help make you more competitive as a candidate. Should you shell out 100K for one when you can pay 10K for one online? Probably not. In all likelihood, you're not gonna get $90K in marginal benefit from the more expensive program. Pick a known school (probably avoid really obscure schools, the name does count for a little) and you'll be fine. Big bonus here if you can sucker your employer into paying for it.

**WILL XYZ CERTIFICATE HELP MY RESUME?**

Does your certificate say ""AWS"" or ""AZURE"" on it? If not, no.

**DO I NEED TO KNOW XYZ MATH TOPIC?**

Yes. Stop asking. Probably learn probability, be familiar with linear algebra, and understand what the hell a partial derivative is. Learn how to test hypotheses. Ultimately you need to know what the heck is going on math-wise in your predictions otherwise the company is going to go bankrupt and it will be all your fault. 

**WHAT IF I'M BAD AT MATH?**

Git gud. Do some studying or something. MIT opencourseware has a bunch of free recorded math classes. If you want to learn some Linear Algebra, Gilbert Strang is your guy. 

**WHAT PROGRAMMING LANGUAGES SHOULD I LEARN?**

STOP ASKING THIS QUESTION. I CAN GOOGLE ""HOW TO BE A DATA SCIENTIST"" AND EVERY SINGLE GARBAGE TDS ARTICLE WILL TELL YOU SQL AND PYTHON/R. YOU'RE LUCKY YOU DON'T HAVE TO DEAL WITH THE JOY OF SEGMENTATION FAULTS TO RUN A SIMPLE LINEAR REGRESSION. 

**SHOULD I LEARN PYTHON OR R?**

Both. Python is more widely used and tends to be more general purpose than R. R is better at statistics and data analysis, but is a bit more niche. 
Take your pick to start, but ultimately you're gonna want to learn both you slacker.

**SHOULD I MAKE A PORTFOLIO?**

Yes. And don't put some BS housing price regression, iris classification, or titanic survival project on it either. Next question.

**WHAT SHOULD I DO AS A PROJECT?**

IDK what are you interested in? If you say twitter sentiment stock market prediction go sit in the corner and think about what you just said. Every half brained first year student who can pip install sklearn and do model.fit() has tried unsuccessfully to predict the stock market. The efficient market hypothesis is a thing for a reason. There are literally millions of other free datasets out there you have one of the most powerful search engines at your fingertips to go find them. Pick something you're interested in, find some data, and analyze it. 

**DO I NEED TO BE GOOD WITH PEOPLE?** (courtesy of /u/bikeskata)

Yes! First, when you're applying, no one wants to work with a weirdo. You should be able to have a basic conversation with people, and they shouldn't come away from it thinking you'll follow them home and wear their skin as a suit. Once you get a job, you'll be interacting with colleagues, and you'll need them to care about your analysis. Presumably, there are non-technical people making decisions you'll need to bring in as well. If you can't explain to a moderately intelligent person why they should care about the thing that took you 3 days (and cost $$$ in cloud computing costs), you probably won't have your position for long. You don't need to be the life of the party, but you should be pleasant to be around.


**WHAT IF I HAVE OTHER QUESTIONS?**

READ THE GD /R/DATASCIENCE SUB WIKI. IT'S THERE FOR A REASON AND HAS GOOD INFORMATION.

And if you're posting these questions on /r/datascience, please for the love of all that is good in this world, use the weekly thread. Your post is gonna get nuked by the mods and no one is going to see it and you're going to die alone.",1636388717.0,1635.0,215.0,/r/datascience/comments/qph4tx/how_to_get_a_job_in_data_science_a_semiharsh_qa/,https://www.reddit.com/r/datascience/comments/qph4tx/how_to_get_a_job_in_data_science_a_semiharsh_qa/,save_the_panda_bears,datascience,0.96,True,False,False,False,0.0,1745834649.019939,Tech & Programming,13.0,1020.0,1024.0,Monday,11.0,November,2021.0,False,0.9978,0.128,0.041,0.832,positive,how to get a job in data science a semiharsh qa guide,how do i get a job in data science hey you yes you person asking how do i get a job in data scienceanalyticsmleai whatever bs job with data in the title i got news for you there are two simple rules to getting one of these jobs have experience dont have no experience there are approximately entry level candidates who think theyre qualified because they did a week bootcamp for every entry level job i dont need to be a statistician to tell you your odds of landing one of these arent great how do i get experience are you currently employed if not get a job if you are figure out a way to apply data science in your job then put it on your resume mega bonus points here if you can figure out a way to attribute a dollar value to your contribution talk to your supervisor about career aspirations at yearendmidyear reviews maybe youll find a way to transfer to a role internally and skip the whole resume ignoring phase alternatively network be friends with people who are in the roles you want to be in maybe theyll help you find a job at their company why am i not getting interviews idk maybe you dont have the required experience maybe there are other people applying for the same position maybe your resume stinks if youre getting response rate youre doing great quit whining is xyz degree good for data science does your degree involve some sort of nonremedial math higher than college algebra does your degree involve taking any sort of programming classes if yes congratulations your degree will pass most base requirements for data science is it the best probably not unless youre cs or some really heavy math degree where half your classes are taught in greek letters dont come at me with those art history and underwater basket weaving degrees unless you have multiple years experience doing something else should i do xyz bootcampmicromasters do you have experience no this aint gonna help you as much as you think it might are you experienced and want to learn more about how data science works this could be helpful should i do xyz masters in data science program congratulations doing a masters is usually a good idea and will help make you more competitive as a candidate should you shell out k for one when you can pay k for one online probably not in all likelihood youre not gonna get k in marginal benefit from the more expensive program pick a known school probably avoid really obscure schools the name does count for a little and youll be fine big bonus here if you can sucker your employer into paying for it will xyz certificate help my resume does your certificate say aws or azure on it if not no do i need to know xyz math topic yes stop asking probably learn probability be familiar with linear algebra and understand what the hell a partial derivative is learn how to test hypotheses ultimately you need to know what the heck is going on mathwise in your predictions otherwise the company is going to go bankrupt and it will be all your fault what if im bad at math git gud do some studying or something mit opencourseware has a bunch of free recorded math classes if you want to learn some linear algebra gilbert strang is your guy what programming languages should i learn stop asking this question i can google how to be a data scientist and every single garbage tds article will tell you sql and pythonr youre lucky you dont have to deal with the joy of segmentation faults to run a simple linear regression should i learn python or r both python is more widely used and tends to be more general purpose than r r is better at statistics and data analysis but is a bit more niche take your pick to start but ultimately youre gonna want to learn both you slacker should i make a portfolio yes and dont put some bs housing price regression iris classification or titanic survival project on it either next question what should i do as a project idk what are you interested in if you say twitter sentiment stock market prediction go sit in the corner and think about what you just said every half brained first year student who can pip install sklearn and do modelfit has tried unsuccessfully to predict the stock market the efficient market hypothesis is a thing for a reason there are literally millions of other free datasets out there you have one of the most powerful search engines at your fingertips to go find them pick something youre interested in find some data and analyze it do i need to be good with people courtesy of ubikeskata yes first when youre applying no one wants to work with a weirdo you should be able to have a basic conversation with people and they shouldnt come away from it thinking youll follow them home and wear their skin as a suit once you get a job youll be interacting with colleagues and youll need them to care about your analysis presumably there are nontechnical people making decisions youll need to bring in as well if you cant explain to a moderately intelligent person why they should care about the thing that took you days and cost in cloud computing costs you probably wont have your position for long you dont need to be the life of the party but you should be pleasant to be around what if i have other questions read the gd rdatascience sub wiki its there for a reason and has good information and if youre posting these questions on rdatascience please for the love of all that is good in this world use the weekly thread your post is gonna get nuked by the mods and no one is going to see it and youre going to die alone,how to get a job in data science a semiharsh qa guide how do i get a job in data science hey you yes you person asking how do i get a job in data scienceanalyticsmleai whatever bs job with data in the title i got news for you there are two simple rules to getting one of these jobs have experience dont have no experience there are approximately entry level candidates who think theyre qualified because they did a week bootcamp for every entry level job i dont need to be a statistician to tell you your odds of landing one of these arent great how do i get experience are you currently employed if not get a job if you are figure out a way to apply data science in your job then put it on your resume mega bonus points here if you can figure out a way to attribute a dollar value to your contribution talk to your supervisor about career aspirations at yearendmidyear reviews maybe youll find a way to transfer to a role internally and skip the whole resume ignoring phase alternatively network be friends with people who are in the roles you want to be in maybe theyll help you find a job at their company why am i not getting interviews idk maybe you dont have the required experience maybe there are other people applying for the same position maybe your resume stinks if youre getting response rate youre doing great quit whining is xyz degree good for data science does your degree involve some sort of nonremedial math higher than college algebra does your degree involve taking any sort of programming classes if yes congratulations your degree will pass most base requirements for data science is it the best probably not unless youre cs or some really heavy math degree where half your classes are taught in greek letters dont come at me with those art history and underwater basket weaving degrees unless you have multiple years experience doing something else should i do xyz bootcampmicromasters do you have experience no this aint gonna help you as much as you think it might are you experienced and want to learn more about how data science works this could be helpful should i do xyz masters in data science program congratulations doing a masters is usually a good idea and will help make you more competitive as a candidate should you shell out k for one when you can pay k for one online probably not in all likelihood youre not gonna get k in marginal benefit from the more expensive program pick a known school probably avoid really obscure schools the name does count for a little and youll be fine big bonus here if you can sucker your employer into paying for it will xyz certificate help my resume does your certificate say aws or azure on it if not no do i need to know xyz math topic yes stop asking probably learn probability be familiar with linear algebra and understand what the hell a partial derivative is learn how to test hypotheses ultimately you need to know what the heck is going on mathwise in your predictions otherwise the company is going to go bankrupt and it will be all your fault what if im bad at math git gud do some studying or something mit opencourseware has a bunch of free recorded math classes if you want to learn some linear algebra gilbert strang is your guy what programming languages should i learn stop asking this question i can google how to be a data scientist and every single garbage tds article will tell you sql and pythonr youre lucky you dont have to deal with the joy of segmentation faults to run a simple linear regression should i learn python or r both python is more widely used and tends to be more general purpose than r r is better at statistics and data analysis but is a bit more niche take your pick to start but ultimately youre gonna want to learn both you slacker should i make a portfolio yes and dont put some bs housing price regression iris classification or titanic survival project on it either next question what should i do as a project idk what are you interested in if you say twitter sentiment stock market prediction go sit in the corner and think about what you just said every half brained first year student who can pip install sklearn and do modelfit has tried unsuccessfully to predict the stock market the efficient market hypothesis is a thing for a reason there are literally millions of other free datasets out there you have one of the most powerful search engines at your fingertips to go find them pick something youre interested in find some data and analyze it do i need to be good with people courtesy of ubikeskata yes first when youre applying no one wants to work with a weirdo you should be able to have a basic conversation with people and they shouldnt come away from it thinking youll follow them home and wear their skin as a suit once you get a job youll be interacting with colleagues and youll need them to care about your analysis presumably there are nontechnical people making decisions youll need to bring in as well if you cant explain to a moderately intelligent person why they should care about the thing that took you days and cost in cloud computing costs you probably wont have your position for long you dont need to be the life of the party but you should be pleasant to be around what if i have other questions read the gd rdatascience sub wiki its there for a reason and has good information and if youre posting these questions on rdatascience please for the love of all that is good in this world use the weekly thread your post is gonna get nuked by the mods and no one is going to see it and youre going to die alone,"data, job, youre, get, science",2021-11-08 16:25:17,how to get a job in data science a semiharsh qa guide how do i get a job in data science hey you yes you person asking how do i get a job in data scienceanalyticsmleai whatever bs job with data in the title i got news for you there are two simple rules to getting one of these jobs have experience dont have no experience there are approximately entry level candidates who think theyre qualified because they did a week bootcamp for every entry level job i dont need to be a statistician to tell you your odds of landing one of these arent great how do i get experience are you currently employed if not get a job if you are figure out a way to apply data science in your job then put it on your resume mega bonus points here if you can figure out a way to attribute a dollar value to your contribution talk to your supervisor about career aspirations at yearendmidyear reviews maybe youll find a way to transfer to a role internally and skip the whole resume ignoring phase alternatively network be friends with people who are in the roles you want to be in maybe theyll help you find a job at their company why am i not getting interviews idk maybe you dont have the required experience maybe there are other people applying for the same position maybe your resume stinks if youre getting response rate youre doing great quit whining is xyz degree good for data science does your degree involve some sort of nonremedial math higher than college algebra does your degree involve taking any sort of programming classes if yes congratulations your degree will pass most base requirements for data science is it the best probably not unless youre cs or some really heavy math degree where half your classes are taught in greek letters dont come at me with those art history and underwater basket weaving degrees unless you have multiple years experience doing something else should i do xyz bootcampmicromasters do you have experience no this aint gonna help you as much as you think it might are you experienced and want to learn more about how data science works this could be helpful should i do xyz masters in data science program congratulations doing a masters is usually a good idea and will help make you more competitive as a candidate should you shell out k for one when you can pay k for one online probably not in all likelihood youre not gonna get k in marginal benefit from the more expensive program pick a known school probably avoid really obscure schools the name does count for a little and youll be fine big bonus here if you can sucker your employer into paying for it will xyz certificate help my resume does your certificate say aws or azure on it if not no do i need to know xyz math topic yes stop asking probably learn probability be familiar with linear algebra and understand what the hell a partial derivative is learn how to test hypotheses ultimately you need to know what the heck is going on mathwise in your predictions otherwise the company is going to go bankrupt and it will be all your fault what if im bad at math git gud do some studying or something mit opencourseware has a bunch of free recorded math classes if you want to learn some linear algebra gilbert strang is your guy what programming languages should i learn stop asking this question i can google how to be a data scientist and every single garbage tds article will tell you sql and pythonr youre lucky you dont have to deal with the joy of segmentation faults to run a simple linear regression should i learn python or r both python is more widely used and tends to be more general purpose than r r is better at statistics and data analysis but is a bit more niche take your pick to start but ultimately youre gonna want to learn both you slacker should i make a portfolio yes and dont put some bs housing price regression iris classification or titanic survival project on it either next question what should i do as a project idk what are you interested in if you say twitter sentiment stock market prediction go sit in the corner and think about what you just said every half brained first year student who can pip install sklearn and do modelfit has tried unsuccessfully to predict the stock market the efficient market hypothesis is a thing for a reason there are literally millions of other free datasets out there you have one of the most powerful search engines at your fingertips to go find them pick something youre interested in find some data and analyze it do i need to be good with people courtesy of ubikeskata yes first when youre applying no one wants to work with a weirdo you should be able to have a basic conversation with people and they shouldnt come away from it thinking youll follow them home and wear their skin as a suit once you get a job youll be interacting with colleagues and youll need them to care about your analysis presumably there are nontechnical people making decisions youll need to bring in as well if you cant explain to a moderately intelligent person why they should care about the thing that took you days and cost in cloud computing costs you probably wont have your position for long you dont need to be the life of the party but you should be pleasant to be around what if i have other questions read the gd rdatascience sub wiki its there for a reason and has good information and if youre posting these questions on rdatascience please for the love of all that is good in this world use the weekly thread your post is gonna get nuked by the mods and no one is going to see it and youre going to die alone,"['get', 'job', 'data', 'science', 'semiharsh', 'guide', 'get', 'job', 'data', 'science', 'hey', 'yes', 'person', 'asking', 'get', 'job', 'data', 'scienceanalyticsmleai', 'whatever', 'job', 'data', 'title', 'got', 'news', 'two', 'simple', 'rule', 'getting', 'one', 'job', 'experience', 'dont', 'experience', 'approximately', 'entry', 'level', 'candidate', 'think', 'theyre', 'qualified', 'week', 'bootcamp', 'every', 'entry', 'level', 'job', 'dont', 'need', 'statistician', 'tell', 'odds', 'landing', 'one', 'arent', 'great', 'get', 'experience', 'currently', 'employed', 'get', 'job', 'figure', 'way', 'apply', 'data', 'science', 'job', 'put', 'resume', 'mega', 'bonus', 'point', 'figure', 'way', 'attribute', 'dollar', 'value', 'contribution', 'talk', 'supervisor', 'career', 'aspiration', 'yearendmidyear', 'review', 'maybe', 'youll', 'find', 'way', 'transfer', 'role', 'internally', 'skip', 'whole', 'resume', 'ignoring', 'phase', 'alternatively', 'network', 'friend', 'people', 'role', 'want', 'maybe', 'theyll', 'help', 'find', 'job', 'company', 'getting', 'interview', 'idk', 'maybe', 'dont', 'required', 'experience', 'maybe', 'people', 'applying', 'position', 'maybe', 'resume', 'stink', 'youre', 'getting', 'response', 'rate', 'youre', 'great', 'quit', 'whining', 'xyz', 'degree', 'good', 'data', 'science', 'degree', 'involve', 'sort', 'nonremedial', 'math', 'higher', 'college', 'algebra', 'degree', 'involve', 'taking', 'sort', 'programming', 'class', 'yes', 'congratulation', 'degree', 'pas', 'base', 'requirement', 'data', 'science', 'best', 'probably', 'unless', 'youre', 'really', 'heavy', 'math', 'degree', 'half', 'class', 'taught', 'greek', 'letter', 'dont', 'come', 'art', 'history', 'underwater', 'basket', 'weaving', 'degree', 'unless', 'multiple', 'year', 'experience', 'something', 'else', 'xyz', 'bootcampmicromasters', 'experience', 'aint', 'gon', 'help', 'much', 'think', 'might', 'experienced', 'want', 'learn', 'data', 'science', 'work', 'could', 'helpful', 'xyz', 'master', 'data', 'science', 'program', 'congratulation', 'master', 'usually', 'good', 'idea', 'help', 'make', 'competitive', 'candidate', 'shell', 'one', 'pay', 'one', 'online', 'probably', 'likelihood', 'youre', 'gon', 'get', 'marginal', 'benefit', 'expensive', 'program', 'pick', 'known', 'school', 'probably', 'avoid', 'really', 'obscure', 'school', 'name', 'count', 'little', 'youll', 'fine', 'big', 'bonus', 'sucker', 'employer', 'paying', 'xyz', 'certificate', 'help', 'resume', 'certificate', 'say', 'aws', 'azure', 'need', 'know', 'xyz', 'math', 'topic', 'yes', 'stop', 'asking', 'probably', 'learn', 'probability', 'familiar', 'linear', 'algebra', 'understand', 'hell', 'partial', 'derivative', 'learn', 'test', 'hypothesis', 'ultimately', 'need', 'know', 'heck', 'going', 'mathwise', 'prediction', 'otherwise', 'company', 'going', 'bankrupt', 'fault', 'bad', 'math', 'git', 'gud', 'studying', 'something', 'mit', 'opencourseware', 'bunch', 'free', 'recorded', 'math', 'class', 'want', 'learn', 'linear', 'algebra', 'gilbert', 'strang', 'guy', 'programming', 'language', 'learn', 'stop', 'asking', 'question', 'google', 'data', 'scientist', 'every', 'single', 'garbage', 'tds', 'article', 'tell', 'sql', 'pythonr', 'youre', 'lucky', 'dont', 'deal', 'joy', 'segmentation', 'fault', 'run', 'simple', 'linear', 'regression', 'learn', 'python', 'python', 'widely', 'used', 'tends', 'general', 'purpose', 'better', 'statistic', 'data', 'analysis', 'bit', 'niche', 'take', 'pick', 'start', 'ultimately', 'youre', 'gon', 'want', 'learn', 'slacker', 'make', 'portfolio', 'yes', 'dont', 'put', 'housing', 'price', 'regression', 'iris', 'classification', 'titanic', 'survival', 'project', 'either', 'next', 'question', 'project', 'idk', 'interested', 'say', 'twitter', 'sentiment', 'stock', 'market', 'prediction', 'sit', 'corner', 'think', 'said', 'every', 'half', 'brained', 'first', 'year', 'student', 'pip', 'install', 'sklearn', 'modelfit', 'tried', 'unsuccessfully', 'predict', 'stock', 'market', 'efficient', 'market', 'hypothesis', 'thing', 'reason', 'literally', 'million', 'free', 'datasets', 'one', 'powerful', 'search', 'engine', 'fingertip', 'find', 'pick', 'something', 'youre', 'interested', 'find', 'data', 'analyze', 'need', 'good', 'people', 'courtesy', 'ubikeskata', 'yes', 'first', 'youre', 'applying', 'one', 'want', 'work', 'weirdo', 'able', 'basic', 'conversation', 'people', 'shouldnt', 'come', 'away', 'thinking', 'youll', 'follow', 'home', 'wear', 'skin', 'suit', 'get', 'job', 'youll', 'interacting', 'colleague', 'youll', 'need', 'care', 'analysis', 'presumably', 'nontechnical', 'people', 'making', 'decision', 'youll', 'need', 'bring', 'well', 'cant', 'explain', 'moderately', 'intelligent', 'person', 'care', 'thing', 'took', 'day', 'cost', 'cloud', 'computing', 'cost', 'probably', 'wont', 'position', 'long', 'dont', 'need', 'life', 'party', 'pleasant', 'around', 'question', 'read', 'rdatascience', 'sub', 'wiki', 'reason', 'good', 'information', 'youre', 'posting', 'question', 'rdatascience', 'please', 'love', 'good', 'world', 'use', 'weekly', 'thread', 'post', 'gon', 'get', 'nuked', 'mod', 'one', 'going', 'see', 'youre', 'going', 'die', 'alone']",,,,
d6buto,K-means be like: Mine ! MINE ! MINE !,,1568887322.0,1603.0,29.0,/r/datascience/comments/d6buto/kmeans_be_like_mine_mine_mine/,https://i.redd.it/apqss6kzxin31.jpg,postal__dude,datascience,0.97,False,False,False,False,0.0,1745834650.087585,Tech & Programming,9.0,0.0,6.0,Thursday,6.0,September,2019.0,False,0.3612,0.333,0.0,0.667,positive,kmeans be like mine mine mine,,kmeans be like mine mine mine ,"mine, kmeans, like",2019-09-19 10:02:02,kmeans be like mine mine mine ,"['kmeans', 'like', 'mine', 'mine', 'mine']",,,,
1hxalxo,Companies are finally hiring,"I applied to 80+ jobs before the new year and got rejected or didn’t hear back from most of them. A few positions were a level or two lower than my currently level. I got only 1 interview and I did accept the offer. 

In the last week, 4 companies reached out for interviews. Just want to put this out there for those who are still looking. Keep going at it. 

Edit - thank you all for the congratulations and I’m sorry I can’t respond to DMs. Here are answers to some common questions. 

1. The technical coding challenge was only SQL. Frankly in my 8 years of analytics, none of my peers use Python regularly unless their role is to automate or data engineering. You’re better off mastering SQL by using leetcode and DataLemur

2. Interviews at all the FAANGs are similar. Call with HR rep, first round is with 1 person and might be technical. Then a final round with a bunch of individual interviews on the same day. Most of the questions will be STAR format. 

3. As for my skillsets, I advertise myself as someone who can build strategy, project manage, and can do deep dive analyses. I’m never going to compete against the recent grads and experts in ML/LLM/AI on technical skills, that’s just an endless grind to stay at the top. I would strongly recommend others to sharpen their soft skills. A video I watched recently is from The Diary of a CEO with Body Language Expert with Vanessa Edwards. I legit used a few tips during my interviews and I thought that helped ",1736421422.0,1576.0,133.0,/r/datascience/comments/1hxalxo/companies_are_finally_hiring/,https://www.reddit.com/r/datascience/comments/1hxalxo/companies_are_finally_hiring/,mediocrity4,datascience,0.98,True,False,False,False,0.0,1745834650.306453,Tech & Programming,4.0,270.0,265.0,Thursday,6.0,January,2025.0,False,0.91,0.084,0.026,0.89,positive,companies are finally hiring,i applied to jobs before the new year and got rejected or didnt hear back from most of them a few positions were a level or two lower than my currently level i got only interview and i did accept the offer in the last week companies reached out for interviews just want to put this out there for those who are still looking keep going at it edit thank you all for the congratulations and im sorry i cant respond to dms here are answers to some common questions the technical coding challenge was only sql frankly in my years of analytics none of my peers use python regularly unless their role is to automate or data engineering youre better off mastering sql by using leetcode and datalemur interviews at all the faangs are similar call with hr rep first round is with person and might be technical then a final round with a bunch of individual interviews on the same day most of the questions will be star format as for my skillsets i advertise myself as someone who can build strategy project manage and can do deep dive analyses im never going to compete against the recent grads and experts in mlllmai on technical skills thats just an endless grind to stay at the top i would strongly recommend others to sharpen their soft skills a video i watched recently is from the diary of a ceo with body language expert with vanessa edwards i legit used a few tips during my interviews and i thought that helped,companies are finally hiring i applied to jobs before the new year and got rejected or didnt hear back from most of them a few positions were a level or two lower than my currently level i got only interview and i did accept the offer in the last week companies reached out for interviews just want to put this out there for those who are still looking keep going at it edit thank you all for the congratulations and im sorry i cant respond to dms here are answers to some common questions the technical coding challenge was only sql frankly in my years of analytics none of my peers use python regularly unless their role is to automate or data engineering youre better off mastering sql by using leetcode and datalemur interviews at all the faangs are similar call with hr rep first round is with person and might be technical then a final round with a bunch of individual interviews on the same day most of the questions will be star format as for my skillsets i advertise myself as someone who can build strategy project manage and can do deep dive analyses im never going to compete against the recent grads and experts in mlllmai on technical skills thats just an endless grind to stay at the top i would strongly recommend others to sharpen their soft skills a video i watched recently is from the diary of a ceo with body language expert with vanessa edwards i legit used a few tips during my interviews and i thought that helped,"interview, technical, company, year, got",2025-01-09 11:17:02,companies are finally hiring i applied to jobs before the new year and got rejected or didnt hear back from most of them a few positions were a level or two lower than my currently level i got only interview and i did accept the offer in the last week companies reached out for interviews just want to put this out there for those who are still looking keep going at it edit thank you all for the congratulations and im sorry i cant respond to dms here are answers to some common questions the technical coding challenge was only sql frankly in my years of analytics none of my peers use python regularly unless their role is to automate or data engineering youre better off mastering sql by using leetcode and datalemur interviews at all the faangs are similar call with hr rep first round is with person and might be technical then a final round with a bunch of individual interviews on the same day most of the questions will be star format as for my skillsets i advertise myself as someone who can build strategy project manage and can do deep dive analyses im never going to compete against the recent grads and experts in mlllmai on technical skills thats just an endless grind to stay at the top i would strongly recommend others to sharpen their soft skills a video i watched recently is from the diary of a ceo with body language expert with vanessa edwards i legit used a few tips during my interviews and i thought that helped,"['company', 'finally', 'hiring', 'applied', 'job', 'new', 'year', 'got', 'rejected', 'didnt', 'hear', 'back', 'position', 'level', 'two', 'lower', 'currently', 'level', 'got', 'interview', 'accept', 'offer', 'last', 'week', 'company', 'reached', 'interview', 'want', 'put', 'still', 'looking', 'keep', 'going', 'edit', 'thank', 'congratulation', 'sorry', 'cant', 'respond', 'dm', 'answer', 'common', 'question', 'technical', 'coding', 'challenge', 'sql', 'frankly', 'year', 'analytics', 'none', 'peer', 'use', 'python', 'regularly', 'unless', 'role', 'automate', 'data', 'engineering', 'youre', 'better', 'mastering', 'sql', 'using', 'leetcode', 'datalemur', 'interview', 'faangs', 'similar', 'call', 'rep', 'first', 'round', 'person', 'might', 'technical', 'final', 'round', 'bunch', 'individual', 'interview', 'day', 'question', 'star', 'format', 'skillsets', 'advertise', 'someone', 'build', 'strategy', 'project', 'manage', 'deep', 'dive', 'analysis', 'never', 'going', 'compete', 'recent', 'grad', 'expert', 'mlllmai', 'technical', 'skill', 'thats', 'endless', 'grind', 'stay', 'top', 'would', 'strongly', 'recommend', 'others', 'sharpen', 'soft', 'skill', 'video', 'watched', 'recently', 'diary', 'ceo', 'body', 'language', 'expert', 'vanessa', 'edward', 'legit', 'used', 'tip', 'interview', 'thought', 'helped']",,,,
s0dn5b,2022 Mood,,1641797504.0,1573.0,88.0,/r/datascience/comments/s0dn5b/2022_mood/,https://i.redd.it/s7olw2f01ra81.jpg,caksters,datascience,0.98,False,False,False,False,0.0,1745834651.080806,Tech & Programming,2.0,0.0,1.0,Monday,1.0,January,2022.0,False,0.0,0.0,0.0,1.0,neutral,mood,,mood ,mood,2022-01-10 06:51:44,mood ,['mood'],,,,
xbl58o,Here are the questions I was asked for my entry level DS job!,"Hey everyone. I posted a thread a few days ago about being nervous about my first DS interview. The thread was taken down by mods due to it being more appropriate for the stickied thread. So I want to make this thread less about questions, but more of an informative post to show you some of the questions I was asked. Hopefully it's helpful for newbies and veterans alike!

&#x200B;

**SQL:**

* What is a view?
* Is a table dynamic or static?
* Difference between a primary key and foreign key
* Inner Join vs. Left Join scenario (pretty sure it was from w3schools. ez pz)
* WHERE vs. HAVING
* When would you use a subquery? Provide an example
* How would you improve the performance of a slow query?
* EDIT: Some aggregation and GROUP by questions (MAX, AVG, COUNT, etc.) that I just remembered.

**Python**

* Explanation of libraries I use (Pandas mainly)
* How would you get the maximum result from a list?
* Can you explain the concept of functions
* Difference between FOR and WHILE loops?
* Give some examples of how you would clean dirty data.

**Tableau:**

* What is a calculated field? Provide some examples in your work
* What is the difference between a live view and extract? When would you use each?
* More information given on the data I work with

**Statistics:**

* Explain what a p-value is to someone who has no idea what that is.
* Explanation on linear/logistic regression modeling.
* What is standard deviation? Examples?
* Difference between STDEV and Variance?
* What statistics do you currently work with? (Descriptive mainly... mean, median, mode, stdev, confidence intervals)

I advanced to round 3 immediately, which is pretty much a shoe-in according to the hiring manager. I am very excited because it seems like a great opportunity. Even if I don't get it, I still felt like I interviewed very well and did my best. I am very proud of myself.

120k a year w/ benefits, bonuses, and training courses a week to help me learn more advanced DS concepts, Python, or whatever I want. I am so excited.",1662909364.0,1572.0,254.0,/r/datascience/comments/xbl58o/here_are_the_questions_i_was_asked_for_my_entry/,https://www.reddit.com/r/datascience/comments/xbl58o/here_are_the_questions_i_was_asked_for_my_entry/,dsdude1337,datascience,0.99,True,False,False,False,0.0,1745834651.612904,Tech & Programming,13.0,363.0,354.0,Sunday,11.0,September,2022.0,True,0.9983,0.25,0.021,0.73,positive,here are the questions i was asked for my entry level ds job,hey everyone i posted a thread a few days ago about being nervous about my first ds interview the thread was taken down by mods due to it being more appropriate for the stickied thread so i want to make this thread less about questions but more of an informative post to show you some of the questions i was asked hopefully its helpful for newbies and veterans alike xb sql what is a view is a table dynamic or static difference between a primary key and foreign key inner join vs left join scenario pretty sure it was from wschools ez pz where vs having when would you use a subquery provide an example how would you improve the performance of a slow query edit some aggregation and group by questions max avg count etc that i just remembered python explanation of libraries i use pandas mainly how would you get the maximum result from a list can you explain the concept of functions difference between for and while loops give some examples of how you would clean dirty data tableau what is a calculated field provide some examples in your work what is the difference between a live view and extract when would you use each more information given on the data i work with statistics explain what a pvalue is to someone who has no idea what that is explanation on linearlogistic regression modeling what is standard deviation examples difference between stdev and variance what statistics do you currently work with descriptive mainly mean median mode stdev confidence intervals i advanced to round immediately which is pretty much a shoein according to the hiring manager i am very excited because it seems like a great opportunity even if i dont get it i still felt like i interviewed very well and did my best i am very proud of myself k a year w benefits bonuses and training courses a week to help me learn more advanced ds concepts python or whatever i want i am so excited,here are the questions i was asked for my entry level ds job hey everyone i posted a thread a few days ago about being nervous about my first ds interview the thread was taken down by mods due to it being more appropriate for the stickied thread so i want to make this thread less about questions but more of an informative post to show you some of the questions i was asked hopefully its helpful for newbies and veterans alike xb sql what is a view is a table dynamic or static difference between a primary key and foreign key inner join vs left join scenario pretty sure it was from wschools ez pz where vs having when would you use a subquery provide an example how would you improve the performance of a slow query edit some aggregation and group by questions max avg count etc that i just remembered python explanation of libraries i use pandas mainly how would you get the maximum result from a list can you explain the concept of functions difference between for and while loops give some examples of how you would clean dirty data tableau what is a calculated field provide some examples in your work what is the difference between a live view and extract when would you use each more information given on the data i work with statistics explain what a pvalue is to someone who has no idea what that is explanation on linearlogistic regression modeling what is standard deviation examples difference between stdev and variance what statistics do you currently work with descriptive mainly mean median mode stdev confidence intervals i advanced to round immediately which is pretty much a shoein according to the hiring manager i am very excited because it seems like a great opportunity even if i dont get it i still felt like i interviewed very well and did my best i am very proud of myself k a year w benefits bonuses and training courses a week to help me learn more advanced ds concepts python or whatever i want i am so excited,"would, question, thread, difference, example",2022-09-11 15:16:04,here are the questions i was asked for my entry level ds job hey everyone i posted a thread a few days ago about being nervous about my first ds interview the thread was taken down by mods due to it being more appropriate for the stickied thread so i want to make this thread less about questions but more of an informative post to show you some of the questions i was asked hopefully its helpful for newbies and veterans alike xb sql what is a view is a table dynamic or static difference between a primary key and foreign key inner join vs left join scenario pretty sure it was from wschools ez pz where vs having when would you use a subquery provide an example how would you improve the performance of a slow query edit some aggregation and group by questions max avg count etc that i just remembered python explanation of libraries i use pandas mainly how would you get the maximum result from a list can you explain the concept of functions difference between for and while loops give some examples of how you would clean dirty data tableau what is a calculated field provide some examples in your work what is the difference between a live view and extract when would you use each more information given on the data i work with statistics explain what a pvalue is to someone who has no idea what that is explanation on linearlogistic regression modeling what is standard deviation examples difference between stdev and variance what statistics do you currently work with descriptive mainly mean median mode stdev confidence intervals i advanced to round immediately which is pretty much a shoein according to the hiring manager i am very excited because it seems like a great opportunity even if i dont get it i still felt like i interviewed very well and did my best i am very proud of myself k a year w benefits bonuses and training courses a week to help me learn more advanced ds concepts python or whatever i want i am so excited,"['question', 'asked', 'entry', 'level', 'job', 'hey', 'everyone', 'posted', 'thread', 'day', 'ago', 'nervous', 'first', 'interview', 'thread', 'taken', 'mod', 'due', 'appropriate', 'stickied', 'thread', 'want', 'make', 'thread', 'less', 'question', 'informative', 'post', 'show', 'question', 'asked', 'hopefully', 'helpful', 'newbie', 'veteran', 'alike', 'sql', 'view', 'table', 'dynamic', 'static', 'difference', 'primary', 'key', 'foreign', 'key', 'inner', 'join', 'left', 'join', 'scenario', 'pretty', 'sure', 'wschools', 'would', 'use', 'subquery', 'provide', 'example', 'would', 'improve', 'performance', 'slow', 'query', 'edit', 'aggregation', 'group', 'question', 'max', 'avg', 'count', 'etc', 'remembered', 'python', 'explanation', 'library', 'use', 'panda', 'mainly', 'would', 'get', 'maximum', 'result', 'list', 'explain', 'concept', 'function', 'difference', 'loop', 'give', 'example', 'would', 'clean', 'dirty', 'data', 'tableau', 'calculated', 'field', 'provide', 'example', 'work', 'difference', 'live', 'view', 'extract', 'would', 'use', 'information', 'given', 'data', 'work', 'statistic', 'explain', 'pvalue', 'someone', 'idea', 'explanation', 'linearlogistic', 'regression', 'modeling', 'standard', 'deviation', 'example', 'difference', 'stdev', 'variance', 'statistic', 'currently', 'work', 'descriptive', 'mainly', 'mean', 'median', 'mode', 'stdev', 'confidence', 'interval', 'advanced', 'round', 'immediately', 'pretty', 'much', 'shoein', 'according', 'hiring', 'manager', 'excited', 'seems', 'like', 'great', 'opportunity', 'even', 'dont', 'get', 'still', 'felt', 'like', 'interviewed', 'well', 'best', 'proud', 'year', 'benefit', 'bonus', 'training', 'course', 'week', 'help', 'learn', 'advanced', 'concept', 'python', 'whatever', 'want', 'excited']",,,,
cu26yc,Data Scientists on languages...,,1566501561.0,1570.0,167.0,/r/datascience/comments/cu26yc/data_scientists_on_languages/,https://i.redd.it/tl3fmvuqv1i31.jpg,,datascience,0.98,False,False,False,False,0.0,1745834652.919536,Tech & Programming,4.0,0.0,4.0,Thursday,15.0,August,2019.0,False,0.0,0.0,0.0,1.0,neutral,data scientists on languages,,data scientists on languages ,"data, scientist, language",2019-08-22 19:19:21,data scientists on languages ,"['data', 'scientist', 'language']",,,,
tn3xh2,"The media really doesn’t know what we do, do they?",,1648155095.0,1561.0,174.0,/r/datascience/comments/tn3xh2/the_media_really_doesnt_know_what_we_do_do_they/,https://i.imgur.com/U9IgtPh.jpg,Fintech_ML,datascience,0.94,False,False,False,False,0.0,1745834653.902896,Tech & Programming,10.0,0.0,10.0,Thursday,16.0,March,2022.0,False,0.0,0.0,0.0,1.0,neutral,the media really doesnt know what we do do they,,the media really doesnt know what we do do they ,"medium, really, doesnt, know",2022-03-24 20:51:35,the media really doesnt know what we do do they ,"['medium', 'really', 'doesnt', 'know']",,,,
124cshz,SMB interviews be like:,,1679978051.0,1535.0,89.0,/r/datascience/comments/124cshz/smb_interviews_be_like/,https://i.redd.it/q2or4qsireqa1.png,1-800-GANKS,datascience,0.98,False,False,False,False,0.0,1745834654.680876,Tech & Programming,4.0,0.0,4.0,Tuesday,0.0,March,2023.0,False,0.3612,0.455,0.0,0.545,positive,smb interviews be like,,smb interviews be like ,"smb, interview, like",2023-03-28 04:34:11,smb interviews be like ,"['smb', 'interview', 'like']",,,,
ztwkky,Job hunt results as a mid-level Data Scientist w/ ADHD,,1671840226.0,1532.0,197.0,/r/datascience/comments/ztwkky/job_hunt_results_as_a_midlevel_data_scientist_w/,https://i.redd.it/kxtetcbjlq7a1.png,GirlLunarExplorer,datascience,0.94,False,False,False,False,0.0,1745834655.120006,Tech & Programming,10.0,0.0,10.0,Friday,19.0,December,2022.0,False,0.0,0.0,0.0,1.0,neutral,job hunt results as a midlevel data scientist w adhd,,job hunt results as a midlevel data scientist w adhd ,"job, hunt, result, midlevel, data",2022-12-24 00:03:46,job hunt results as a midlevel data scientist w adhd ,"['job', 'hunt', 'result', 'midlevel', 'data', 'scientist', 'adhd']",,,,
glfdmm,"A ""Data Science"" company stole my gf's ML project and reposted it as their own. What do I do?","Dean Hoffman responds: [https://www.reddit.com/r/datascience/comments/gmirks/my\_apologies\_from\_a\_data\_science\_company\_stole\_my/](https://www.reddit.com/r/datascience/comments/gmirks/my_apologies_from_a_data_science_company_stole_my/)

Hi,

My girlfriend is a 22 year old university student passionate about data science, and she just posted my first article on Medium using Machine-Learning (that took her months of research and coding to put together). Her post only has about 500 views, but to her surprise today a reddit user called [**Dean-Hoffman**](https://www.reddit.com/user/Dean-Hoffman/) **posted a link to his own data science company where he copy-pasted her article.** He didn't contact her about reposting it, didn't give her proper credit and **ridiculously added a ""Contact Data Scientist"" at the end with his name on it**. On the article, he clearly stated he is the author in multiple locations. This is the ""Data Science"" company that links from the article on his website: [https://www.actionablelabs.com/](https://www.actionablelabs.com/)

Apparently the guy Dean Hoffman is the ""founder"" of the company and refers to himself on the About Us as **""offering the highest commitment to excellence, personal integrity, and business ethics.""**

Update: Hey, this is the girlfriend that wrote the article. First of all, thank you all that made the time to reply, research and help me find answers. It's really appreciated.  So far, this is what we know about this person (or people):

\- This website has been stealing hundreds, if not thousands, of data science projects and articles from legitimate data scientists and writers.

\- The stolen content website in definitely bot-operated as the owner posts dozens of articles a day, completely copy+paste, mainly from Medium, TechCrunch and Towards Data Science.

\- It's confirmed that Dean-Hoffman from the Linkedin that links from his company (Actionable Labs) is a real person and the same Dean-Hoffman that is stealing content and running a data company.

\- If you go on his linkedin, under ""Data Scientist - Pennsylvania Department of General Services"" you will find that he mentions ""Actionable Insights"" (the stolen content website) in one of his experiences. Completely absurd.

UPDATE 2: Medium and TDS unfortunately can't do much for me individually as the authors are the ones who own the rights to the articles. TDS will try to reach out to the owner and ask them to take the posts down. I hope they see that their whole website is being copied, which would most likely infringe their TOS.

Please don't comment anything that contains the words ""copyright"", ""infringement"" or related words on her article as it may trigger keyword algorithms that delete copyrighted articles posted to Medium (and thus could have her article deleted). Thank you!

This is his post on reddit: [https://www.reddit.com/user/Dean-Hoffman/comments/gkoxpd/ai\_and\_real\_state\_predicting\_rental\_prices\_in/](https://www.reddit.com/user/Dean-Hoffman/comments/gkoxpd/ai_and_real_state_predicting_rental_prices_in/)

This is the article he stole from her: [https://www.actionableinsights.org/ai-and-real-state-predicting-rental-prices-in-amsterdam/](https://www.actionableinsights.org/ai-and-real-state-predicting-rental-prices-in-amsterdam/)

This is her article, posted on Medium, which has very strict plagiarism protections posted on April 24th: [https://towardsdatascience.com/ai-and-real-state-renting-in-amsterdam-part-1-5fce18238dbc](https://towardsdatascience.com/ai-and-real-state-renting-in-amsterdam-part-1-5fce18238dbc)",1589721968.0,1498.0,75.0,/r/datascience/comments/glfdmm/a_data_science_company_stole_my_gfs_ml_project/,https://www.reddit.com/r/datascience/comments/glfdmm/a_data_science_company_stole_my_gfs_ml_project/,eawal,datascience,0.98,True,False,False,False,0.0,1745834656.078194,Tech & Programming,19.0,448.0,454.0,Sunday,9.0,May,2020.0,True,0.962,0.101,0.058,0.841,positive,a data science company stole my gfs ml project and reposted it as their own what do i do,dean hoffman responds hi my girlfriend is a year old university student passionate about data science and she just posted my first article on medium using machinelearning that took her months of research and coding to put together her post only has about views but to her surprise today a reddit user called deanhoffman posted a link to his own data science company where he copypasted her article he didnt contact her about reposting it didnt give her proper credit and ridiculously added a contact data scientist at the end with his name on it on the article he clearly stated he is the author in multiple locations this is the data science company that links from the article on his website apparently the guy dean hoffman is the founder of the company and refers to himself on the about us as offering the highest commitment to excellence personal integrity and business ethics update hey this is the girlfriend that wrote the article first of all thank you all that made the time to reply research and help me find answers its really appreciated so far this is what we know about this person or people this website has been stealing hundreds if not thousands of data science projects and articles from legitimate data scientists and writers the stolen content website in definitely botoperated as the owner posts dozens of articles a day completely copypaste mainly from medium techcrunch and towards data science its confirmed that deanhoffman from the linkedin that links from his company actionable labs is a real person and the same deanhoffman that is stealing content and running a data company if you go on his linkedin under data scientist pennsylvania department of general services you will find that he mentions actionable insights the stolen content website in one of his experiences completely absurd update medium and tds unfortunately cant do much for me individually as the authors are the ones who own the rights to the articles tds will try to reach out to the owner and ask them to take the posts down i hope they see that their whole website is being copied which would most likely infringe their tos please dont comment anything that contains the words copyright infringement or related words on her article as it may trigger keyword algorithms that delete copyrighted articles posted to medium and thus could have her article deleted thank you this is his post on reddit this is the article he stole from her this is her article posted on medium which has very strict plagiarism protections posted on april th,a data science company stole my gfs ml project and reposted it as their own what do i do dean hoffman responds hi my girlfriend is a year old university student passionate about data science and she just posted my first article on medium using machinelearning that took her months of research and coding to put together her post only has about views but to her surprise today a reddit user called deanhoffman posted a link to his own data science company where he copypasted her article he didnt contact her about reposting it didnt give her proper credit and ridiculously added a contact data scientist at the end with his name on it on the article he clearly stated he is the author in multiple locations this is the data science company that links from the article on his website apparently the guy dean hoffman is the founder of the company and refers to himself on the about us as offering the highest commitment to excellence personal integrity and business ethics update hey this is the girlfriend that wrote the article first of all thank you all that made the time to reply research and help me find answers its really appreciated so far this is what we know about this person or people this website has been stealing hundreds if not thousands of data science projects and articles from legitimate data scientists and writers the stolen content website in definitely botoperated as the owner posts dozens of articles a day completely copypaste mainly from medium techcrunch and towards data science its confirmed that deanhoffman from the linkedin that links from his company actionable labs is a real person and the same deanhoffman that is stealing content and running a data company if you go on his linkedin under data scientist pennsylvania department of general services you will find that he mentions actionable insights the stolen content website in one of his experiences completely absurd update medium and tds unfortunately cant do much for me individually as the authors are the ones who own the rights to the articles tds will try to reach out to the owner and ask them to take the posts down i hope they see that their whole website is being copied which would most likely infringe their tos please dont comment anything that contains the words copyright infringement or related words on her article as it may trigger keyword algorithms that delete copyrighted articles posted to medium and thus could have her article deleted thank you this is his post on reddit this is the article he stole from her this is her article posted on medium which has very strict plagiarism protections posted on april th,"article, data, science, company, posted",2020-05-17 13:26:08,a data science company stole my gfs ml project and reposted it as their own what do i do dean hoffman responds hi my girlfriend is a year old university student passionate about data science and she just posted my first article on medium using machinelearning that took her months of research and coding to put together her post only has about views but to her surprise today a reddit user called deanhoffman posted a link to his own data science company where he copypasted her article he didnt contact her about reposting it didnt give her proper credit and ridiculously added a contact data scientist at the end with his name on it on the article he clearly stated he is the author in multiple locations this is the data science company that links from the article on his website apparently the guy dean hoffman is the founder of the company and refers to himself on the about us as offering the highest commitment to excellence personal integrity and business ethics update hey this is the girlfriend that wrote the article first of all thank you all that made the time to reply research and help me find answers its really appreciated so far this is what we know about this person or people this website has been stealing hundreds if not thousands of data science projects and articles from legitimate data scientists and writers the stolen content website in definitely botoperated as the owner posts dozens of articles a day completely copypaste mainly from medium techcrunch and towards data science its confirmed that deanhoffman from the linkedin that links from his company actionable labs is a real person and the same deanhoffman that is stealing content and running a data company if you go on his linkedin under data scientist pennsylvania department of general services you will find that he mentions actionable insights the stolen content website in one of his experiences completely absurd update medium and tds unfortunately cant do much for me individually as the authors are the ones who own the rights to the articles tds will try to reach out to the owner and ask them to take the posts down i hope they see that their whole website is being copied which would most likely infringe their tos please dont comment anything that contains the words copyright infringement or related words on her article as it may trigger keyword algorithms that delete copyrighted articles posted to medium and thus could have her article deleted thank you this is his post on reddit this is the article he stole from her this is her article posted on medium which has very strict plagiarism protections posted on april th,"['data', 'science', 'company', 'stole', 'gfs', 'project', 'reposted', 'dean', 'hoffman', 'responds', 'girlfriend', 'year', 'old', 'university', 'student', 'passionate', 'data', 'science', 'posted', 'first', 'article', 'medium', 'using', 'machinelearning', 'took', 'month', 'research', 'coding', 'put', 'together', 'post', 'view', 'surprise', 'today', 'reddit', 'user', 'called', 'deanhoffman', 'posted', 'link', 'data', 'science', 'company', 'copypasted', 'article', 'didnt', 'contact', 'reposting', 'didnt', 'give', 'proper', 'credit', 'ridiculously', 'added', 'contact', 'data', 'scientist', 'end', 'name', 'article', 'clearly', 'stated', 'author', 'multiple', 'location', 'data', 'science', 'company', 'link', 'article', 'website', 'apparently', 'guy', 'dean', 'hoffman', 'founder', 'company', 'refers', 'offering', 'highest', 'commitment', 'excellence', 'personal', 'integrity', 'business', 'ethic', 'update', 'hey', 'girlfriend', 'wrote', 'article', 'first', 'thank', 'made', 'time', 'reply', 'research', 'help', 'find', 'answer', 'really', 'appreciated', 'far', 'know', 'person', 'people', 'website', 'stealing', 'hundred', 'thousand', 'data', 'science', 'project', 'article', 'legitimate', 'data', 'scientist', 'writer', 'stolen', 'content', 'website', 'definitely', 'botoperated', 'owner', 'post', 'dozen', 'article', 'day', 'completely', 'copypaste', 'mainly', 'medium', 'techcrunch', 'towards', 'data', 'science', 'confirmed', 'deanhoffman', 'linkedin', 'link', 'company', 'actionable', 'lab', 'real', 'person', 'deanhoffman', 'stealing', 'content', 'running', 'data', 'company', 'linkedin', 'data', 'scientist', 'pennsylvania', 'department', 'general', 'service', 'find', 'mention', 'actionable', 'insight', 'stolen', 'content', 'website', 'one', 'experience', 'completely', 'absurd', 'update', 'medium', 'tds', 'unfortunately', 'cant', 'much', 'individually', 'author', 'one', 'right', 'article', 'tds', 'try', 'reach', 'owner', 'ask', 'take', 'post', 'hope', 'see', 'whole', 'website', 'copied', 'would', 'likely', 'infringe', 'tos', 'please', 'dont', 'comment', 'anything', 'contains', 'word', 'copyright', 'infringement', 'related', 'word', 'article', 'may', 'trigger', 'keyword', 'algorithm', 'delete', 'copyrighted', 'article', 'posted', 'medium', 'thus', 'could', 'article', 'deleted', 'thank', 'post', 'reddit', 'article', 'stole', 'article', 'posted', 'medium', 'strict', 'plagiarism', 'protection', 'posted', 'april']",,,,
x6ji1j,Happy meme Monday,,1662393088.0,1491.0,33.0,/r/datascience/comments/x6ji1j/happy_meme_monday/,https://i.redd.it/5nxxj1ama2m91.png,-Zubenelgenubi,datascience,0.99,False,False,False,False,0.0,1745834656.690628,Tech & Programming,3.0,0.0,3.0,Monday,11.0,September,2022.0,False,0.5719,0.649,0.0,0.351,positive,happy meme monday,,happy meme monday ,"happy, meme, monday",2022-09-05 15:51:28,happy meme monday ,"['happy', 'meme', 'monday']",,,,
zqsseu,Agree?,,1671553809.0,1482.0,55.0,/r/datascience/comments/zqsseu/agree/,https://i.redd.it/q9b3rccof47a1.jpg,Apprehensive_Level_8,datascience,0.91,False,False,False,False,0.0,1745834657.162399,Tech & Programming,1.0,0.0,1.0,Tuesday,11.0,December,2022.0,False,0.3612,1.0,0.0,0.0,positive,agree,,agree ,agree,2022-12-20 16:30:09,agree ,['agree'],,,,
ur5521,“I would like to nominate CNN for the worst data visualization of 2022”,,1652732665.0,1480.0,88.0,/r/datascience/comments/ur5521/i_would_like_to_nominate_cnn_for_the_worst_data/,https://i.redd.it/zjcqepf8dwz81.jpg,rotterdamn8,datascience,0.99,False,False,False,False,0.0,1745834657.43047,Tech & Programming,13.0,0.0,12.0,Monday,16.0,May,2022.0,False,-0.3818,0.16,0.263,0.577,negative,i would like to nominate cnn for the worst data visualization of,,i would like to nominate cnn for the worst data visualization of ,"would, like, nominate, cnn, worst",2022-05-16 20:24:25,i would like to nominate cnn for the worst data visualization of ,"['would', 'like', 'nominate', 'cnn', 'worst', 'data', 'visualization']",,,,
p6lpws,Very proud of my CS book collection.,,1629268445.0,1471.0,131.0,/r/datascience/comments/p6lpws/very_proud_of_my_cs_book_collection/,https://i.redd.it/can2b292a2i71.jpg,,datascience,0.95,False,False,False,False,0.0,1745834657.977619,Tech & Programming,7.0,0.0,7.0,Wednesday,2.0,August,2021.0,False,0.5256,0.361,0.0,0.639,positive,very proud of my cs book collection,,very proud of my cs book collection ,"proud, book, collection",2021-08-18 06:34:05,very proud of my cs book collection ,"['proud', 'book', 'collection']",,,,
wjycg3,Choose your modeler,,1660035499.0,1462.0,70.0,/r/datascience/comments/wjycg3/choose_your_modeler/,https://i.redd.it/4fwef9ktjng91.png,curizzo,datascience,0.98,False,False,False,False,0.0,1745834658.576846,Tech & Programming,3.0,0.0,3.0,Tuesday,4.0,August,2022.0,False,0.0,0.0,0.0,1.0,neutral,choose your modeler,,choose your modeler ,"choose, modeler",2022-08-09 08:58:19,choose your modeler ,"['choose', 'modeler']",,,,
mcy1zw,Alan Turing is the new face on the British £50 note,,1616678379.0,1437.0,93.0,/r/datascience/comments/mcy1zw/alan_turing_is_the_new_face_on_the_british_50_note/,https://www.reddit.com/r/unitedkingdom/comments/mct0kf/new_alan_turing_50_note_design_is_revealed/?utm_source=share&utm_medium=ios_app&utm_name=iossmf,BullCityPicker,datascience,0.99,False,False,False,False,0.0,1745834658.95649,Tech & Programming,11.0,0.0,10.0,Thursday,9.0,March,2021.0,False,0.0,0.0,0.0,1.0,neutral,alan turing is the new face on the british note,,alan turing is the new face on the british note ,"alan, turing, new, face, british",2021-03-25 13:19:39,alan turing is the new face on the british note ,"['alan', 'turing', 'new', 'face', 'british', 'note']",,,,
f20n3x,when I start EDA on a new project,,1581384043.0,1426.0,9.0,/r/datascience/comments/f20n3x/when_i_start_eda_on_a_new_project/,https://i.redd.it/886thyh557g41.jpg,jonboighini,datascience,0.98,False,False,False,False,0.0,1745834659.651289,Tech & Programming,8.0,0.0,8.0,Monday,20.0,February,2020.0,False,0.0,0.0,0.0,1.0,neutral,when i start eda on a new project,,when i start eda on a new project ,"start, eda, new, project",2020-02-11 01:20:43,when i start eda on a new project ,"['start', 'eda', 'new', 'project']",,,,
qdai89,"I just explained recall/precision to a non-DS, and he got it immediately","Explain it like fishing with a net. You use a wide net, and catch 80 of 100 total fish in a lake. That's 80% recall. But you also get 80 rocks in your net. That means 50% precision, half of the net's contents is junk. You could use a smaller net and target one pocket of the lake where there are lots of fish and no rocks, but you might only get 20 of the fish in order to get 0 rocks. That is 20% recall and 100% precision.

Seriously, it made me so happy since I've butted against this for years. Equations make people's eyes glaze over, but my PM understood this immediately over a voice call, without diagrams or anything.

Also I googled this and found it's a common explanation, but I'd never heard of it in my 4 years working as a DS. ",1634882352.0,1417.0,64.0,/r/datascience/comments/qdai89/i_just_explained_recallprecision_to_a_nonds_and/,https://www.reddit.com/r/datascience/comments/qdai89/i_just_explained_recallprecision_to_a_nonds_and/,question_23,datascience,0.98,True,False,False,False,1.0,1745834659.828001,Tech & Programming,12.0,146.0,148.0,Friday,1.0,October,2021.0,False,0.6717,0.057,0.033,0.91,positive,i just explained recallprecision to a nonds and he got it immediately,explain it like fishing with a net you use a wide net and catch of total fish in a lake thats recall but you also get rocks in your net that means precision half of the nets contents is junk you could use a smaller net and target one pocket of the lake where there are lots of fish and no rocks but you might only get of the fish in order to get rocks that is recall and precision seriously it made me so happy since ive butted against this for years equations make peoples eyes glaze over but my pm understood this immediately over a voice call without diagrams or anything also i googled this and found its a common explanation but id never heard of it in my years working as a ds,i just explained recallprecision to a nonds and he got it immediately explain it like fishing with a net you use a wide net and catch of total fish in a lake thats recall but you also get rocks in your net that means precision half of the nets contents is junk you could use a smaller net and target one pocket of the lake where there are lots of fish and no rocks but you might only get of the fish in order to get rocks that is recall and precision seriously it made me so happy since ive butted against this for years equations make peoples eyes glaze over but my pm understood this immediately over a voice call without diagrams or anything also i googled this and found its a common explanation but id never heard of it in my years working as a ds,"net, fish, get, rock, immediately",2021-10-22 05:59:12,i just explained recallprecision to a nonds and he got it immediately explain it like fishing with a net you use a wide net and catch of total fish in a lake thats recall but you also get rocks in your net that means precision half of the nets contents is junk you could use a smaller net and target one pocket of the lake where there are lots of fish and no rocks but you might only get of the fish in order to get rocks that is recall and precision seriously it made me so happy since ive butted against this for years equations make peoples eyes glaze over but my pm understood this immediately over a voice call without diagrams or anything also i googled this and found its a common explanation but id never heard of it in my years working as a ds,"['explained', 'recallprecision', 'nonds', 'got', 'immediately', 'explain', 'like', 'fishing', 'net', 'use', 'wide', 'net', 'catch', 'total', 'fish', 'lake', 'thats', 'recall', 'also', 'get', 'rock', 'net', 'mean', 'precision', 'half', 'net', 'content', 'junk', 'could', 'use', 'smaller', 'net', 'target', 'one', 'pocket', 'lake', 'lot', 'fish', 'rock', 'might', 'get', 'fish', 'order', 'get', 'rock', 'recall', 'precision', 'seriously', 'made', 'happy', 'since', 'ive', 'butted', 'year', 'equation', 'make', 'people', 'eye', 'glaze', 'understood', 'immediately', 'voice', 'call', 'without', 'diagram', 'anything', 'also', 'googled', 'found', 'common', 'explanation', 'never', 'heard', 'year', 'working']",,,,
1b1au2f,Data scientist quits her job at Spotify,In summary and basically talks about how she was managing a high priority product at Spotify after 3 years at Spotify. She was the ONLY DATA SCIENTIST working on this project and with pushy stakeholders she was working 14-15 hour days. Frankly this would piss me the fuck off. How the hell does some shit like this even happen? How common is this? For a place like Spotify it sounds quite shocking. How do you manage a “pushy” stakeholder?,1709037427.0,1389.0,368.0,/r/datascience/comments/1b1au2f/data_scientist_quits_her_job_at_spotify/,https://youtu.be/OMI4Wu9wnY0?si=teFkXgTnPmUAuAyU,Direct-Touch469,datascience,0.91,False,False,False,False,0.0,1745834660.228724,Tech & Programming,7.0,79.0,84.0,Tuesday,7.0,February,2024.0,False,-0.9485,0.051,0.219,0.73,negative,data scientist quits her job at spotify,in summary and basically talks about how she was managing a high priority product at spotify after years at spotify she was the only data scientist working on this project and with pushy stakeholders she was working hour days frankly this would piss me the fuck off how the hell does some shit like this even happen how common is this for a place like spotify it sounds quite shocking how do you manage a pushy stakeholder,data scientist quits her job at spotify in summary and basically talks about how she was managing a high priority product at spotify after years at spotify she was the only data scientist working on this project and with pushy stakeholders she was working hour days frankly this would piss me the fuck off how the hell does some shit like this even happen how common is this for a place like spotify it sounds quite shocking how do you manage a pushy stakeholder,"spotify, data, scientist, working, pushy",2024-02-27 12:37:07,data scientist quits her job at spotify in summary and basically talks about how she was managing a high priority product at spotify after years at spotify she was the only data scientist working on this project and with pushy stakeholders she was working hour days frankly this would piss me the fuck off how the hell does some shit like this even happen how common is this for a place like spotify it sounds quite shocking how do you manage a pushy stakeholder,"['data', 'scientist', 'quits', 'job', 'spotify', 'summary', 'basically', 'talk', 'managing', 'high', 'priority', 'product', 'spotify', 'year', 'spotify', 'data', 'scientist', 'working', 'project', 'pushy', 'stakeholder', 'working', 'hour', 'day', 'frankly', 'would', 'piss', 'fuck', 'hell', 'shit', 'like', 'even', 'happen', 'common', 'place', 'like', 'spotify', 'sound', 'quite', 'shocking', 'manage', 'pushy', 'stakeholder']",,,,
qypj5f,I'll never find an entry level job,,1637478495.0,1389.0,205.0,/r/datascience/comments/qypj5f/ill_never_find_an_entry_level_job/,https://i.redd.it/uss8ci5rew081.jpg,streak_quest,datascience,0.97,False,False,False,False,0.0,1745834662.323042,Tech & Programming,7.0,0.0,7.0,Sunday,2.0,November,2021.0,True,-0.4215,0.0,0.318,0.682,negative,ill never find an entry level job,,ill never find an entry level job ,"ill, never, find, entry, level",2021-11-21 07:08:15,ill never find an entry level job ,"['ill', 'never', 'find', 'entry', 'level', 'job']",,,,
1g3ajqa,tanh me later,,1728891744.0,1382.0,27.0,/r/datascience/comments/1g3ajqa/tanh_me_later/,https://i.redd.it/qzjthphseoud1.jpeg,Manticore-Mk2,datascience,0.95,False,False,False,False,0.0,1745834663.236334,Tech & Programming,3.0,0.0,3.0,Monday,3.0,October,2024.0,False,0.0,0.0,0.0,1.0,neutral,tanh me later,,tanh me later ,"tanh, later",2024-10-14 07:42:24,tanh me later ,"['tanh', 'later']",,,,
j4auif,I created a complete overview of machine learning concepts seen in 27 data science and machine learning interviews,"Hey everyone,

During my last interview cycle, I did 27 machine learning and data science interviews at a bunch of companies (from Google to a \~8-person YC-backed computer vision startup). Afterwards, I wrote an overview of all the concepts that showed up, presented as a series of tutorials along with practice questions at the end of each section.

I hope you find it helpful! [ML Primer](https://www.confetti.ai/assets/ml-primer/ml_primer.pdf)",1601705416.0,1380.0,101.0,/r/datascience/comments/j4auif/i_created_a_complete_overview_of_machine_learning/,https://www.reddit.com/r/datascience/comments/j4auif/i_created_a_complete_overview_of_machine_learning/,ElegantFeeling,datascience,0.99,True,False,False,False,3.0,1745834663.450031,Tech & Programming,18.0,66.0,82.0,Saturday,2.0,October,2020.0,True,0.8271,0.122,0.0,0.878,positive,i created a complete overview of machine learning concepts seen in data science and machine learning interviews,hey everyone during my last interview cycle i did machine learning and data science interviews at a bunch of companies from google to a person ycbacked computer vision startup afterwards i wrote an overview of all the concepts that showed up presented as a series of tutorials along with practice questions at the end of each section i hope you find it helpful ml primer,i created a complete overview of machine learning concepts seen in data science and machine learning interviews hey everyone during my last interview cycle i did machine learning and data science interviews at a bunch of companies from google to a person ycbacked computer vision startup afterwards i wrote an overview of all the concepts that showed up presented as a series of tutorials along with practice questions at the end of each section i hope you find it helpful ml primer,"machine, learning, interview, overview, concept",2020-10-03 06:10:16,i created a complete overview of machine learning concepts seen in data science and machine learning interviews hey everyone during my last interview cycle i did machine learning and data science interviews at a bunch of companies from google to a person ycbacked computer vision startup afterwards i wrote an overview of all the concepts that showed up presented as a series of tutorials along with practice questions at the end of each section i hope you find it helpful ml primer,"['created', 'complete', 'overview', 'machine', 'learning', 'concept', 'seen', 'data', 'science', 'machine', 'learning', 'interview', 'hey', 'everyone', 'last', 'interview', 'cycle', 'machine', 'learning', 'data', 'science', 'interview', 'bunch', 'company', 'google', 'person', 'ycbacked', 'computer', 'vision', 'startup', 'afterwards', 'wrote', 'overview', 'concept', 'showed', 'presented', 'series', 'tutorial', 'along', 'practice', 'question', 'end', 'section', 'hope', 'find', 'helpful', 'primer']",,,,
u6dlyr,£19.91/hr for a PhD Data scientist 😭😂😂,,1650289752.0,1374.0,331.0,/r/datascience/comments/u6dlyr/1991hr_for_a_phd_data_scientist/,https://i.redd.it/r8fgcc27lau81.jpg,Cotto079,datascience,0.95,False,False,False,False,0.0,1745834663.978601,Tech & Programming,7.0,0.0,6.0,Monday,9.0,April,2022.0,False,0.0,0.0,0.0,1.0,neutral,hr for a phd data scientist,,hr for a phd data scientist ,"phd, data, scientist",2022-04-18 13:49:12,hr for a phd data scientist ,"['phd', 'data', 'scientist']",,,,
oikye2,Based on a true story,,1626068158.0,1365.0,32.0,/r/datascience/comments/oikye2/based_on_a_true_story/,https://i.redd.it/mtyo342oxpa71.png,Drunken_Economist,datascience,0.97,False,False,False,False,0.0,1745834665.849582,Tech & Programming,5.0,0.0,5.0,Monday,1.0,July,2021.0,False,0.4215,0.483,0.0,0.517,positive,based on a true story,,based on a true story ,"based, true, story",2021-07-12 05:35:58,based on a true story ,"['based', 'true', 'story']",,,,
uz12cu,Results of my first data science job search. Some insight in the comments.,,1653666340.0,1351.0,150.0,/r/datascience/comments/uz12cu/results_of_my_first_data_science_job_search_some/,https://i.redd.it/9efr8hatg1291.png,BasedAcid,datascience,0.95,False,False,False,False,0.0,1745834666.093563,Tech & Programming,13.0,0.0,13.0,Friday,11.0,May,2022.0,False,0.0,0.0,0.0,1.0,neutral,results of my first data science job search some insight in the comments,,results of my first data science job search some insight in the comments ,"result, first, data, science, job",2022-05-27 15:45:40,results of my first data science job search some insight in the comments ,"['result', 'first', 'data', 'science', 'job', 'search', 'insight', 'comment']",,,,
rmcgwt,HBR says that data cleaning is not time consuming to acquire and not useful 🤣😆😂,,1640200517.0,1347.0,282.0,/r/datascience/comments/rmcgwt/hbr_says_that_data_cleaning_is_not_time_consuming/,https://i.redd.it/a57zypsj85781.png,geo_jam,datascience,0.93,False,False,False,False,0.0,1745834667.074079,Tech & Programming,15.0,0.0,14.0,Wednesday,14.0,December,2021.0,False,-0.3412,0.0,0.156,0.844,negative,hbr says that data cleaning is not time consuming to acquire and not useful,,hbr says that data cleaning is not time consuming to acquire and not useful ,"hbr, say, data, cleaning, time",2021-12-22 19:15:17,hbr says that data cleaning is not time consuming to acquire and not useful ,"['hbr', 'say', 'data', 'cleaning', 'time', 'consuming', 'acquire', 'useful']",,,,
tqbez2,me picking a learning rate for my model,,1648480088.0,1318.0,29.0,/r/datascience/comments/tqbez2/me_picking_a_learning_rate_for_my_model/,https://v.redd.it/heh07w3145q81,pap_n_whores,datascience,0.99,False,False,False,False,0.0,1745834668.264251,Tech & Programming,8.0,0.0,8.0,Monday,11.0,March,2022.0,False,0.0,0.0,0.0,1.0,neutral,me picking a learning rate for my model,,me picking a learning rate for my model ,"picking, learning, rate, model",2022-03-28 15:08:08,me picking a learning rate for my model ,"['picking', 'learning', 'rate', 'model']",,,,
ycgmbu,Data = Oil,,1666631018.0,1310.0,78.0,/r/datascience/comments/ycgmbu/data_oil/,https://i.redd.it/d8xfyn96csv91.jpg,realbigflavor,datascience,0.97,False,False,False,False,0.0,1745834668.497936,Tech & Programming,3.0,0.0,2.0,Monday,13.0,October,2022.0,False,0.0,0.0,0.0,1.0,neutral,data oil,,data oil ,"data, oil",2022-10-24 17:03:38,data oil ,"['data', 'oil']",,,,
p7hpd9,"The Key Word in Data Science is Science, not Data","I know reddit doesn't represent real life, but just look at the titles of this sub. They're all about tools, code languages/packages, and algorithms. I think to most aspiring data scientists, that's how they see the profession. You're given a tech stack, some data, and your goal is to apply x tool/algorithm to y data. My argument is this is only going to work at super junior levels, and I believe it's the reason why there's a huge oversupply of junior data scientists but teams still can't find competent seniors.  


As another experiment, just head over to r/dataisbeautiful right now. You'll see a ton of different techs used to generate some decent and some awful visualizations. All of those people were able to access, clean, and plot data. There's no shortage of people who can do that. But what you'll notice if you read that sub, is there's a huge lack of people thinking critically about the data they're working with, and that's the science aspect.

&#x200B;

I feel like every week there's a new topic here on how long until data scientists are obsolete. I don't think data scientists are getting less valuable, but people who can just use tool x to leverage data y are. Why would I hire a senior data scientist to create a dashboard when I can teach an intern tableau and get 95% of the same thing? Whether it's recognizing Simpson's paradox, knowing when to keep/stop digging into research questions, figuring out when gathering more data is necessary, knowing how to communicate findings in ways that make an impact, the science part of data science is by far the most valuable. Some people call them soft skills, but I'm not a huge fan of the term. It's science. Unfortunately these are the toughest skills to learn and also the toughest skills to interview for, so I don't suspect you'll see companies steering away from technical questions in interviews any time soon. But mastering the science aspect of data science is I believe the best way to make yourself extremely valuable.",1629388865.0,1304.0,155.0,/r/datascience/comments/p7hpd9/the_key_word_in_data_science_is_science_not_data/,https://www.reddit.com/r/datascience/comments/p7hpd9/the_key_word_in_data_science_is_science_not_data/,,datascience,0.96,True,False,False,False,0.0,1745834668.991714,Tech & Programming,10.0,346.0,355.0,Thursday,12.0,August,2021.0,False,0.9555,0.113,0.08,0.807,positive,the key word in data science is science not data,i know reddit doesnt represent real life but just look at the titles of this sub theyre all about tools code languagespackages and algorithms i think to most aspiring data scientists thats how they see the profession youre given a tech stack some data and your goal is to apply x toolalgorithm to y data my argument is this is only going to work at super junior levels and i believe its the reason why theres a huge oversupply of junior data scientists but teams still cant find competent seniors as another experiment just head over to rdataisbeautiful right now youll see a ton of different techs used to generate some decent and some awful visualizations all of those people were able to access clean and plot data theres no shortage of people who can do that but what youll notice if you read that sub is theres a huge lack of people thinking critically about the data theyre working with and thats the science aspect xb i feel like every week theres a new topic here on how long until data scientists are obsolete i dont think data scientists are getting less valuable but people who can just use tool x to leverage data y are why would i hire a senior data scientist to create a dashboard when i can teach an intern tableau and get of the same thing whether its recognizing simpsons paradox knowing when to keepstop digging into research questions figuring out when gathering more data is necessary knowing how to communicate findings in ways that make an impact the science part of data science is by far the most valuable some people call them soft skills but im not a huge fan of the term its science unfortunately these are the toughest skills to learn and also the toughest skills to interview for so i dont suspect youll see companies steering away from technical questions in interviews any time soon but mastering the science aspect of data science is i believe the best way to make yourself extremely valuable,the key word in data science is science not data i know reddit doesnt represent real life but just look at the titles of this sub theyre all about tools code languagespackages and algorithms i think to most aspiring data scientists thats how they see the profession youre given a tech stack some data and your goal is to apply x toolalgorithm to y data my argument is this is only going to work at super junior levels and i believe its the reason why theres a huge oversupply of junior data scientists but teams still cant find competent seniors as another experiment just head over to rdataisbeautiful right now youll see a ton of different techs used to generate some decent and some awful visualizations all of those people were able to access clean and plot data theres no shortage of people who can do that but what youll notice if you read that sub is theres a huge lack of people thinking critically about the data theyre working with and thats the science aspect xb i feel like every week theres a new topic here on how long until data scientists are obsolete i dont think data scientists are getting less valuable but people who can just use tool x to leverage data y are why would i hire a senior data scientist to create a dashboard when i can teach an intern tableau and get of the same thing whether its recognizing simpsons paradox knowing when to keepstop digging into research questions figuring out when gathering more data is necessary knowing how to communicate findings in ways that make an impact the science part of data science is by far the most valuable some people call them soft skills but im not a huge fan of the term its science unfortunately these are the toughest skills to learn and also the toughest skills to interview for so i dont suspect youll see companies steering away from technical questions in interviews any time soon but mastering the science aspect of data science is i believe the best way to make yourself extremely valuable,"data, science, scientist, people, there",2021-08-19 16:01:05,the key word in data science is science not data i know reddit doesnt represent real life but just look at the titles of this sub theyre all about tools code languagespackages and algorithms i think to most aspiring data scientists thats how they see the profession youre given a tech stack some data and your goal is to apply x toolalgorithm to y data my argument is this is only going to work at super junior levels and i believe its the reason why theres a huge oversupply of junior data scientists but teams still cant find competent seniors as another experiment just head over to rdataisbeautiful right now youll see a ton of different techs used to generate some decent and some awful visualizations all of those people were able to access clean and plot data theres no shortage of people who can do that but what youll notice if you read that sub is theres a huge lack of people thinking critically about the data theyre working with and thats the science aspect xb i feel like every week theres a new topic here on how long until data scientists are obsolete i dont think data scientists are getting less valuable but people who can just use tool x to leverage data y are why would i hire a senior data scientist to create a dashboard when i can teach an intern tableau and get of the same thing whether its recognizing simpsons paradox knowing when to keepstop digging into research questions figuring out when gathering more data is necessary knowing how to communicate findings in ways that make an impact the science part of data science is by far the most valuable some people call them soft skills but im not a huge fan of the term its science unfortunately these are the toughest skills to learn and also the toughest skills to interview for so i dont suspect youll see companies steering away from technical questions in interviews any time soon but mastering the science aspect of data science is i believe the best way to make yourself extremely valuable,"['key', 'word', 'data', 'science', 'science', 'data', 'know', 'reddit', 'doesnt', 'represent', 'real', 'life', 'look', 'title', 'sub', 'theyre', 'tool', 'code', 'languagespackages', 'algorithm', 'think', 'aspiring', 'data', 'scientist', 'thats', 'see', 'profession', 'youre', 'given', 'tech', 'stack', 'data', 'goal', 'apply', 'toolalgorithm', 'data', 'argument', 'going', 'work', 'super', 'junior', 'level', 'believe', 'reason', 'there', 'huge', 'oversupply', 'junior', 'data', 'scientist', 'team', 'still', 'cant', 'find', 'competent', 'senior', 'another', 'experiment', 'head', 'rdataisbeautiful', 'right', 'youll', 'see', 'ton', 'different', 'tech', 'used', 'generate', 'decent', 'awful', 'visualization', 'people', 'able', 'access', 'clean', 'plot', 'data', 'there', 'shortage', 'people', 'youll', 'notice', 'read', 'sub', 'there', 'huge', 'lack', 'people', 'thinking', 'critically', 'data', 'theyre', 'working', 'thats', 'science', 'aspect', 'feel', 'like', 'every', 'week', 'there', 'new', 'topic', 'long', 'data', 'scientist', 'obsolete', 'dont', 'think', 'data', 'scientist', 'getting', 'less', 'valuable', 'people', 'use', 'tool', 'leverage', 'data', 'would', 'hire', 'senior', 'data', 'scientist', 'create', 'dashboard', 'teach', 'intern', 'tableau', 'get', 'thing', 'whether', 'recognizing', 'simpson', 'paradox', 'knowing', 'keepstop', 'digging', 'research', 'question', 'figuring', 'gathering', 'data', 'necessary', 'knowing', 'communicate', 'finding', 'way', 'make', 'impact', 'science', 'part', 'data', 'science', 'far', 'valuable', 'people', 'call', 'soft', 'skill', 'huge', 'fan', 'term', 'science', 'unfortunately', 'toughest', 'skill', 'learn', 'also', 'toughest', 'skill', 'interview', 'dont', 'suspect', 'youll', 'see', 'company', 'steering', 'away', 'technical', 'question', 'interview', 'time', 'soon', 'mastering', 'science', 'aspect', 'data', 'science', 'believe', 'best', 'way', 'make', 'extremely', 'valuable']",,,,
vwvg8j,Congrats to us I guess?,,1657579475.0,1302.0,50.0,/r/datascience/comments/vwvg8j/congrats_to_us_i_guess/,https://i.imgur.com/H0lYnaj.jpg,coalcracker462,datascience,0.97,False,False,False,False,0.0,1745834669.876402,Tech & Programming,5.0,0.0,5.0,Monday,18.0,July,2022.0,False,0.5267,0.531,0.0,0.469,positive,congrats to us i guess,,congrats to us i guess ,"congrats, guess",2022-07-11 22:44:35,congrats to us i guess ,"['congrats', 'guess']",,,,
f1rufm,We've all been there.,,1581348458.0,1300.0,48.0,/r/datascience/comments/f1rufm/weve_all_been_there/,https://i.redd.it/03756y0874g41.jpg,Nateorade,datascience,0.96,False,False,False,False,0.0,1745834670.209499,Tech & Programming,4.0,0.0,4.0,Monday,10.0,February,2020.0,False,0.0,0.0,0.0,1.0,neutral,weve all been there,,weve all been there ,weve,2020-02-10 15:27:38,weve all been there ,['weve'],,,,
1jo4g14,It's important work.,,1743431151.0,1281.0,50.0,/r/datascience/comments/1jo4g14/its_important_work/,https://i.redd.it/9mcl3buvb1se1.png,ElectrikMetriks,datascience,0.99,False,False,False,False,0.0,1745834670.542089,Tech & Programming,3.0,0.0,3.0,Monday,10.0,March,2025.0,False,0.2023,0.474,0.0,0.526,positive,its important work,,its important work ,"important, work",2025-03-31 14:25:51,its important work ,"['important', 'work']",,,,
e0puay,How much real is it?? 😂😅,,1574550646.0,1279.0,50.0,/r/datascience/comments/e0puay/how_much_real_is_it/,https://i.redd.it/jhg8s6eypi041.png,Osiris_R,datascience,0.94,False,False,False,False,0.0,1745834670.817131,Tech & Programming,6.0,0.0,5.0,Saturday,18.0,November,2019.0,True,0.0,0.0,0.0,1.0,neutral,how much real is it,,how much real is it ,"much, real",2019-11-23 23:10:46,how much real is it ,"['much', 'real']",,,,
mp6ink,I found a research paper that is almost entirely my copied-and-pasted Kaggle work?,"I did some work a couple of years ago on W.H.O. suicide statistics. Here's my [Kaggle project](https://www.kaggle.com/lmorgan95/r-suicide-rates-in-depth-stats-insights) from April 2019, and here's the [research paper](https://www.researchgate.net/publication/338479643_Analysis_of_Mental_Health_Program_based_on_Suicide_Rate_Trends_1985_to_2015) from January 2020.

It was immediately clear from me seeing the graphs that the work was the same, but most of the findings are entire paragraphs lifted from my work. This isn't the first time this has happened but it's probably the most egregious. My work is obviously not mentioned in the references.

Is there anything I can actually do here? I don't care about people using or adapting my public work as long as credit is given, but copying most of it and giving no credit really isn't cool.

**Edit:** Thanks for all the help and advice. I contacted the universities of the authors this morning (no response yet... and I can't help but feel like I'm not going to get one)",1618200565.0,1267.0,111.0,/r/datascience/comments/mp6ink/i_found_a_research_paper_that_is_almost_entirely/,https://www.reddit.com/r/datascience/comments/mp6ink/i_found_a_research_paper_that_is_almost_entirely/,supra95,datascience,0.99,True,False,False,False,0.0,1745834671.159752,Tech & Programming,13.0,148.0,159.0,Monday,0.0,April,2021.0,False,0.6472,0.124,0.1,0.776,positive,i found a research paper that is almost entirely my copiedandpasted kaggle work,i did some work a couple of years ago on who suicide statistics heres my kaggle project from april and heres the research paper from january it was immediately clear from me seeing the graphs that the work was the same but most of the findings are entire paragraphs lifted from my work this isnt the first time this has happened but its probably the most egregious my work is obviously not mentioned in the references is there anything i can actually do here i dont care about people using or adapting my public work as long as credit is given but copying most of it and giving no credit really isnt cool edit thanks for all the help and advice i contacted the universities of the authors this morning no response yet and i cant help but feel like im not going to get one,i found a research paper that is almost entirely my copiedandpasted kaggle work i did some work a couple of years ago on who suicide statistics heres my kaggle project from april and heres the research paper from january it was immediately clear from me seeing the graphs that the work was the same but most of the findings are entire paragraphs lifted from my work this isnt the first time this has happened but its probably the most egregious my work is obviously not mentioned in the references is there anything i can actually do here i dont care about people using or adapting my public work as long as credit is given but copying most of it and giving no credit really isnt cool edit thanks for all the help and advice i contacted the universities of the authors this morning no response yet and i cant help but feel like im not going to get one,"work, research, paper, kaggle, here",2021-04-12 04:09:25,i found a research paper that is almost entirely my copiedandpasted kaggle work i did some work a couple of years ago on who suicide statistics heres my kaggle project from april and heres the research paper from january it was immediately clear from me seeing the graphs that the work was the same but most of the findings are entire paragraphs lifted from my work this isnt the first time this has happened but its probably the most egregious my work is obviously not mentioned in the references is there anything i can actually do here i dont care about people using or adapting my public work as long as credit is given but copying most of it and giving no credit really isnt cool edit thanks for all the help and advice i contacted the universities of the authors this morning no response yet and i cant help but feel like im not going to get one,"['found', 'research', 'paper', 'almost', 'entirely', 'copiedandpasted', 'kaggle', 'work', 'work', 'couple', 'year', 'ago', 'suicide', 'statistic', 'here', 'kaggle', 'project', 'april', 'here', 'research', 'paper', 'january', 'immediately', 'clear', 'seeing', 'graph', 'work', 'finding', 'entire', 'paragraph', 'lifted', 'work', 'isnt', 'first', 'time', 'happened', 'probably', 'egregious', 'work', 'obviously', 'mentioned', 'reference', 'anything', 'actually', 'dont', 'care', 'people', 'using', 'adapting', 'public', 'work', 'long', 'credit', 'given', 'copying', 'giving', 'credit', 'really', 'isnt', 'cool', 'edit', 'thanks', 'help', 'advice', 'contacted', 'university', 'author', 'morning', 'response', 'yet', 'cant', 'help', 'feel', 'like', 'going', 'get', 'one']",,,,
yhrlpj,"PYTHON CHARTS: a new visualization website feaaturing matplotlib, seaborn and plotly [Over 500 charts with reproducible code]","I've recently launched ""PYTHON CHARTS"", a website that provides lots of matplotlib, seaborn and plotly easy-to-follow tutorials with reproducible code, both in English and Spanish.  


Link: [https://python-charts.com/](https://python-charts.com/)  
Link (spanish): [https://python-charts.com/es/](https://python-charts.com/es/)

&#x200B;

https://preview.redd.it/v4kwjk5hn0x91.png?width=939&format=png&auto=webp&s=e2b92d7db2d6c63ce4bff55dabe34e96236d646e

The posts are filterable based on the chart type and library:

https://preview.redd.it/4tfvn5prn0x91.png?width=898&format=png&auto=webp&s=e7cba3f1bda4ec05fcf7f1a21489d1811c3e4a30

Each tutorial will guide the reader step by step from a basic to more styled chart:

https://preview.redd.it/yrsnxpdwn0x91.png?width=694&format=png&auto=webp&s=ea772dda73588bbf87326e8ef384d002e0355f76

The site also provides some color tools to copy matplotlib colors both in HEX or by its name. You can also convert HEX to RGB in the page:

https://preview.redd.it/hxhdctl2o0x91.png?width=890&format=png&auto=webp&s=5cc280970d2112986d5ba35205e6aa6f224689e5

&#x200B;

* I created this website on my spare time for all those finding the original docs difficult to follow.
* This site has its equivalent in R: [https://r-charts.com/](https://r-charts.com/)

Hope you like it!",1667167934.0,1264.0,63.0,/r/datascience/comments/yhrlpj/python_charts_a_new_visualization_website/,https://www.reddit.com/r/datascience/comments/yhrlpj/python_charts_a_new_visualization_website/,JZOSS,datascience,0.99,True,False,False,False,1.0,1745834671.719763,Tech & Programming,17.0,123.0,130.0,Sunday,18.0,October,2022.0,True,0.7717,0.084,0.019,0.897,positive,python charts a new visualization website feaaturing matplotlib seaborn and plotly over charts with reproducible code,ive recently launched python charts a website that provides lots of matplotlib seaborn and plotly easytofollow tutorials with reproducible code both in english and spanish link link spanish xb the posts are filterable based on the chart type and library each tutorial will guide the reader step by step from a basic to more styled chart the site also provides some color tools to copy matplotlib colors both in hex or by its name you can also convert hex to rgb in the page xb i created this website on my spare time for all those finding the original docs difficult to follow this site has its equivalent in r hope you like it,python charts a new visualization website feaaturing matplotlib seaborn and plotly over charts with reproducible code ive recently launched python charts a website that provides lots of matplotlib seaborn and plotly easytofollow tutorials with reproducible code both in english and spanish link link spanish xb the posts are filterable based on the chart type and library each tutorial will guide the reader step by step from a basic to more styled chart the site also provides some color tools to copy matplotlib colors both in hex or by its name you can also convert hex to rgb in the page xb i created this website on my spare time for all those finding the original docs difficult to follow this site has its equivalent in r hope you like it,"chart, website, matplotlib, python, seaborn",2022-10-30 22:12:14,python charts a new visualization website feaaturing matplotlib seaborn and plotly over charts with reproducible code ive recently launched python charts a website that provides lots of matplotlib seaborn and plotly easytofollow tutorials with reproducible code both in english and spanish link link spanish xb the posts are filterable based on the chart type and library each tutorial will guide the reader step by step from a basic to more styled chart the site also provides some color tools to copy matplotlib colors both in hex or by its name you can also convert hex to rgb in the page xb i created this website on my spare time for all those finding the original docs difficult to follow this site has its equivalent in r hope you like it,"['python', 'chart', 'new', 'visualization', 'website', 'feaaturing', 'matplotlib', 'seaborn', 'plotly', 'chart', 'reproducible', 'code', 'ive', 'recently', 'launched', 'python', 'chart', 'website', 'provides', 'lot', 'matplotlib', 'seaborn', 'plotly', 'easytofollow', 'tutorial', 'reproducible', 'code', 'english', 'spanish', 'link', 'link', 'spanish', 'post', 'filterable', 'based', 'chart', 'type', 'library', 'tutorial', 'guide', 'reader', 'step', 'step', 'basic', 'styled', 'chart', 'site', 'also', 'provides', 'color', 'tool', 'copy', 'matplotlib', 'color', 'hex', 'name', 'also', 'convert', 'hex', 'rgb', 'page', 'created', 'website', 'spare', 'time', 'finding', 'original', 'doc', 'difficult', 'follow', 'site', 'equivalent', 'hope', 'like']",,,,
1jiql82,"""Hey, you have a second for a quick call? It will just take a minute""",,1742822691.0,1231.0,43.0,/r/datascience/comments/1jiql82/hey_you_have_a_second_for_a_quick_call_it_will/,https://i.redd.it/dz5jp9cm2nqe1.png,ElectrikMetriks,datascience,0.99,False,False,False,False,0.0,1745834672.097801,Tech & Programming,15.0,0.0,15.0,Monday,9.0,March,2025.0,False,0.0,0.0,0.0,1.0,neutral,hey you have a second for a quick call it will just take a minute,,hey you have a second for a quick call it will just take a minute ,"hey, second, quick, call, take",2025-03-24 13:24:51,hey you have a second for a quick call it will just take a minute ,"['hey', 'second', 'quick', 'call', 'take', 'minute']",,,,
1520fwk,XKCD Comic does machine learning,,1689596507.0,1238.0,74.0,/r/datascience/comments/1520fwk/xkcd_comic_does_machine_learning/,https://i.redd.it/wivgvxmvpicb1.jpg,rotterdamn8,datascience,0.97,False,False,False,False,0.0,1745834672.392141,Tech & Programming,5.0,0.0,5.0,Monday,8.0,July,2023.0,False,0.0,0.0,0.0,1.0,neutral,xkcd comic does machine learning,,xkcd comic does machine learning ,"xkcd, comic, machine, learning",2023-07-17 12:21:47,xkcd comic does machine learning ,"['xkcd', 'comic', 'machine', 'learning']",,,,
o468ms,"Hi! I just expanded the Data Science Cheatsheet to five pages, added material on Time Series, Statistics, and A/B Testing, and landed my first full-time job","Hey all! You might remember me from the Data Science Cheatsheet I posted a few months ago ([here](https://www.reddit.com/r/datascience/comments/ljftgi/i_created_a_fourpage_data_science_cheatsheet_to/)). The support from that was incredible, and I thought I’d share an update.

Since then, I’ve gone through a dozen interviews, ranging from FANG to startups to MBB, and updated the cheatsheet with topics I’ve seen covered in actual interviews.

Improvements include:

* Added Time Series
* Added Statistics
* Added A/B Testing
* Improved Distribution Section
* Added Multi-class SVM
* Added HMM
* Miscellaneous Section
* And a bunch of other small changes scattered throughout!

These topics, along with the material covered previously, are all condensed in a convenient five-page Data Science Cheatsheet, found [here](https://github.com/aaronwangy/Data-Science-Cheatsheet).

I’ll be heading to a FANG company as a DS after graduation, and I hope this cheatsheet is helpful to those on the job hunt or just looking to brush up on machine learning concepts. Feel free to leave any suggestions and star/save the repo for reference and future updates!

Cheers, AW

Github Repo: [https://github.com/aaronwangy/Data-Science-Cheatsheet](https://github.com/aaronwangy/Data-Science-Cheatsheet)",1624197509.0,1228.0,61.0,/r/datascience/comments/o468ms/hi_i_just_expanded_the_data_science_cheatsheet_to/,https://www.reddit.com/r/datascience/comments/o468ms/hi_i_just_expanded_the_data_science_cheatsheet_to/,WirelessSushi,datascience,0.99,True,False,False,False,0.0,1745834672.864293,Tech & Programming,26.0,170.0,187.0,Sunday,9.0,June,2021.0,True,0.9545,0.116,0.021,0.863,positive,hi i just expanded the data science cheatsheet to five pages added material on time series statistics and ab testing and landed my first fulltime job,hey all you might remember me from the data science cheatsheet i posted a few months ago here the support from that was incredible and i thought id share an update since then ive gone through a dozen interviews ranging from fang to startups to mbb and updated the cheatsheet with topics ive seen covered in actual interviews improvements include added time series added statistics added ab testing improved distribution section added multiclass svm added hmm miscellaneous section and a bunch of other small changes scattered throughout these topics along with the material covered previously are all condensed in a convenient fivepage data science cheatsheet found here ill be heading to a fang company as a ds after graduation and i hope this cheatsheet is helpful to those on the job hunt or just looking to brush up on machine learning concepts feel free to leave any suggestions and starsave the repo for reference and future updates cheers aw github repo,hi i just expanded the data science cheatsheet to five pages added material on time series statistics and ab testing and landed my first fulltime job hey all you might remember me from the data science cheatsheet i posted a few months ago here the support from that was incredible and i thought id share an update since then ive gone through a dozen interviews ranging from fang to startups to mbb and updated the cheatsheet with topics ive seen covered in actual interviews improvements include added time series added statistics added ab testing improved distribution section added multiclass svm added hmm miscellaneous section and a bunch of other small changes scattered throughout these topics along with the material covered previously are all condensed in a convenient fivepage data science cheatsheet found here ill be heading to a fang company as a ds after graduation and i hope this cheatsheet is helpful to those on the job hunt or just looking to brush up on machine learning concepts feel free to leave any suggestions and starsave the repo for reference and future updates cheers aw github repo,"added, cheatsheet, data, science, material",2021-06-20 13:58:29,hi i just expanded the data science cheatsheet to five pages added material on time series statistics and ab testing and landed my first fulltime job hey all you might remember me from the data science cheatsheet i posted a few months ago here the support from that was incredible and i thought id share an update since then ive gone through a dozen interviews ranging from fang to startups to mbb and updated the cheatsheet with topics ive seen covered in actual interviews improvements include added time series added statistics added ab testing improved distribution section added multiclass svm added hmm miscellaneous section and a bunch of other small changes scattered throughout these topics along with the material covered previously are all condensed in a convenient fivepage data science cheatsheet found here ill be heading to a fang company as a ds after graduation and i hope this cheatsheet is helpful to those on the job hunt or just looking to brush up on machine learning concepts feel free to leave any suggestions and starsave the repo for reference and future updates cheers aw github repo,"['expanded', 'data', 'science', 'cheatsheet', 'five', 'page', 'added', 'material', 'time', 'series', 'statistic', 'testing', 'landed', 'first', 'fulltime', 'job', 'hey', 'might', 'remember', 'data', 'science', 'cheatsheet', 'posted', 'month', 'ago', 'support', 'incredible', 'thought', 'share', 'update', 'since', 'ive', 'gone', 'dozen', 'interview', 'ranging', 'fang', 'startup', 'mbb', 'updated', 'cheatsheet', 'topic', 'ive', 'seen', 'covered', 'actual', 'interview', 'improvement', 'include', 'added', 'time', 'series', 'added', 'statistic', 'added', 'testing', 'improved', 'distribution', 'section', 'added', 'multiclass', 'svm', 'added', 'hmm', 'miscellaneous', 'section', 'bunch', 'small', 'change', 'scattered', 'throughout', 'topic', 'along', 'material', 'covered', 'previously', 'condensed', 'convenient', 'fivepage', 'data', 'science', 'cheatsheet', 'found', 'ill', 'heading', 'fang', 'company', 'graduation', 'hope', 'cheatsheet', 'helpful', 'job', 'hunt', 'looking', 'brush', 'machine', 'learning', 'concept', 'feel', 'free', 'leave', 'suggestion', 'starsave', 'repo', 'reference', 'future', 'update', 'cheer', 'github', 'repo']",,,,
qgx1vm,"Data Science is 80% fighting with IT, 19% cleaning data and 1% of all the cool and sexy crap you hear about the field. Agree?",,1635342377.0,1206.0,175.0,/r/datascience/comments/qgx1vm/data_science_is_80_fighting_with_it_19_cleaning/,https://www.reddit.com/r/datascience/comments/qgx1vm/data_science_is_80_fighting_with_it_19_cleaning/,informatica6,datascience,0.95,True,False,False,False,0.0,1745834673.227702,Tech & Programming,25.0,0.0,22.0,Wednesday,9.0,October,2021.0,False,0.4767,0.271,0.168,0.561,positive,data science is fighting with it cleaning data and of all the cool and sexy crap you hear about the field agree,,data science is fighting with it cleaning data and of all the cool and sexy crap you hear about the field agree ,"data, science, fighting, cleaning, cool",2021-10-27 13:46:17,data science is fighting with it cleaning data and of all the cool and sexy crap you hear about the field agree ,"['data', 'science', 'fighting', 'cleaning', 'data', 'cool', 'sexy', 'crap', 'hear', 'field', 'agree']",,,,
pymzvn,"It’s a sad day, spilled coffee on the ML bible",,1633018211.0,1204.0,154.0,/r/datascience/comments/pymzvn/its_a_sad_day_spilled_coffee_on_the_ml_bible/,https://i.redd.it/ix9uhdi10oq71.jpg,veeeerain,datascience,0.95,False,False,False,False,0.0,1745834700.761109,Tech & Programming,10.0,0.0,10.0,Thursday,12.0,September,2021.0,False,-0.4767,0.0,0.279,0.721,negative,its a sad day spilled coffee on the ml bible,,its a sad day spilled coffee on the ml bible ,"sad, day, spilled, coffee, bible",2021-09-30 16:10:11,its a sad day spilled coffee on the ml bible ,"['sad', 'day', 'spilled', 'coffee', 'bible']",,,,
1en7t9g,Data Science interviews these days,,1723128240.0,1191.0,310.0,/r/datascience/comments/1en7t9g/data_science_interviews_these_days/,https://i.redd.it/qt6114lpcghd1.png,xandie985,datascience,0.97,False,False,False,False,0.0,1745834701.9431,Tech & Programming,5.0,0.0,5.0,Thursday,10.0,August,2024.0,False,0.0,0.0,0.0,1.0,neutral,data science interviews these days,,data science interviews these days ,"data, science, interview, day",2024-08-08 14:44:00,data science interviews these days ,"['data', 'science', 'interview', 'day']",,,,
vi5cvr,Your background and experience at COMPANY caught my attention.,,1655904701.0,1190.0,120.0,/r/datascience/comments/vi5cvr/your_background_and_experience_at_company_caught/,https://i.redd.it/yqjf6tqbd6791.jpg,mattstats,datascience,0.98,False,False,False,False,0.0,1745834703.958437,Tech & Programming,9.0,0.0,9.0,Wednesday,9.0,June,2022.0,False,0.0,0.0,0.0,1.0,neutral,your background and experience at company caught my attention,,your background and experience at company caught my attention ,"background, experience, company, caught, attention",2022-06-22 13:31:41,your background and experience at company caught my attention ,"['background', 'experience', 'company', 'caught', 'attention']",,,,
13ilm03,I investigated the Underground Economy of Glassdoor Reviews,"Online company reviews are high stakes.

Top reviews on sites like Glassdoor and Google can get thousands of impressions each month and are major drivers of brand perception.

Employers know this. And when I come across multiple 5 star reviews left with no cons, or a Pulitzer worthy essay from a former intern, I become suspicious.

These reviews start to resemble 30 under 30 lists: so artificially constructed that you begin to question their credibility in the first place.

The scrutiny around company reviews is well documented; some companies file lawsuits worth over a million dollars to reveal anonymous reviewers that complain about their jobs.

Whilst it's the flashy lawsuits that make the headlines, there also exists an underground economy of company reviews operating quietly every single day.

In this underground economy, some companies pay over $150 to freelancers to try and get a negative review removed. If they want “better” results, they go to the plethora of Online Reputation Management services (ORMs) in the United States that can charge retainers worth thousands of dollars.

The supply of positive reviews exists too. My research led me to find companies, including a prominent Y-Combinator backed startup, that solicit fake positive reviews from online freelancers to improve their rating.

Many of these mercenary fake reviewers, often based in South East Asia, make a full time living doing this, netting over $2,000 per month.

Some of these run such sophisticated operations that they’ve even created their own pricing tiers (e.g $35 per original review, $20 to post an already created review from an email address), a la SaaS offering.

Others operate on a contingency fee agreement model, where they only get paid if they’re able to take a negative review down.

The underground economy of company reviews is well and truly alive. And today we’re going to find out how it operates.

***Note***: For more content like this, [*subscribe*](https://www.careerfair.io/subscribe) *to my newsletter. In a couple of weeks, I'll be releasing my guide to writing a killer resume.*

**Adding reviews**

The barriers to entry for adding fake reviews are much lower than for getting reviews removed, so that’s where we’ll start.

To write an employer review, all you really need is the ability to create an email address. For most sites, you don’t need any proof of employment (say like a company specific email address).

I went on a gig marketplace site and posted a pretty vague post related to wanting to find out more on how to improve a company’s online presence.

Within minutes of posting a gig, my inbox was flooded with proposals:

https://preview.redd.it/esx3904qa20b1.png?width=3064&format=png&auto=webp&s=2ff3a2f8528fee99aabb830f27ea71a7569ebb2e

After a bit of chatting, I narrowed the scope of their services and summarized their rates into the table below:

|Channel|Cost|Timeline|Model|
|:-|:-|:-|:-|
|Freelancer #1|$10 per review|Monthly|Unlimited|
|Freelancer #2|$35 per original review, $20 per already created review|Monthly|Unlimited|
|Freelancer #3|$25 per review|Monthly|Unlimited|
|Freelancer #4|$25 per review|Monthly|10 reviews|
|Freelancer #5|$20 per review|Monthly|Unlimited|
|Online Reputation Management Agency|$300 subscription|Monthly|8 reviews|

Let’s dive a bit deeper into the services that Freelancer #5 offered.

Freelancer #5 explained to me he had been writing reviews for one particular company for the past 4 months now. Each month he wrote them 10 reviews.

&#x200B;

https://preview.redd.it/n1ddox6cb20b1.png?width=2684&format=png&auto=webp&s=5c271d0eec4328cb78d7d2cb85dfffa3f9eb72f8

In another message, he tells me he’s offering the same services to 5 other companies. Doing some quick math:

5 companies x 10 reviews per company x $25 per review = $1,250 per month

Considering the average person in Pakistan earns $150 per month, that’s not bad change at all.

One of the companies that he’s offering his services to includes a Y-Combinator backed startup. I won’t name the company, but here’s what its average Glassdoor review rating distribution looks like:

https://preview.redd.it/2np5b6fdb20b1.png?width=2420&format=png&auto=webp&s=f8cafaa85453b0933a18eb5c30f931b3bb893c46

5 star reviews account for over 77% of the company’s total reviews. Obviously, no one is buying fake reviews that make them look bad.

But here’s the thing: freelancers are getting quite smart when it comes to writing reviews that don’t look too fishy. They tend to do this by spacing the reviews out (so that they don’t come in “spikes” – more on this later) and they also make sure that they’re not always leaving the “cons” section blank.

Don’t get me wrong, if you come across this company’s reviews, it’d be pretty easy to tell they’re quite strange. In fact, I can’t even post some screenshots here because it’d give the company away immediately.

But it would be challenging to conclude that the above company is buying reviews just by analyzing review volume and distribution without actually reading some of the reviews.

The same company is also buying reviews on Google Reviews.

Sidenote: I got curious about how he’s been writing 50 reviews from 50 different emails per month. Would he actually create 50 different email addresses? And what about the IP address – doesn’t Glassdoor flag multiple reviews from the same IP?

One of the freelancers answered my question:

&#x200B;

https://preview.redd.it/g4id2yqeb20b1.png?width=2572&format=png&auto=webp&s=c2a77fdea8834a6d90f02b8b3eb67b3a874f3df2

Moving on – another company that seems to buy fake reviews seems to be having some more trouble. Approximately a month after a freelancer linked me to fake reviews he had written for this company, all five reviews that he had linked me to had been removed:

&#x200B;

https://preview.redd.it/99fdvcgfb20b1.png?width=3116&format=png&auto=webp&s=b7e244529fc62b5c824d925feb61fd2cc16cbfd5

Based on this [Glassdoor webinar](https://youtu.be/3iy0JWOS1gs) from 2018, “if it is found that a user has created multiple email accounts to submit reviews, then ALL submissions from that user are deleted” – so likely Glassdoor’s content moderation team flagged one of the initial reviews and the same freelancer who was writing reviews for that company had all the fake reviews deleted.

So far, it looks like the key to an effective fake review creation strategy lies in:

* Spacing the fake reviews out
* Writing each review from a different IP address (i.e benefit of being part of a team)
* Using language that isn’t an obvious giveaway

On that third point: the reality is that many of these freelancers’ first language is not English.

As an experiment, I turned to everybody’s favorite new toy, ChatGPT, and asked it to write me a positive Glassdoor review:

https://preview.redd.it/8w7cal9gb20b1.png?width=3164&format=png&auto=webp&s=860c39b11c5813e8b7fabdbb038d73c565cc98cf

And I’d say that the above answer was better than 95% of the fake reviews I came across.

**Removing reviews**

The process for removing an employer review usually works like this:

1. You identify one or multiple reviews that you want removed
2. You verify whether the review violates the site's Guidelines, or whether there’s something else about the review(s) that could get it removed.
3. You file an appeal to get it removed.

As an example, Glassdoor’s Review guidelines can be found [here](https://help.glassdoor.com/s/article/Community-Guidelines?language=en_US#:~:text=See%20More-,Review%C2%A0Guidelines,-Millions%20of%20job). Mainly, they forbid mentioning anyone by name who’s not an executive and revealing proprietary or confidential information, amongst a host of other things.

Sounds simple enough right? Well, according to one of the freelancers I messaged:

&#x200B;

https://preview.redd.it/x6s8hsyac20b1.png?width=2036&format=png&auto=webp&s=f86c386f864198dc43faeb41faea378090c20107

After some research, I summarized the different vendors and prices in the table below:

&#x200B;

|Channel|Cost|Timeline|Model|Self reported success rate|
|:-|:-|:-|:-|:-|
|Freelancer #1|$100 per review|3 days|Contingency Agreement Model|100%|
|Freelancer #2|$30 per review|7 days|Contingency Agreement Model|100%|
|Reputation management service #2|$450 per review|21 business days|Contingency Agreement Model|Unknown|
|Reputation management service #3|$1000 per review|Undefined|Contingency Agreement Model|100%|
|Reputation management service #4 Plan 1|$550 per review|5-6 weeks|Contingency Agreement Model|50-75%|
|Reputation management service #4 Plan 2|$300 Subscription + $100 per each review removed|Monthly service|Subscription plan|50-75%|
|Freelancer #3|$20|Undefined|Pay regardless|Undefined|
|Freelancer #4|$500|Undefined|Contingency Agreement Model|Undefined|

As you can see, unlike the fake review generation market, the prices vary quite a bit for getting reviews removed.

At one end, you have freelancers on gig marketplaces that will attempt to remove a review for less than $100. And then on the other end, you have ORMs (Online Reputation Management Agencies) that have multiple employees and more comprehensive packages in place. The one constant seems to be that most companies operate on a contingency agreement model (i.e pay only if review gets removed).

**Analyzing reviews**

ReviewMeta is a site that analyzes Amazon reviews and tells you how many are legitimate. The creator of the site, Tommy Noonan, mentions in an [interview with NPR](https://www.npr.org/sections/money/2018/06/27/623990036/episode-850-the-fake-review-hunter) that the main giveaway that a product is soliciting fake reviews is:

* A large, suspicious flood of positive reviews at the exact same time. For example, a 3 day stretch of time constituting 30% of total reviews.
* Phrases and words that are constantly repeated, especially in the section with no cons
* Brand monogamists (only review products from one company)

Whilst the last two bullets are hard to track, the first can be used to analyze different companies’ reviews and to check if there might be some funky business going on.

After a couple of days, I have the ability to track review volume and review ratings over time for any company that I specify:

https://preview.redd.it/ehcbw2oje20b1.png?width=1653&format=png&auto=webp&s=b448ff35eb9878fbb1686de2fa8cf031e4ed3e05

Let the games begin.

## Voluntary Response Bias

One of the biggest challenges that review platforms face is the Voluntary Response bias.

Research shows many of today’s most popular online review platforms (e.g Amazon) have a distribution of opinion that is highly polarized, with many extreme positive and/or negative reviews, and few moderate opinions.

Think about it: have you ever felt moderately satisfied at your job and thought to yourself, now would be a great time to leave a Glassdoor review? Probably not.

On the other hand, if you’ve had a terrible experience or even just had one thing really flip you off, you might be quite likely to leave an angry review.

Consider when a company goes through layoffs. You’re going to have a flood of angry reviews coming your way and are likely going to experience a “spike” in reviews.

**Note:** Just like the Wall Street Journal’s methodology described [here](https://archive.is/20201016094732/https://www.wsj.com/articles/companies-manipulate-glassdoor-by-inflating-rankings-and-pressuring-employees-11548171977#selection-3965.0-3968.0), I considered there to be a spike if the total number of reviews in the month was greater than three standard deviations above the mean of the surrounding months.

Let’s take the company below. Here’s a graph of of their review volume since Jan 2020, including when they announced one of their first round of layoffs in June 2022:

https://preview.redd.it/n6kd9ejle20b1.png?width=3216&format=png&auto=webp&s=9eea2f3836617feca37eb88b1d3f67c8fa1b6fe2

In June 2022, approximately 19% of this company's 52 reviews were 1 star reviews (compared to an overall average of around 10%). This is what we could call a statistically significant spike in reviews. It also illustrates how the employees most likely to leave reviews are the ones that obviously had a bad experience (i.e getting laid off).

Here’s another company that had a similar spike in negative reviews due to layoffs in November 2022:

https://preview.redd.it/4vcnr1ine20b1.png?width=2408&format=png&auto=webp&s=f3877fb315ccc5d9a9294306a9f86616cb0fabd2

This company had an approximate 20% 1 star review rate (compared to an overall average of 12%) in November 2022, as well as an Avg Rating of 2.96 that month (compared to an overall average rating of 3.73).Unless HR is proactive, their reviews page risks succumbing to an echochamber of negative reviews that can really tilt one way.

**Note:** Glassdoor does state (based on [this video](https://www.youtube.com/watch?v=3iy0JWOS1gs) from 2017) that about 75% of the reviews on their platform are neutral. Their “give to get policy” has helped in keeping the platform from becoming too polarized.

I can understand why HR teams, like the ones that Nader talked to me about earlier, take a proactive stance towards managing their reviews. If they don’t try to control their reputation themselves, then their reputation risks getting controlled by the employees that had the worst possible experience.

## Goodhart’s Law

Goodhart’s law states the following:

*""When a measure becomes a target, it ceases to be a good measure""*

Every October, Glassdoor publishes their Best Places To Work ranking.

In a [report](https://www.wsj.com/articles/companies-manipulate-glassdoor-by-inflating-rankings-and-pressuring-employees-11548171977) that the WSJ did a couple of years ago, they found large spikes in the number of reviews that some companies (e.g SpaceX, Bain & Co, etc) got in September. The logic here is that some companies try to artificially inflate their Glassdoor reviews right before the October deadline.

I decided to revisit some of this analysis with Glassdoor’s 2023 Best Places To Work Ranking.

One of the companies I examined is rated as one of the best places to work in 2023. Let’s refer to this company as FunPlaceToWork.

Here is how their review volume looks like for all of 2022:

https://preview.redd.it/4e656zkqe20b1.png?width=2516&format=png&auto=webp&s=07141a66c56be7a6818efb9b1a4d912ee0021c91

FunPlaceToWork got around 50 reviews in September 2022. Of those 50 reviews, 96% were 5 star reviews.

FunPlaceToWork averaged 12 reviews per month up till then in 2022. Also, in the prior six months, the average percent of 5 star reviews received every month was \~75%.

Both the spike in volume of reviews and the spike in percentage of five star reviews are statistically significant.

I find it strange that Glassdoor’s proprietary algorithm and/or Human Content Moderation team did not find a spike of this nature unusual. If we look at Glassdoor’s eligibility criteria for the award, it’s as follows:

https://preview.redd.it/hag04y7se20b1.png?width=2868&format=png&auto=webp&s=ec2b920e126a8ea42b40d35aaa55d5341e69d022

The goal, according to Glassdoor, is to collect “authentic and unbiased reviews”.

Whilst there’s nothing against the rules for asking your employees to leave you reviews, I find the statistically significant spike of reviews at odds with the goal of collecting ""unbiased and authentic"" reviews (which Glassdoor states is the purpose of the awards).

Glassdoor states that an employer is allowed to ask its employees to leave reviews, but that they are not allowed to “coerce” them. Examples of what you can’t do:

* Offer incentives like Gift Cards in exchange for positive reviews.
* Withholding their reference letter unless they leave you a positive review.
* Anything that leads you to require proof for the employee to show you that they wrote a review.

It is possible to play by the rules (i.e not break any of the above rules) and to still in my opinion not collect authentic and unbiased reviews.

They say that you shouldn’t hate the player but the game – I think **FunPlaceToWork** played by the rules, won fair and square, and that this is simply a perfect example of Goodhart’s Law.

I reached out to Glassdoor ([awards@glassdoor.com](mailto:awards@glassdoor.com)) about the above and this is the reply I got:

https://preview.redd.it/x0dqq39ue20b1.png?width=4800&format=png&auto=webp&s=c0102c963be9486370b340f2f473cbc6650fc48a

**Conclusion**

When I was 22, on an [F1 visa with 3 months to find work](https://www.careerfair.io/job-hunt-story), I didn’t give a damn about bad reviews. I needed a job and I’d sign any piece of paper you put in front of me.

Compare that to someone at the peak of their career, someone with optionality and a multitude of job offers; an “A-Player”, as the experts call it, would absolutely have the luxury of choice and discard a job offer based on bad company reviews.

For most people, the impact of online company reviews lies somewhere in the middle. In marketing, there’s a concept of a “marketing touchpoint” - an interaction with the brand over the course of the whole buying journey.

Company reviews are one of the many touchpoints a job seeker experiences over their interview process. And with the technology industry booming the past couple of years, companies couldn’t afford to slack on any touchpoints, including this one.

After all, when others start to game the system, you’re at a disadvantage if you don’t. The rewards can be quite high. Certainly higher than just trying to be as transparent as possible.

HR leaders are often more incentivized to inflate their metrics than to get honest feedback. Fake review writers have bills to pay. ORMs know that companies are desperate. And the platforms, well, aren’t always paying attention.

The result is a potluck of interests that leads to an underground economy.

One that ends up hurting the job seeker.

\*\*\*

Whew. That took a while (about 3 months in fact). Thanks for reading. For more content like this, [subscribe](https://www.careerfair.io/subscribe) to my newsletter. It's my best content delivered to your inbox once every 2 weeks.",1684187136.0,1167.0,63.0,/r/datascience/comments/13ilm03/i_investigated_the_underground_economy_of/,https://www.reddit.com/r/datascience/comments/13ilm03/i_investigated_the_underground_economy_of/,ibsurvivors,datascience,0.99,True,False,False,False,2.0,1745834704.961027,Tech & Programming,8.0,2604.0,2500.0,Monday,17.0,May,2023.0,False,0.9996,0.138,0.065,0.797,positive,i investigated the underground economy of glassdoor reviews,online company reviews are high stakes top reviews on sites like glassdoor and google can get thousands of impressions each month and are major drivers of brand perception employers know this and when i come across multiple star reviews left with no cons or a pulitzer worthy essay from a former intern i become suspicious these reviews start to resemble under lists so artificially constructed that you begin to question their credibility in the first place the scrutiny around company reviews is well documented some companies file lawsuits worth over a million dollars to reveal anonymous reviewers that complain about their jobs whilst its the flashy lawsuits that make the headlines there also exists an underground economy of company reviews operating quietly every single day in this underground economy some companies pay over to freelancers to try and get a negative review removed if they want better results they go to the plethora of online reputation management services orms in the united states that can charge retainers worth thousands of dollars the supply of positive reviews exists too my research led me to find companies including a prominent ycombinator backed startup that solicit fake positive reviews from online freelancers to improve their rating many of these mercenary fake reviewers often based in south east asia make a full time living doing this netting over per month some of these run such sophisticated operations that theyve even created their own pricing tiers eg per original review to post an already created review from an email address a la saas offering others operate on a contingency fee agreement model where they only get paid if theyre able to take a negative review down the underground economy of company reviews is well and truly alive and today were going to find out how it operates note for more content like this subscribe to my newsletter in a couple of weeks ill be releasing my guide to writing a killer resume adding reviews the barriers to entry for adding fake reviews are much lower than for getting reviews removed so thats where well start to write an employer review all you really need is the ability to create an email address for most sites you dont need any proof of employment say like a company specific email address i went on a gig marketplace site and posted a pretty vague post related to wanting to find out more on how to improve a companys online presence within minutes of posting a gig my inbox was flooded with proposals after a bit of chatting i narrowed the scope of their services and summarized their rates into the table below channelcosttimelinemodel freelancer per reviewmonthlyunlimited freelancer per original review per already created reviewmonthlyunlimited freelancer per reviewmonthlyunlimited freelancer per reviewmonthly reviews freelancer per reviewmonthlyunlimited online reputation management agency subscriptionmonthly reviews lets dive a bit deeper into the services that freelancer offered freelancer explained to me he had been writing reviews for one particular company for the past months now each month he wrote them reviews xb in another message he tells me hes offering the same services to other companies doing some quick math companies x reviews per company x per review per month considering the average person in pakistan earns per month thats not bad change at all one of the companies that hes offering his services to includes a ycombinator backed startup i wont name the company but heres what its average glassdoor review rating distribution looks like star reviews account for over of the companys total reviews obviously no one is buying fake reviews that make them look bad but heres the thing freelancers are getting quite smart when it comes to writing reviews that dont look too fishy they tend to do this by spacing the reviews out so that they dont come in spikes more on this later and they also make sure that theyre not always leaving the cons section blank dont get me wrong if you come across this companys reviews itd be pretty easy to tell theyre quite strange in fact i cant even post some screenshots here because itd give the company away immediately but it would be challenging to conclude that the above company is buying reviews just by analyzing review volume and distribution without actually reading some of the reviews the same company is also buying reviews on google reviews sidenote i got curious about how hes been writing reviews from different emails per month would he actually create different email addresses and what about the ip address doesnt glassdoor flag multiple reviews from the same ip one of the freelancers answered my question xb moving on another company that seems to buy fake reviews seems to be having some more trouble approximately a month after a freelancer linked me to fake reviews he had written for this company all five reviews that he had linked me to had been removed xb based on this glassdoor webinar from if it is found that a user has created multiple email accounts to submit reviews then all submissions from that user are deleted so likely glassdoors content moderation team flagged one of the initial reviews and the same freelancer who was writing reviews for that company had all the fake reviews deleted so far it looks like the key to an effective fake review creation strategy lies in spacing the fake reviews out writing each review from a different ip address ie benefit of being part of a team using language that isnt an obvious giveaway on that third point the reality is that many of these freelancers first language is not english as an experiment i turned to everybodys favorite new toy chatgpt and asked it to write me a positive glassdoor review and id say that the above answer was better than of the fake reviews i came across removing reviews the process for removing an employer review usually works like this you identify one or multiple reviews that you want removed you verify whether the review violates the sites guidelines or whether theres something else about the reviews that could get it removed you file an appeal to get it removed as an example glassdoors review guidelines can be found here mainly they forbid mentioning anyone by name whos not an executive and revealing proprietary or confidential information amongst a host of other things sounds simple enough right well according to one of the freelancers i messaged xb after some research i summarized the different vendors and prices in the table below xb channelcosttimelinemodelself reported success rate freelancer per review dayscontingency agreement model freelancer per review dayscontingency agreement model reputation management service per review business dayscontingency agreement modelunknown reputation management service per reviewundefinedcontingency agreement model reputation management service plan per review weekscontingency agreement model reputation management service plan subscription per each review removedmonthly servicesubscription plan freelancer undefinedpay regardlessundefined freelancer undefinedcontingency agreement modelundefined as you can see unlike the fake review generation market the prices vary quite a bit for getting reviews removed at one end you have freelancers on gig marketplaces that will attempt to remove a review for less than and then on the other end you have orms online reputation management agencies that have multiple employees and more comprehensive packages in place the one constant seems to be that most companies operate on a contingency agreement model ie pay only if review gets removed analyzing reviews reviewmeta is a site that analyzes amazon reviews and tells you how many are legitimate the creator of the site tommy noonan mentions in an interview with npr that the main giveaway that a product is soliciting fake reviews is a large suspicious flood of positive reviews at the exact same time for example a day stretch of time constituting of total reviews phrases and words that are constantly repeated especially in the section with no cons brand monogamists only review products from one company whilst the last two bullets are hard to track the first can be used to analyze different companies reviews and to check if there might be some funky business going on after a couple of days i have the ability to track review volume and review ratings over time for any company that i specify let the games begin voluntary response bias one of the biggest challenges that review platforms face is the voluntary response bias research shows many of todays most popular online review platforms eg amazon have a distribution of opinion that is highly polarized with many extreme positive andor negative reviews and few moderate opinions think about it have you ever felt moderately satisfied at your job and thought to yourself now would be a great time to leave a glassdoor review probably not on the other hand if youve had a terrible experience or even just had one thing really flip you off you might be quite likely to leave an angry review consider when a company goes through layoffs youre going to have a flood of angry reviews coming your way and are likely going to experience a spike in reviews note just like the wall street journals methodology described here i considered there to be a spike if the total number of reviews in the month was greater than three standard deviations above the mean of the surrounding months lets take the company below heres a graph of of their review volume since jan including when they announced one of their first round of layoffs in june in june approximately of this companys reviews were star reviews compared to an overall average of around this is what we could call a statistically significant spike in reviews it also illustrates how the employees most likely to leave reviews are the ones that obviously had a bad experience ie getting laid off heres another company that had a similar spike in negative reviews due to layoffs in november this company had an approximate star review rate compared to an overall average of in november as well as an avg rating of that month compared to an overall average rating of unless hr is proactive their reviews page risks succumbing to an echochamber of negative reviews that can really tilt one way note glassdoor does state based on this video from that about of the reviews on their platform are neutral their give to get policy has helped in keeping the platform from becoming too polarized i can understand why hr teams like the ones that nader talked to me about earlier take a proactive stance towards managing their reviews if they dont try to control their reputation themselves then their reputation risks getting controlled by the employees that had the worst possible experience goodharts law goodharts law states the following when a measure becomes a target it ceases to be a good measure every october glassdoor publishes their best places to work ranking in a report that the wsj did a couple of years ago they found large spikes in the number of reviews that some companies eg spacex bain co etc got in september the logic here is that some companies try to artificially inflate their glassdoor reviews right before the october deadline i decided to revisit some of this analysis with glassdoors best places to work ranking one of the companies i examined is rated as one of the best places to work in lets refer to this company as funplacetowork here is how their review volume looks like for all of funplacetowork got around reviews in september of those reviews were star reviews funplacetowork averaged reviews per month up till then in also in the prior six months the average percent of star reviews received every month was both the spike in volume of reviews and the spike in percentage of five star reviews are statistically significant i find it strange that glassdoors proprietary algorithm andor human content moderation team did not find a spike of this nature unusual if we look at glassdoors eligibility criteria for the award its as follows the goal according to glassdoor is to collect authentic and unbiased reviews whilst theres nothing against the rules for asking your employees to leave you reviews i find the statistically significant spike of reviews at odds with the goal of collecting unbiased and authentic reviews which glassdoor states is the purpose of the awards glassdoor states that an employer is allowed to ask its employees to leave reviews but that they are not allowed to coerce them examples of what you cant do offer incentives like gift cards in exchange for positive reviews withholding their reference letter unless they leave you a positive review anything that leads you to require proof for the employee to show you that they wrote a review it is possible to play by the rules ie not break any of the above rules and to still in my opinion not collect authentic and unbiased reviews they say that you shouldnt hate the player but the game i think funplacetowork played by the rules won fair and square and that this is simply a perfect example of goodharts law i reached out to glassdoor awardsglassdoorcommailtoawardsglassdoorcom about the above and this is the reply i got conclusion when i was on an f visa with months to find work i didnt give a damn about bad reviews i needed a job and id sign any piece of paper you put in front of me compare that to someone at the peak of their career someone with optionality and a multitude of job offers an aplayer as the experts call it would absolutely have the luxury of choice and discard a job offer based on bad company reviews for most people the impact of online company reviews lies somewhere in the middle in marketing theres a concept of a marketing touchpoint an interaction with the brand over the course of the whole buying journey company reviews are one of the many touchpoints a job seeker experiences over their interview process and with the technology industry booming the past couple of years companies couldnt afford to slack on any touchpoints including this one after all when others start to game the system youre at a disadvantage if you dont the rewards can be quite high certainly higher than just trying to be as transparent as possible hr leaders are often more incentivized to inflate their metrics than to get honest feedback fake review writers have bills to pay orms know that companies are desperate and the platforms well arent always paying attention the result is a potluck of interests that leads to an underground economy one that ends up hurting the job seeker whew that took a while about months in fact thanks for reading for more content like this subscribe to my newsletter its my best content delivered to your inbox once every weeks,i investigated the underground economy of glassdoor reviews online company reviews are high stakes top reviews on sites like glassdoor and google can get thousands of impressions each month and are major drivers of brand perception employers know this and when i come across multiple star reviews left with no cons or a pulitzer worthy essay from a former intern i become suspicious these reviews start to resemble under lists so artificially constructed that you begin to question their credibility in the first place the scrutiny around company reviews is well documented some companies file lawsuits worth over a million dollars to reveal anonymous reviewers that complain about their jobs whilst its the flashy lawsuits that make the headlines there also exists an underground economy of company reviews operating quietly every single day in this underground economy some companies pay over to freelancers to try and get a negative review removed if they want better results they go to the plethora of online reputation management services orms in the united states that can charge retainers worth thousands of dollars the supply of positive reviews exists too my research led me to find companies including a prominent ycombinator backed startup that solicit fake positive reviews from online freelancers to improve their rating many of these mercenary fake reviewers often based in south east asia make a full time living doing this netting over per month some of these run such sophisticated operations that theyve even created their own pricing tiers eg per original review to post an already created review from an email address a la saas offering others operate on a contingency fee agreement model where they only get paid if theyre able to take a negative review down the underground economy of company reviews is well and truly alive and today were going to find out how it operates note for more content like this subscribe to my newsletter in a couple of weeks ill be releasing my guide to writing a killer resume adding reviews the barriers to entry for adding fake reviews are much lower than for getting reviews removed so thats where well start to write an employer review all you really need is the ability to create an email address for most sites you dont need any proof of employment say like a company specific email address i went on a gig marketplace site and posted a pretty vague post related to wanting to find out more on how to improve a companys online presence within minutes of posting a gig my inbox was flooded with proposals after a bit of chatting i narrowed the scope of their services and summarized their rates into the table below channelcosttimelinemodel freelancer per reviewmonthlyunlimited freelancer per original review per already created reviewmonthlyunlimited freelancer per reviewmonthlyunlimited freelancer per reviewmonthly reviews freelancer per reviewmonthlyunlimited online reputation management agency subscriptionmonthly reviews lets dive a bit deeper into the services that freelancer offered freelancer explained to me he had been writing reviews for one particular company for the past months now each month he wrote them reviews xb in another message he tells me hes offering the same services to other companies doing some quick math companies x reviews per company x per review per month considering the average person in pakistan earns per month thats not bad change at all one of the companies that hes offering his services to includes a ycombinator backed startup i wont name the company but heres what its average glassdoor review rating distribution looks like star reviews account for over of the companys total reviews obviously no one is buying fake reviews that make them look bad but heres the thing freelancers are getting quite smart when it comes to writing reviews that dont look too fishy they tend to do this by spacing the reviews out so that they dont come in spikes more on this later and they also make sure that theyre not always leaving the cons section blank dont get me wrong if you come across this companys reviews itd be pretty easy to tell theyre quite strange in fact i cant even post some screenshots here because itd give the company away immediately but it would be challenging to conclude that the above company is buying reviews just by analyzing review volume and distribution without actually reading some of the reviews the same company is also buying reviews on google reviews sidenote i got curious about how hes been writing reviews from different emails per month would he actually create different email addresses and what about the ip address doesnt glassdoor flag multiple reviews from the same ip one of the freelancers answered my question xb moving on another company that seems to buy fake reviews seems to be having some more trouble approximately a month after a freelancer linked me to fake reviews he had written for this company all five reviews that he had linked me to had been removed xb based on this glassdoor webinar from if it is found that a user has created multiple email accounts to submit reviews then all submissions from that user are deleted so likely glassdoors content moderation team flagged one of the initial reviews and the same freelancer who was writing reviews for that company had all the fake reviews deleted so far it looks like the key to an effective fake review creation strategy lies in spacing the fake reviews out writing each review from a different ip address ie benefit of being part of a team using language that isnt an obvious giveaway on that third point the reality is that many of these freelancers first language is not english as an experiment i turned to everybodys favorite new toy chatgpt and asked it to write me a positive glassdoor review and id say that the above answer was better than of the fake reviews i came across removing reviews the process for removing an employer review usually works like this you identify one or multiple reviews that you want removed you verify whether the review violates the sites guidelines or whether theres something else about the reviews that could get it removed you file an appeal to get it removed as an example glassdoors review guidelines can be found here mainly they forbid mentioning anyone by name whos not an executive and revealing proprietary or confidential information amongst a host of other things sounds simple enough right well according to one of the freelancers i messaged xb after some research i summarized the different vendors and prices in the table below xb channelcosttimelinemodelself reported success rate freelancer per review dayscontingency agreement model freelancer per review dayscontingency agreement model reputation management service per review business dayscontingency agreement modelunknown reputation management service per reviewundefinedcontingency agreement model reputation management service plan per review weekscontingency agreement model reputation management service plan subscription per each review removedmonthly servicesubscription plan freelancer undefinedpay regardlessundefined freelancer undefinedcontingency agreement modelundefined as you can see unlike the fake review generation market the prices vary quite a bit for getting reviews removed at one end you have freelancers on gig marketplaces that will attempt to remove a review for less than and then on the other end you have orms online reputation management agencies that have multiple employees and more comprehensive packages in place the one constant seems to be that most companies operate on a contingency agreement model ie pay only if review gets removed analyzing reviews reviewmeta is a site that analyzes amazon reviews and tells you how many are legitimate the creator of the site tommy noonan mentions in an interview with npr that the main giveaway that a product is soliciting fake reviews is a large suspicious flood of positive reviews at the exact same time for example a day stretch of time constituting of total reviews phrases and words that are constantly repeated especially in the section with no cons brand monogamists only review products from one company whilst the last two bullets are hard to track the first can be used to analyze different companies reviews and to check if there might be some funky business going on after a couple of days i have the ability to track review volume and review ratings over time for any company that i specify let the games begin voluntary response bias one of the biggest challenges that review platforms face is the voluntary response bias research shows many of todays most popular online review platforms eg amazon have a distribution of opinion that is highly polarized with many extreme positive andor negative reviews and few moderate opinions think about it have you ever felt moderately satisfied at your job and thought to yourself now would be a great time to leave a glassdoor review probably not on the other hand if youve had a terrible experience or even just had one thing really flip you off you might be quite likely to leave an angry review consider when a company goes through layoffs youre going to have a flood of angry reviews coming your way and are likely going to experience a spike in reviews note just like the wall street journals methodology described here i considered there to be a spike if the total number of reviews in the month was greater than three standard deviations above the mean of the surrounding months lets take the company below heres a graph of of their review volume since jan including when they announced one of their first round of layoffs in june in june approximately of this companys reviews were star reviews compared to an overall average of around this is what we could call a statistically significant spike in reviews it also illustrates how the employees most likely to leave reviews are the ones that obviously had a bad experience ie getting laid off heres another company that had a similar spike in negative reviews due to layoffs in november this company had an approximate star review rate compared to an overall average of in november as well as an avg rating of that month compared to an overall average rating of unless hr is proactive their reviews page risks succumbing to an echochamber of negative reviews that can really tilt one way note glassdoor does state based on this video from that about of the reviews on their platform are neutral their give to get policy has helped in keeping the platform from becoming too polarized i can understand why hr teams like the ones that nader talked to me about earlier take a proactive stance towards managing their reviews if they dont try to control their reputation themselves then their reputation risks getting controlled by the employees that had the worst possible experience goodharts law goodharts law states the following when a measure becomes a target it ceases to be a good measure every october glassdoor publishes their best places to work ranking in a report that the wsj did a couple of years ago they found large spikes in the number of reviews that some companies eg spacex bain co etc got in september the logic here is that some companies try to artificially inflate their glassdoor reviews right before the october deadline i decided to revisit some of this analysis with glassdoors best places to work ranking one of the companies i examined is rated as one of the best places to work in lets refer to this company as funplacetowork here is how their review volume looks like for all of funplacetowork got around reviews in september of those reviews were star reviews funplacetowork averaged reviews per month up till then in also in the prior six months the average percent of star reviews received every month was both the spike in volume of reviews and the spike in percentage of five star reviews are statistically significant i find it strange that glassdoors proprietary algorithm andor human content moderation team did not find a spike of this nature unusual if we look at glassdoors eligibility criteria for the award its as follows the goal according to glassdoor is to collect authentic and unbiased reviews whilst theres nothing against the rules for asking your employees to leave you reviews i find the statistically significant spike of reviews at odds with the goal of collecting unbiased and authentic reviews which glassdoor states is the purpose of the awards glassdoor states that an employer is allowed to ask its employees to leave reviews but that they are not allowed to coerce them examples of what you cant do offer incentives like gift cards in exchange for positive reviews withholding their reference letter unless they leave you a positive review anything that leads you to require proof for the employee to show you that they wrote a review it is possible to play by the rules ie not break any of the above rules and to still in my opinion not collect authentic and unbiased reviews they say that you shouldnt hate the player but the game i think funplacetowork played by the rules won fair and square and that this is simply a perfect example of goodharts law i reached out to glassdoor awardsglassdoorcommailtoawardsglassdoorcom about the above and this is the reply i got conclusion when i was on an f visa with months to find work i didnt give a damn about bad reviews i needed a job and id sign any piece of paper you put in front of me compare that to someone at the peak of their career someone with optionality and a multitude of job offers an aplayer as the experts call it would absolutely have the luxury of choice and discard a job offer based on bad company reviews for most people the impact of online company reviews lies somewhere in the middle in marketing theres a concept of a marketing touchpoint an interaction with the brand over the course of the whole buying journey company reviews are one of the many touchpoints a job seeker experiences over their interview process and with the technology industry booming the past couple of years companies couldnt afford to slack on any touchpoints including this one after all when others start to game the system youre at a disadvantage if you dont the rewards can be quite high certainly higher than just trying to be as transparent as possible hr leaders are often more incentivized to inflate their metrics than to get honest feedback fake review writers have bills to pay orms know that companies are desperate and the platforms well arent always paying attention the result is a potluck of interests that leads to an underground economy one that ends up hurting the job seeker whew that took a while about months in fact thanks for reading for more content like this subscribe to my newsletter its my best content delivered to your inbox once every weeks,"review, company, one, freelancer, per",2023-05-15 21:45:36,i investigated the underground economy of glassdoor reviews online company reviews are high stakes top reviews on sites like glassdoor and google can get thousands of impressions each month and are major drivers of brand perception employers know this and when i come across multiple star reviews left with no cons or a pulitzer worthy essay from a former intern i become suspicious these reviews start to resemble under lists so artificially constructed that you begin to question their credibility in the first place the scrutiny around company reviews is well documented some companies file lawsuits worth over a million dollars to reveal anonymous reviewers that complain about their jobs whilst its the flashy lawsuits that make the headlines there also exists an underground economy of company reviews operating quietly every single day in this underground economy some companies pay over to freelancers to try and get a negative review removed if they want better results they go to the plethora of online reputation management services orms in the united states that can charge retainers worth thousands of dollars the supply of positive reviews exists too my research led me to find companies including a prominent ycombinator backed startup that solicit fake positive reviews from online freelancers to improve their rating many of these mercenary fake reviewers often based in south east asia make a full time living doing this netting over per month some of these run such sophisticated operations that theyve even created their own pricing tiers eg per original review to post an already created review from an email address a la saas offering others operate on a contingency fee agreement model where they only get paid if theyre able to take a negative review down the underground economy of company reviews is well and truly alive and today were going to find out how it operates note for more content like this subscribe to my newsletter in a couple of weeks ill be releasing my guide to writing a killer resume adding reviews the barriers to entry for adding fake reviews are much lower than for getting reviews removed so thats where well start to write an employer review all you really need is the ability to create an email address for most sites you dont need any proof of employment say like a company specific email address i went on a gig marketplace site and posted a pretty vague post related to wanting to find out more on how to improve a companys online presence within minutes of posting a gig my inbox was flooded with proposals after a bit of chatting i narrowed the scope of their services and summarized their rates into the table below channelcosttimelinemodel freelancer per reviewmonthlyunlimited freelancer per original review per already created reviewmonthlyunlimited freelancer per reviewmonthlyunlimited freelancer per reviewmonthly reviews freelancer per reviewmonthlyunlimited online reputation management agency subscriptionmonthly reviews lets dive a bit deeper into the services that freelancer offered freelancer explained to me he had been writing reviews for one particular company for the past months now each month he wrote them reviews xb in another message he tells me hes offering the same services to other companies doing some quick math companies x reviews per company x per review per month considering the average person in pakistan earns per month thats not bad change at all one of the companies that hes offering his services to includes a ycombinator backed startup i wont name the company but heres what its average glassdoor review rating distribution looks like star reviews account for over of the companys total reviews obviously no one is buying fake reviews that make them look bad but heres the thing freelancers are getting quite smart when it comes to writing reviews that dont look too fishy they tend to do this by spacing the reviews out so that they dont come in spikes more on this later and they also make sure that theyre not always leaving the cons section blank dont get me wrong if you come across this companys reviews itd be pretty easy to tell theyre quite strange in fact i cant even post some screenshots here because itd give the company away immediately but it would be challenging to conclude that the above company is buying reviews just by analyzing review volume and distribution without actually reading some of the reviews the same company is also buying reviews on google reviews sidenote i got curious about how hes been writing reviews from different emails per month would he actually create different email addresses and what about the ip address doesnt glassdoor flag multiple reviews from the same ip one of the freelancers answered my question xb moving on another company that seems to buy fake reviews seems to be having some more trouble approximately a month after a freelancer linked me to fake reviews he had written for this company all five reviews that he had linked me to had been removed xb based on this glassdoor webinar from if it is found that a user has created multiple email accounts to submit reviews then all submissions from that user are deleted so likely glassdoors content moderation team flagged one of the initial reviews and the same freelancer who was writing reviews for that company had all the fake reviews deleted so far it looks like the key to an effective fake review creation strategy lies in spacing the fake reviews out writing each review from a different ip address ie benefit of being part of a team using language that isnt an obvious giveaway on that third point the reality is that many of these freelancers first language is not english as an experiment i turned to everybodys favorite new toy chatgpt and asked it to write me a positive glassdoor review and id say that the above answer was better than of the fake reviews i came across removing reviews the process for removing an employer review usually works like this you identify one or multiple reviews that you want removed you verify whether the review violates the sites guidelines or whether theres something else about the reviews that could get it removed you file an appeal to get it removed as an example glassdoors review guidelines can be found here mainly they forbid mentioning anyone by name whos not an executive and revealing proprietary or confidential information amongst a host of other things sounds simple enough right well according to one of the freelancers i messaged xb after some research i summarized the different vendors and prices in the table below xb channelcosttimelinemodelself reported success rate freelancer per review dayscontingency agreement model freelancer per review dayscontingency agreement model reputation management service per review business dayscontingency agreement modelunknown reputation management service per reviewundefinedcontingency agreement model reputation management service plan per review weekscontingency agreement model reputation management service plan subscription per each review removedmonthly servicesubscription plan freelancer undefinedpay regardlessundefined freelancer undefinedcontingency agreement modelundefined as you can see unlike the fake review generation market the prices vary quite a bit for getting reviews removed at one end you have freelancers on gig marketplaces that will attempt to remove a review for less than and then on the other end you have orms online reputation management agencies that have multiple employees and more comprehensive packages in place the one constant seems to be that most companies operate on a contingency agreement model ie pay only if review gets removed analyzing reviews reviewmeta is a site that analyzes amazon reviews and tells you how many are legitimate the creator of the site tommy noonan mentions in an interview with npr that the main giveaway that a product is soliciting fake reviews is a large suspicious flood of positive reviews at the exact same time for example a day stretch of time constituting of total reviews phrases and words that are constantly repeated especially in the section with no cons brand monogamists only review products from one company whilst the last two bullets are hard to track the first can be used to analyze different companies reviews and to check if there might be some funky business going on after a couple of days i have the ability to track review volume and review ratings over time for any company that i specify let the games begin voluntary response bias one of the biggest challenges that review platforms face is the voluntary response bias research shows many of todays most popular online review platforms eg amazon have a distribution of opinion that is highly polarized with many extreme positive andor negative reviews and few moderate opinions think about it have you ever felt moderately satisfied at your job and thought to yourself now would be a great time to leave a glassdoor review probably not on the other hand if youve had a terrible experience or even just had one thing really flip you off you might be quite likely to leave an angry review consider when a company goes through layoffs youre going to have a flood of angry reviews coming your way and are likely going to experience a spike in reviews note just like the wall street journals methodology described here i considered there to be a spike if the total number of reviews in the month was greater than three standard deviations above the mean of the surrounding months lets take the company below heres a graph of of their review volume since jan including when they announced one of their first round of layoffs in june in june approximately of this companys reviews were star reviews compared to an overall average of around this is what we could call a statistically significant spike in reviews it also illustrates how the employees most likely to leave reviews are the ones that obviously had a bad experience ie getting laid off heres another company that had a similar spike in negative reviews due to layoffs in november this company had an approximate star review rate compared to an overall average of in november as well as an avg rating of that month compared to an overall average rating of unless hr is proactive their reviews page risks succumbing to an echochamber of negative reviews that can really tilt one way note glassdoor does state based on this video from that about of the reviews on their platform are neutral their give to get policy has helped in keeping the platform from becoming too polarized i can understand why hr teams like the ones that nader talked to me about earlier take a proactive stance towards managing their reviews if they dont try to control their reputation themselves then their reputation risks getting controlled by the employees that had the worst possible experience goodharts law goodharts law states the following when a measure becomes a target it ceases to be a good measure every october glassdoor publishes their best places to work ranking in a report that the wsj did a couple of years ago they found large spikes in the number of reviews that some companies eg spacex bain co etc got in september the logic here is that some companies try to artificially inflate their glassdoor reviews right before the october deadline i decided to revisit some of this analysis with glassdoors best places to work ranking one of the companies i examined is rated as one of the best places to work in lets refer to this company as funplacetowork here is how their review volume looks like for all of funplacetowork got around reviews in september of those reviews were star reviews funplacetowork averaged reviews per month up till then in also in the prior six months the average percent of star reviews received every month was both the spike in volume of reviews and the spike in percentage of five star reviews are statistically significant i find it strange that glassdoors proprietary algorithm andor human content moderation team did not find a spike of this nature unusual if we look at glassdoors eligibility criteria for the award its as follows the goal according to glassdoor is to collect authentic and unbiased reviews whilst theres nothing against the rules for asking your employees to leave you reviews i find the statistically significant spike of reviews at odds with the goal of collecting unbiased and authentic reviews which glassdoor states is the purpose of the awards glassdoor states that an employer is allowed to ask its employees to leave reviews but that they are not allowed to coerce them examples of what you cant do offer incentives like gift cards in exchange for positive reviews withholding their reference letter unless they leave you a positive review anything that leads you to require proof for the employee to show you that they wrote a review it is possible to play by the rules ie not break any of the above rules and to still in my opinion not collect authentic and unbiased reviews they say that you shouldnt hate the player but the game i think funplacetowork played by the rules won fair and square and that this is simply a perfect example of goodharts law i reached out to glassdoor awardsglassdoorcommailtoawardsglassdoorcom about the above and this is the reply i got conclusion when i was on an f visa with months to find work i didnt give a damn about bad reviews i needed a job and id sign any piece of paper you put in front of me compare that to someone at the peak of their career someone with optionality and a multitude of job offers an aplayer as the experts call it would absolutely have the luxury of choice and discard a job offer based on bad company reviews for most people the impact of online company reviews lies somewhere in the middle in marketing theres a concept of a marketing touchpoint an interaction with the brand over the course of the whole buying journey company reviews are one of the many touchpoints a job seeker experiences over their interview process and with the technology industry booming the past couple of years companies couldnt afford to slack on any touchpoints including this one after all when others start to game the system youre at a disadvantage if you dont the rewards can be quite high certainly higher than just trying to be as transparent as possible hr leaders are often more incentivized to inflate their metrics than to get honest feedback fake review writers have bills to pay orms know that companies are desperate and the platforms well arent always paying attention the result is a potluck of interests that leads to an underground economy one that ends up hurting the job seeker whew that took a while about months in fact thanks for reading for more content like this subscribe to my newsletter its my best content delivered to your inbox once every weeks,"['investigated', 'underground', 'economy', 'glassdoor', 'review', 'online', 'company', 'review', 'high', 'stake', 'top', 'review', 'site', 'like', 'glassdoor', 'google', 'get', 'thousand', 'impression', 'month', 'major', 'driver', 'brand', 'perception', 'employer', 'know', 'come', 'across', 'multiple', 'star', 'review', 'left', 'con', 'pulitzer', 'worthy', 'essay', 'former', 'intern', 'become', 'suspicious', 'review', 'start', 'resemble', 'list', 'artificially', 'constructed', 'begin', 'question', 'credibility', 'first', 'place', 'scrutiny', 'around', 'company', 'review', 'well', 'documented', 'company', 'file', 'lawsuit', 'worth', 'million', 'dollar', 'reveal', 'anonymous', 'reviewer', 'complain', 'job', 'whilst', 'flashy', 'lawsuit', 'make', 'headline', 'also', 'exists', 'underground', 'economy', 'company', 'review', 'operating', 'quietly', 'every', 'single', 'day', 'underground', 'economy', 'company', 'pay', 'freelancer', 'try', 'get', 'negative', 'review', 'removed', 'want', 'better', 'result', 'plethora', 'online', 'reputation', 'management', 'service', 'orms', 'united', 'state', 'charge', 'retainer', 'worth', 'thousand', 'dollar', 'supply', 'positive', 'review', 'exists', 'research', 'led', 'find', 'company', 'including', 'prominent', 'ycombinator', 'backed', 'startup', 'solicit', 'fake', 'positive', 'review', 'online', 'freelancer', 'improve', 'rating', 'many', 'mercenary', 'fake', 'reviewer', 'often', 'based', 'south', 'east', 'asia', 'make', 'full', 'time', 'living', 'netting', 'per', 'month', 'run', 'sophisticated', 'operation', 'theyve', 'even', 'created', 'pricing', 'tier', 'per', 'original', 'review', 'post', 'already', 'created', 'review', 'email', 'address', 'saas', 'offering', 'others', 'operate', 'contingency', 'fee', 'agreement', 'model', 'get', 'paid', 'theyre', 'able', 'take', 'negative', 'review', 'underground', 'economy', 'company', 'review', 'well', 'truly', 'alive', 'today', 'going', 'find', 'operates', 'note', 'content', 'like', 'subscribe', 'newsletter', 'couple', 'week', 'ill', 'releasing', 'guide', 'writing', 'killer', 'resume', 'adding', 'review', 'barrier', 'entry', 'adding', 'fake', 'review', 'much', 'lower', 'getting', 'review', 'removed', 'thats', 'well', 'start', 'write', 'employer', 'review', 'really', 'need', 'ability', 'create', 'email', 'address', 'site', 'dont', 'need', 'proof', 'employment', 'say', 'like', 'company', 'specific', 'email', 'address', 'went', 'gig', 'marketplace', 'site', 'posted', 'pretty', 'vague', 'post', 'related', 'wanting', 'find', 'improve', 'company', 'online', 'presence', 'within', 'minute', 'posting', 'gig', 'inbox', 'flooded', 'proposal', 'bit', 'chatting', 'narrowed', 'scope', 'service', 'summarized', 'rate', 'table', 'channelcosttimelinemodel', 'freelancer', 'per', 'reviewmonthlyunlimited', 'freelancer', 'per', 'original', 'review', 'per', 'already', 'created', 'reviewmonthlyunlimited', 'freelancer', 'per', 'reviewmonthlyunlimited', 'freelancer', 'per', 'reviewmonthly', 'review', 'freelancer', 'per', 'reviewmonthlyunlimited', 'online', 'reputation', 'management', 'agency', 'subscriptionmonthly', 'review', 'let', 'dive', 'bit', 'deeper', 'service', 'freelancer', 'offered', 'freelancer', 'explained', 'writing', 'review', 'one', 'particular', 'company', 'past', 'month', 'month', 'wrote', 'review', 'another', 'message', 'tell', 'he', 'offering', 'service', 'company', 'quick', 'math', 'company', 'review', 'per', 'company', 'per', 'review', 'per', 'month', 'considering', 'average', 'person', 'pakistan', 'earns', 'per', 'month', 'thats', 'bad', 'change', 'one', 'company', 'he', 'offering', 'service', 'includes', 'ycombinator', 'backed', 'startup', 'wont', 'name', 'company', 'here', 'average', 'glassdoor', 'review', 'rating', 'distribution', 'look', 'like', 'star', 'review', 'account', 'company', 'total', 'review', 'obviously', 'one', 'buying', 'fake', 'review', 'make', 'look', 'bad', 'here', 'thing', 'freelancer', 'getting', 'quite', 'smart', 'come', 'writing', 'review', 'dont', 'look', 'fishy', 'tend', 'spacing', 'review', 'dont', 'come', 'spike', 'later', 'also', 'make', 'sure', 'theyre', 'always', 'leaving', 'con', 'section', 'blank', 'dont', 'get', 'wrong', 'come', 'across', 'company', 'review', 'itd', 'pretty', 'easy', 'tell', 'theyre', 'quite', 'strange', 'fact', 'cant', 'even', 'post', 'screenshots', 'itd', 'give', 'company', 'away', 'immediately', 'would', 'challenging', 'conclude', 'company', 'buying', 'review', 'analyzing', 'review', 'volume', 'distribution', 'without', 'actually', 'reading', 'review', 'company', 'also', 'buying', 'review', 'google', 'review', 'sidenote', 'got', 'curious', 'he', 'writing', 'review', 'different', 'email', 'per', 'month', 'would', 'actually', 'create', 'different', 'email', 'address', 'address', 'doesnt', 'glassdoor', 'flag', 'multiple', 'review', 'one', 'freelancer', 'answered', 'question', 'moving', 'another', 'company', 'seems', 'buy', 'fake', 'review', 'seems', 'trouble', 'approximately', 'month', 'freelancer', 'linked', 'fake', 'review', 'written', 'company', 'five', 'review', 'linked', 'removed', 'based', 'glassdoor', 'webinar', 'found', 'user', 'created', 'multiple', 'email', 'account', 'submit', 'review', 'submission', 'user', 'deleted', 'likely', 'glassdoors', 'content', 'moderation', 'team', 'flagged', 'one', 'initial', 'review', 'freelancer', 'writing', 'review', 'company', 'fake', 'review', 'deleted', 'far', 'look', 'like', 'key', 'effective', 'fake', 'review', 'creation', 'strategy', 'lie', 'spacing', 'fake', 'review', 'writing', 'review', 'different', 'address', 'benefit', 'part', 'team', 'using', 'language', 'isnt', 'obvious', 'giveaway', 'third', 'point', 'reality', 'many', 'freelancer', 'first', 'language', 'english', 'experiment', 'turned', 'everybodys', 'favorite', 'new', 'toy', 'chatgpt', 'asked', 'write', 'positive', 'glassdoor', 'review', 'say', 'answer', 'better', 'fake', 'review', 'came', 'across', 'removing', 'review', 'process', 'removing', 'employer', 'review', 'usually', 'work', 'like', 'identify', 'one', 'multiple', 'review', 'want', 'removed', 'verify', 'whether', 'review', 'violates', 'site', 'guideline', 'whether', 'there', 'something', 'else', 'review', 'could', 'get', 'removed', 'file', 'appeal', 'get', 'removed', 'example', 'glassdoors', 'review', 'guideline', 'found', 'mainly', 'forbid', 'mentioning', 'anyone', 'name', 'who', 'executive', 'revealing', 'proprietary', 'confidential', 'information', 'amongst', 'host', 'thing', 'sound', 'simple', 'enough', 'right', 'well', 'according', 'one', 'freelancer', 'messaged', 'research', 'summarized', 'different', 'vendor', 'price', 'table', 'channelcosttimelinemodelself', 'reported', 'success', 'rate', 'freelancer', 'per', 'review', 'dayscontingency', 'agreement', 'model', 'freelancer', 'per', 'review', 'dayscontingency', 'agreement', 'model', 'reputation', 'management', 'service', 'per', 'review', 'business', 'dayscontingency', 'agreement', 'modelunknown', 'reputation', 'management', 'service', 'per', 'reviewundefinedcontingency', 'agreement', 'model', 'reputation', 'management', 'service', 'plan', 'per', 'review', 'weekscontingency', 'agreement', 'model', 'reputation', 'management', 'service', 'plan', 'subscription', 'per', 'review', 'removedmonthly', 'servicesubscription', 'plan', 'freelancer', 'undefinedpay', 'regardlessundefined', 'freelancer', 'undefinedcontingency', 'agreement', 'modelundefined', 'see', 'unlike', 'fake', 'review', 'generation', 'market', 'price', 'vary', 'quite', 'bit', 'getting', 'review', 'removed', 'one', 'end', 'freelancer', 'gig', 'marketplace', 'attempt', 'remove', 'review', 'less', 'end', 'orms', 'online', 'reputation', 'management', 'agency', 'multiple', 'employee', 'comprehensive', 'package', 'place', 'one', 'constant', 'seems', 'company', 'operate', 'contingency', 'agreement', 'model', 'pay', 'review', 'get', 'removed', 'analyzing', 'review', 'reviewmeta', 'site', 'analyzes', 'amazon', 'review', 'tell', 'many', 'legitimate', 'creator', 'site', 'tommy', 'noonan', 'mention', 'interview', 'npr', 'main', 'giveaway', 'product', 'soliciting', 'fake', 'review', 'large', 'suspicious', 'flood', 'positive', 'review', 'exact', 'time', 'example', 'day', 'stretch', 'time', 'constituting', 'total', 'review', 'phrase', 'word', 'constantly', 'repeated', 'especially', 'section', 'con', 'brand', 'monogamist', 'review', 'product', 'one', 'company', 'whilst', 'last', 'two', 'bullet', 'hard', 'track', 'first', 'used', 'analyze', 'different', 'company', 'review', 'check', 'might', 'funky', 'business', 'going', 'couple', 'day', 'ability', 'track', 'review', 'volume', 'review', 'rating', 'time', 'company', 'specify', 'let', 'game', 'begin', 'voluntary', 'response', 'bias', 'one', 'biggest', 'challenge', 'review', 'platform', 'face', 'voluntary', 'response', 'bias', 'research', 'show', 'many', 'today', 'popular', 'online', 'review', 'platform', 'amazon', 'distribution', 'opinion', 'highly', 'polarized', 'many', 'extreme', 'positive', 'andor', 'negative', 'review', 'moderate', 'opinion', 'think', 'ever', 'felt', 'moderately', 'satisfied', 'job', 'thought', 'would', 'great', 'time', 'leave', 'glassdoor', 'review', 'probably', 'hand', 'youve', 'terrible', 'experience', 'even', 'one', 'thing', 'really', 'flip', 'might', 'quite', 'likely', 'leave', 'angry', 'review', 'consider', 'company', 'go', 'layoff', 'youre', 'going', 'flood', 'angry', 'review', 'coming', 'way', 'likely', 'going', 'experience', 'spike', 'review', 'note', 'like', 'wall', 'street', 'journal', 'methodology', 'described', 'considered', 'spike', 'total', 'number', 'review', 'month', 'greater', 'three', 'standard', 'deviation', 'mean', 'surrounding', 'month', 'let', 'take', 'company', 'here', 'graph', 'review', 'volume', 'since', 'jan', 'including', 'announced', 'one', 'first', 'round', 'layoff', 'june', 'june', 'approximately', 'company', 'review', 'star', 'review', 'compared', 'overall', 'average', 'around', 'could', 'call', 'statistically', 'significant', 'spike', 'review', 'also', 'illustrates', 'employee', 'likely', 'leave', 'review', 'one', 'obviously', 'bad', 'experience', 'getting', 'laid', 'here', 'another', 'company', 'similar', 'spike', 'negative', 'review', 'due', 'layoff', 'november', 'company', 'approximate', 'star', 'review', 'rate', 'compared', 'overall', 'average', 'november', 'well', 'avg', 'rating', 'month', 'compared', 'overall', 'average', 'rating', 'unless', 'proactive', 'review', 'page', 'risk', 'succumbing', 'echochamber', 'negative', 'review', 'really', 'tilt', 'one', 'way', 'note', 'glassdoor', 'state', 'based', 'video', 'review', 'platform', 'neutral', 'give', 'get', 'policy', 'helped', 'keeping', 'platform', 'becoming', 'polarized', 'understand', 'team', 'like', 'one', 'nader', 'talked', 'earlier', 'take', 'proactive', 'stance', 'towards', 'managing', 'review', 'dont', 'try', 'control', 'reputation', 'reputation', 'risk', 'getting', 'controlled', 'employee', 'worst', 'possible', 'experience', 'goodharts', 'law', 'goodharts', 'law', 'state', 'following', 'measure', 'becomes', 'target', 'cease', 'good', 'measure', 'every', 'october', 'glassdoor', 'publishes', 'best', 'place', 'work', 'ranking', 'report', 'wsj', 'couple', 'year', 'ago', 'found', 'large', 'spike', 'number', 'review', 'company', 'spacex', 'bain', 'etc', 'got', 'september', 'logic', 'company', 'try', 'artificially', 'inflate', 'glassdoor', 'review', 'right', 'october', 'deadline', 'decided', 'revisit', 'analysis', 'glassdoors', 'best', 'place', 'work', 'ranking', 'one', 'company', 'examined', 'rated', 'one', 'best', 'place', 'work', 'let', 'refer', 'company', 'funplacetowork', 'review', 'volume', 'look', 'like', 'funplacetowork', 'got', 'around', 'review', 'september', 'review', 'star', 'review', 'funplacetowork', 'averaged', 'review', 'per', 'month', 'till', 'also', 'prior', 'six', 'month', 'average', 'percent', 'star', 'review', 'received', 'every', 'month', 'spike', 'volume', 'review', 'spike', 'percentage', 'five', 'star', 'review', 'statistically', 'significant', 'find', 'strange', 'glassdoors', 'proprietary', 'algorithm', 'andor', 'human', 'content', 'moderation', 'team', 'find', 'spike', 'nature', 'unusual', 'look', 'glassdoors', 'eligibility', 'criterion', 'award', 'follows', 'goal', 'according', 'glassdoor', 'collect', 'authentic', 'unbiased', 'review', 'whilst', 'there', 'nothing', 'rule', 'asking', 'employee', 'leave', 'review', 'find', 'statistically', 'significant', 'spike', 'review', 'odds', 'goal', 'collecting', 'unbiased', 'authentic', 'review', 'glassdoor', 'state', 'purpose', 'award', 'glassdoor', 'state', 'employer', 'allowed', 'ask', 'employee', 'leave', 'review', 'allowed', 'coerce', 'example', 'cant', 'offer', 'incentive', 'like', 'gift', 'card', 'exchange', 'positive', 'review', 'withholding', 'reference', 'letter', 'unless', 'leave', 'positive', 'review', 'anything', 'lead', 'require', 'proof', 'employee', 'show', 'wrote', 'review', 'possible', 'play', 'rule', 'break', 'rule', 'still', 'opinion', 'collect', 'authentic', 'unbiased', 'review', 'say', 'shouldnt', 'hate', 'player', 'game', 'think', 'funplacetowork', 'played', 'rule', 'fair', 'square', 'simply', 'perfect', 'example', 'goodharts', 'law', 'reached', 'glassdoor', 'awardsglassdoorcommailtoawardsglassdoorcom', 'reply', 'got', 'conclusion', 'visa', 'month', 'find', 'work', 'didnt', 'give', 'damn', 'bad', 'review', 'needed', 'job', 'sign', 'piece', 'paper', 'put', 'front', 'compare', 'someone', 'peak', 'career', 'someone', 'optionality', 'multitude', 'job', 'offer', 'aplayer', 'expert', 'call', 'would', 'absolutely', 'luxury', 'choice', 'discard', 'job', 'offer', 'based', 'bad', 'company', 'review', 'people', 'impact', 'online', 'company', 'review', 'lie', 'somewhere', 'middle', 'marketing', 'there', 'concept', 'marketing', 'touchpoint', 'interaction', 'brand', 'course', 'whole', 'buying', 'journey', 'company', 'review', 'one', 'many', 'touchpoints', 'job', 'seeker', 'experience', 'interview', 'process', 'technology', 'industry', 'booming', 'past', 'couple', 'year', 'company', 'couldnt', 'afford', 'slack', 'touchpoints', 'including', 'one', 'others', 'start', 'game', 'system', 'youre', 'disadvantage', 'dont', 'reward', 'quite', 'high', 'certainly', 'higher', 'trying', 'transparent', 'possible', 'leader', 'often', 'incentivized', 'inflate', 'metric', 'get', 'honest', 'feedback', 'fake', 'review', 'writer', 'bill', 'pay', 'orms', 'know', 'company', 'desperate', 'platform', 'well', 'arent', 'always', 'paying', 'attention', 'result', 'potluck', 'interest', 'lead', 'underground', 'economy', 'one', 'end', 'hurting', 'job', 'seeker', 'whew', 'took', 'month', 'fact', 'thanks', 'reading', 'content', 'like', 'subscribe', 'newsletter', 'best', 'content', 'delivered', 'inbox', 'every', 'week']",,,,
16fm64z,It be like this now,,1694407587.0,1158.0,55.0,/r/datascience/comments/16fm64z/it_be_like_this_now/,https://i.redd.it/6t60nlvo3knb1.jpg,OverratedDataScience,datascience,0.98,False,False,False,False,1.0,1745834705.517669,Tech & Programming,5.0,0.0,5.0,Monday,0.0,September,2023.0,False,0.3612,0.385,0.0,0.615,positive,it be like this now,,it be like this now ,like,2023-09-11 04:46:27,it be like this now ,['like'],,,,
dv7mdc,"""If you torture the data long enough, it will confess to anything."" - Ronald Coase, MIT [250 x 110]",,1573550456.0,1155.0,34.0,/r/datascience/comments/dv7mdc/if_you_torture_the_data_long_enough_it_will/,https://i.redd.it/5rg06b0c38y31.png,mk4rim,datascience,0.98,False,False,False,False,0.0,1745834705.850619,Tech & Programming,19.0,0.0,16.0,Tuesday,4.0,November,2019.0,False,-0.5994,0.0,0.218,0.782,negative,if you torture the data long enough it will confess to anything ronald coase mit x,,if you torture the data long enough it will confess to anything ronald coase mit x ,"torture, data, long, enough, confess",2019-11-12 09:20:56,if you torture the data long enough it will confess to anything ronald coase mit x ,"['torture', 'data', 'long', 'enough', 'confess', 'anything', 'ronald', 'coase', 'mit']",,,,
dijadz,An easy guide for choosing visual graphs!!,,1571195783.0,1144.0,34.0,/r/datascience/comments/dijadz/an_easy_guide_for_choosing_visual_graphs/,https://i.redd.it/wnzyb35elts31.jpg,vulpinecode,datascience,0.97,False,False,False,False,0.0,1745834706.202263,Tech & Programming,7.0,0.0,7.0,Tuesday,23.0,October,2019.0,False,0.4404,0.326,0.0,0.674,positive,an easy guide for choosing visual graphs,,an easy guide for choosing visual graphs ,"easy, guide, choosing, visual, graph",2019-10-16 03:16:23,an easy guide for choosing visual graphs ,"['easy', 'guide', 'choosing', 'visual', 'graph']",,,,
18ak46b,What opinion about data science would you defend like this?,,1701696235.0,1136.0,641.0,/r/datascience/comments/18ak46b/what_opinion_about_data_science_would_you_defend/,https://i.redd.it/20r6sbok4a4c1.jpg,OverratedDataScience,datascience,0.94,False,False,False,False,0.0,1745834706.551754,Tech & Programming,10.0,0.0,10.0,Monday,8.0,December,2023.0,False,0.3612,0.217,0.0,0.783,positive,what opinion about data science would you defend like this,,what opinion about data science would you defend like this ,"opinion, data, science, would, defend",2023-12-04 13:23:55,what opinion about data science would you defend like this ,"['opinion', 'data', 'science', 'would', 'defend', 'like']",,,,
ypr93q,"hot take: forget data science, we need more analysts","People are obsessed with pursuing data science roles for some reason. I guess it's interesting work with a high skill ceiling. Thats why I'm pursuing it. But nobody talks about the data analyst. The folks who write SQL for reporting, create dashboards, and provide insights. Data science does do all this in a more sophisticated way, but the reality is most tech companies or start ups do not even have an appetite for that kind of work since they are so focused on growth. If you're struggling to get into data science, consider analytics. The pay is still good (100k plus if you're doing product analytics) and a natural growth path from there can totally be data science. Don't rule it out, you have options. End 😊",1667924978.0,1129.0,190.0,/r/datascience/comments/ypr93q/hot_take_forget_data_science_we_need_more_analysts/,https://www.reddit.com/r/datascience/comments/ypr93q/hot_take_forget_data_science_we_need_more_analysts/,djaycat,datascience,0.95,True,False,False,False,0.0,1745834709.180765,Tech & Programming,9.0,127.0,135.0,Tuesday,11.0,November,2022.0,False,0.975,0.187,0.052,0.76,positive,hot take forget data science we need more analysts,people are obsessed with pursuing data science roles for some reason i guess its interesting work with a high skill ceiling thats why im pursuing it but nobody talks about the data analyst the folks who write sql for reporting create dashboards and provide insights data science does do all this in a more sophisticated way but the reality is most tech companies or start ups do not even have an appetite for that kind of work since they are so focused on growth if youre struggling to get into data science consider analytics the pay is still good k plus if youre doing product analytics and a natural growth path from there can totally be data science dont rule it out you have options end,hot take forget data science we need more analysts people are obsessed with pursuing data science roles for some reason i guess its interesting work with a high skill ceiling thats why im pursuing it but nobody talks about the data analyst the folks who write sql for reporting create dashboards and provide insights data science does do all this in a more sophisticated way but the reality is most tech companies or start ups do not even have an appetite for that kind of work since they are so focused on growth if youre struggling to get into data science consider analytics the pay is still good k plus if youre doing product analytics and a natural growth path from there can totally be data science dont rule it out you have options end,"data, science, analyst, pursuing, work",2022-11-08 16:29:38,hot take forget data science we need more analysts people are obsessed with pursuing data science roles for some reason i guess its interesting work with a high skill ceiling thats why im pursuing it but nobody talks about the data analyst the folks who write sql for reporting create dashboards and provide insights data science does do all this in a more sophisticated way but the reality is most tech companies or start ups do not even have an appetite for that kind of work since they are so focused on growth if youre struggling to get into data science consider analytics the pay is still good k plus if youre doing product analytics and a natural growth path from there can totally be data science dont rule it out you have options end,"['hot', 'take', 'forget', 'data', 'science', 'need', 'analyst', 'people', 'obsessed', 'pursuing', 'data', 'science', 'role', 'reason', 'guess', 'interesting', 'work', 'high', 'skill', 'ceiling', 'thats', 'pursuing', 'nobody', 'talk', 'data', 'analyst', 'folk', 'write', 'sql', 'reporting', 'create', 'dashboard', 'provide', 'insight', 'data', 'science', 'sophisticated', 'way', 'reality', 'tech', 'company', 'start', 'ups', 'even', 'appetite', 'kind', 'work', 'since', 'focused', 'growth', 'youre', 'struggling', 'get', 'data', 'science', 'consider', 'analytics', 'pay', 'still', 'good', 'plus', 'youre', 'product', 'analytics', 'natural', 'growth', 'path', 'totally', 'data', 'science', 'dont', 'rule', 'option', 'end']",,,,
11ddeft,"When Pandas.read_csv ""helpfully"" guesses the data type of each column",,1677508776.0,1112.0,23.0,/r/datascience/comments/11ddeft/when_pandasread_csv_helpfully_guesses_the_data/,https://i.redd.it/tppr6p77tqka1.png,dumplechan,datascience,0.97,False,False,False,False,0.0,1745834710.330567,Tech & Programming,10.0,0.0,10.0,Monday,9.0,February,2023.0,False,0.5106,0.268,0.0,0.732,positive,when pandasread_csv helpfully guesses the data type of each column,,when pandasread_csv helpfully guesses the data type of each column ,"pandasread_csv, helpfully, guess, data, type",2023-02-27 14:39:36,when pandasread_csv helpfully guesses the data type of each column ,"['pandasread_csv', 'helpfully', 'guess', 'data', 'type', 'column']",,,,
eufeqm,How to learn data science “best practices” if you’re the only data scientist at your first job?,"I’m a grad student in my final year. 

I just accepted a spring internship at a well-known tech company that  doesn’t have a data scientist in the particular group I’ll be working in. If I do well, the plan is to be brought on full time post graduation later this summer. 

I know a lot about stats, ML, A/B testing etc. However, I’m less familiar with putting things in production or writing “production level code”. 

Are there any books/learning resources I should look into before I start? 

At the moment, I’m considering [Clean Code](https://www.amazon.com/dp/0132350882/ref=cm_sw_r_cp_awdb_t1_wyIlEb93NCPQF), [Designing Data-Intensive Applications](http://shop.oreilly.com/product/0636920032175.do), and [Geurilla Analytics](https://guerrilla-analytics.net/). Which (if any) of these should I read?

Any other recommendations/words of advice are much appreciated!",1580082946.0,1113.0,50.0,/r/datascience/comments/eufeqm/how_to_learn_data_science_best_practices_if_youre/,https://www.reddit.com/r/datascience/comments/eufeqm/how_to_learn_data_science_best_practices_if_youre/,Folasade_Adu,datascience,0.99,True,False,False,False,0.0,1745834710.568519,Tech & Programming,17.0,116.0,133.0,Sunday,18.0,January,2020.0,True,0.891,0.108,0.021,0.871,positive,how to learn data science best practices if youre the only data scientist at your first job,im a grad student in my final year i just accepted a spring internship at a wellknown tech company that doesnt have a data scientist in the particular group ill be working in if i do well the plan is to be brought on full time post graduation later this summer i know a lot about stats ml ab testing etc however im less familiar with putting things in production or writing production level code are there any bookslearning resources i should look into before i start at the moment im considering clean code designing dataintensive applications and geurilla analytics which if any of these should i read any other recommendationswords of advice are much appreciated,how to learn data science best practices if youre the only data scientist at your first job im a grad student in my final year i just accepted a spring internship at a wellknown tech company that doesnt have a data scientist in the particular group ill be working in if i do well the plan is to be brought on full time post graduation later this summer i know a lot about stats ml ab testing etc however im less familiar with putting things in production or writing production level code are there any bookslearning resources i should look into before i start at the moment im considering clean code designing dataintensive applications and geurilla analytics which if any of these should i read any other recommendationswords of advice are much appreciated,"data, scientist, production, code, learn",2020-01-26 23:55:46,how to learn data science best practices if youre the only data scientist at your first job im a grad student in my final year i just accepted a spring internship at a wellknown tech company that doesnt have a data scientist in the particular group ill be working in if i do well the plan is to be brought on full time post graduation later this summer i know a lot about stats ml ab testing etc however im less familiar with putting things in production or writing production level code are there any bookslearning resources i should look into before i start at the moment im considering clean code designing dataintensive applications and geurilla analytics which if any of these should i read any other recommendationswords of advice are much appreciated,"['learn', 'data', 'science', 'best', 'practice', 'youre', 'data', 'scientist', 'first', 'job', 'grad', 'student', 'final', 'year', 'accepted', 'spring', 'internship', 'wellknown', 'tech', 'company', 'doesnt', 'data', 'scientist', 'particular', 'group', 'ill', 'working', 'well', 'plan', 'brought', 'full', 'time', 'post', 'graduation', 'later', 'summer', 'know', 'lot', 'stats', 'testing', 'etc', 'however', 'less', 'familiar', 'putting', 'thing', 'production', 'writing', 'production', 'level', 'code', 'bookslearning', 'resource', 'look', 'start', 'moment', 'considering', 'clean', 'code', 'designing', 'dataintensive', 'application', 'geurilla', 'analytics', 'read', 'recommendationswords', 'advice', 'much', 'appreciated']",,,,
xf6ifb,Simplified guide to how QR codes work.,,1663272423.0,1107.0,21.0,/r/datascience/comments/xf6ifb/simplified_guide_to_how_qr_codes_work/,https://i.redd.it/5bzlfvqvnzn91.jpg,leefaf,datascience,0.98,False,False,False,False,0.0,1745834710.924972,Tech & Programming,7.0,0.0,7.0,Thursday,16.0,September,2022.0,False,0.0,0.0,0.0,1.0,neutral,simplified guide to how qr codes work,,simplified guide to how qr codes work ,"simplified, guide, code, work",2022-09-15 20:07:03,simplified guide to how qr codes work ,"['simplified', 'guide', 'code', 'work']",,,,
10ikd4i,Thoughts?,,1674396216.0,1094.0,90.0,/r/datascience/comments/10ikd4i/thoughts/,https://i.redd.it/w1ognrxxplda1.png,deepcontractor,datascience,0.95,False,False,False,False,0.0,1745834711.2121,Tech & Programming,1.0,0.0,1.0,Sunday,9.0,January,2023.0,True,0.0,0.0,0.0,1.0,neutral,thoughts,,thoughts ,thought,2023-01-22 14:03:36,thoughts ,['thought'],,,,
1fyrawz,A guide to passing the A/B test interview question in tech companies,"Hey all,

I'm a Sr. Analytics Data Scientist at a large tech firm (not FAANG) and I conduct about \~3 interviews per week. I wanted to share my advice on how to pass A/B test interview questions as this is an area I commonly see candidates get dinged. Hope it helps.

Product analytics and data scientist interviews at tech companies often include an A/B testing component. Here is my framework on how to answer A/B testing interview questions. Please note that this is not necessarily a guide to design a good A/B test. Rather, it is a guide to help you convince an interviewer that you know how to design A/B tests.

**A/B Test Interview Framework**

Imagine during the interview that you get asked “Walk me through how you would A/B test this new feature?”. This framework will help you pass these types of questions.

**Phase 1: Set the context for the experiment. Why do we want to AB test, what is our goal, what do we want to measure?**

1. The first step is to clarify the purpose and value of the experiment with the interviewer. Is it even worth running an A/B test? Interviewers want to know that the candidate can tie experiments to business goals.
2. Specify what exactly is the treatment, and what hypothesis are we testing? Too often I see candidates fail to specify what the treatment is, and what is the hypothesis that they want to test. It’s important to spell this out for your interviewer. 
3. After specifying the treatment and the hypothesis, you need to define the metrics that you will track and measure.
   * Success metrics: Identify at least 2-3 candidate success metrics. Then narrow it down to one and propose it to the interviewer to get their thoughts.
   * Guardrail metrics: Guardrail metrics are metrics that you do not want to harm. You don’t necessarily want to improve them, but you definitely don’t want to harm them. Come up with 2-4 of these.
   * Tracking metrics: Tracking metrics help explain the movement in the success metrics. Come up with 1-4 of these.

**Phase 2: How do we design the experiment to measure what we want to measure?**

1. Now that you have your treatment, hypothesis, and metrics, the next step is to determine the unit of randomization for the experiment, and when each unit will enter the experiment. You should pick a unit of randomization such that you can measure success your metrics, avoid interference and network effects, and consider user experience.
   * As a simple example, let’s say you want to test a treatment that changes the color of the checkout button on an ecommerce website from blue to green. How would you randomize this? You could randomize at the user level and say that every person that visits your website will be randomized into the treatment or control group. Another way would be to randomize at the session level, or even at the checkout page level. 
   * When each unit will enter the experiment is also important. Using the example above, you could have a person enter the experiment as soon as they visit the website. However, many users will not get all the way to the checkout page so you will end up with a lot of users who never even got a chance to see your treatment, which will dilute your experiment. In this case, it might make sense to have a person enter the experiment once they reach the checkout page. You want to choose your unit of randomization and when they will enter the experiment such that you have minimal dilution. In a perfect world, every unit would have the chance to be exposed to your treatment.
2. Next, you need to determine which statistical test(s) you will use to analyze the results. Is a simple t-test sufficient, or do you need quasi-experimental techniques like difference in differences? Do you require heteroskedastic robust standard errors or clustered standard errors?
   * The t-test and z-test of proportions are two of the most common tests.
3. The next step is to conduct a power analysis to determine the number of observations required and how long to run the experiment. You can either state that you would conduct a power analysis using an alpha of 0.05 and power of 80%, or ask the interviewer if the company has standards you should use.
   * I’m not going to go into how to calculate power here, but know that in any AB  test interview question, you will have to mention power. For some companies, and in junior roles, just mentioning this will be good enough. Other companies, especially for more senior roles, might ask you more specifics about how to calculate power. 
4. Final considerations for the experiment design: 
   * Are you testing multiple metrics? If so, account for that in your analysis. A really common academic answer is the Bonferonni correction. I've never seen anyone use it in real life though, because it is too conservative. A more common way is to control the False Discovery Rate. You can google this. Alternatively, the book [Trustworthy Online Controlled Experiments](https://amzn.to/4dzXyZP) by Ron Kohavi discusses how to do this (note: this is an affiliate link). 
   * Do any stakeholders need to be informed about the experiment? 
   * Are there any novelty effects or change aversion that could impact interpretation?
5. If your unit of randomization is larger than your analysis unit, you may need to adjust how you calculate your standard errors.
6. You might be thinking “why would I need to use difference-in-difference in an AB test”? In my experience, this is common when doing a geography based randomization on a relatively small sample size. Let’s say that you want to randomize by city in the state of California. It’s likely that even though you are randomizing which cities are in the treatment and control groups, that your two groups will have pre-existing biases. A common solution is to use difference-in-difference. I’m not saying this is right or wrong, but it’s a common solution that I have seen in tech companies.

**Phase 3:** **The experiment is over. Now what?**

1. After you “run” the A/B test, you now have some data. Consider what recommendations you can make from them. What insights can you derive to take actionable steps for the business? Speaking to this will earn you brownie points with the interviewer.
   * For example, can you think of some useful ways to segment your experiment data to determine whether there were heterogeneous treatment effects?

**Common follow-up questions, or “gotchas”**

These are common questions that interviewers will ask to see if you really understand A/B testing.

* Let’s say that you are mid-way through running your A/B test and the performance starts to get worse. It had a strong start but now your success metric is degrading. Why do you think this could be?
   * A common answer is novelty effect
* Let’s say that your AB test is concluded and your chosen p-value cutoff is 0.05. However, your success metric has a p-value of 0.06. What do you do?
   * Some options are: Extend the experiment. Run the experiment again.
   * You can also say that you would discuss the risk of a false positive with your business stakeholders. It may be that the treatment doesn’t have much downside, so the company is OK with rolling out the feature, even if there is no true improvement. However, this is a discussion that needs to be had with all relevant stakeholders and as a data scientist or product analyst, you need to help quantify the risk of rolling out a false positive treatment.
* Your success metric was stat sig positive, but one of your guardrail metrics was harmed. What do you do?
   * Investigate the cause of the guardrail metric dropping. Once the cause is identified, work with the product manager or business stakeholders to update the treatment such that hopefully the guardrail will not be harmed, and run the experiment again.
   * Alternatively, see if there is a segment of the population where the guardrail metric was not harmed. Release the treatment to only this population segment.
* Your success metric ended up being stat sig negative. How would you diagnose this? 

I know this is really long but honestly, most of the steps I listed could be an entire blog post by itself. If you don't understand anything, I encourage you to do some more research about it, or get the book that I linked above (I've read it 3 times through myself). Lastly, don't feel like you need to be an A/B test expert to pass the interview. We hire folks who have no A/B testing experience but can demonstrate framework of designing AB tests such as the one I have just laid out. Good luck!",1728360485.0,1088.0,115.0,/r/datascience/comments/1fyrawz/a_guide_to_passing_the_ab_test_interview_question/,https://www.reddit.com/r/datascience/comments/1fyrawz/a_guide_to_passing_the_ab_test_interview_question/,productanalyst9,datascience,0.99,True,False,False,False,0.0,1745834711.794316,Tech & Programming,12.0,1480.0,1450.0,Tuesday,0.0,October,2024.0,False,0.9982,0.111,0.044,0.845,positive,a guide to passing the ab test interview question in tech companies,hey all im a sr analytics data scientist at a large tech firm not faang and i conduct about interviews per week i wanted to share my advice on how to pass ab test interview questions as this is an area i commonly see candidates get dinged hope it helps product analytics and data scientist interviews at tech companies often include an ab testing component here is my framework on how to answer ab testing interview questions please note that this is not necessarily a guide to design a good ab test rather it is a guide to help you convince an interviewer that you know how to design ab tests ab test interview framework imagine during the interview that you get asked walk me through how you would ab test this new feature this framework will help you pass these types of questions phase set the context for the experiment why do we want to ab test what is our goal what do we want to measure the first step is to clarify the purpose and value of the experiment with the interviewer is it even worth running an ab test interviewers want to know that the candidate can tie experiments to business goals specify what exactly is the treatment and what hypothesis are we testing too often i see candidates fail to specify what the treatment is and what is the hypothesis that they want to test its important to spell this out for your interviewer after specifying the treatment and the hypothesis you need to define the metrics that you will track and measure success metrics identify at least candidate success metrics then narrow it down to one and propose it to the interviewer to get their thoughts guardrail metrics guardrail metrics are metrics that you do not want to harm you dont necessarily want to improve them but you definitely dont want to harm them come up with of these tracking metrics tracking metrics help explain the movement in the success metrics come up with of these phase how do we design the experiment to measure what we want to measure now that you have your treatment hypothesis and metrics the next step is to determine the unit of randomization for the experiment and when each unit will enter the experiment you should pick a unit of randomization such that you can measure success your metrics avoid interference and network effects and consider user experience as a simple example lets say you want to test a treatment that changes the color of the checkout button on an ecommerce website from blue to green how would you randomize this you could randomize at the user level and say that every person that visits your website will be randomized into the treatment or control group another way would be to randomize at the session level or even at the checkout page level when each unit will enter the experiment is also important using the example above you could have a person enter the experiment as soon as they visit the website however many users will not get all the way to the checkout page so you will end up with a lot of users who never even got a chance to see your treatment which will dilute your experiment in this case it might make sense to have a person enter the experiment once they reach the checkout page you want to choose your unit of randomization and when they will enter the experiment such that you have minimal dilution in a perfect world every unit would have the chance to be exposed to your treatment next you need to determine which statistical tests you will use to analyze the results is a simple ttest sufficient or do you need quasiexperimental techniques like difference in differences do you require heteroskedastic robust standard errors or clustered standard errors the ttest and ztest of proportions are two of the most common tests the next step is to conduct a power analysis to determine the number of observations required and how long to run the experiment you can either state that you would conduct a power analysis using an alpha of and power of or ask the interviewer if the company has standards you should use im not going to go into how to calculate power here but know that in any ab test interview question you will have to mention power for some companies and in junior roles just mentioning this will be good enough other companies especially for more senior roles might ask you more specifics about how to calculate power final considerations for the experiment design are you testing multiple metrics if so account for that in your analysis a really common academic answer is the bonferonni correction ive never seen anyone use it in real life though because it is too conservative a more common way is to control the false discovery rate you can google this alternatively the book trustworthy online controlled experiments by ron kohavi discusses how to do this note this is an affiliate link do any stakeholders need to be informed about the experiment are there any novelty effects or change aversion that could impact interpretation if your unit of randomization is larger than your analysis unit you may need to adjust how you calculate your standard errors you might be thinking why would i need to use differenceindifference in an ab test in my experience this is common when doing a geography based randomization on a relatively small sample size lets say that you want to randomize by city in the state of california its likely that even though you are randomizing which cities are in the treatment and control groups that your two groups will have preexisting biases a common solution is to use differenceindifference im not saying this is right or wrong but its a common solution that i have seen in tech companies phase the experiment is over now what after you run the ab test you now have some data consider what recommendations you can make from them what insights can you derive to take actionable steps for the business speaking to this will earn you brownie points with the interviewer for example can you think of some useful ways to segment your experiment data to determine whether there were heterogeneous treatment effects common followup questions or gotchas these are common questions that interviewers will ask to see if you really understand ab testing lets say that you are midway through running your ab test and the performance starts to get worse it had a strong start but now your success metric is degrading why do you think this could be a common answer is novelty effect lets say that your ab test is concluded and your chosen pvalue cutoff is however your success metric has a pvalue of what do you do some options are extend the experiment run the experiment again you can also say that you would discuss the risk of a false positive with your business stakeholders it may be that the treatment doesnt have much downside so the company is ok with rolling out the feature even if there is no true improvement however this is a discussion that needs to be had with all relevant stakeholders and as a data scientist or product analyst you need to help quantify the risk of rolling out a false positive treatment your success metric was stat sig positive but one of your guardrail metrics was harmed what do you do investigate the cause of the guardrail metric dropping once the cause is identified work with the product manager or business stakeholders to update the treatment such that hopefully the guardrail will not be harmed and run the experiment again alternatively see if there is a segment of the population where the guardrail metric was not harmed release the treatment to only this population segment your success metric ended up being stat sig negative how would you diagnose this i know this is really long but honestly most of the steps i listed could be an entire blog post by itself if you dont understand anything i encourage you to do some more research about it or get the book that i linked above ive read it times through myself lastly dont feel like you need to be an ab test expert to pass the interview we hire folks who have no ab testing experience but can demonstrate framework of designing ab tests such as the one i have just laid out good luck,a guide to passing the ab test interview question in tech companies hey all im a sr analytics data scientist at a large tech firm not faang and i conduct about interviews per week i wanted to share my advice on how to pass ab test interview questions as this is an area i commonly see candidates get dinged hope it helps product analytics and data scientist interviews at tech companies often include an ab testing component here is my framework on how to answer ab testing interview questions please note that this is not necessarily a guide to design a good ab test rather it is a guide to help you convince an interviewer that you know how to design ab tests ab test interview framework imagine during the interview that you get asked walk me through how you would ab test this new feature this framework will help you pass these types of questions phase set the context for the experiment why do we want to ab test what is our goal what do we want to measure the first step is to clarify the purpose and value of the experiment with the interviewer is it even worth running an ab test interviewers want to know that the candidate can tie experiments to business goals specify what exactly is the treatment and what hypothesis are we testing too often i see candidates fail to specify what the treatment is and what is the hypothesis that they want to test its important to spell this out for your interviewer after specifying the treatment and the hypothesis you need to define the metrics that you will track and measure success metrics identify at least candidate success metrics then narrow it down to one and propose it to the interviewer to get their thoughts guardrail metrics guardrail metrics are metrics that you do not want to harm you dont necessarily want to improve them but you definitely dont want to harm them come up with of these tracking metrics tracking metrics help explain the movement in the success metrics come up with of these phase how do we design the experiment to measure what we want to measure now that you have your treatment hypothesis and metrics the next step is to determine the unit of randomization for the experiment and when each unit will enter the experiment you should pick a unit of randomization such that you can measure success your metrics avoid interference and network effects and consider user experience as a simple example lets say you want to test a treatment that changes the color of the checkout button on an ecommerce website from blue to green how would you randomize this you could randomize at the user level and say that every person that visits your website will be randomized into the treatment or control group another way would be to randomize at the session level or even at the checkout page level when each unit will enter the experiment is also important using the example above you could have a person enter the experiment as soon as they visit the website however many users will not get all the way to the checkout page so you will end up with a lot of users who never even got a chance to see your treatment which will dilute your experiment in this case it might make sense to have a person enter the experiment once they reach the checkout page you want to choose your unit of randomization and when they will enter the experiment such that you have minimal dilution in a perfect world every unit would have the chance to be exposed to your treatment next you need to determine which statistical tests you will use to analyze the results is a simple ttest sufficient or do you need quasiexperimental techniques like difference in differences do you require heteroskedastic robust standard errors or clustered standard errors the ttest and ztest of proportions are two of the most common tests the next step is to conduct a power analysis to determine the number of observations required and how long to run the experiment you can either state that you would conduct a power analysis using an alpha of and power of or ask the interviewer if the company has standards you should use im not going to go into how to calculate power here but know that in any ab test interview question you will have to mention power for some companies and in junior roles just mentioning this will be good enough other companies especially for more senior roles might ask you more specifics about how to calculate power final considerations for the experiment design are you testing multiple metrics if so account for that in your analysis a really common academic answer is the bonferonni correction ive never seen anyone use it in real life though because it is too conservative a more common way is to control the false discovery rate you can google this alternatively the book trustworthy online controlled experiments by ron kohavi discusses how to do this note this is an affiliate link do any stakeholders need to be informed about the experiment are there any novelty effects or change aversion that could impact interpretation if your unit of randomization is larger than your analysis unit you may need to adjust how you calculate your standard errors you might be thinking why would i need to use differenceindifference in an ab test in my experience this is common when doing a geography based randomization on a relatively small sample size lets say that you want to randomize by city in the state of california its likely that even though you are randomizing which cities are in the treatment and control groups that your two groups will have preexisting biases a common solution is to use differenceindifference im not saying this is right or wrong but its a common solution that i have seen in tech companies phase the experiment is over now what after you run the ab test you now have some data consider what recommendations you can make from them what insights can you derive to take actionable steps for the business speaking to this will earn you brownie points with the interviewer for example can you think of some useful ways to segment your experiment data to determine whether there were heterogeneous treatment effects common followup questions or gotchas these are common questions that interviewers will ask to see if you really understand ab testing lets say that you are midway through running your ab test and the performance starts to get worse it had a strong start but now your success metric is degrading why do you think this could be a common answer is novelty effect lets say that your ab test is concluded and your chosen pvalue cutoff is however your success metric has a pvalue of what do you do some options are extend the experiment run the experiment again you can also say that you would discuss the risk of a false positive with your business stakeholders it may be that the treatment doesnt have much downside so the company is ok with rolling out the feature even if there is no true improvement however this is a discussion that needs to be had with all relevant stakeholders and as a data scientist or product analyst you need to help quantify the risk of rolling out a false positive treatment your success metric was stat sig positive but one of your guardrail metrics was harmed what do you do investigate the cause of the guardrail metric dropping once the cause is identified work with the product manager or business stakeholders to update the treatment such that hopefully the guardrail will not be harmed and run the experiment again alternatively see if there is a segment of the population where the guardrail metric was not harmed release the treatment to only this population segment your success metric ended up being stat sig negative how would you diagnose this i know this is really long but honestly most of the steps i listed could be an entire blog post by itself if you dont understand anything i encourage you to do some more research about it or get the book that i linked above ive read it times through myself lastly dont feel like you need to be an ab test expert to pass the interview we hire folks who have no ab testing experience but can demonstrate framework of designing ab tests such as the one i have just laid out good luck,"experiment, test, metric, treatment, want",2024-10-08 04:08:05,a guide to passing the ab test interview question in tech companies hey all im a sr analytics data scientist at a large tech firm not faang and i conduct about interviews per week i wanted to share my advice on how to pass ab test interview questions as this is an area i commonly see candidates get dinged hope it helps product analytics and data scientist interviews at tech companies often include an ab testing component here is my framework on how to answer ab testing interview questions please note that this is not necessarily a guide to design a good ab test rather it is a guide to help you convince an interviewer that you know how to design ab tests ab test interview framework imagine during the interview that you get asked walk me through how you would ab test this new feature this framework will help you pass these types of questions phase set the context for the experiment why do we want to ab test what is our goal what do we want to measure the first step is to clarify the purpose and value of the experiment with the interviewer is it even worth running an ab test interviewers want to know that the candidate can tie experiments to business goals specify what exactly is the treatment and what hypothesis are we testing too often i see candidates fail to specify what the treatment is and what is the hypothesis that they want to test its important to spell this out for your interviewer after specifying the treatment and the hypothesis you need to define the metrics that you will track and measure success metrics identify at least candidate success metrics then narrow it down to one and propose it to the interviewer to get their thoughts guardrail metrics guardrail metrics are metrics that you do not want to harm you dont necessarily want to improve them but you definitely dont want to harm them come up with of these tracking metrics tracking metrics help explain the movement in the success metrics come up with of these phase how do we design the experiment to measure what we want to measure now that you have your treatment hypothesis and metrics the next step is to determine the unit of randomization for the experiment and when each unit will enter the experiment you should pick a unit of randomization such that you can measure success your metrics avoid interference and network effects and consider user experience as a simple example lets say you want to test a treatment that changes the color of the checkout button on an ecommerce website from blue to green how would you randomize this you could randomize at the user level and say that every person that visits your website will be randomized into the treatment or control group another way would be to randomize at the session level or even at the checkout page level when each unit will enter the experiment is also important using the example above you could have a person enter the experiment as soon as they visit the website however many users will not get all the way to the checkout page so you will end up with a lot of users who never even got a chance to see your treatment which will dilute your experiment in this case it might make sense to have a person enter the experiment once they reach the checkout page you want to choose your unit of randomization and when they will enter the experiment such that you have minimal dilution in a perfect world every unit would have the chance to be exposed to your treatment next you need to determine which statistical tests you will use to analyze the results is a simple ttest sufficient or do you need quasiexperimental techniques like difference in differences do you require heteroskedastic robust standard errors or clustered standard errors the ttest and ztest of proportions are two of the most common tests the next step is to conduct a power analysis to determine the number of observations required and how long to run the experiment you can either state that you would conduct a power analysis using an alpha of and power of or ask the interviewer if the company has standards you should use im not going to go into how to calculate power here but know that in any ab test interview question you will have to mention power for some companies and in junior roles just mentioning this will be good enough other companies especially for more senior roles might ask you more specifics about how to calculate power final considerations for the experiment design are you testing multiple metrics if so account for that in your analysis a really common academic answer is the bonferonni correction ive never seen anyone use it in real life though because it is too conservative a more common way is to control the false discovery rate you can google this alternatively the book trustworthy online controlled experiments by ron kohavi discusses how to do this note this is an affiliate link do any stakeholders need to be informed about the experiment are there any novelty effects or change aversion that could impact interpretation if your unit of randomization is larger than your analysis unit you may need to adjust how you calculate your standard errors you might be thinking why would i need to use differenceindifference in an ab test in my experience this is common when doing a geography based randomization on a relatively small sample size lets say that you want to randomize by city in the state of california its likely that even though you are randomizing which cities are in the treatment and control groups that your two groups will have preexisting biases a common solution is to use differenceindifference im not saying this is right or wrong but its a common solution that i have seen in tech companies phase the experiment is over now what after you run the ab test you now have some data consider what recommendations you can make from them what insights can you derive to take actionable steps for the business speaking to this will earn you brownie points with the interviewer for example can you think of some useful ways to segment your experiment data to determine whether there were heterogeneous treatment effects common followup questions or gotchas these are common questions that interviewers will ask to see if you really understand ab testing lets say that you are midway through running your ab test and the performance starts to get worse it had a strong start but now your success metric is degrading why do you think this could be a common answer is novelty effect lets say that your ab test is concluded and your chosen pvalue cutoff is however your success metric has a pvalue of what do you do some options are extend the experiment run the experiment again you can also say that you would discuss the risk of a false positive with your business stakeholders it may be that the treatment doesnt have much downside so the company is ok with rolling out the feature even if there is no true improvement however this is a discussion that needs to be had with all relevant stakeholders and as a data scientist or product analyst you need to help quantify the risk of rolling out a false positive treatment your success metric was stat sig positive but one of your guardrail metrics was harmed what do you do investigate the cause of the guardrail metric dropping once the cause is identified work with the product manager or business stakeholders to update the treatment such that hopefully the guardrail will not be harmed and run the experiment again alternatively see if there is a segment of the population where the guardrail metric was not harmed release the treatment to only this population segment your success metric ended up being stat sig negative how would you diagnose this i know this is really long but honestly most of the steps i listed could be an entire blog post by itself if you dont understand anything i encourage you to do some more research about it or get the book that i linked above ive read it times through myself lastly dont feel like you need to be an ab test expert to pass the interview we hire folks who have no ab testing experience but can demonstrate framework of designing ab tests such as the one i have just laid out good luck,"['guide', 'passing', 'test', 'interview', 'question', 'tech', 'company', 'hey', 'analytics', 'data', 'scientist', 'large', 'tech', 'firm', 'faang', 'conduct', 'interview', 'per', 'week', 'wanted', 'share', 'advice', 'pas', 'test', 'interview', 'question', 'area', 'commonly', 'see', 'candidate', 'get', 'dinged', 'hope', 'help', 'product', 'analytics', 'data', 'scientist', 'interview', 'tech', 'company', 'often', 'include', 'testing', 'component', 'framework', 'answer', 'testing', 'interview', 'question', 'please', 'note', 'necessarily', 'guide', 'design', 'good', 'test', 'rather', 'guide', 'help', 'convince', 'interviewer', 'know', 'design', 'test', 'test', 'interview', 'framework', 'imagine', 'interview', 'get', 'asked', 'walk', 'would', 'test', 'new', 'feature', 'framework', 'help', 'pas', 'type', 'question', 'phase', 'set', 'context', 'experiment', 'want', 'test', 'goal', 'want', 'measure', 'first', 'step', 'clarify', 'purpose', 'value', 'experiment', 'interviewer', 'even', 'worth', 'running', 'test', 'interviewer', 'want', 'know', 'candidate', 'tie', 'experiment', 'business', 'goal', 'specify', 'exactly', 'treatment', 'hypothesis', 'testing', 'often', 'see', 'candidate', 'fail', 'specify', 'treatment', 'hypothesis', 'want', 'test', 'important', 'spell', 'interviewer', 'specifying', 'treatment', 'hypothesis', 'need', 'define', 'metric', 'track', 'measure', 'success', 'metric', 'identify', 'least', 'candidate', 'success', 'metric', 'narrow', 'one', 'propose', 'interviewer', 'get', 'thought', 'guardrail', 'metric', 'guardrail', 'metric', 'metric', 'want', 'harm', 'dont', 'necessarily', 'want', 'improve', 'definitely', 'dont', 'want', 'harm', 'come', 'tracking', 'metric', 'tracking', 'metric', 'help', 'explain', 'movement', 'success', 'metric', 'come', 'phase', 'design', 'experiment', 'measure', 'want', 'measure', 'treatment', 'hypothesis', 'metric', 'next', 'step', 'determine', 'unit', 'randomization', 'experiment', 'unit', 'enter', 'experiment', 'pick', 'unit', 'randomization', 'measure', 'success', 'metric', 'avoid', 'interference', 'network', 'effect', 'consider', 'user', 'experience', 'simple', 'example', 'let', 'say', 'want', 'test', 'treatment', 'change', 'color', 'checkout', 'button', 'ecommerce', 'website', 'blue', 'green', 'would', 'randomize', 'could', 'randomize', 'user', 'level', 'say', 'every', 'person', 'visit', 'website', 'randomized', 'treatment', 'control', 'group', 'another', 'way', 'would', 'randomize', 'session', 'level', 'even', 'checkout', 'page', 'level', 'unit', 'enter', 'experiment', 'also', 'important', 'using', 'example', 'could', 'person', 'enter', 'experiment', 'soon', 'visit', 'website', 'however', 'many', 'user', 'get', 'way', 'checkout', 'page', 'end', 'lot', 'user', 'never', 'even', 'got', 'chance', 'see', 'treatment', 'dilute', 'experiment', 'case', 'might', 'make', 'sense', 'person', 'enter', 'experiment', 'reach', 'checkout', 'page', 'want', 'choose', 'unit', 'randomization', 'enter', 'experiment', 'minimal', 'dilution', 'perfect', 'world', 'every', 'unit', 'would', 'chance', 'exposed', 'treatment', 'next', 'need', 'determine', 'statistical', 'test', 'use', 'analyze', 'result', 'simple', 'ttest', 'sufficient', 'need', 'quasiexperimental', 'technique', 'like', 'difference', 'difference', 'require', 'heteroskedastic', 'robust', 'standard', 'error', 'clustered', 'standard', 'error', 'ttest', 'ztest', 'proportion', 'two', 'common', 'test', 'next', 'step', 'conduct', 'power', 'analysis', 'determine', 'number', 'observation', 'required', 'long', 'run', 'experiment', 'either', 'state', 'would', 'conduct', 'power', 'analysis', 'using', 'alpha', 'power', 'ask', 'interviewer', 'company', 'standard', 'use', 'going', 'calculate', 'power', 'know', 'test', 'interview', 'question', 'mention', 'power', 'company', 'junior', 'role', 'mentioning', 'good', 'enough', 'company', 'especially', 'senior', 'role', 'might', 'ask', 'specific', 'calculate', 'power', 'final', 'consideration', 'experiment', 'design', 'testing', 'multiple', 'metric', 'account', 'analysis', 'really', 'common', 'academic', 'answer', 'bonferonni', 'correction', 'ive', 'never', 'seen', 'anyone', 'use', 'real', 'life', 'though', 'conservative', 'common', 'way', 'control', 'false', 'discovery', 'rate', 'google', 'alternatively', 'book', 'trustworthy', 'online', 'controlled', 'experiment', 'ron', 'kohavi', 'discusses', 'note', 'affiliate', 'link', 'stakeholder', 'need', 'informed', 'experiment', 'novelty', 'effect', 'change', 'aversion', 'could', 'impact', 'interpretation', 'unit', 'randomization', 'larger', 'analysis', 'unit', 'may', 'need', 'adjust', 'calculate', 'standard', 'error', 'might', 'thinking', 'would', 'need', 'use', 'differenceindifference', 'test', 'experience', 'common', 'geography', 'based', 'randomization', 'relatively', 'small', 'sample', 'size', 'let', 'say', 'want', 'randomize', 'city', 'state', 'california', 'likely', 'even', 'though', 'randomizing', 'city', 'treatment', 'control', 'group', 'two', 'group', 'preexisting', 'bias', 'common', 'solution', 'use', 'differenceindifference', 'saying', 'right', 'wrong', 'common', 'solution', 'seen', 'tech', 'company', 'phase', 'experiment', 'run', 'test', 'data', 'consider', 'recommendation', 'make', 'insight', 'derive', 'take', 'actionable', 'step', 'business', 'speaking', 'earn', 'brownie', 'point', 'interviewer', 'example', 'think', 'useful', 'way', 'segment', 'experiment', 'data', 'determine', 'whether', 'heterogeneous', 'treatment', 'effect', 'common', 'followup', 'question', 'gotchas', 'common', 'question', 'interviewer', 'ask', 'see', 'really', 'understand', 'testing', 'let', 'say', 'midway', 'running', 'test', 'performance', 'start', 'get', 'worse', 'strong', 'start', 'success', 'metric', 'degrading', 'think', 'could', 'common', 'answer', 'novelty', 'effect', 'let', 'say', 'test', 'concluded', 'chosen', 'pvalue', 'cutoff', 'however', 'success', 'metric', 'pvalue', 'option', 'extend', 'experiment', 'run', 'experiment', 'also', 'say', 'would', 'discus', 'risk', 'false', 'positive', 'business', 'stakeholder', 'may', 'treatment', 'doesnt', 'much', 'downside', 'company', 'rolling', 'feature', 'even', 'true', 'improvement', 'however', 'discussion', 'need', 'relevant', 'stakeholder', 'data', 'scientist', 'product', 'analyst', 'need', 'help', 'quantify', 'risk', 'rolling', 'false', 'positive', 'treatment', 'success', 'metric', 'stat', 'sig', 'positive', 'one', 'guardrail', 'metric', 'harmed', 'investigate', 'cause', 'guardrail', 'metric', 'dropping', 'cause', 'identified', 'work', 'product', 'manager', 'business', 'stakeholder', 'update', 'treatment', 'hopefully', 'guardrail', 'harmed', 'run', 'experiment', 'alternatively', 'see', 'segment', 'population', 'guardrail', 'metric', 'harmed', 'release', 'treatment', 'population', 'segment', 'success', 'metric', 'ended', 'stat', 'sig', 'negative', 'would', 'diagnose', 'know', 'really', 'long', 'honestly', 'step', 'listed', 'could', 'entire', 'blog', 'post', 'dont', 'understand', 'anything', 'encourage', 'research', 'get', 'book', 'linked', 'ive', 'read', 'time', 'lastly', 'dont', 'feel', 'like', 'need', 'test', 'expert', 'pas', 'interview', 'hire', 'folk', 'testing', 'experience', 'demonstrate', 'framework', 'designing', 'test', 'one', 'laid', 'good', 'luck']",,,,
w4k8w8,"""Only"" 3 rounds of interviews!",,1658419094.0,1071.0,180.0,/r/datascience/comments/w4k8w8/only_3_rounds_of_interviews/,https://i.redd.it/19l4umhb1yc91.png,coronnial,datascience,0.96,False,False,False,False,0.0,1745834712.357865,Tech & Programming,5.0,0.0,4.0,Thursday,11.0,July,2022.0,False,0.0,0.0,0.0,1.0,neutral,only rounds of interviews,,only rounds of interviews ,"round, interview",2022-07-21 15:58:14,only rounds of interviews ,"['round', 'interview']",,,,
nue01q,"Data Science and Data Analytics is becoming ultra glorified / romanticized, and I don't think people are really told what they are getting into.","I honestly, don't think people wanting to break into Data Science really know what all it entails. It just sounds good, and sounds like it will make them lots of money.

No one tells people what comes with the job. There are a lot of headaches that come with it, and you have to be a very patient person.

When any person starts out in IT, they learn some psychology. How to manage users and their expectations. You learn what to say and what not to say. You learn how to appear confident and reassuring even if you're getting up to speed in the moment. The good ones do anyway.

Data Science, BI, DA - you have to have those skills multiplied by ten. You have to be better than the rest at managing expectations. You have to learn how to avoid support drains, and be thinking ahead all of the time.

The data science people are the only people I respect as much as the people in Systems. Because other fields, you learn one thing and only one side of it, call yourself an engineer despite knowing one side. Sys Engineers have to know a little about everything and base knowledge in all kinds of things/ They are constantly growing. Data Science folks are similar because they have to know a wide assortment of things, and they have to know all of the tips and tricks at their disposal to get their desired result. Which means they will know Python, multiple types of SQL, Pandas, Jupyter, and so on. They'll pivot in Excel in a pinch if they need to.

But the main reason I respect them is just because of how patient they have to be to want to work in their field for 30+ years.

Our DA left in 2018 and one of my roles was a senior DBA, so they just put her job on top of mine. I learned a lot and I got very good at SQL and streamlining and reducing task turn around for reports and data tasks. But I obviously didn't have the time to dive ultra deep into the rabbit hole, and I didn't want to. Because I knew it wasn't for me.

We were acquired, and I transitioned all of that stuff onto the BI team of the new company. I have so much respect for those people. I am still answering questions and taking one off requests. This morning I was just hit in the face with how much I dislike actually doing he DS/DA side. A Sales Senior Manager needed something with some data. I asked a follow up question. I needed a key piece of info to ensure I did the right thing and didn't have to do re work later. They said they would get it to me later.

They emailed it to me at 7:11am this morning, then messaged me before my shift - ""Hey, I don't see the data task with the blah blah being done. We needed it 6/3."" And I am thinking - then why wait until 6/7 to give me the info. We got the request 6/4, and I asked you on 6/4, then you waited the weekend to get it to me.

And those individuals who just keep coming back telling you the data wasn't what they expected or wanted when it is what they asked for.. I'm so happy to be just a senior sys engineer again working on large scale infra.

It's not for everyone, and I think they need to talk about and teach managing expectations so you don't shoot yourself in the foot. Luckily the BI team of the new company are phenomenal, and now I am out of the game. 

But I am learning more Python at home in my spare time and things like Jupyter so I don't regress skill wise. Python is useful in what I do anyway. I've rewritten several PS automation scripts in it.",1623076428.0,1068.0,188.0,/r/datascience/comments/nue01q/data_science_and_data_analytics_is_becoming_ultra/,https://www.reddit.com/r/datascience/comments/nue01q/data_science_and_data_analytics_is_becoming_ultra/,,datascience,0.96,True,False,False,False,0.0,1745834713.325118,Tech & Programming,24.0,663.0,677.0,Monday,10.0,June,2021.0,False,0.9937,0.098,0.021,0.881,positive,data science and data analytics is becoming ultra glorified romanticized and i dont think people are really told what they are getting into,i honestly dont think people wanting to break into data science really know what all it entails it just sounds good and sounds like it will make them lots of money no one tells people what comes with the job there are a lot of headaches that come with it and you have to be a very patient person when any person starts out in it they learn some psychology how to manage users and their expectations you learn what to say and what not to say you learn how to appear confident and reassuring even if youre getting up to speed in the moment the good ones do anyway data science bi da you have to have those skills multiplied by ten you have to be better than the rest at managing expectations you have to learn how to avoid support drains and be thinking ahead all of the time the data science people are the only people i respect as much as the people in systems because other fields you learn one thing and only one side of it call yourself an engineer despite knowing one side sys engineers have to know a little about everything and base knowledge in all kinds of things they are constantly growing data science folks are similar because they have to know a wide assortment of things and they have to know all of the tips and tricks at their disposal to get their desired result which means they will know python multiple types of sql pandas jupyter and so on theyll pivot in excel in a pinch if they need to but the main reason i respect them is just because of how patient they have to be to want to work in their field for years our da left in and one of my roles was a senior dba so they just put her job on top of mine i learned a lot and i got very good at sql and streamlining and reducing task turn around for reports and data tasks but i obviously didnt have the time to dive ultra deep into the rabbit hole and i didnt want to because i knew it wasnt for me we were acquired and i transitioned all of that stuff onto the bi team of the new company i have so much respect for those people i am still answering questions and taking one off requests this morning i was just hit in the face with how much i dislike actually doing he dsda side a sales senior manager needed something with some data i asked a follow up question i needed a key piece of info to ensure i did the right thing and didnt have to do re work later they said they would get it to me later they emailed it to me at am this morning then messaged me before my shift hey i dont see the data task with the blah blah being done we needed it and i am thinking then why wait until to give me the info we got the request and i asked you on then you waited the weekend to get it to me and those individuals who just keep coming back telling you the data wasnt what they expected or wanted when it is what they asked for im so happy to be just a senior sys engineer again working on large scale infra its not for everyone and i think they need to talk about and teach managing expectations so you dont shoot yourself in the foot luckily the bi team of the new company are phenomenal and now i am out of the game but i am learning more python at home in my spare time and things like jupyter so i dont regress skill wise python is useful in what i do anyway ive rewritten several ps automation scripts in it,data science and data analytics is becoming ultra glorified romanticized and i dont think people are really told what they are getting into i honestly dont think people wanting to break into data science really know what all it entails it just sounds good and sounds like it will make them lots of money no one tells people what comes with the job there are a lot of headaches that come with it and you have to be a very patient person when any person starts out in it they learn some psychology how to manage users and their expectations you learn what to say and what not to say you learn how to appear confident and reassuring even if youre getting up to speed in the moment the good ones do anyway data science bi da you have to have those skills multiplied by ten you have to be better than the rest at managing expectations you have to learn how to avoid support drains and be thinking ahead all of the time the data science people are the only people i respect as much as the people in systems because other fields you learn one thing and only one side of it call yourself an engineer despite knowing one side sys engineers have to know a little about everything and base knowledge in all kinds of things they are constantly growing data science folks are similar because they have to know a wide assortment of things and they have to know all of the tips and tricks at their disposal to get their desired result which means they will know python multiple types of sql pandas jupyter and so on theyll pivot in excel in a pinch if they need to but the main reason i respect them is just because of how patient they have to be to want to work in their field for years our da left in and one of my roles was a senior dba so they just put her job on top of mine i learned a lot and i got very good at sql and streamlining and reducing task turn around for reports and data tasks but i obviously didnt have the time to dive ultra deep into the rabbit hole and i didnt want to because i knew it wasnt for me we were acquired and i transitioned all of that stuff onto the bi team of the new company i have so much respect for those people i am still answering questions and taking one off requests this morning i was just hit in the face with how much i dislike actually doing he dsda side a sales senior manager needed something with some data i asked a follow up question i needed a key piece of info to ensure i did the right thing and didnt have to do re work later they said they would get it to me later they emailed it to me at am this morning then messaged me before my shift hey i dont see the data task with the blah blah being done we needed it and i am thinking then why wait until to give me the info we got the request and i asked you on then you waited the weekend to get it to me and those individuals who just keep coming back telling you the data wasnt what they expected or wanted when it is what they asked for im so happy to be just a senior sys engineer again working on large scale infra its not for everyone and i think they need to talk about and teach managing expectations so you dont shoot yourself in the foot luckily the bi team of the new company are phenomenal and now i am out of the game but i am learning more python at home in my spare time and things like jupyter so i dont regress skill wise python is useful in what i do anyway ive rewritten several ps automation scripts in it,"data, people, one, science, dont",2021-06-07 14:33:48,data science and data analytics is becoming ultra glorified romanticized and i dont think people are really told what they are getting into i honestly dont think people wanting to break into data science really know what all it entails it just sounds good and sounds like it will make them lots of money no one tells people what comes with the job there are a lot of headaches that come with it and you have to be a very patient person when any person starts out in it they learn some psychology how to manage users and their expectations you learn what to say and what not to say you learn how to appear confident and reassuring even if youre getting up to speed in the moment the good ones do anyway data science bi da you have to have those skills multiplied by ten you have to be better than the rest at managing expectations you have to learn how to avoid support drains and be thinking ahead all of the time the data science people are the only people i respect as much as the people in systems because other fields you learn one thing and only one side of it call yourself an engineer despite knowing one side sys engineers have to know a little about everything and base knowledge in all kinds of things they are constantly growing data science folks are similar because they have to know a wide assortment of things and they have to know all of the tips and tricks at their disposal to get their desired result which means they will know python multiple types of sql pandas jupyter and so on theyll pivot in excel in a pinch if they need to but the main reason i respect them is just because of how patient they have to be to want to work in their field for years our da left in and one of my roles was a senior dba so they just put her job on top of mine i learned a lot and i got very good at sql and streamlining and reducing task turn around for reports and data tasks but i obviously didnt have the time to dive ultra deep into the rabbit hole and i didnt want to because i knew it wasnt for me we were acquired and i transitioned all of that stuff onto the bi team of the new company i have so much respect for those people i am still answering questions and taking one off requests this morning i was just hit in the face with how much i dislike actually doing he dsda side a sales senior manager needed something with some data i asked a follow up question i needed a key piece of info to ensure i did the right thing and didnt have to do re work later they said they would get it to me later they emailed it to me at am this morning then messaged me before my shift hey i dont see the data task with the blah blah being done we needed it and i am thinking then why wait until to give me the info we got the request and i asked you on then you waited the weekend to get it to me and those individuals who just keep coming back telling you the data wasnt what they expected or wanted when it is what they asked for im so happy to be just a senior sys engineer again working on large scale infra its not for everyone and i think they need to talk about and teach managing expectations so you dont shoot yourself in the foot luckily the bi team of the new company are phenomenal and now i am out of the game but i am learning more python at home in my spare time and things like jupyter so i dont regress skill wise python is useful in what i do anyway ive rewritten several ps automation scripts in it,"['data', 'science', 'data', 'analytics', 'becoming', 'ultra', 'glorified', 'romanticized', 'dont', 'think', 'people', 'really', 'told', 'getting', 'honestly', 'dont', 'think', 'people', 'wanting', 'break', 'data', 'science', 'really', 'know', 'entail', 'sound', 'good', 'sound', 'like', 'make', 'lot', 'money', 'one', 'tell', 'people', 'come', 'job', 'lot', 'headache', 'come', 'patient', 'person', 'person', 'start', 'learn', 'psychology', 'manage', 'user', 'expectation', 'learn', 'say', 'say', 'learn', 'appear', 'confident', 'reassuring', 'even', 'youre', 'getting', 'speed', 'moment', 'good', 'one', 'anyway', 'data', 'science', 'skill', 'multiplied', 'ten', 'better', 'rest', 'managing', 'expectation', 'learn', 'avoid', 'support', 'drain', 'thinking', 'ahead', 'time', 'data', 'science', 'people', 'people', 'respect', 'much', 'people', 'system', 'field', 'learn', 'one', 'thing', 'one', 'side', 'call', 'engineer', 'despite', 'knowing', 'one', 'side', 'sys', 'engineer', 'know', 'little', 'everything', 'base', 'knowledge', 'kind', 'thing', 'constantly', 'growing', 'data', 'science', 'folk', 'similar', 'know', 'wide', 'assortment', 'thing', 'know', 'tip', 'trick', 'disposal', 'get', 'desired', 'result', 'mean', 'know', 'python', 'multiple', 'type', 'sql', 'panda', 'jupyter', 'theyll', 'pivot', 'excel', 'pinch', 'need', 'main', 'reason', 'respect', 'patient', 'want', 'work', 'field', 'year', 'left', 'one', 'role', 'senior', 'dba', 'put', 'job', 'top', 'mine', 'learned', 'lot', 'got', 'good', 'sql', 'streamlining', 'reducing', 'task', 'turn', 'around', 'report', 'data', 'task', 'obviously', 'didnt', 'time', 'dive', 'ultra', 'deep', 'rabbit', 'hole', 'didnt', 'want', 'knew', 'wasnt', 'acquired', 'transitioned', 'stuff', 'onto', 'team', 'new', 'company', 'much', 'respect', 'people', 'still', 'answering', 'question', 'taking', 'one', 'request', 'morning', 'hit', 'face', 'much', 'dislike', 'actually', 'dsda', 'side', 'sale', 'senior', 'manager', 'needed', 'something', 'data', 'asked', 'follow', 'question', 'needed', 'key', 'piece', 'info', 'ensure', 'right', 'thing', 'didnt', 'work', 'later', 'said', 'would', 'get', 'later', 'emailed', 'morning', 'messaged', 'shift', 'hey', 'dont', 'see', 'data', 'task', 'blah', 'blah', 'done', 'needed', 'thinking', 'wait', 'give', 'info', 'got', 'request', 'asked', 'waited', 'weekend', 'get', 'individual', 'keep', 'coming', 'back', 'telling', 'data', 'wasnt', 'expected', 'wanted', 'asked', 'happy', 'senior', 'sys', 'engineer', 'working', 'large', 'scale', 'infra', 'everyone', 'think', 'need', 'talk', 'teach', 'managing', 'expectation', 'dont', 'shoot', 'foot', 'luckily', 'team', 'new', 'company', 'phenomenal', 'game', 'learning', 'python', 'home', 'spare', 'time', 'thing', 'like', 'jupyter', 'dont', 'regress', 'skill', 'wise', 'python', 'useful', 'anyway', 'ive', 'rewritten', 'several', 'automation', 'script']",,,,
hudog1,Distributed Computing and SQL,,1595213982.0,1069.0,54.0,/r/datascience/comments/hudog1/distributed_computing_and_sql/,https://mamg.makeameme.org/when-you-advertise-2c8984af95.jpg,EvanstonNU,datascience,0.96,False,False,False,False,0.0,1745834714.405732,Tech & Programming,4.0,0.0,4.0,Sunday,22.0,July,2020.0,True,0.0,0.0,0.0,1.0,neutral,distributed computing and sql,,distributed computing and sql ,"distributed, computing, sql",2020-07-20 02:59:42,distributed computing and sql ,"['distributed', 'computing', 'sql']",,,,
gyv6to,Useless tutorials and blog post will NOT improve your CV but WILL waste our time,"I see everywhere an inflation of data science blog posts, Medium posts, Linkedin posts which are adding literally ZERO value to everybody in the field. If you think we need another explanation of why p-values are important, or how to read a CSV file in Pandas, you are wrong and you are wasting your and my time. Walk me through a nasty dataset cleaning process. Show me an end to end project of yours. Enlighten me with that new, weird, just-out-of-the-Academic-press new kind of Neural Network. But showing me how to make a line plot in Matplotlib? Thanks, there are 5000 tutorials out there for that. If you are doing this, and hoping that your reputation will improve as a consequence (and maybe your chances of getting hired) you are doing yourself a terrible service. Stop the noise, do ONE really new and impressive thing and you will have: (1) actually added value and (2) started to make a name for yourself out there. Thanks for watching.",1591603855.0,1059.0,142.0,/r/datascience/comments/gyv6to/useless_tutorials_and_blog_post_will_not_improve/,https://www.reddit.com/r/datascience/comments/gyv6to/useless_tutorials_and_blog_post_will_not_improve/,,datascience,0.94,True,False,False,False,0.0,1745834714.851186,Tech & Programming,15.0,167.0,179.0,Monday,4.0,June,2020.0,False,0.073,0.145,0.148,0.707,positive,useless tutorials and blog post will not improve your cv but will waste our time,i see everywhere an inflation of data science blog posts medium posts linkedin posts which are adding literally zero value to everybody in the field if you think we need another explanation of why pvalues are important or how to read a csv file in pandas you are wrong and you are wasting your and my time walk me through a nasty dataset cleaning process show me an end to end project of yours enlighten me with that new weird justoutoftheacademicpress new kind of neural network but showing me how to make a line plot in matplotlib thanks there are tutorials out there for that if you are doing this and hoping that your reputation will improve as a consequence and maybe your chances of getting hired you are doing yourself a terrible service stop the noise do one really new and impressive thing and you will have actually added value and started to make a name for yourself out there thanks for watching,useless tutorials and blog post will not improve your cv but will waste our time i see everywhere an inflation of data science blog posts medium posts linkedin posts which are adding literally zero value to everybody in the field if you think we need another explanation of why pvalues are important or how to read a csv file in pandas you are wrong and you are wasting your and my time walk me through a nasty dataset cleaning process show me an end to end project of yours enlighten me with that new weird justoutoftheacademicpress new kind of neural network but showing me how to make a line plot in matplotlib thanks there are tutorials out there for that if you are doing this and hoping that your reputation will improve as a consequence and maybe your chances of getting hired you are doing yourself a terrible service stop the noise do one really new and impressive thing and you will have actually added value and started to make a name for yourself out there thanks for watching,"post, new, tutorial, blog, improve",2020-06-08 08:10:55,useless tutorials and blog post will not improve your cv but will waste our time i see everywhere an inflation of data science blog posts medium posts linkedin posts which are adding literally zero value to everybody in the field if you think we need another explanation of why pvalues are important or how to read a csv file in pandas you are wrong and you are wasting your and my time walk me through a nasty dataset cleaning process show me an end to end project of yours enlighten me with that new weird justoutoftheacademicpress new kind of neural network but showing me how to make a line plot in matplotlib thanks there are tutorials out there for that if you are doing this and hoping that your reputation will improve as a consequence and maybe your chances of getting hired you are doing yourself a terrible service stop the noise do one really new and impressive thing and you will have actually added value and started to make a name for yourself out there thanks for watching,"['useless', 'tutorial', 'blog', 'post', 'improve', 'waste', 'time', 'see', 'everywhere', 'inflation', 'data', 'science', 'blog', 'post', 'medium', 'post', 'linkedin', 'post', 'adding', 'literally', 'zero', 'value', 'everybody', 'field', 'think', 'need', 'another', 'explanation', 'pvalues', 'important', 'read', 'csv', 'file', 'panda', 'wrong', 'wasting', 'time', 'walk', 'nasty', 'dataset', 'cleaning', 'process', 'show', 'end', 'end', 'project', 'enlighten', 'new', 'weird', 'justoutoftheacademicpress', 'new', 'kind', 'neural', 'network', 'showing', 'make', 'line', 'plot', 'matplotlib', 'thanks', 'tutorial', 'hoping', 'reputation', 'improve', 'consequence', 'maybe', 'chance', 'getting', 'hired', 'terrible', 'service', 'stop', 'noise', 'one', 'really', 'new', 'impressive', 'thing', 'actually', 'added', 'value', 'started', 'make', 'name', 'thanks', 'watching']",,,,
wz7pfk,Entry level job market illustrated: it really is a numbers game,,1661619422.0,1064.0,191.0,/r/datascience/comments/wz7pfk/entry_level_job_market_illustrated_it_really_is_a/,https://www.reddit.com/gallery/wz7pfk,sc4s2cg,datascience,0.94,False,False,False,False,0.0,1745834715.658513,Tech & Programming,11.0,0.0,11.0,Saturday,12.0,August,2022.0,True,0.0,0.0,0.0,1.0,neutral,entry level job market illustrated it really is a numbers game,,entry level job market illustrated it really is a numbers game ,"entry, level, job, market, illustrated",2022-08-27 16:57:02,entry level job market illustrated it really is a numbers game ,"['entry', 'level', 'job', 'market', 'illustrated', 'really', 'number', 'game']",,,,
1augdle,The BS they tell about Data Science…,"1. In what world does a Director of DS only make $200k, and the VP of Anything only make $210k???

2. In what world does the compensation increase become smaller, the higher the promotion? 

3. They present it as if this is completely achievable just by “following the path”, while in reality it takes a lot of luck and politics to become anything higher than a DS manager, and it happens very rarely. ",1708323275.0,1055.0,340.0,/r/datascience/comments/1augdle/the_bs_they_tell_about_data_science/,https://i.redd.it/3zl80ug6ihjc1.jpeg,zi_ang,datascience,0.94,False,False,False,False,0.0,1745834717.238794,Tech & Programming,7.0,73.0,77.0,Monday,1.0,February,2024.0,False,0.7841,0.103,0.0,0.897,positive,the bs they tell about data science,in what world does a director of ds only make k and the vp of anything only make k in what world does the compensation increase become smaller the higher the promotion they present it as if this is completely achievable just by following the path while in reality it takes a lot of luck and politics to become anything higher than a ds manager and it happens very rarely,the bs they tell about data science in what world does a director of ds only make k and the vp of anything only make k in what world does the compensation increase become smaller the higher the promotion they present it as if this is completely achievable just by following the path while in reality it takes a lot of luck and politics to become anything higher than a ds manager and it happens very rarely,"world, make, anything, become, higher",2024-02-19 06:14:35,the bs they tell about data science in what world does a director of ds only make k and the vp of anything only make k in what world does the compensation increase become smaller the higher the promotion they present it as if this is completely achievable just by following the path while in reality it takes a lot of luck and politics to become anything higher than a ds manager and it happens very rarely,"['tell', 'data', 'science', 'world', 'director', 'make', 'anything', 'make', 'world', 'compensation', 'increase', 'become', 'smaller', 'higher', 'promotion', 'present', 'completely', 'achievable', 'following', 'path', 'reality', 'take', 'lot', 'luck', 'politics', 'become', 'anything', 'higher', 'manager', 'happens', 'rarely']",,,,
ynx8o8,Data Science Hierarchy of Needs ... as relevant as ever,,1667757226.0,1060.0,47.0,/r/datascience/comments/ynx8o8/data_science_hierarchy_of_needs_as_relevant_as/,https://i.redd.it/nz777nsfuey91.jpg,abeassi408,datascience,0.93,False,False,False,False,0.0,1745834718.888655,Tech & Programming,10.0,0.0,9.0,Sunday,12.0,November,2022.0,True,0.0,0.0,0.0,1.0,neutral,data science hierarchy of needs as relevant as ever,,data science hierarchy of needs as relevant as ever ,"data, science, hierarchy, need, relevant",2022-11-06 17:53:46,data science hierarchy of needs as relevant as ever ,"['data', 'science', 'hierarchy', 'need', 'relevant', 'ever']",,,,
vx6kcx,Describe Data Science in Three Words,,1657616044.0,1053.0,270.0,/r/datascience/comments/vx6kcx/describe_data_science_in_three_words/,https://i.redd.it/3r36uflzp3b91.jpg,Duncan_Sarasti,datascience,0.92,False,False,False,False,0.0,1745834719.232394,Tech & Programming,6.0,0.0,6.0,Tuesday,4.0,July,2022.0,False,0.0,0.0,0.0,1.0,neutral,describe data science in three words,,describe data science in three words ,"describe, data, science, three, word",2022-07-12 08:54:04,describe data science in three words ,"['describe', 'data', 'science', 'three', 'word']",,,,
xwv9m3,Is anyone tired of all the BS elitism about “statistical rigor”,"These nerds talk about something like “train/test” splits and “overfitting.” Whatever loser, while you were lost in your textbook I was busy delivering actionable business insights for key stakeholders.

Look loser, I’m glad you paid big money for some fancy degree in statistics or whatever, but while you were up in your Ivory tower learning useless skills like bootstrapping, I was here on the ground working with real data, solving real business cases and delivering value. 

Python? Don’t make me laugh. Excel is all you need. Why spend time on “containerization” and “dependency management” when I can fire up my trusty old XP machine in order to convert Jan’s old workbook into xlsx? 

Plotting? Built into Excel. Aggregation? Built into Excel. Transformer-based natural language embeddings? Not built into Excel, and thus not important. While you were religiously watching Coursera videos, I was learning from Steve Balmer’s every move. That man knew how to deliver business insight using actionable intelligence. 

I’m all about the North Star metrics. I align with the business leaders. I distill all day.

Dweebs on my team keep talking about “controlling for multiple hypotheses” and “effect sizes.”  Is it an Excel function? No? Then forget it, we have real work to do here.",1665027951.0,1049.0,166.0,/r/datascience/comments/xwv9m3/is_anyone_tired_of_all_the_bs_elitism_about/,https://www.reddit.com/r/datascience/comments/xwv9m3/is_anyone_tired_of_all_the_bs_elitism_about/,pic_bot,datascience,0.85,True,False,False,False,0.0,1745834720.770098,Tech & Programming,11.0,206.0,217.0,Wednesday,23.0,October,2022.0,False,0.9789,0.185,0.099,0.716,positive,is anyone tired of all the bs elitism about statistical rigor,these nerds talk about something like traintest splits and overfitting whatever loser while you were lost in your textbook i was busy delivering actionable business insights for key stakeholders look loser im glad you paid big money for some fancy degree in statistics or whatever but while you were up in your ivory tower learning useless skills like bootstrapping i was here on the ground working with real data solving real business cases and delivering value python dont make me laugh excel is all you need why spend time on containerization and dependency management when i can fire up my trusty old xp machine in order to convert jans old workbook into xlsx plotting built into excel aggregation built into excel transformerbased natural language embeddings not built into excel and thus not important while you were religiously watching coursera videos i was learning from steve balmers every move that man knew how to deliver business insight using actionable intelligence im all about the north star metrics i align with the business leaders i distill all day dweebs on my team keep talking about controlling for multiple hypotheses and effect sizes is it an excel function no then forget it we have real work to do here,is anyone tired of all the bs elitism about statistical rigor these nerds talk about something like traintest splits and overfitting whatever loser while you were lost in your textbook i was busy delivering actionable business insights for key stakeholders look loser im glad you paid big money for some fancy degree in statistics or whatever but while you were up in your ivory tower learning useless skills like bootstrapping i was here on the ground working with real data solving real business cases and delivering value python dont make me laugh excel is all you need why spend time on containerization and dependency management when i can fire up my trusty old xp machine in order to convert jans old workbook into xlsx plotting built into excel aggregation built into excel transformerbased natural language embeddings not built into excel and thus not important while you were religiously watching coursera videos i was learning from steve balmers every move that man knew how to deliver business insight using actionable intelligence im all about the north star metrics i align with the business leaders i distill all day dweebs on my team keep talking about controlling for multiple hypotheses and effect sizes is it an excel function no then forget it we have real work to do here,"excel, business, real, built, like",2022-10-06 03:45:51,is anyone tired of all the bs elitism about statistical rigor these nerds talk about something like traintest splits and overfitting whatever loser while you were lost in your textbook i was busy delivering actionable business insights for key stakeholders look loser im glad you paid big money for some fancy degree in statistics or whatever but while you were up in your ivory tower learning useless skills like bootstrapping i was here on the ground working with real data solving real business cases and delivering value python dont make me laugh excel is all you need why spend time on containerization and dependency management when i can fire up my trusty old xp machine in order to convert jans old workbook into xlsx plotting built into excel aggregation built into excel transformerbased natural language embeddings not built into excel and thus not important while you were religiously watching coursera videos i was learning from steve balmers every move that man knew how to deliver business insight using actionable intelligence im all about the north star metrics i align with the business leaders i distill all day dweebs on my team keep talking about controlling for multiple hypotheses and effect sizes is it an excel function no then forget it we have real work to do here,"['anyone', 'tired', 'elitism', 'statistical', 'rigor', 'nerd', 'talk', 'something', 'like', 'traintest', 'split', 'overfitting', 'whatever', 'loser', 'lost', 'textbook', 'busy', 'delivering', 'actionable', 'business', 'insight', 'key', 'stakeholder', 'look', 'loser', 'glad', 'paid', 'big', 'money', 'fancy', 'degree', 'statistic', 'whatever', 'ivory', 'tower', 'learning', 'useless', 'skill', 'like', 'bootstrapping', 'ground', 'working', 'real', 'data', 'solving', 'real', 'business', 'case', 'delivering', 'value', 'python', 'dont', 'make', 'laugh', 'excel', 'need', 'spend', 'time', 'containerization', 'dependency', 'management', 'fire', 'trusty', 'old', 'machine', 'order', 'convert', 'jan', 'old', 'workbook', 'xlsx', 'plotting', 'built', 'excel', 'aggregation', 'built', 'excel', 'transformerbased', 'natural', 'language', 'embeddings', 'built', 'excel', 'thus', 'important', 'religiously', 'watching', 'coursera', 'video', 'learning', 'steve', 'balmers', 'every', 'move', 'man', 'knew', 'deliver', 'business', 'insight', 'using', 'actionable', 'intelligence', 'north', 'star', 'metric', 'align', 'business', 'leader', 'distill', 'day', 'dweeb', 'team', 'keep', 'talking', 'controlling', 'multiple', 'hypothesis', 'effect', 'size', 'excel', 'function', 'forget', 'real', 'work']",,,,
ff81cd,I got a job!!,"After 20+interviews, 3 onsites, tons of heartbreak, feelings of failure, tears, disappointment and support and love from everyone around me I DID IT and I’m going to be a machine learning engineer. 

This subreddit provided me with a wealth of information and I’m so excited to start working. What advice would you give to someone just starting a new job? 

I’ll have to wear many hats, data visualization, machine learning, database development and opportunities to work on C# software development and UI dev too. Thanks for any advice!!",1583644840.0,1037.0,107.0,/r/datascience/comments/ff81cd/i_got_a_job/,https://www.reddit.com/r/datascience/comments/ff81cd/i_got_a_job/,shitinmyunderwear,datascience,0.96,True,False,False,False,1.0,1745834721.503653,Tech & Programming,4.0,88.0,91.0,Sunday,0.0,March,2020.0,True,0.5742,0.175,0.141,0.684,positive,i got a job,after interviews onsites tons of heartbreak feelings of failure tears disappointment and support and love from everyone around me i did it and im going to be a machine learning engineer this subreddit provided me with a wealth of information and im so excited to start working what advice would you give to someone just starting a new job ill have to wear many hats data visualization machine learning database development and opportunities to work on c software development and ui dev too thanks for any advice,i got a job after interviews onsites tons of heartbreak feelings of failure tears disappointment and support and love from everyone around me i did it and im going to be a machine learning engineer this subreddit provided me with a wealth of information and im so excited to start working what advice would you give to someone just starting a new job ill have to wear many hats data visualization machine learning database development and opportunities to work on c software development and ui dev too thanks for any advice,"job, machine, learning, advice, development",2020-03-08 05:20:40,i got a job after interviews onsites tons of heartbreak feelings of failure tears disappointment and support and love from everyone around me i did it and im going to be a machine learning engineer this subreddit provided me with a wealth of information and im so excited to start working what advice would you give to someone just starting a new job ill have to wear many hats data visualization machine learning database development and opportunities to work on c software development and ui dev too thanks for any advice,"['got', 'job', 'interview', 'onsites', 'ton', 'heartbreak', 'feeling', 'failure', 'tear', 'disappointment', 'support', 'love', 'everyone', 'around', 'going', 'machine', 'learning', 'engineer', 'subreddit', 'provided', 'wealth', 'information', 'excited', 'start', 'working', 'advice', 'would', 'give', 'someone', 'starting', 'new', 'job', 'ill', 'wear', 'many', 'hat', 'data', 'visualization', 'machine', 'learning', 'database', 'development', 'opportunity', 'work', 'software', 'development', 'dev', 'thanks', 'advice']",,,,
rgb80b,A piece of advice I wish I gave myself before going into Data Science.," And here it is: you will not have everything, so don’t even try.  


You can’t have a deep understanding of every Data Science field. Either have a shallow knowledge of many disciplines (consultant), or specialize in one or two (specialist). Time is not infinite.  


You can’t do practical Data Science, and discover new methods at the same time. Either you solve existing problems using existing tools, or you spend years developing a new one. Time is not infinite.  


You can’t work on many projects concurrently. You have only so much attention span, and so much free time you use to think about solutions. Again, time is not infinite.",1639499404.0,1037.0,114.0,/r/datascience/comments/rgb80b/a_piece_of_advice_i_wish_i_gave_myself_before/,https://www.reddit.com/r/datascience/comments/rgb80b/a_piece_of_advice_i_wish_i_gave_myself_before/,harsh5161,datascience,0.98,True,False,False,False,0.0,1745834722.111264,Tech & Programming,14.0,108.0,122.0,Tuesday,11.0,December,2021.0,False,0.7251,0.079,0.022,0.899,positive,a piece of advice i wish i gave myself before going into data science,and here it is you will not have everything so dont even try you cant have a deep understanding of every data science field either have a shallow knowledge of many disciplines consultant or specialize in one or two specialist time is not infinite you cant do practical data science and discover new methods at the same time either you solve existing problems using existing tools or you spend years developing a new one time is not infinite you cant work on many projects concurrently you have only so much attention span and so much free time you use to think about solutions again time is not infinite,a piece of advice i wish i gave myself before going into data science and here it is you will not have everything so dont even try you cant have a deep understanding of every data science field either have a shallow knowledge of many disciplines consultant or specialize in one or two specialist time is not infinite you cant do practical data science and discover new methods at the same time either you solve existing problems using existing tools or you spend years developing a new one time is not infinite you cant work on many projects concurrently you have only so much attention span and so much free time you use to think about solutions again time is not infinite,"time, data, science, cant, infinite",2021-12-14 16:30:04,a piece of advice i wish i gave myself before going into data science and here it is you will not have everything so dont even try you cant have a deep understanding of every data science field either have a shallow knowledge of many disciplines consultant or specialize in one or two specialist time is not infinite you cant do practical data science and discover new methods at the same time either you solve existing problems using existing tools or you spend years developing a new one time is not infinite you cant work on many projects concurrently you have only so much attention span and so much free time you use to think about solutions again time is not infinite,"['piece', 'advice', 'wish', 'gave', 'going', 'data', 'science', 'everything', 'dont', 'even', 'try', 'cant', 'deep', 'understanding', 'every', 'data', 'science', 'field', 'either', 'shallow', 'knowledge', 'many', 'discipline', 'consultant', 'specialize', 'one', 'two', 'specialist', 'time', 'infinite', 'cant', 'practical', 'data', 'science', 'discover', 'new', 'method', 'time', 'either', 'solve', 'existing', 'problem', 'using', 'existing', 'tool', 'spend', 'year', 'developing', 'new', 'one', 'time', 'infinite', 'cant', 'work', 'many', 'project', 'concurrently', 'much', 'attention', 'span', 'much', 'free', 'time', 'use', 'think', 'solution', 'time', 'infinite']",,,,
cmit48,Poor little data analysts,,1565047976.0,1037.0,100.0,/r/datascience/comments/cmit48/poor_little_data_analysts/,https://i.redd.it/yuh43yxmtpe31.jpg,da_chosen1,datascience,0.95,False,False,False,False,0.0,1745834722.670837,Tech & Programming,4.0,0.0,4.0,Monday,19.0,August,2019.0,False,-0.4767,0.0,0.508,0.492,negative,poor little data analysts,,poor little data analysts ,"poor, little, data, analyst",2019-08-05 23:32:56,poor little data analysts ,"['poor', 'little', 'data', 'analyst']",,,,
1200b4s,Very simple guys. This is the way to go.,,1679611564.0,1030.0,252.0,/r/datascience/comments/1200b4s/very_simple_guys_this_is_the_way_to_go/,https://i.redd.it/aspuqjwxhkpa1.png,ricky1435,datascience,0.85,False,False,False,False,0.0,1745834723.38108,Tech & Programming,9.0,0.0,9.0,Thursday,18.0,March,2023.0,False,0.0,0.0,0.0,1.0,neutral,very simple guys this is the way to go,,very simple guys this is the way to go ,"simple, guy, way",2023-03-23 22:46:04,very simple guys this is the way to go ,"['simple', 'guy', 'way']",,,,
tqe3y6,Anyone needs EC2 instance?,,1648487369.0,1033.0,47.0,/r/datascience/comments/tqe3y6/anyone_needs_ec2_instance/,https://i.redd.it/4wpc943sp5q81.jpg,karaposu,datascience,0.99,False,False,False,False,0.0,1745834724.696717,Tech & Programming,4.0,0.0,4.0,Monday,13.0,March,2022.0,False,0.0,0.0,0.0,1.0,neutral,anyone needs ec instance,,anyone needs ec instance ,"anyone, need, instance",2022-03-28 17:09:29,anyone needs ec instance ,"['anyone', 'need', 'instance']",,,,
at80o8,Being a recent graduate,,1550780985.0,1027.0,172.0,/r/datascience/comments/at80o8/being_a_recent_graduate/,https://i.redd.it/cjputnyiezh21.jpg,c1nv1n,datascience,0.93,False,False,False,False,0.0,1745834725.035746,Tech & Programming,4.0,0.0,4.0,Thursday,15.0,February,2019.0,False,0.0,0.0,0.0,1.0,neutral,being a recent graduate,,being a recent graduate ,"recent, graduate",2019-02-21 20:29:45,being a recent graduate ,"['recent', 'graduate']",,,,
roufb5,I finally figured out K's nearest neighbors...,They are J and L,1640514551.0,1015.0,36.0,/r/datascience/comments/roufb5/i_finally_figured_out_ks_nearest_neighbors/,https://www.reddit.com/r/datascience/comments/roufb5/i_finally_figured_out_ks_nearest_neighbors/,bhendel,datascience,0.94,True,False,False,False,0.0,1745834725.750419,Tech & Programming,7.0,5.0,12.0,Sunday,5.0,December,2021.0,True,0.0,0.0,0.0,1.0,neutral,i finally figured out ks nearest neighbors,they are j and l,i finally figured out ks nearest neighbors they are j and l,"finally, figured, nearest, neighbor",2021-12-26 10:29:11,i finally figured out ks nearest neighbors they are j and l,"['finally', 'figured', 'nearest', 'neighbor']",,,,
a88ejl,xkcd: Machine Learing,,1545385052.0,1004.0,32.0,/r/datascience/comments/a88ejl/xkcd_machine_learing/,https://i.redd.it/5v5s8apnpl521.png,rohan36,datascience,0.96,False,False,False,False,0.0,1745834725.972168,Tech & Programming,3.0,0.0,3.0,Friday,4.0,December,2018.0,False,0.0,0.0,0.0,1.0,neutral,xkcd machine learing,,xkcd machine learing ,"xkcd, machine, learing",2018-12-21 09:37:32,xkcd machine learing ,"['xkcd', 'machine', 'learing']",,,,
b2q0nd,Map of Data Science,,1552953141.0,1009.0,66.0,/r/datascience/comments/b2q0nd/map_of_data_science/,https://i.redd.it/tnvy8tjhtym21.png,mr_dicaprio,datascience,0.94,False,False,False,False,1.0,1745834726.206622,Tech & Programming,4.0,0.0,4.0,Monday,19.0,March,2019.0,False,0.0,0.0,0.0,1.0,neutral,map of data science,,map of data science ,"map, data, science",2019-03-18 23:52:21,map of data science ,"['map', 'data', 'science']",,,,
wp96s5,Prime example of omitted bovariable bias,,1660593412.0,1005.0,31.0,/r/datascience/comments/wp96s5/prime_example_of_omitted_bovariable_bias/,https://i.redd.it/0dp8ftq9nxh91.jpg,TuxedoFloorca,datascience,1.0,False,False,False,False,0.0,1745834726.551488,Tech & Programming,6.0,0.0,6.0,Monday,15.0,August,2022.0,False,-0.1027,0.0,0.219,0.781,negative,prime example of omitted bovariable bias,,prime example of omitted bovariable bias ,"prime, example, omitted, bovariable, bias",2022-08-15 19:56:52,prime example of omitted bovariable bias ,"['prime', 'example', 'omitted', 'bovariable', 'bias']",,,,
g12zmd,20 Best Libraries for Data Science in R,,1586859476.0,1008.0,80.0,/r/datascience/comments/g12zmd/20_best_libraries_for_data_science_in_r/,https://i.redd.it/36ejeoleers41.jpg,TheInsaneApp,datascience,0.95,False,False,False,False,0.0,1745834726.806393,Tech & Programming,8.0,0.0,7.0,Tuesday,6.0,April,2020.0,False,0.6369,0.457,0.0,0.543,positive,best libraries for data science in r,,best libraries for data science in r ,"best, library, data, science",2020-04-14 10:17:56,best libraries for data science in r ,"['best', 'library', 'data', 'science']",,,,
1avoc19,Linear Regression is underrated,"Hey folks,

Wanted to share a quick story from the trenches of data science. I am not a data scientist but engineer however I've been working on a dynamic pricing project where the client was all in on neural networks to predict product sales and figure out the best prices using overly complicated setup. They tried linear regression once, didn't work magic instantly, so they jumped ship to the neural network, which took them days to train.

I thought, ""Hold on, let's not ditch linear regression just yet."" Gave it another go, dove a bit deeper, and bam - it worked wonders. Not only did it spit out results in seconds (compared to the days of training the neural networks took), but it also gave us clear insights on how different factors were affecting sales. Something the neural network's complexity just couldn't offer as plainly.

Moral of the story? Sometimes the simplest tools are the best for the job. Linear regression, logistic regression, decision trees might seem too basic next to flashy neural networks, but it's quick, effective, and gets straight to the point. Plus, you don't need to wait days to see if you're on the right track.

So, before you go all in on the latest and greatest tech, don't forget to give the classics a shot. Sometimes, they're all you need.

Cheers!

Edit: Because I keep getting lot of comments why this post sounds like linkedin post, gonna explain upfront that I used grammarly to improve my writing (English is not my first language)",1708452432.0,1004.0,201.0,/r/datascience/comments/1avoc19/linear_regression_is_underrated/,https://www.reddit.com/r/datascience/comments/1avoc19/linear_regression_is_underrated/,caksters,datascience,0.96,True,False,False,False,0.0,1745834727.252238,Tech & Programming,4.0,257.0,260.0,Tuesday,13.0,February,2024.0,False,0.9934,0.16,0.0,0.84,positive,linear regression is underrated,hey folks wanted to share a quick story from the trenches of data science i am not a data scientist but engineer however ive been working on a dynamic pricing project where the client was all in on neural networks to predict product sales and figure out the best prices using overly complicated setup they tried linear regression once didnt work magic instantly so they jumped ship to the neural network which took them days to train i thought hold on lets not ditch linear regression just yet gave it another go dove a bit deeper and bam it worked wonders not only did it spit out results in seconds compared to the days of training the neural networks took but it also gave us clear insights on how different factors were affecting sales something the neural networks complexity just couldnt offer as plainly moral of the story sometimes the simplest tools are the best for the job linear regression logistic regression decision trees might seem too basic next to flashy neural networks but its quick effective and gets straight to the point plus you dont need to wait days to see if youre on the right track so before you go all in on the latest and greatest tech dont forget to give the classics a shot sometimes theyre all you need cheers edit because i keep getting lot of comments why this post sounds like linkedin post gonna explain upfront that i used grammarly to improve my writing english is not my first language,linear regression is underrated hey folks wanted to share a quick story from the trenches of data science i am not a data scientist but engineer however ive been working on a dynamic pricing project where the client was all in on neural networks to predict product sales and figure out the best prices using overly complicated setup they tried linear regression once didnt work magic instantly so they jumped ship to the neural network which took them days to train i thought hold on lets not ditch linear regression just yet gave it another go dove a bit deeper and bam it worked wonders not only did it spit out results in seconds compared to the days of training the neural networks took but it also gave us clear insights on how different factors were affecting sales something the neural networks complexity just couldnt offer as plainly moral of the story sometimes the simplest tools are the best for the job linear regression logistic regression decision trees might seem too basic next to flashy neural networks but its quick effective and gets straight to the point plus you dont need to wait days to see if youre on the right track so before you go all in on the latest and greatest tech dont forget to give the classics a shot sometimes theyre all you need cheers edit because i keep getting lot of comments why this post sounds like linkedin post gonna explain upfront that i used grammarly to improve my writing english is not my first language,"regression, neural, network, linear, day",2024-02-20 18:07:12,linear regression is underrated hey folks wanted to share a quick story from the trenches of data science i am not a data scientist but engineer however ive been working on a dynamic pricing project where the client was all in on neural networks to predict product sales and figure out the best prices using overly complicated setup they tried linear regression once didnt work magic instantly so they jumped ship to the neural network which took them days to train i thought hold on lets not ditch linear regression just yet gave it another go dove a bit deeper and bam it worked wonders not only did it spit out results in seconds compared to the days of training the neural networks took but it also gave us clear insights on how different factors were affecting sales something the neural networks complexity just couldnt offer as plainly moral of the story sometimes the simplest tools are the best for the job linear regression logistic regression decision trees might seem too basic next to flashy neural networks but its quick effective and gets straight to the point plus you dont need to wait days to see if youre on the right track so before you go all in on the latest and greatest tech dont forget to give the classics a shot sometimes theyre all you need cheers edit because i keep getting lot of comments why this post sounds like linkedin post gonna explain upfront that i used grammarly to improve my writing english is not my first language,"['linear', 'regression', 'underrated', 'hey', 'folk', 'wanted', 'share', 'quick', 'story', 'trench', 'data', 'science', 'data', 'scientist', 'engineer', 'however', 'ive', 'working', 'dynamic', 'pricing', 'project', 'client', 'neural', 'network', 'predict', 'product', 'sale', 'figure', 'best', 'price', 'using', 'overly', 'complicated', 'setup', 'tried', 'linear', 'regression', 'didnt', 'work', 'magic', 'instantly', 'jumped', 'ship', 'neural', 'network', 'took', 'day', 'train', 'thought', 'hold', 'let', 'ditch', 'linear', 'regression', 'yet', 'gave', 'another', 'dove', 'bit', 'deeper', 'bam', 'worked', 'wonder', 'spit', 'result', 'second', 'compared', 'day', 'training', 'neural', 'network', 'took', 'also', 'gave', 'clear', 'insight', 'different', 'factor', 'affecting', 'sale', 'something', 'neural', 'network', 'complexity', 'couldnt', 'offer', 'plainly', 'moral', 'story', 'sometimes', 'simplest', 'tool', 'best', 'job', 'linear', 'regression', 'logistic', 'regression', 'decision', 'tree', 'might', 'seem', 'basic', 'next', 'flashy', 'neural', 'network', 'quick', 'effective', 'get', 'straight', 'point', 'plus', 'dont', 'need', 'wait', 'day', 'see', 'youre', 'right', 'track', 'latest', 'greatest', 'tech', 'dont', 'forget', 'give', 'classic', 'shot', 'sometimes', 'theyre', 'need', 'cheer', 'edit', 'keep', 'getting', 'lot', 'comment', 'post', 'sound', 'like', 'linkedin', 'post', 'gon', 'explain', 'upfront', 'used', 'grammarly', 'improve', 'writing', 'english', 'first', 'language']",,,,
xd9ewk,Data Science: A Roadmap,,1663080195.0,998.0,67.0,/r/datascience/comments/xd9ewk/data_science_a_roadmap/,https://i.redd.it/olliotmm1nn91.png,save_the_panda_bears,datascience,0.97,False,False,False,False,0.0,1745834728.318506,Tech & Programming,4.0,0.0,4.0,Tuesday,10.0,September,2022.0,False,0.0,0.0,0.0,1.0,neutral,data science a roadmap,,data science a roadmap ,"data, science, roadmap",2022-09-13 14:43:15,data science a roadmap ,"['data', 'science', 'roadmap']",,,,
ra6teb,Wish I could get same performance training and testing datasets in imbalanced dataset,,1638795831.0,997.0,22.0,/r/datascience/comments/ra6teb/wish_i_could_get_same_performance_training_and/,https://i.redd.it/kg7gkvtp7x381.png,harsh5161,datascience,0.98,False,False,False,False,0.0,1745834728.744674,Tech & Programming,13.0,0.0,13.0,Monday,8.0,December,2021.0,False,0.4019,0.197,0.0,0.803,positive,wish i could get same performance training and testing datasets in imbalanced dataset,,wish i could get same performance training and testing datasets in imbalanced dataset ,"wish, could, get, performance, training",2021-12-06 13:03:51,wish i could get same performance training and testing datasets in imbalanced dataset ,"['wish', 'could', 'get', 'performance', 'training', 'testing', 'datasets', 'imbalanced', 'dataset']",,,,
xfnjqa,"“If you torture the data long enough, it will confess to anything”-Ronald H. Coase.",,1663323877.0,988.0,49.0,/r/datascience/comments/xfnjqa/if_you_torture_the_data_long_enough_it_will/,https://www.reddit.com/r/datascience/comments/xfnjqa/if_you_torture_the_data_long_enough_it_will/,SOTP_,datascience,0.98,True,False,False,False,1.0,1745834728.941218,Tech & Programming,14.0,0.0,14.0,Friday,6.0,September,2022.0,False,-0.5994,0.0,0.245,0.755,negative,if you torture the data long enough it will confess to anythingronald h coase,,if you torture the data long enough it will confess to anythingronald h coase ,"torture, data, long, enough, confess",2022-09-16 10:24:37,if you torture the data long enough it will confess to anythingronald h coase ,"['torture', 'data', 'long', 'enough', 'confess', 'anythingronald', 'coase']",,,,
s0kndc,Don't Look Up pierced my soul,,1641823213.0,993.0,43.0,/r/datascience/comments/s0kndc/dont_look_up_pierced_my_soul/,https://i.redd.it/pmmw4fyq9va81.jpg,RB_7,datascience,0.98,False,False,False,False,0.0,1745834729.351777,Tech & Programming,6.0,0.0,6.0,Monday,9.0,January,2022.0,False,0.0,0.0,0.0,1.0,neutral,dont look up pierced my soul,,dont look up pierced my soul ,"dont, look, pierced, soul",2022-01-10 14:00:13,dont look up pierced my soul ,"['dont', 'look', 'pierced', 'soul']",,,,
c7l6fo,Working with huge data be like,,1561937374.0,986.0,22.0,/r/datascience/comments/c7l6fo/working_with_huge_data_be_like/,https://i.redd.it/soxf7dr4wk731.jpg,Mylonite0105,datascience,0.97,False,False,False,False,1.0,1745834729.982243,Tech & Programming,6.0,0.0,6.0,Sunday,19.0,June,2019.0,True,0.5859,0.545,0.0,0.455,positive,working with huge data be like,,working with huge data be like ,"working, huge, data, like",2019-06-30 23:29:34,working with huge data be like ,"['working', 'huge', 'data', 'like']",,,,
fm17ja,"To All ""Data Scientists"" out there, Crowdsourcing COVID-19","Recently there's massive influx of ""teams of data scientists"" looking to crowd source ideas for doing an analysis related task regarding the SARS-COV 2 or COVID-19.

I ask of you, please take into consideration data science is only useful for exploratory analysis at this point. Please take into account that current common tools in ""data science"" are ""bias reinforcers"", not great to predict on fat and long tailed distributions. The algorithms are not objective and there's epidemiologists, virologists (read data scientists) who can do a better job at this than you. Statistical analysis will eat machine learning in this task. Don't pretend to use AI, it won't work.

Don't pretend to crowd source over kaggle, your data is old and stale the moment it comes out unless the outbreak has fully ended for a month in your data. If you have a skill you also need the expertise of people IN THE FIELD OF HEALTHCARE. If your best work is overfitting some algorithm to be a kaggle ""grand master"" then please seriously consider studying decision making under risk and uncertainty and refrain from giving advice.

Machine learning is label (or bias) based, take into account that the labels could be wrong that the cleaning operations are wrong. If you really want to help, look to see if there's teams of doctors or healthcare professionals who need help. Don't create a team of non-subject-matter-expert ""data scientists"". Have people who understand biology.

I know people see this as an opportunity to become famous and build a portfolio and some others see it as an opportunity to help. If you're the type that wants to be famous, trust me you won't. You can't bring a knife (logistic regression) to a tank fight.",1584732960.0,988.0,157.0,/r/datascience/comments/fm17ja/to_all_data_scientists_out_there_crowdsourcing/,https://www.reddit.com/r/datascience/comments/fm17ja/to_all_data_scientists_out_there_crowdsourcing/,hypothesenulle,datascience,0.91,True,False,False,False,1.0,1745834730.160316,Tech & Programming,8.0,289.0,296.0,Friday,15.0,March,2020.0,False,0.9655,0.136,0.07,0.794,positive,to all data scientists out there crowdsourcing covid,recently theres massive influx of teams of data scientists looking to crowd source ideas for doing an analysis related task regarding the sarscov or covid i ask of you please take into consideration data science is only useful for exploratory analysis at this point please take into account that current common tools in data science are bias reinforcers not great to predict on fat and long tailed distributions the algorithms are not objective and theres epidemiologists virologists read data scientists who can do a better job at this than you statistical analysis will eat machine learning in this task dont pretend to use ai it wont work dont pretend to crowd source over kaggle your data is old and stale the moment it comes out unless the outbreak has fully ended for a month in your data if you have a skill you also need the expertise of people in the field of healthcare if your best work is overfitting some algorithm to be a kaggle grand master then please seriously consider studying decision making under risk and uncertainty and refrain from giving advice machine learning is label or bias based take into account that the labels could be wrong that the cleaning operations are wrong if you really want to help look to see if theres teams of doctors or healthcare professionals who need help dont create a team of nonsubjectmatterexpert data scientists have people who understand biology i know people see this as an opportunity to become famous and build a portfolio and some others see it as an opportunity to help if youre the type that wants to be famous trust me you wont you cant bring a knife logistic regression to a tank fight,to all data scientists out there crowdsourcing covid recently theres massive influx of teams of data scientists looking to crowd source ideas for doing an analysis related task regarding the sarscov or covid i ask of you please take into consideration data science is only useful for exploratory analysis at this point please take into account that current common tools in data science are bias reinforcers not great to predict on fat and long tailed distributions the algorithms are not objective and theres epidemiologists virologists read data scientists who can do a better job at this than you statistical analysis will eat machine learning in this task dont pretend to use ai it wont work dont pretend to crowd source over kaggle your data is old and stale the moment it comes out unless the outbreak has fully ended for a month in your data if you have a skill you also need the expertise of people in the field of healthcare if your best work is overfitting some algorithm to be a kaggle grand master then please seriously consider studying decision making under risk and uncertainty and refrain from giving advice machine learning is label or bias based take into account that the labels could be wrong that the cleaning operations are wrong if you really want to help look to see if theres teams of doctors or healthcare professionals who need help dont create a team of nonsubjectmatterexpert data scientists have people who understand biology i know people see this as an opportunity to become famous and build a portfolio and some others see it as an opportunity to help if youre the type that wants to be famous trust me you wont you cant bring a knife logistic regression to a tank fight,"data, scientist, there, team, analysis",2020-03-20 19:36:00,to all data scientists out there crowdsourcing covid recently theres massive influx of teams of data scientists looking to crowd source ideas for doing an analysis related task regarding the sarscov or covid i ask of you please take into consideration data science is only useful for exploratory analysis at this point please take into account that current common tools in data science are bias reinforcers not great to predict on fat and long tailed distributions the algorithms are not objective and theres epidemiologists virologists read data scientists who can do a better job at this than you statistical analysis will eat machine learning in this task dont pretend to use ai it wont work dont pretend to crowd source over kaggle your data is old and stale the moment it comes out unless the outbreak has fully ended for a month in your data if you have a skill you also need the expertise of people in the field of healthcare if your best work is overfitting some algorithm to be a kaggle grand master then please seriously consider studying decision making under risk and uncertainty and refrain from giving advice machine learning is label or bias based take into account that the labels could be wrong that the cleaning operations are wrong if you really want to help look to see if theres teams of doctors or healthcare professionals who need help dont create a team of nonsubjectmatterexpert data scientists have people who understand biology i know people see this as an opportunity to become famous and build a portfolio and some others see it as an opportunity to help if youre the type that wants to be famous trust me you wont you cant bring a knife logistic regression to a tank fight,"['data', 'scientist', 'crowdsourcing', 'covid', 'recently', 'there', 'massive', 'influx', 'team', 'data', 'scientist', 'looking', 'crowd', 'source', 'idea', 'analysis', 'related', 'task', 'regarding', 'sarscov', 'covid', 'ask', 'please', 'take', 'consideration', 'data', 'science', 'useful', 'exploratory', 'analysis', 'point', 'please', 'take', 'account', 'current', 'common', 'tool', 'data', 'science', 'bias', 'reinforcer', 'great', 'predict', 'fat', 'long', 'tailed', 'distribution', 'algorithm', 'objective', 'there', 'epidemiologist', 'virologist', 'read', 'data', 'scientist', 'better', 'job', 'statistical', 'analysis', 'eat', 'machine', 'learning', 'task', 'dont', 'pretend', 'use', 'wont', 'work', 'dont', 'pretend', 'crowd', 'source', 'kaggle', 'data', 'old', 'stale', 'moment', 'come', 'unless', 'outbreak', 'fully', 'ended', 'month', 'data', 'skill', 'also', 'need', 'expertise', 'people', 'field', 'healthcare', 'best', 'work', 'overfitting', 'algorithm', 'kaggle', 'grand', 'master', 'please', 'seriously', 'consider', 'studying', 'decision', 'making', 'risk', 'uncertainty', 'refrain', 'giving', 'advice', 'machine', 'learning', 'label', 'bias', 'based', 'take', 'account', 'label', 'could', 'wrong', 'cleaning', 'operation', 'wrong', 'really', 'want', 'help', 'look', 'see', 'there', 'team', 'doctor', 'healthcare', 'professional', 'need', 'help', 'dont', 'create', 'team', 'nonsubjectmatterexpert', 'data', 'scientist', 'people', 'understand', 'biology', 'know', 'people', 'see', 'opportunity', 'become', 'famous', 'build', 'portfolio', 'others', 'see', 'opportunity', 'help', 'youre', 'type', 'want', 'famous', 'trust', 'wont', 'cant', 'bring', 'knife', 'logistic', 'regression', 'tank', 'fight']",,,,
1g6w4n8,the R vs Python debate is exhausting,"just pick one or learn both for the love of god.

yes, python is excellent for making a production level pipeline. but am I going to tell epidemiologists to drop R for it? nope. they are not making pipelines, they're making automated reports and doing EDA. it's fine. do I tell biostatisticans in pharma to drop R for python? No! These are scientists, they are focusing on a whole lot more than building code. R works fine for them and there are frameworks in R _built specifically for them_.

and would I tell a data engineer to replace python with R? no. good luck running R pipelines in databricks and maintaining its code.

I think this sub underestimates how many people write code for data manipulation, analysis, and report generation that _are not_ and _will not_ build a production level pipelines. 

Data science is a huge umbrella, there is room for both freaking languages.
",1729295396.0,982.0,386.0,/r/datascience/comments/1g6w4n8/the_r_vs_python_debate_is_exhausting/,https://www.reddit.com/r/datascience/comments/1g6w4n8/the_r_vs_python_debate_is_exhausting/,bee_advised,datascience,0.94,True,False,False,False,0.0,1745834731.085075,Tech & Programming,7.0,154.0,161.0,Friday,19.0,October,2024.0,False,0.1901,0.136,0.126,0.738,positive,the r vs python debate is exhausting,just pick one or learn both for the love of god yes python is excellent for making a production level pipeline but am i going to tell epidemiologists to drop r for it nope they are not making pipelines theyre making automated reports and doing eda its fine do i tell biostatisticans in pharma to drop r for python no these are scientists they are focusing on a whole lot more than building code r works fine for them and there are frameworks in r _built specifically for them_ and would i tell a data engineer to replace python with r no good luck running r pipelines in databricks and maintaining its code i think this sub underestimates how many people write code for data manipulation analysis and report generation that _are not_ and _will not_ build a production level pipelines data science is a huge umbrella there is room for both freaking languages,the r vs python debate is exhausting just pick one or learn both for the love of god yes python is excellent for making a production level pipeline but am i going to tell epidemiologists to drop r for it nope they are not making pipelines theyre making automated reports and doing eda its fine do i tell biostatisticans in pharma to drop r for python no these are scientists they are focusing on a whole lot more than building code r works fine for them and there are frameworks in r _built specifically for them_ and would i tell a data engineer to replace python with r no good luck running r pipelines in databricks and maintaining its code i think this sub underestimates how many people write code for data manipulation analysis and report generation that _are not_ and _will not_ build a production level pipelines data science is a huge umbrella there is room for both freaking languages,"python, pipeline, making, tell, code",2024-10-18 23:49:56,the r vs python debate is exhausting just pick one or learn both for the love of god yes python is excellent for making a production level pipeline but am i going to tell epidemiologists to drop r for it nope they are not making pipelines theyre making automated reports and doing eda its fine do i tell biostatisticans in pharma to drop r for python no these are scientists they are focusing on a whole lot more than building code r works fine for them and there are frameworks in r _built specifically for them_ and would i tell a data engineer to replace python with r no good luck running r pipelines in databricks and maintaining its code i think this sub underestimates how many people write code for data manipulation analysis and report generation that _are not_ and _will not_ build a production level pipelines data science is a huge umbrella there is room for both freaking languages,"['python', 'debate', 'exhausting', 'pick', 'one', 'learn', 'love', 'god', 'yes', 'python', 'excellent', 'making', 'production', 'level', 'pipeline', 'going', 'tell', 'epidemiologist', 'drop', 'nope', 'making', 'pipeline', 'theyre', 'making', 'automated', 'report', 'eda', 'fine', 'tell', 'biostatisticans', 'pharma', 'drop', 'python', 'scientist', 'focusing', 'whole', 'lot', 'building', 'code', 'work', 'fine', 'framework', '_built', 'specifically', 'them_', 'would', 'tell', 'data', 'engineer', 'replace', 'python', 'good', 'luck', 'running', 'pipeline', 'databricks', 'maintaining', 'code', 'think', 'sub', 'underestimate', 'many', 'people', 'write', 'code', 'data', 'manipulation', 'analysis', 'report', 'generation', '_are', 'not_', '_will', 'not_', 'build', 'production', 'level', 'pipeline', 'data', 'science', 'huge', 'umbrella', 'room', 'freaking', 'language']",,,,
lkn4rl,Please STOP asking Data Scientists about Leetcode questions meant for Software Engineers for job interviews,"I've been working as a Data Scientist long enough to say that asking Leetcode questions for Data Scientists is completely disrespectful. This is both for both product and ML-based data scientists.

Something simple is fine, like hashmaps, two pointers, strings, some light algorithms etc. But graph theories, DFS with trees/dynamic programming has nothing to do with data analytics, ML fundamentals, statistical foundations, and data storytelling competence.

I really don't understand. When you have a wealth of ways to distinguish competent Data Scientists from juniors during interview pipeline (complicated SQL, pandas, data munging, visualization, ML training, building simulation code, etc.), why you'd rather choose questions like ""how many moves do you need to get a Queen chess piece from this position to another on a chessboard"" as a way of measuring how well a Data Scientist would perform analytics or ML training on the job. It really just feels like SWEs making fun of Data Scientists about how poor programmers we are.

Most companies don't pull crap like this, but for those who do, PLEASE STOP. Unless we received a BA or MA in computer science -- which majority if not most of us did not -- we won't be able to solve shit like this unless we cheat and look at answers directly on leetcode or geekforgeeks. And it's infuriating and embarrassing for us to sink to this kind of level to solve questions that aren't meant for us. I get that Data people need to know programming, but WE AREN'T SWEs, and DS is not SWE.

**Edit**: I'm getting a lot of replies saying that I suck at programming and I need to learn SWE fundamentals. I said over and over that I'm not against understanding foundations of SWE (hashmaps, runtime, pointers, optimized solutions vs brute force). These are important. But when you get into highly niched algorithm named after somebody where you need to do some complicated tricks or build a whole system that requires multiple functions, DFS-based dynamic programming, multiple inheritance methods all in 45 minutes that would unnerve even seasoned SWEs out of practice, that's when it becomes totally unreasonable, outside the realm of data science, and just disrespectful to what Data Scientists do on a daily basis. But that's the line I draw, and the overall question is: at what point do interview questions become unjustifiable and unrelated to the position at hand? I've spent years using pandas, scikit-learn, tableau, and complicated SQL for daily data tasks. Why is it that you can't test me on this stuff which occurs on day-to-day basis for majority of data scientists?

**Edit Edit:** Btw, shame on those of you just downvoting everything I'm saying without reading any of it (I can't even locate my own comments anymore). It's immature and completely ridiculous. I know it's the internet, but have some decency and respect for your interlocutors. You guys are all professionals right?",1613423073.0,979.0,324.0,/r/datascience/comments/lkn4rl/please_stop_asking_data_scientists_about_leetcode/,https://www.reddit.com/r/datascience/comments/lkn4rl/please_stop_asking_data_scientists_about_leetcode/,,datascience,0.91,True,False,False,False,1.0,1745834733.13229,Tech & Programming,15.0,484.0,496.0,Monday,16.0,February,2021.0,False,0.9612,0.114,0.071,0.815,positive,please stop asking data scientists about leetcode questions meant for software engineers for job interviews,ive been working as a data scientist long enough to say that asking leetcode questions for data scientists is completely disrespectful this is both for both product and mlbased data scientists something simple is fine like hashmaps two pointers strings some light algorithms etc but graph theories dfs with treesdynamic programming has nothing to do with data analytics ml fundamentals statistical foundations and data storytelling competence i really dont understand when you have a wealth of ways to distinguish competent data scientists from juniors during interview pipeline complicated sql pandas data munging visualization ml training building simulation code etc why youd rather choose questions like how many moves do you need to get a queen chess piece from this position to another on a chessboard as a way of measuring how well a data scientist would perform analytics or ml training on the job it really just feels like swes making fun of data scientists about how poor programmers we are most companies dont pull crap like this but for those who do please stop unless we received a ba or ma in computer science which majority if not most of us did not we wont be able to solve shit like this unless we cheat and look at answers directly on leetcode or geekforgeeks and its infuriating and embarrassing for us to sink to this kind of level to solve questions that arent meant for us i get that data people need to know programming but we arent swes and ds is not swe edit im getting a lot of replies saying that i suck at programming and i need to learn swe fundamentals i said over and over that im not against understanding foundations of swe hashmaps runtime pointers optimized solutions vs brute force these are important but when you get into highly niched algorithm named after somebody where you need to do some complicated tricks or build a whole system that requires multiple functions dfsbased dynamic programming multiple inheritance methods all in minutes that would unnerve even seasoned swes out of practice thats when it becomes totally unreasonable outside the realm of data science and just disrespectful to what data scientists do on a daily basis but thats the line i draw and the overall question is at what point do interview questions become unjustifiable and unrelated to the position at hand ive spent years using pandas scikitlearn tableau and complicated sql for daily data tasks why is it that you cant test me on this stuff which occurs on daytoday basis for majority of data scientists edit edit btw shame on those of you just downvoting everything im saying without reading any of it i cant even locate my own comments anymore its immature and completely ridiculous i know its the internet but have some decency and respect for your interlocutors you guys are all professionals right,please stop asking data scientists about leetcode questions meant for software engineers for job interviews ive been working as a data scientist long enough to say that asking leetcode questions for data scientists is completely disrespectful this is both for both product and mlbased data scientists something simple is fine like hashmaps two pointers strings some light algorithms etc but graph theories dfs with treesdynamic programming has nothing to do with data analytics ml fundamentals statistical foundations and data storytelling competence i really dont understand when you have a wealth of ways to distinguish competent data scientists from juniors during interview pipeline complicated sql pandas data munging visualization ml training building simulation code etc why youd rather choose questions like how many moves do you need to get a queen chess piece from this position to another on a chessboard as a way of measuring how well a data scientist would perform analytics or ml training on the job it really just feels like swes making fun of data scientists about how poor programmers we are most companies dont pull crap like this but for those who do please stop unless we received a ba or ma in computer science which majority if not most of us did not we wont be able to solve shit like this unless we cheat and look at answers directly on leetcode or geekforgeeks and its infuriating and embarrassing for us to sink to this kind of level to solve questions that arent meant for us i get that data people need to know programming but we arent swes and ds is not swe edit im getting a lot of replies saying that i suck at programming and i need to learn swe fundamentals i said over and over that im not against understanding foundations of swe hashmaps runtime pointers optimized solutions vs brute force these are important but when you get into highly niched algorithm named after somebody where you need to do some complicated tricks or build a whole system that requires multiple functions dfsbased dynamic programming multiple inheritance methods all in minutes that would unnerve even seasoned swes out of practice thats when it becomes totally unreasonable outside the realm of data science and just disrespectful to what data scientists do on a daily basis but thats the line i draw and the overall question is at what point do interview questions become unjustifiable and unrelated to the position at hand ive spent years using pandas scikitlearn tableau and complicated sql for daily data tasks why is it that you cant test me on this stuff which occurs on daytoday basis for majority of data scientists edit edit btw shame on those of you just downvoting everything im saying without reading any of it i cant even locate my own comments anymore its immature and completely ridiculous i know its the internet but have some decency and respect for your interlocutors you guys are all professionals right,"data, scientist, question, like, programming",2021-02-15 21:04:33,please stop asking data scientists about leetcode questions meant for software engineers for job interviews ive been working as a data scientist long enough to say that asking leetcode questions for data scientists is completely disrespectful this is both for both product and mlbased data scientists something simple is fine like hashmaps two pointers strings some light algorithms etc but graph theories dfs with treesdynamic programming has nothing to do with data analytics ml fundamentals statistical foundations and data storytelling competence i really dont understand when you have a wealth of ways to distinguish competent data scientists from juniors during interview pipeline complicated sql pandas data munging visualization ml training building simulation code etc why youd rather choose questions like how many moves do you need to get a queen chess piece from this position to another on a chessboard as a way of measuring how well a data scientist would perform analytics or ml training on the job it really just feels like swes making fun of data scientists about how poor programmers we are most companies dont pull crap like this but for those who do please stop unless we received a ba or ma in computer science which majority if not most of us did not we wont be able to solve shit like this unless we cheat and look at answers directly on leetcode or geekforgeeks and its infuriating and embarrassing for us to sink to this kind of level to solve questions that arent meant for us i get that data people need to know programming but we arent swes and ds is not swe edit im getting a lot of replies saying that i suck at programming and i need to learn swe fundamentals i said over and over that im not against understanding foundations of swe hashmaps runtime pointers optimized solutions vs brute force these are important but when you get into highly niched algorithm named after somebody where you need to do some complicated tricks or build a whole system that requires multiple functions dfsbased dynamic programming multiple inheritance methods all in minutes that would unnerve even seasoned swes out of practice thats when it becomes totally unreasonable outside the realm of data science and just disrespectful to what data scientists do on a daily basis but thats the line i draw and the overall question is at what point do interview questions become unjustifiable and unrelated to the position at hand ive spent years using pandas scikitlearn tableau and complicated sql for daily data tasks why is it that you cant test me on this stuff which occurs on daytoday basis for majority of data scientists edit edit btw shame on those of you just downvoting everything im saying without reading any of it i cant even locate my own comments anymore its immature and completely ridiculous i know its the internet but have some decency and respect for your interlocutors you guys are all professionals right,"['please', 'stop', 'asking', 'data', 'scientist', 'leetcode', 'question', 'meant', 'software', 'engineer', 'job', 'interview', 'ive', 'working', 'data', 'scientist', 'long', 'enough', 'say', 'asking', 'leetcode', 'question', 'data', 'scientist', 'completely', 'disrespectful', 'product', 'mlbased', 'data', 'scientist', 'something', 'simple', 'fine', 'like', 'hashmaps', 'two', 'pointer', 'string', 'light', 'algorithm', 'etc', 'graph', 'theory', 'dfs', 'treesdynamic', 'programming', 'nothing', 'data', 'analytics', 'fundamental', 'statistical', 'foundation', 'data', 'storytelling', 'competence', 'really', 'dont', 'understand', 'wealth', 'way', 'distinguish', 'competent', 'data', 'scientist', 'junior', 'interview', 'pipeline', 'complicated', 'sql', 'panda', 'data', 'munging', 'visualization', 'training', 'building', 'simulation', 'code', 'etc', 'youd', 'rather', 'choose', 'question', 'like', 'many', 'move', 'need', 'get', 'queen', 'chess', 'piece', 'position', 'another', 'chessboard', 'way', 'measuring', 'well', 'data', 'scientist', 'would', 'perform', 'analytics', 'training', 'job', 'really', 'feel', 'like', 'swes', 'making', 'fun', 'data', 'scientist', 'poor', 'programmer', 'company', 'dont', 'pull', 'crap', 'like', 'please', 'stop', 'unless', 'received', 'computer', 'science', 'majority', 'wont', 'able', 'solve', 'shit', 'like', 'unless', 'cheat', 'look', 'answer', 'directly', 'leetcode', 'geekforgeeks', 'infuriating', 'embarrassing', 'sink', 'kind', 'level', 'solve', 'question', 'arent', 'meant', 'get', 'data', 'people', 'need', 'know', 'programming', 'arent', 'swes', 'swe', 'edit', 'getting', 'lot', 'reply', 'saying', 'suck', 'programming', 'need', 'learn', 'swe', 'fundamental', 'said', 'understanding', 'foundation', 'swe', 'hashmaps', 'runtime', 'pointer', 'optimized', 'solution', 'brute', 'force', 'important', 'get', 'highly', 'niched', 'algorithm', 'named', 'somebody', 'need', 'complicated', 'trick', 'build', 'whole', 'system', 'requires', 'multiple', 'function', 'dfsbased', 'dynamic', 'programming', 'multiple', 'inheritance', 'method', 'minute', 'would', 'unnerve', 'even', 'seasoned', 'swes', 'practice', 'thats', 'becomes', 'totally', 'unreasonable', 'outside', 'realm', 'data', 'science', 'disrespectful', 'data', 'scientist', 'daily', 'basis', 'thats', 'line', 'draw', 'overall', 'question', 'point', 'interview', 'question', 'become', 'unjustifiable', 'unrelated', 'position', 'hand', 'ive', 'spent', 'year', 'using', 'panda', 'scikitlearn', 'tableau', 'complicated', 'sql', 'daily', 'data', 'task', 'cant', 'test', 'stuff', 'occurs', 'daytoday', 'basis', 'majority', 'data', 'scientist', 'edit', 'edit', 'btw', 'shame', 'downvoting', 'everything', 'saying', 'without', 'reading', 'cant', 'even', 'locate', 'comment', 'anymore', 'immature', 'completely', 'ridiculous', 'know', 'internet', 'decency', 'respect', 'interlocutor', 'guy', 'professional', 'right']",,,,
npurud,I’m so sick of corporate morons,"[RANT]

Hey gang, stand back, it’s rant time. 

Analytics is a new field at my work, and I’m here to pioneer it. I work In corporate at a large medical devices company. 

I’ve had the luxury of an amazing boss, some amazing colleagues, and decent budget. 

But for the love of fucking god... I am so sick of being thrown responsibility or projects because good ol mary in sales watched a video on “gesture recognition”. The ideas are a great, and I have a framework for filtering them, but the fucking pressure, the initiation of projects with 0 data, no aim at data collection, no quality assurance or risk management and the icing on the cake, “we should roll out an MVP in 2 months”. What in gods name is that shit? 

I’m the asshole. I’m always the asshole. 
“Here are my requirements if we wish to complete this project in the given time frame.” 
“So... why can’t you develop it now?”
Bro... for starters, I’m not a full fledged software engineer / deep learning god. 

I ask for resources or a relaxed time, and I get 0. 


I don’t need advice. I know what I need to do. I just love this community and felt the need to rant.",1622556223.0,974.0,240.0,/r/datascience/comments/npurud/im_so_sick_of_corporate_morons/,https://www.reddit.com/r/datascience/comments/npurud/im_so_sick_of_corporate_morons/,,datascience,0.97,True,False,False,False,0.0,1745834734.88875,Tech & Programming,6.0,210.0,212.0,Tuesday,10.0,June,2021.0,False,0.946,0.173,0.128,0.699,positive,im so sick of corporate morons,rant hey gang stand back its rant time analytics is a new field at my work and im here to pioneer it i work in corporate at a large medical devices company ive had the luxury of an amazing boss some amazing colleagues and decent budget but for the love of fucking god i am so sick of being thrown responsibility or projects because good ol mary in sales watched a video on gesture recognition the ideas are a great and i have a framework for filtering them but the fucking pressure the initiation of projects with data no aim at data collection no quality assurance or risk management and the icing on the cake we should roll out an mvp in months what in gods name is that shit im the asshole im always the asshole here are my requirements if we wish to complete this project in the given time frame so why cant you develop it now bro for starters im not a full fledged software engineer deep learning god i ask for resources or a relaxed time and i get i dont need advice i know what i need to do i just love this community and felt the need to rant,im so sick of corporate morons rant hey gang stand back its rant time analytics is a new field at my work and im here to pioneer it i work in corporate at a large medical devices company ive had the luxury of an amazing boss some amazing colleagues and decent budget but for the love of fucking god i am so sick of being thrown responsibility or projects because good ol mary in sales watched a video on gesture recognition the ideas are a great and i have a framework for filtering them but the fucking pressure the initiation of projects with data no aim at data collection no quality assurance or risk management and the icing on the cake we should roll out an mvp in months what in gods name is that shit im the asshole im always the asshole here are my requirements if we wish to complete this project in the given time frame so why cant you develop it now bro for starters im not a full fledged software engineer deep learning god i ask for resources or a relaxed time and i get i dont need advice i know what i need to do i just love this community and felt the need to rant,"rant, time, god, project, need",2021-06-01 14:03:43,im so sick of corporate morons rant hey gang stand back its rant time analytics is a new field at my work and im here to pioneer it i work in corporate at a large medical devices company ive had the luxury of an amazing boss some amazing colleagues and decent budget but for the love of fucking god i am so sick of being thrown responsibility or projects because good ol mary in sales watched a video on gesture recognition the ideas are a great and i have a framework for filtering them but the fucking pressure the initiation of projects with data no aim at data collection no quality assurance or risk management and the icing on the cake we should roll out an mvp in months what in gods name is that shit im the asshole im always the asshole here are my requirements if we wish to complete this project in the given time frame so why cant you develop it now bro for starters im not a full fledged software engineer deep learning god i ask for resources or a relaxed time and i get i dont need advice i know what i need to do i just love this community and felt the need to rant,"['sick', 'corporate', 'moron', 'rant', 'hey', 'gang', 'stand', 'back', 'rant', 'time', 'analytics', 'new', 'field', 'work', 'pioneer', 'work', 'corporate', 'large', 'medical', 'device', 'company', 'ive', 'luxury', 'amazing', 'bos', 'amazing', 'colleague', 'decent', 'budget', 'love', 'fucking', 'god', 'sick', 'thrown', 'responsibility', 'project', 'good', 'mary', 'sale', 'watched', 'video', 'gesture', 'recognition', 'idea', 'great', 'framework', 'filtering', 'fucking', 'pressure', 'initiation', 'project', 'data', 'aim', 'data', 'collection', 'quality', 'assurance', 'risk', 'management', 'icing', 'cake', 'roll', 'mvp', 'month', 'god', 'name', 'shit', 'asshole', 'always', 'asshole', 'requirement', 'wish', 'complete', 'project', 'given', 'time', 'frame', 'cant', 'develop', 'bro', 'starter', 'full', 'fledged', 'software', 'engineer', 'deep', 'learning', 'god', 'ask', 'resource', 'relaxed', 'time', 'get', 'dont', 'need', 'advice', 'know', 'need', 'love', 'community', 'felt', 'need', 'rant']",,,,
uiuqwp,"""Type I and Type Ii Errors"" are the worst terms in statistics","Just saw some guy rant about DS candidates not know what ""Type I and Type Ii Errors"" are and I have to admit that I was, like -- wait, which one's which again?

I never use the terms, because I hate them. They are just the perfect example of how Statistics were developed by people with *terrible* communication skills.

The official definition of a Type I error is: ""The mistaken rejection of an actually true null hypothesis.""

So, you are wrong that you are wrong that your hypothesis is wrong, when, actually, its true that it is not true.

It's, like, the result of a contest on who can make a simple concept as confusing as possible that ended with someone excitedly saying: ""Wait, wait, wait! Don't call it a false positive -- just call it 'Type I'. That'll *really* screw 'em up!""

Stats guys, why are you like this.",1651747721.0,983.0,182.0,/r/datascience/comments/uiuqwp/type_i_and_type_ii_errors_are_the_worst_terms_in/,https://www.reddit.com/r/datascience/comments/uiuqwp/type_i_and_type_ii_errors_are_the_worst_terms_in/,takenorinvalid,datascience,0.96,True,False,False,False,0.0,1745834736.659888,Tech & Programming,12.0,150.0,160.0,Thursday,6.0,May,2022.0,False,-0.9039,0.147,0.21,0.643,negative,type i and type ii errors are the worst terms in statistics,just saw some guy rant about ds candidates not know what type i and type ii errors are and i have to admit that i was like wait which ones which again i never use the terms because i hate them they are just the perfect example of how statistics were developed by people with terrible communication skills the official definition of a type i error is the mistaken rejection of an actually true null hypothesis so you are wrong that you are wrong that your hypothesis is wrong when actually its true that it is not true its like the result of a contest on who can make a simple concept as confusing as possible that ended with someone excitedly saying wait wait wait dont call it a false positive just call it type i thatll really screw em up stats guys why are you like this,type i and type ii errors are the worst terms in statistics just saw some guy rant about ds candidates not know what type i and type ii errors are and i have to admit that i was like wait which ones which again i never use the terms because i hate them they are just the perfect example of how statistics were developed by people with terrible communication skills the official definition of a type i error is the mistaken rejection of an actually true null hypothesis so you are wrong that you are wrong that your hypothesis is wrong when actually its true that it is not true its like the result of a contest on who can make a simple concept as confusing as possible that ended with someone excitedly saying wait wait wait dont call it a false positive just call it type i thatll really screw em up stats guys why are you like this,"type, wait, error, like, true",2022-05-05 10:48:41,type i and type ii errors are the worst terms in statistics just saw some guy rant about ds candidates not know what type i and type ii errors are and i have to admit that i was like wait which ones which again i never use the terms because i hate them they are just the perfect example of how statistics were developed by people with terrible communication skills the official definition of a type i error is the mistaken rejection of an actually true null hypothesis so you are wrong that you are wrong that your hypothesis is wrong when actually its true that it is not true its like the result of a contest on who can make a simple concept as confusing as possible that ended with someone excitedly saying wait wait wait dont call it a false positive just call it type i thatll really screw em up stats guys why are you like this,"['type', 'type', 'error', 'worst', 'term', 'statistic', 'saw', 'guy', 'rant', 'candidate', 'know', 'type', 'type', 'error', 'admit', 'like', 'wait', 'one', 'never', 'use', 'term', 'hate', 'perfect', 'example', 'statistic', 'developed', 'people', 'terrible', 'communication', 'skill', 'official', 'definition', 'type', 'error', 'mistaken', 'rejection', 'actually', 'true', 'null', 'hypothesis', 'wrong', 'wrong', 'hypothesis', 'wrong', 'actually', 'true', 'true', 'like', 'result', 'contest', 'make', 'simple', 'concept', 'confusing', 'possible', 'ended', 'someone', 'excitedly', 'saying', 'wait', 'wait', 'wait', 'dont', 'call', 'false', 'positive', 'call', 'type', 'thatll', 'really', 'screw', 'stats', 'guy', 'like']",,,,
bbprie,Everyone's reaction when I tell them what I do...,,1554922161.0,974.0,84.0,/r/datascience/comments/bbprie/everyones_reaction_when_i_tell_them_what_i_do/,https://i.redd.it/g3f6dm1eghr21.jpg,theyklledkenny,datascience,0.96,False,False,False,False,0.0,1745834737.890033,Tech & Programming,9.0,0.0,9.0,Wednesday,14.0,April,2019.0,False,0.0,0.0,0.0,1.0,neutral,everyones reaction when i tell them what i do,,everyones reaction when i tell them what i do ,"everyones, reaction, tell",2019-04-10 18:49:21,everyones reaction when i tell them what i do ,"['everyones', 'reaction', 'tell']",,,,
ael5rz,Don't be this guy. (x-post from r/programmerhumor),,1547140894.0,974.0,78.0,/r/datascience/comments/ael5rz/dont_be_this_guy_xpost_from_rprogrammerhumor/,https://i.redd.it/ptvi5zyx1l921.jpg,,datascience,0.98,False,False,False,False,0.0,1745834738.402724,Tech & Programming,7.0,0.0,7.0,Thursday,12.0,January,2019.0,False,0.0,0.0,0.0,1.0,neutral,dont be this guy xpost from rprogrammerhumor,,dont be this guy xpost from rprogrammerhumor ,"dont, guy, xpost, rprogrammerhumor",2019-01-10 17:21:34,dont be this guy xpost from rprogrammerhumor ,"['dont', 'guy', 'xpost', 'rprogrammerhumor']",,,,
k7iytr,Landing a Senior Data Scientist Job After 6 Months of Unemployment,"I graduated this year with a masters of statistics. In this article, I will explain the process that ultimately led to my offer for a **Senior Data Scientist ** position for a company in the SF Bay Area. The components of the process that led to my success, in no particular order, were: crafting my resume and LinkedIn, building skills and projects, staying motivated (during the pandemic), decoding the data science interview process, and determining my professional goals.

(**EDIT // Important Note: this is not big N or FAANG, since in the comments people are using top top companies to benchmark my experience**)

## Preface 

As with any statistical inference, a singleton dataset won't yield robustness. I was an unusual applicant to my grad program, and am an unorthodox candidate for DS roles, which is why it took me six months to find a job while my peers all had several offers immediately following graduation (and some months in advance!). I worked for 6 years between my undergrad and masters in the nonprofit world and had many different job titles, as noted in Edit #2 below. Coming back to school was a huge pivot and career shift, and so I am extremely fortunate to have found a firm who recognized the unique strengths I bring to the table; I was also extremely fortunate to interact with this firm at the right time where my unique strength combination was part of their strategic plan. 

**Takeaway:** My experience is not a modal experience, but the tools I used and the lessons I learned may be useful for others. I would have appreciated reading it two years ago, so I'm putting it here in case others relate. Also a friendly reminders to aspiring or current data scientists not to conflate [prior and posterior probabilities](https://www.investopedia.com/terms/p/posterior-probability.asp).

## Crafting My Resume and LinkedIn

I completely botched my first DS resume. I borrowed a classmate's resume and used it as a template, and tried to copy what they had done. But they had internships, relevant projects, and a better GPA than me, so my version looked... weird, since I didn't have any of those things. Also, I was still expecting people to ""read between the lines"" on my resume instead of being as clear as possible. I started applying and connecting with folks, and what I am shocked by is that **not one person I asked about my resume gave substantial or useful feedback**. The one useful piece of feedback that I received was from my parents, who remarked ""this doesn't seem to really sell you; you're much better in person than on this paper."" While initially, I was resistant to rehauling my resume, I decided to spend a full week almost full time rehauling my resume. This paid off, because I saw a significant uptick in responses and was able to get several first round interviews. The main changes I made:

- Only put what is relevant to the role you are applying for. Even though I had some impressive accomplishments from other projects or roles, I chose the projects or skills that were relevant to data science. 
- Similar to the [first rule of road-side beet sales](https://i.pinimg.com/originals/19/3d/b6/193db68d6c65ce5881edcbd84c1e436c.jpg), I put my best features in the top half of my resume. 
- I used Canva to make a visually appealing resume, and later switched to a LaTeX resume template to make my resume more professional looking. This was a very very good decision, and I got so much positive feedback from recruiters and hiring managers after making that change. 
- I used a LaTeX cover letter template to write cover letters, which made it look very official and professional. It was easier to produce because I could just make a new document in overleaf and change small portions in the letter, since it's mostly common across applications, and once you do enough you have even domain specific and role specific letters ready to go.

**Takeaway:** your image matters a lot. Make sure to craft it carefully, and tailor it for roles that you are really interested in. 

## Building Skills and Projects

My strategy for learning something is spend at least a week or two finding the best resource, then pay whatever it costs (in your budget) and use it 100%. Don't find 16 free cheat sheets and ""shortcuts"". I researched every resource I could find (many thanks to r/datascience, r/machinelearning, and r/cscareersquestions) and I tried out a few, but saw that many only give free temporary access to some subsection of the entire platform, so you can't really explore past the first few questions or modules. However, I saw a reddit post talking about some site called [DataCamp](https://learn.datacamp.com/) where they gave you 7 days for free, but it was full access. I looked through the catalogue and found a lot of what I wanted to learn. I took a week and devoted 8 hours per day to going through the modules. There are some things I would change, but for the most part, it is very well designed, and extremely helpful. I earned somewhere around 20K ""experience"" on the platform, which means I finished \~100-200 exercises from data engineering, modeling, or reviewing OOP in Python. Then at the end of the free trial, they emailed me a 62% coupon for a year's subscription, which brought it down to an insanely reasonable number, like between 100-150 bucks? Easy decision, since I had already mapped my curriculum through the rest of their materials, and they have new courses coming out every 1-2 weeks. 

For textbooks, anything from O'Reily with an animal on the front is probably going to be a good resource. I burned through about a half dozen of those books, taking notes and building the example projects, then moving to DataCamp to do similar projects, then once I felt confident, I would find a dataset from Kaggle or the UCI ML repo and try to carry out the steps, then benchmark my findings with some medium article where someone did the same thing. **Try to keep projects at the center of your learning, then find materials that will add to the project.** This is much more transferrable to a job, and learning to think in this way will help you in interviews. 

I saw an instagram account I follow put out a survey and was getting a lot of responses, but the way they were reporting the data was not able to do full justice to the story they were trying to tell. So I reached out and asked if I could take a look, and they were super excited to have someone with experience weigh in. So I ended up getting a few different spreadsheets, some with categorical and quantitative data and some categorical, while one of the responses was meant for a massively long response (Some users inputted over 1000 words). Do you see where this is going? It's basically a playground where my boss has 0 expectations and all I have to do is improve on autogenerated excel charts. I began cleaning the data in a notebook, then built a set of scripts, then loaded a database, then made a dashboard for the team (using a python flask app), and scheduled cron jobs to extract the data and report results to the ceo/founder of this nonprofit. Every new DataCamp module I completed was one more secret to the puzzle of how to present and improve the data visuals, process, and my code. I got invited to meetings with the other leaders, asked about business decisions, and got to be part of the real life cycle of their mission. 

Now that I had a taste of what that looked like, I reached out to my gym; they keep all of their members data on lifting progress and workout goals in an app, and I was able to give them a fun graphic and report for their members, and they shared on social media and saw an uptick in new memberships! I considered packaging this ""product"" and emailing other gyms, but I got overwhelmed by the pandemic/election and decided to put extra stuff on the back burner and wait for later when I have more skills. 

**Takeaway:** make your learning project driven, and document your entire project, including packaging in several different formats, making a clear write-up, and versions of a verbal explanation that take 1 minute, 5 minutes, and 20 minutes. Then, explain it for a PhD, a CEO, a peer, and a non-technical client (or whatever audiences you want, provided they vary by technical understanding and business investment). Try to carry every project through the finish line. As an example, this post/article is my way of compiling a high-level overview of the job search process--the ""finish line"" of this 6 month project.


## Decoding the Data Science Interview Process

Have you ever been invited to church by your friend, but they didn't explain anything before you got there? You don't know when to raise your hands, or to stand up or sit down, or why the man up front is yelling? That's how I felt for the last 6 months. From when you're supposed to negotiate salary, wtf a ""first year cliff"" is, or what you're allowed to ask and to whom, nobody teaches you this stuff. Why does everything have to be so goddamned awkward and needlessly confusing? I have teaching experience so all of this infuriated me as a very eager learner. 

There are two kinds of people you will encounter: 
- Those who pretend to know the answer, and give you bullshit advice or project onto your experience
- Those who know the answer, but don't know how to explain it, or give equally useless advice like ""just keep applying"". 

Nobody will tell you the truth to your face, or give you meaningful feedback of any kind, and I asked for it *constantly*. They will send you a form email, ghost you, or dodge your questions and judge you for breaking  etiquette **you have no idea about**. 

### My Process

I decided to submit some applications on Linkedin every other day as a benchmark, and took advantage of the ""Easy Apply"" feature to get more applications out. There is a tradeoff between quality and quantity in the applications you send out. Aside from more applications going out, I needed more information, so I decided to use my network to do some decoding.

I went on Facebook, IG, and my LinkedIn and filtered by software, data, CS, analyst etc until I had a list of people to ask questions to. I contacted each of them and asked for a brief phone call to get their advice and to hear about their experience in role R at company C. Here are examples of the questions I asked:

- What are your career goals and how have they changed?
- What are some of the important technologies or libraries to be fluent in as a [their role / your desired role]?
- What helps a candidate stand out when you’re selecting for promotion or advancement?
- What is the culture of [their company] in terms of work / life balance and expectations?
- What does a normal day / week look like?
- What do teams look like and how are projects carried out?
- In risk analytics / Risk dynamics, what are the industry tools?
- For risk analytics, what are differentiators in top analysts?
- What is the culture like?

The final question I always ask is: 

- How do internal referrals work and would you be willing to submit one on my behalf?

I got some first round interviews or conversations with recruiters through this method, but none of the connections panned out, and I only got one technical interview, which was a coding challenge that I answered 5/6 correct, so was not invited to the next round. 

Now that I had exhausted my first round connections, it was time to go to strangers. I went to company pages on LinkedIn and clicked ""people"" and filtered by Data Scientist / Analyst / Data Engineer, then reached out with the following message:

> Subject Line: **[Fellow University Alum]\* wondering about [Company]**
>
>Hey [name], 
>
>My name is [name] and I just finished up at [school] with an [degree] in [major]! I have a background in [sub-filed] and love what I have seen in the job descriptions at [company], and I was wondering if you wouldn't mind connecting and answering some questions I have about the data scientist role and how your experience has been. Thanks so much for your time!
>
>Best, 
>[name]

\* replace ""Fellow University Alum"" with whatever way you can connect with the person based on their profile. Otherwise just say ""Aspiring Data Scientist"" or something humble and eager.

I got several interviews and referrals from strangers this way. 


**Takeaway:** use your network and reach out to make as many connections as possible in order to learn more about what you want or don't want. They may also be happy to refer you to a position.

## Determining My Professional Goals

I interviewed for the following positions: Intern, Research Associate, Data Engineer, Machine Learning Engineer, Data Analyst, Product Analyst, Analyst, Consultant, Product Manager, and others. 

I talked to a lot of people and wanted to understand what motivates them, what they are experiencing in their role, and what they hope for in the future. What skills do they have, and are those skills transferrable? It seems to me that coding practices and statistical intuition are very transferrable, and so I wanted a role that would allow me to improve those two things. I want to be able to transfer what I learn in my next role to future roles, and I'm not attached to any particular industry. So it was important for me to distinguish myself from those who love coding, or those who want a 9-5 without much challenge, or those who want to do analyst work but don't want to become leaders. Benchmarking and measuring your goals and feelings against others similar to you but in different roles and spaces is an excellent way to figure out what you want to do, and even what size of company you prefer. 

My set of values pre-job offer:

- Any size company, but prefer a medium team size, and a company without too much bureaucracy. 
- Exposure to ML as well as data-wrangling, without too much emphasis on one vs. the other. 
- If I can mentor or help more junior developers, I would enjoy that.
- Have an enjoyable connection to other employees during the interview process.
- If possible, a company that has a meaningful contribution to society, or positive local impact.
- Being able to bring my ideas and whole self to the job, not just a clock-in clock-out situation. 


**Takeaway:** find out what positions interest you, and try to craft your profile, projects, and skills to fit that role. Don't be afraid to say no to positions if they don't meet your criteria.

## Staying Motivated

The 2020 turbulence shook everything that wasn't securely tied down. I've spent much of my free time on calls with friends and family about navigating the challenges they are facing this year. I had weekends and whole weeks where I didn't do anything except scroll on reddit, tiktok, IG, etc. and felt like shit. I had other weeks where I felt like a superhero, learning things and gaining confidence, getting a website to work, debugging part of a data pipeline, etc. Here are the things that helped me stay on track:

- Getting enough nutrients and listening to my body's caloric needs.
- Stretching and foam-rolling when I feel stiff or uncomfortable sitting all day.
- Lifting weights or going for a walk.
- Taking one or two weeks to stop applying because of rejection fatigue.
- Scheduling phone calls with other people in the same boat to commiserate.
- Watching stand up comedy on youtube to crack up and laugh to break the day's tension.
- Limiting doom scrolling and hyper vigilance (our house was 2 miles from one of the fires, so that was hard).
- Any time I needed a nap, I took that nap. 
- Unfollow anything that isn't encouraging, uplifting, or useful to me in this period of time.

## Giving Back

I was SO LONELY on this journey, and resources on Reddit have helped me massively. As a way to give back to the community, I want to offer the following things for free: 

- A 10-15 minute zoom call to advise you or answer your questions about how to get the Data Science job you're looking for (limited to how many I can fit in next week and who is in dire need). 
- A tailored response to your personal question or situation via email, or advice on how to improve your resume.
- A follow up post on this subreddit answering the top several questions I get.
- Answering as many questions in the comments as I can. I'll reply [""pass""](https://www.educative.io/edpresso/what-is-pass-statement-in-python) in some cases, or refer you to resources that were useful to me. 

**Update: Survey now closed. See Edit #5.** 

**Edit #1**: Formatting, added link to [DataCamp](https://learn.datacamp.com/)

**Edit #2:** It's an important note that I worked for 6 years in the nonprofit world before coming back to school. Here's a quote from one of my responses below: 
>""I worked in the nonprofit world and had a lot of different roles and responsibilities, including working abroad in a humanitarian capacity, translating for conferences, logistics and operations, participating in making curriculum for staff and volunteers, casting vision to donors in a fund-development capacity, etc. I wish it were a one-liner 'I worked in software' that would be satisfying or succinct, but it is simply more complicated.""

**Edit #3:** Some people are suggesting that my offers to have a zoom call or offer resume feedback are part of some nefarious ploy to obtain people's information or manipulate them in some way. I'm sorry to hear that. Did you know that there are firms who have been scraping employment data from before the sites had adequate protections in place? I interacted with one such company over the course of my research. It would probably be more efficient for me to make a [LinkedIn Recruiter Profile](https://www.linkedin.com/help/recruiter/answer/a417020/personal-account-vs-recruiter?lang=en#:~:text=LinkedIn%20Recruiter%20is%20a%20talent,of%20active%20and%20passive%20candidates.). Then I could have thousands of emails and LinkedIn profiles all for my nefarious purposes! Muahahahaha! For more stories of recruiting shenanigans, check out r/recruitinghell for best practices. Relevant quote from one of my comments below:
> Hey! I made an edit about this. I had hoped to have some verbal conversations if people were interested, since I have a track record of coaching younger students, teaching, and mentorship. It was the first way I could think to give back to this community aside from writing more posts (which I could certainly do). Is there a method you would suggest that might help that come through more effectively? I definitely don't want to send the wrong message. Thanks!

**Edit #4:** Added Preface section to better contextualize my story.

**Edit #5:** I have closed the survey and will be turning off notifications for this post, following up with the folks who filled out the survey, and writing follow up posts if I get feedback that it will be useful. Thanks to all of you for celebrating with me and helping me make sure this post is as useful for the community as possible! I also received some rather hateful messages, and people disbelieving my story and hard work. I am flattered by your disbelief, because it underscores how incredible my journey has been! Until next time!",1607213572.0,970.0,105.0,/r/datascience/comments/k7iytr/landing_a_senior_data_scientist_job_after_6/,https://www.reddit.com/r/datascience/comments/k7iytr/landing_a_senior_data_scientist_job_after_6/,jakemmman,datascience,0.96,True,False,False,False,0.0,1745834738.897178,Tech & Programming,11.0,3298.0,3222.0,Saturday,19.0,December,2020.0,True,0.9999,0.137,0.042,0.821,positive,landing a senior data scientist job after months of unemployment,i graduated this year with a masters of statistics in this article i will explain the process that ultimately led to my offer for a senior data scientist position for a company in the sf bay area the components of the process that led to my success in no particular order were crafting my resume and linkedin building skills and projects staying motivated during the pandemic decoding the data science interview process and determining my professional goals edit important note this is not big n or faang since in the comments people are using top top companies to benchmark my experience preface as with any statistical inference a singleton dataset wont yield robustness i was an unusual applicant to my grad program and am an unorthodox candidate for ds roles which is why it took me six months to find a job while my peers all had several offers immediately following graduation and some months in advance i worked for years between my undergrad and masters in the nonprofit world and had many different job titles as noted in edit below coming back to school was a huge pivot and career shift and so i am extremely fortunate to have found a firm who recognized the unique strengths i bring to the table i was also extremely fortunate to interact with this firm at the right time where my unique strength combination was part of their strategic plan takeaway my experience is not a modal experience but the tools i used and the lessons i learned may be useful for others i would have appreciated reading it two years ago so im putting it here in case others relate also a friendly reminders to aspiring or current data scientists not to conflate prior and posterior probabilities crafting my resume and linkedin i completely botched my first ds resume i borrowed a classmates resume and used it as a template and tried to copy what they had done but they had internships relevant projects and a better gpa than me so my version looked weird since i didnt have any of those things also i was still expecting people to read between the lines on my resume instead of being as clear as possible i started applying and connecting with folks and what i am shocked by is that not one person i asked about my resume gave substantial or useful feedback the one useful piece of feedback that i received was from my parents who remarked this doesnt seem to really sell you youre much better in person than on this paper while initially i was resistant to rehauling my resume i decided to spend a full week almost full time rehauling my resume this paid off because i saw a significant uptick in responses and was able to get several first round interviews the main changes i made only put what is relevant to the role you are applying for even though i had some impressive accomplishments from other projects or roles i chose the projects or skills that were relevant to data science similar to the first rule of roadside beet sales i put my best features in the top half of my resume i used canva to make a visually appealing resume and later switched to a latex resume template to make my resume more professional looking this was a very very good decision and i got so much positive feedback from recruiters and hiring managers after making that change i used a latex cover letter template to write cover letters which made it look very official and professional it was easier to produce because i could just make a new document in overleaf and change small portions in the letter since its mostly common across applications and once you do enough you have even domain specific and role specific letters ready to go takeaway your image matters a lot make sure to craft it carefully and tailor it for roles that you are really interested in building skills and projects my strategy for learning something is spend at least a week or two finding the best resource then pay whatever it costs in your budget and use it dont find free cheat sheets and shortcuts i researched every resource i could find many thanks to rdatascience rmachinelearning and rcscareersquestions and i tried out a few but saw that many only give free temporary access to some subsection of the entire platform so you cant really explore past the first few questions or modules however i saw a reddit post talking about some site called datacamp where they gave you days for free but it was full access i looked through the catalogue and found a lot of what i wanted to learn i took a week and devoted hours per day to going through the modules there are some things i would change but for the most part it is very well designed and extremely helpful i earned somewhere around k experience on the platform which means i finished exercises from data engineering modeling or reviewing oop in python then at the end of the free trial they emailed me a coupon for a years subscription which brought it down to an insanely reasonable number like between bucks easy decision since i had already mapped my curriculum through the rest of their materials and they have new courses coming out every weeks for textbooks anything from oreily with an animal on the front is probably going to be a good resource i burned through about a half dozen of those books taking notes and building the example projects then moving to datacamp to do similar projects then once i felt confident i would find a dataset from kaggle or the uci ml repo and try to carry out the steps then benchmark my findings with some medium article where someone did the same thing try to keep projects at the center of your learning then find materials that will add to the project this is much more transferrable to a job and learning to think in this way will help you in interviews i saw an instagram account i follow put out a survey and was getting a lot of responses but the way they were reporting the data was not able to do full justice to the story they were trying to tell so i reached out and asked if i could take a look and they were super excited to have someone with experience weigh in so i ended up getting a few different spreadsheets some with categorical and quantitative data and some categorical while one of the responses was meant for a massively long response some users inputted over words do you see where this is going its basically a playground where my boss has expectations and all i have to do is improve on autogenerated excel charts i began cleaning the data in a notebook then built a set of scripts then loaded a database then made a dashboard for the team using a python flask app and scheduled cron jobs to extract the data and report results to the ceofounder of this nonprofit every new datacamp module i completed was one more secret to the puzzle of how to present and improve the data visuals process and my code i got invited to meetings with the other leaders asked about business decisions and got to be part of the real life cycle of their mission now that i had a taste of what that looked like i reached out to my gym they keep all of their members data on lifting progress and workout goals in an app and i was able to give them a fun graphic and report for their members and they shared on social media and saw an uptick in new memberships i considered packaging this product and emailing other gyms but i got overwhelmed by the pandemicelection and decided to put extra stuff on the back burner and wait for later when i have more skills takeaway make your learning project driven and document your entire project including packaging in several different formats making a clear writeup and versions of a verbal explanation that take minute minutes and minutes then explain it for a phd a ceo a peer and a nontechnical client or whatever audiences you want provided they vary by technical understanding and business investment try to carry every project through the finish line as an example this postarticle is my way of compiling a highlevel overview of the job search processthe finish line of this month project decoding the data science interview process have you ever been invited to church by your friend but they didnt explain anything before you got there you dont know when to raise your hands or to stand up or sit down or why the man up front is yelling thats how i felt for the last months from when youre supposed to negotiate salary wtf a first year cliff is or what youre allowed to ask and to whom nobody teaches you this stuff why does everything have to be so goddamned awkward and needlessly confusing i have teaching experience so all of this infuriated me as a very eager learner there are two kinds of people you will encounter those who pretend to know the answer and give you bullshit advice or project onto your experience those who know the answer but dont know how to explain it or give equally useless advice like just keep applying nobody will tell you the truth to your face or give you meaningful feedback of any kind and i asked for it constantly they will send you a form email ghost you or dodge your questions and judge you for breaking etiquette you have no idea about my process i decided to submit some applications on linkedin every other day as a benchmark and took advantage of the easy apply feature to get more applications out there is a tradeoff between quality and quantity in the applications you send out aside from more applications going out i needed more information so i decided to use my network to do some decoding i went on facebook ig and my linkedin and filtered by software data cs analyst etc until i had a list of people to ask questions to i contacted each of them and asked for a brief phone call to get their advice and to hear about their experience in role r at company c here are examples of the questions i asked what are your career goals and how have they changed what are some of the important technologies or libraries to be fluent in as a their role your desired role what helps a candidate stand out when youre selecting for promotion or advancement what is the culture of their company in terms of work life balance and expectations what does a normal day week look like what do teams look like and how are projects carried out in risk analytics risk dynamics what are the industry tools for risk analytics what are differentiators in top analysts what is the culture like the final question i always ask is how do internal referrals work and would you be willing to submit one on my behalf i got some first round interviews or conversations with recruiters through this method but none of the connections panned out and i only got one technical interview which was a coding challenge that i answered correct so was not invited to the next round now that i had exhausted my first round connections it was time to go to strangers i went to company pages on linkedin and clicked people and filtered by data scientist analyst data engineer then reached out with the following message subject line fellow university alum wondering about company hey name my name is name and i just finished up at school with an degree in major i have a background in subfiled and love what i have seen in the job descriptions at company and i was wondering if you wouldnt mind connecting and answering some questions i have about the data scientist role and how your experience has been thanks so much for your time best name replace fellow university alum with whatever way you can connect with the person based on their profile otherwise just say aspiring data scientist or something humble and eager i got several interviews and referrals from strangers this way takeaway use your network and reach out to make as many connections as possible in order to learn more about what you want or dont want they may also be happy to refer you to a position determining my professional goals i interviewed for the following positions intern research associate data engineer machine learning engineer data analyst product analyst analyst consultant product manager and others i talked to a lot of people and wanted to understand what motivates them what they are experiencing in their role and what they hope for in the future what skills do they have and are those skills transferrable it seems to me that coding practices and statistical intuition are very transferrable and so i wanted a role that would allow me to improve those two things i want to be able to transfer what i learn in my next role to future roles and im not attached to any particular industry so it was important for me to distinguish myself from those who love coding or those who want a without much challenge or those who want to do analyst work but dont want to become leaders benchmarking and measuring your goals and feelings against others similar to you but in different roles and spaces is an excellent way to figure out what you want to do and even what size of company you prefer my set of values prejob offer any size company but prefer a medium team size and a company without too much bureaucracy exposure to ml as well as datawrangling without too much emphasis on one vs the other if i can mentor or help more junior developers i would enjoy that have an enjoyable connection to other employees during the interview process if possible a company that has a meaningful contribution to society or positive local impact being able to bring my ideas and whole self to the job not just a clockin clockout situation takeaway find out what positions interest you and try to craft your profile projects and skills to fit that role dont be afraid to say no to positions if they dont meet your criteria staying motivated the turbulence shook everything that wasnt securely tied down ive spent much of my free time on calls with friends and family about navigating the challenges they are facing this year i had weekends and whole weeks where i didnt do anything except scroll on reddit tiktok ig etc and felt like shit i had other weeks where i felt like a superhero learning things and gaining confidence getting a website to work debugging part of a data pipeline etc here are the things that helped me stay on track getting enough nutrients and listening to my bodys caloric needs stretching and foamrolling when i feel stiff or uncomfortable sitting all day lifting weights or going for a walk taking one or two weeks to stop applying because of rejection fatigue scheduling phone calls with other people in the same boat to commiserate watching stand up comedy on youtube to crack up and laugh to break the days tension limiting doom scrolling and hyper vigilance our house was miles from one of the fires so that was hard any time i needed a nap i took that nap unfollow anything that isnt encouraging uplifting or useful to me in this period of time giving back i was so lonely on this journey and resources on reddit have helped me massively as a way to give back to the community i want to offer the following things for free a minute zoom call to advise you or answer your questions about how to get the data science job youre looking for limited to how many i can fit in next week and who is in dire need a tailored response to your personal question or situation via email or advice on how to improve your resume a follow up post on this subreddit answering the top several questions i get answering as many questions in the comments as i can ill reply pass in some cases or refer you to resources that were useful to me update survey now closed see edit edit formatting added link to datacamp edit its an important note that i worked for years in the nonprofit world before coming back to school heres a quote from one of my responses below i worked in the nonprofit world and had a lot of different roles and responsibilities including working abroad in a humanitarian capacity translating for conferences logistics and operations participating in making curriculum for staff and volunteers casting vision to donors in a funddevelopment capacity etc i wish it were a oneliner i worked in software that would be satisfying or succinct but it is simply more complicated edit some people are suggesting that my offers to have a zoom call or offer resume feedback are part of some nefarious ploy to obtain peoples information or manipulate them in some way im sorry to hear that did you know that there are firms who have been scraping employment data from before the sites had adequate protections in place i interacted with one such company over the course of my research it would probably be more efficient for me to make a linkedin recruiter profile then i could have thousands of emails and linkedin profiles all for my nefarious purposes muahahahaha for more stories of recruiting shenanigans check out rrecruitinghell for best practices relevant quote from one of my comments below hey i made an edit about this i had hoped to have some verbal conversations if people were interested since i have a track record of coaching younger students teaching and mentorship it was the first way i could think to give back to this community aside from writing more posts which i could certainly do is there a method you would suggest that might help that come through more effectively i definitely dont want to send the wrong message thanks edit added preface section to better contextualize my story edit i have closed the survey and will be turning off notifications for this post following up with the folks who filled out the survey and writing follow up posts if i get feedback that it will be useful thanks to all of you for celebrating with me and helping me make sure this post is as useful for the community as possible i also received some rather hateful messages and people disbelieving my story and hard work i am flattered by your disbelief because it underscores how incredible my journey has been until next time,landing a senior data scientist job after months of unemployment i graduated this year with a masters of statistics in this article i will explain the process that ultimately led to my offer for a senior data scientist position for a company in the sf bay area the components of the process that led to my success in no particular order were crafting my resume and linkedin building skills and projects staying motivated during the pandemic decoding the data science interview process and determining my professional goals edit important note this is not big n or faang since in the comments people are using top top companies to benchmark my experience preface as with any statistical inference a singleton dataset wont yield robustness i was an unusual applicant to my grad program and am an unorthodox candidate for ds roles which is why it took me six months to find a job while my peers all had several offers immediately following graduation and some months in advance i worked for years between my undergrad and masters in the nonprofit world and had many different job titles as noted in edit below coming back to school was a huge pivot and career shift and so i am extremely fortunate to have found a firm who recognized the unique strengths i bring to the table i was also extremely fortunate to interact with this firm at the right time where my unique strength combination was part of their strategic plan takeaway my experience is not a modal experience but the tools i used and the lessons i learned may be useful for others i would have appreciated reading it two years ago so im putting it here in case others relate also a friendly reminders to aspiring or current data scientists not to conflate prior and posterior probabilities crafting my resume and linkedin i completely botched my first ds resume i borrowed a classmates resume and used it as a template and tried to copy what they had done but they had internships relevant projects and a better gpa than me so my version looked weird since i didnt have any of those things also i was still expecting people to read between the lines on my resume instead of being as clear as possible i started applying and connecting with folks and what i am shocked by is that not one person i asked about my resume gave substantial or useful feedback the one useful piece of feedback that i received was from my parents who remarked this doesnt seem to really sell you youre much better in person than on this paper while initially i was resistant to rehauling my resume i decided to spend a full week almost full time rehauling my resume this paid off because i saw a significant uptick in responses and was able to get several first round interviews the main changes i made only put what is relevant to the role you are applying for even though i had some impressive accomplishments from other projects or roles i chose the projects or skills that were relevant to data science similar to the first rule of roadside beet sales i put my best features in the top half of my resume i used canva to make a visually appealing resume and later switched to a latex resume template to make my resume more professional looking this was a very very good decision and i got so much positive feedback from recruiters and hiring managers after making that change i used a latex cover letter template to write cover letters which made it look very official and professional it was easier to produce because i could just make a new document in overleaf and change small portions in the letter since its mostly common across applications and once you do enough you have even domain specific and role specific letters ready to go takeaway your image matters a lot make sure to craft it carefully and tailor it for roles that you are really interested in building skills and projects my strategy for learning something is spend at least a week or two finding the best resource then pay whatever it costs in your budget and use it dont find free cheat sheets and shortcuts i researched every resource i could find many thanks to rdatascience rmachinelearning and rcscareersquestions and i tried out a few but saw that many only give free temporary access to some subsection of the entire platform so you cant really explore past the first few questions or modules however i saw a reddit post talking about some site called datacamp where they gave you days for free but it was full access i looked through the catalogue and found a lot of what i wanted to learn i took a week and devoted hours per day to going through the modules there are some things i would change but for the most part it is very well designed and extremely helpful i earned somewhere around k experience on the platform which means i finished exercises from data engineering modeling or reviewing oop in python then at the end of the free trial they emailed me a coupon for a years subscription which brought it down to an insanely reasonable number like between bucks easy decision since i had already mapped my curriculum through the rest of their materials and they have new courses coming out every weeks for textbooks anything from oreily with an animal on the front is probably going to be a good resource i burned through about a half dozen of those books taking notes and building the example projects then moving to datacamp to do similar projects then once i felt confident i would find a dataset from kaggle or the uci ml repo and try to carry out the steps then benchmark my findings with some medium article where someone did the same thing try to keep projects at the center of your learning then find materials that will add to the project this is much more transferrable to a job and learning to think in this way will help you in interviews i saw an instagram account i follow put out a survey and was getting a lot of responses but the way they were reporting the data was not able to do full justice to the story they were trying to tell so i reached out and asked if i could take a look and they were super excited to have someone with experience weigh in so i ended up getting a few different spreadsheets some with categorical and quantitative data and some categorical while one of the responses was meant for a massively long response some users inputted over words do you see where this is going its basically a playground where my boss has expectations and all i have to do is improve on autogenerated excel charts i began cleaning the data in a notebook then built a set of scripts then loaded a database then made a dashboard for the team using a python flask app and scheduled cron jobs to extract the data and report results to the ceofounder of this nonprofit every new datacamp module i completed was one more secret to the puzzle of how to present and improve the data visuals process and my code i got invited to meetings with the other leaders asked about business decisions and got to be part of the real life cycle of their mission now that i had a taste of what that looked like i reached out to my gym they keep all of their members data on lifting progress and workout goals in an app and i was able to give them a fun graphic and report for their members and they shared on social media and saw an uptick in new memberships i considered packaging this product and emailing other gyms but i got overwhelmed by the pandemicelection and decided to put extra stuff on the back burner and wait for later when i have more skills takeaway make your learning project driven and document your entire project including packaging in several different formats making a clear writeup and versions of a verbal explanation that take minute minutes and minutes then explain it for a phd a ceo a peer and a nontechnical client or whatever audiences you want provided they vary by technical understanding and business investment try to carry every project through the finish line as an example this postarticle is my way of compiling a highlevel overview of the job search processthe finish line of this month project decoding the data science interview process have you ever been invited to church by your friend but they didnt explain anything before you got there you dont know when to raise your hands or to stand up or sit down or why the man up front is yelling thats how i felt for the last months from when youre supposed to negotiate salary wtf a first year cliff is or what youre allowed to ask and to whom nobody teaches you this stuff why does everything have to be so goddamned awkward and needlessly confusing i have teaching experience so all of this infuriated me as a very eager learner there are two kinds of people you will encounter those who pretend to know the answer and give you bullshit advice or project onto your experience those who know the answer but dont know how to explain it or give equally useless advice like just keep applying nobody will tell you the truth to your face or give you meaningful feedback of any kind and i asked for it constantly they will send you a form email ghost you or dodge your questions and judge you for breaking etiquette you have no idea about my process i decided to submit some applications on linkedin every other day as a benchmark and took advantage of the easy apply feature to get more applications out there is a tradeoff between quality and quantity in the applications you send out aside from more applications going out i needed more information so i decided to use my network to do some decoding i went on facebook ig and my linkedin and filtered by software data cs analyst etc until i had a list of people to ask questions to i contacted each of them and asked for a brief phone call to get their advice and to hear about their experience in role r at company c here are examples of the questions i asked what are your career goals and how have they changed what are some of the important technologies or libraries to be fluent in as a their role your desired role what helps a candidate stand out when youre selecting for promotion or advancement what is the culture of their company in terms of work life balance and expectations what does a normal day week look like what do teams look like and how are projects carried out in risk analytics risk dynamics what are the industry tools for risk analytics what are differentiators in top analysts what is the culture like the final question i always ask is how do internal referrals work and would you be willing to submit one on my behalf i got some first round interviews or conversations with recruiters through this method but none of the connections panned out and i only got one technical interview which was a coding challenge that i answered correct so was not invited to the next round now that i had exhausted my first round connections it was time to go to strangers i went to company pages on linkedin and clicked people and filtered by data scientist analyst data engineer then reached out with the following message subject line fellow university alum wondering about company hey name my name is name and i just finished up at school with an degree in major i have a background in subfiled and love what i have seen in the job descriptions at company and i was wondering if you wouldnt mind connecting and answering some questions i have about the data scientist role and how your experience has been thanks so much for your time best name replace fellow university alum with whatever way you can connect with the person based on their profile otherwise just say aspiring data scientist or something humble and eager i got several interviews and referrals from strangers this way takeaway use your network and reach out to make as many connections as possible in order to learn more about what you want or dont want they may also be happy to refer you to a position determining my professional goals i interviewed for the following positions intern research associate data engineer machine learning engineer data analyst product analyst analyst consultant product manager and others i talked to a lot of people and wanted to understand what motivates them what they are experiencing in their role and what they hope for in the future what skills do they have and are those skills transferrable it seems to me that coding practices and statistical intuition are very transferrable and so i wanted a role that would allow me to improve those two things i want to be able to transfer what i learn in my next role to future roles and im not attached to any particular industry so it was important for me to distinguish myself from those who love coding or those who want a without much challenge or those who want to do analyst work but dont want to become leaders benchmarking and measuring your goals and feelings against others similar to you but in different roles and spaces is an excellent way to figure out what you want to do and even what size of company you prefer my set of values prejob offer any size company but prefer a medium team size and a company without too much bureaucracy exposure to ml as well as datawrangling without too much emphasis on one vs the other if i can mentor or help more junior developers i would enjoy that have an enjoyable connection to other employees during the interview process if possible a company that has a meaningful contribution to society or positive local impact being able to bring my ideas and whole self to the job not just a clockin clockout situation takeaway find out what positions interest you and try to craft your profile projects and skills to fit that role dont be afraid to say no to positions if they dont meet your criteria staying motivated the turbulence shook everything that wasnt securely tied down ive spent much of my free time on calls with friends and family about navigating the challenges they are facing this year i had weekends and whole weeks where i didnt do anything except scroll on reddit tiktok ig etc and felt like shit i had other weeks where i felt like a superhero learning things and gaining confidence getting a website to work debugging part of a data pipeline etc here are the things that helped me stay on track getting enough nutrients and listening to my bodys caloric needs stretching and foamrolling when i feel stiff or uncomfortable sitting all day lifting weights or going for a walk taking one or two weeks to stop applying because of rejection fatigue scheduling phone calls with other people in the same boat to commiserate watching stand up comedy on youtube to crack up and laugh to break the days tension limiting doom scrolling and hyper vigilance our house was miles from one of the fires so that was hard any time i needed a nap i took that nap unfollow anything that isnt encouraging uplifting or useful to me in this period of time giving back i was so lonely on this journey and resources on reddit have helped me massively as a way to give back to the community i want to offer the following things for free a minute zoom call to advise you or answer your questions about how to get the data science job youre looking for limited to how many i can fit in next week and who is in dire need a tailored response to your personal question or situation via email or advice on how to improve your resume a follow up post on this subreddit answering the top several questions i get answering as many questions in the comments as i can ill reply pass in some cases or refer you to resources that were useful to me update survey now closed see edit edit formatting added link to datacamp edit its an important note that i worked for years in the nonprofit world before coming back to school heres a quote from one of my responses below i worked in the nonprofit world and had a lot of different roles and responsibilities including working abroad in a humanitarian capacity translating for conferences logistics and operations participating in making curriculum for staff and volunteers casting vision to donors in a funddevelopment capacity etc i wish it were a oneliner i worked in software that would be satisfying or succinct but it is simply more complicated edit some people are suggesting that my offers to have a zoom call or offer resume feedback are part of some nefarious ploy to obtain peoples information or manipulate them in some way im sorry to hear that did you know that there are firms who have been scraping employment data from before the sites had adequate protections in place i interacted with one such company over the course of my research it would probably be more efficient for me to make a linkedin recruiter profile then i could have thousands of emails and linkedin profiles all for my nefarious purposes muahahahaha for more stories of recruiting shenanigans check out rrecruitinghell for best practices relevant quote from one of my comments below hey i made an edit about this i had hoped to have some verbal conversations if people were interested since i have a track record of coaching younger students teaching and mentorship it was the first way i could think to give back to this community aside from writing more posts which i could certainly do is there a method you would suggest that might help that come through more effectively i definitely dont want to send the wrong message thanks edit added preface section to better contextualize my story edit i have closed the survey and will be turning off notifications for this post following up with the folks who filled out the survey and writing follow up posts if i get feedback that it will be useful thanks to all of you for celebrating with me and helping me make sure this post is as useful for the community as possible i also received some rather hateful messages and people disbelieving my story and hard work i am flattered by your disbelief because it underscores how incredible my journey has been until next time,"data, project, role, resume, company",2020-12-06 00:12:52,landing a senior data scientist job after months of unemployment i graduated this year with a masters of statistics in this article i will explain the process that ultimately led to my offer for a senior data scientist position for a company in the sf bay area the components of the process that led to my success in no particular order were crafting my resume and linkedin building skills and projects staying motivated during the pandemic decoding the data science interview process and determining my professional goals edit important note this is not big n or faang since in the comments people are using top top companies to benchmark my experience preface as with any statistical inference a singleton dataset wont yield robustness i was an unusual applicant to my grad program and am an unorthodox candidate for ds roles which is why it took me six months to find a job while my peers all had several offers immediately following graduation and some months in advance i worked for years between my undergrad and masters in the nonprofit world and had many different job titles as noted in edit below coming back to school was a huge pivot and career shift and so i am extremely fortunate to have found a firm who recognized the unique strengths i bring to the table i was also extremely fortunate to interact with this firm at the right time where my unique strength combination was part of their strategic plan takeaway my experience is not a modal experience but the tools i used and the lessons i learned may be useful for others i would have appreciated reading it two years ago so im putting it here in case others relate also a friendly reminders to aspiring or current data scientists not to conflate prior and posterior probabilities crafting my resume and linkedin i completely botched my first ds resume i borrowed a classmates resume and used it as a template and tried to copy what they had done but they had internships relevant projects and a better gpa than me so my version looked weird since i didnt have any of those things also i was still expecting people to read between the lines on my resume instead of being as clear as possible i started applying and connecting with folks and what i am shocked by is that not one person i asked about my resume gave substantial or useful feedback the one useful piece of feedback that i received was from my parents who remarked this doesnt seem to really sell you youre much better in person than on this paper while initially i was resistant to rehauling my resume i decided to spend a full week almost full time rehauling my resume this paid off because i saw a significant uptick in responses and was able to get several first round interviews the main changes i made only put what is relevant to the role you are applying for even though i had some impressive accomplishments from other projects or roles i chose the projects or skills that were relevant to data science similar to the first rule of roadside beet sales i put my best features in the top half of my resume i used canva to make a visually appealing resume and later switched to a latex resume template to make my resume more professional looking this was a very very good decision and i got so much positive feedback from recruiters and hiring managers after making that change i used a latex cover letter template to write cover letters which made it look very official and professional it was easier to produce because i could just make a new document in overleaf and change small portions in the letter since its mostly common across applications and once you do enough you have even domain specific and role specific letters ready to go takeaway your image matters a lot make sure to craft it carefully and tailor it for roles that you are really interested in building skills and projects my strategy for learning something is spend at least a week or two finding the best resource then pay whatever it costs in your budget and use it dont find free cheat sheets and shortcuts i researched every resource i could find many thanks to rdatascience rmachinelearning and rcscareersquestions and i tried out a few but saw that many only give free temporary access to some subsection of the entire platform so you cant really explore past the first few questions or modules however i saw a reddit post talking about some site called datacamp where they gave you days for free but it was full access i looked through the catalogue and found a lot of what i wanted to learn i took a week and devoted hours per day to going through the modules there are some things i would change but for the most part it is very well designed and extremely helpful i earned somewhere around k experience on the platform which means i finished exercises from data engineering modeling or reviewing oop in python then at the end of the free trial they emailed me a coupon for a years subscription which brought it down to an insanely reasonable number like between bucks easy decision since i had already mapped my curriculum through the rest of their materials and they have new courses coming out every weeks for textbooks anything from oreily with an animal on the front is probably going to be a good resource i burned through about a half dozen of those books taking notes and building the example projects then moving to datacamp to do similar projects then once i felt confident i would find a dataset from kaggle or the uci ml repo and try to carry out the steps then benchmark my findings with some medium article where someone did the same thing try to keep projects at the center of your learning then find materials that will add to the project this is much more transferrable to a job and learning to think in this way will help you in interviews i saw an instagram account i follow put out a survey and was getting a lot of responses but the way they were reporting the data was not able to do full justice to the story they were trying to tell so i reached out and asked if i could take a look and they were super excited to have someone with experience weigh in so i ended up getting a few different spreadsheets some with categorical and quantitative data and some categorical while one of the responses was meant for a massively long response some users inputted over words do you see where this is going its basically a playground where my boss has expectations and all i have to do is improve on autogenerated excel charts i began cleaning the data in a notebook then built a set of scripts then loaded a database then made a dashboard for the team using a python flask app and scheduled cron jobs to extract the data and report results to the ceofounder of this nonprofit every new datacamp module i completed was one more secret to the puzzle of how to present and improve the data visuals process and my code i got invited to meetings with the other leaders asked about business decisions and got to be part of the real life cycle of their mission now that i had a taste of what that looked like i reached out to my gym they keep all of their members data on lifting progress and workout goals in an app and i was able to give them a fun graphic and report for their members and they shared on social media and saw an uptick in new memberships i considered packaging this product and emailing other gyms but i got overwhelmed by the pandemicelection and decided to put extra stuff on the back burner and wait for later when i have more skills takeaway make your learning project driven and document your entire project including packaging in several different formats making a clear writeup and versions of a verbal explanation that take minute minutes and minutes then explain it for a phd a ceo a peer and a nontechnical client or whatever audiences you want provided they vary by technical understanding and business investment try to carry every project through the finish line as an example this postarticle is my way of compiling a highlevel overview of the job search processthe finish line of this month project decoding the data science interview process have you ever been invited to church by your friend but they didnt explain anything before you got there you dont know when to raise your hands or to stand up or sit down or why the man up front is yelling thats how i felt for the last months from when youre supposed to negotiate salary wtf a first year cliff is or what youre allowed to ask and to whom nobody teaches you this stuff why does everything have to be so goddamned awkward and needlessly confusing i have teaching experience so all of this infuriated me as a very eager learner there are two kinds of people you will encounter those who pretend to know the answer and give you bullshit advice or project onto your experience those who know the answer but dont know how to explain it or give equally useless advice like just keep applying nobody will tell you the truth to your face or give you meaningful feedback of any kind and i asked for it constantly they will send you a form email ghost you or dodge your questions and judge you for breaking etiquette you have no idea about my process i decided to submit some applications on linkedin every other day as a benchmark and took advantage of the easy apply feature to get more applications out there is a tradeoff between quality and quantity in the applications you send out aside from more applications going out i needed more information so i decided to use my network to do some decoding i went on facebook ig and my linkedin and filtered by software data cs analyst etc until i had a list of people to ask questions to i contacted each of them and asked for a brief phone call to get their advice and to hear about their experience in role r at company c here are examples of the questions i asked what are your career goals and how have they changed what are some of the important technologies or libraries to be fluent in as a their role your desired role what helps a candidate stand out when youre selecting for promotion or advancement what is the culture of their company in terms of work life balance and expectations what does a normal day week look like what do teams look like and how are projects carried out in risk analytics risk dynamics what are the industry tools for risk analytics what are differentiators in top analysts what is the culture like the final question i always ask is how do internal referrals work and would you be willing to submit one on my behalf i got some first round interviews or conversations with recruiters through this method but none of the connections panned out and i only got one technical interview which was a coding challenge that i answered correct so was not invited to the next round now that i had exhausted my first round connections it was time to go to strangers i went to company pages on linkedin and clicked people and filtered by data scientist analyst data engineer then reached out with the following message subject line fellow university alum wondering about company hey name my name is name and i just finished up at school with an degree in major i have a background in subfiled and love what i have seen in the job descriptions at company and i was wondering if you wouldnt mind connecting and answering some questions i have about the data scientist role and how your experience has been thanks so much for your time best name replace fellow university alum with whatever way you can connect with the person based on their profile otherwise just say aspiring data scientist or something humble and eager i got several interviews and referrals from strangers this way takeaway use your network and reach out to make as many connections as possible in order to learn more about what you want or dont want they may also be happy to refer you to a position determining my professional goals i interviewed for the following positions intern research associate data engineer machine learning engineer data analyst product analyst analyst consultant product manager and others i talked to a lot of people and wanted to understand what motivates them what they are experiencing in their role and what they hope for in the future what skills do they have and are those skills transferrable it seems to me that coding practices and statistical intuition are very transferrable and so i wanted a role that would allow me to improve those two things i want to be able to transfer what i learn in my next role to future roles and im not attached to any particular industry so it was important for me to distinguish myself from those who love coding or those who want a without much challenge or those who want to do analyst work but dont want to become leaders benchmarking and measuring your goals and feelings against others similar to you but in different roles and spaces is an excellent way to figure out what you want to do and even what size of company you prefer my set of values prejob offer any size company but prefer a medium team size and a company without too much bureaucracy exposure to ml as well as datawrangling without too much emphasis on one vs the other if i can mentor or help more junior developers i would enjoy that have an enjoyable connection to other employees during the interview process if possible a company that has a meaningful contribution to society or positive local impact being able to bring my ideas and whole self to the job not just a clockin clockout situation takeaway find out what positions interest you and try to craft your profile projects and skills to fit that role dont be afraid to say no to positions if they dont meet your criteria staying motivated the turbulence shook everything that wasnt securely tied down ive spent much of my free time on calls with friends and family about navigating the challenges they are facing this year i had weekends and whole weeks where i didnt do anything except scroll on reddit tiktok ig etc and felt like shit i had other weeks where i felt like a superhero learning things and gaining confidence getting a website to work debugging part of a data pipeline etc here are the things that helped me stay on track getting enough nutrients and listening to my bodys caloric needs stretching and foamrolling when i feel stiff or uncomfortable sitting all day lifting weights or going for a walk taking one or two weeks to stop applying because of rejection fatigue scheduling phone calls with other people in the same boat to commiserate watching stand up comedy on youtube to crack up and laugh to break the days tension limiting doom scrolling and hyper vigilance our house was miles from one of the fires so that was hard any time i needed a nap i took that nap unfollow anything that isnt encouraging uplifting or useful to me in this period of time giving back i was so lonely on this journey and resources on reddit have helped me massively as a way to give back to the community i want to offer the following things for free a minute zoom call to advise you or answer your questions about how to get the data science job youre looking for limited to how many i can fit in next week and who is in dire need a tailored response to your personal question or situation via email or advice on how to improve your resume a follow up post on this subreddit answering the top several questions i get answering as many questions in the comments as i can ill reply pass in some cases or refer you to resources that were useful to me update survey now closed see edit edit formatting added link to datacamp edit its an important note that i worked for years in the nonprofit world before coming back to school heres a quote from one of my responses below i worked in the nonprofit world and had a lot of different roles and responsibilities including working abroad in a humanitarian capacity translating for conferences logistics and operations participating in making curriculum for staff and volunteers casting vision to donors in a funddevelopment capacity etc i wish it were a oneliner i worked in software that would be satisfying or succinct but it is simply more complicated edit some people are suggesting that my offers to have a zoom call or offer resume feedback are part of some nefarious ploy to obtain peoples information or manipulate them in some way im sorry to hear that did you know that there are firms who have been scraping employment data from before the sites had adequate protections in place i interacted with one such company over the course of my research it would probably be more efficient for me to make a linkedin recruiter profile then i could have thousands of emails and linkedin profiles all for my nefarious purposes muahahahaha for more stories of recruiting shenanigans check out rrecruitinghell for best practices relevant quote from one of my comments below hey i made an edit about this i had hoped to have some verbal conversations if people were interested since i have a track record of coaching younger students teaching and mentorship it was the first way i could think to give back to this community aside from writing more posts which i could certainly do is there a method you would suggest that might help that come through more effectively i definitely dont want to send the wrong message thanks edit added preface section to better contextualize my story edit i have closed the survey and will be turning off notifications for this post following up with the folks who filled out the survey and writing follow up posts if i get feedback that it will be useful thanks to all of you for celebrating with me and helping me make sure this post is as useful for the community as possible i also received some rather hateful messages and people disbelieving my story and hard work i am flattered by your disbelief because it underscores how incredible my journey has been until next time,"['landing', 'senior', 'data', 'scientist', 'job', 'month', 'unemployment', 'graduated', 'year', 'master', 'statistic', 'article', 'explain', 'process', 'ultimately', 'led', 'offer', 'senior', 'data', 'scientist', 'position', 'company', 'bay', 'area', 'component', 'process', 'led', 'success', 'particular', 'order', 'crafting', 'resume', 'linkedin', 'building', 'skill', 'project', 'staying', 'motivated', 'pandemic', 'decoding', 'data', 'science', 'interview', 'process', 'determining', 'professional', 'goal', 'edit', 'important', 'note', 'big', 'faang', 'since', 'comment', 'people', 'using', 'top', 'top', 'company', 'benchmark', 'experience', 'preface', 'statistical', 'inference', 'singleton', 'dataset', 'wont', 'yield', 'robustness', 'unusual', 'applicant', 'grad', 'program', 'unorthodox', 'candidate', 'role', 'took', 'six', 'month', 'find', 'job', 'peer', 'several', 'offer', 'immediately', 'following', 'graduation', 'month', 'advance', 'worked', 'year', 'undergrad', 'master', 'nonprofit', 'world', 'many', 'different', 'job', 'title', 'noted', 'edit', 'coming', 'back', 'school', 'huge', 'pivot', 'career', 'shift', 'extremely', 'fortunate', 'found', 'firm', 'recognized', 'unique', 'strength', 'bring', 'table', 'also', 'extremely', 'fortunate', 'interact', 'firm', 'right', 'time', 'unique', 'strength', 'combination', 'part', 'strategic', 'plan', 'takeaway', 'experience', 'modal', 'experience', 'tool', 'used', 'lesson', 'learned', 'may', 'useful', 'others', 'would', 'appreciated', 'reading', 'two', 'year', 'ago', 'putting', 'case', 'others', 'relate', 'also', 'friendly', 'reminder', 'aspiring', 'current', 'data', 'scientist', 'conflate', 'prior', 'posterior', 'probability', 'crafting', 'resume', 'linkedin', 'completely', 'botched', 'first', 'resume', 'borrowed', 'classmate', 'resume', 'used', 'template', 'tried', 'copy', 'done', 'internship', 'relevant', 'project', 'better', 'gpa', 'version', 'looked', 'weird', 'since', 'didnt', 'thing', 'also', 'still', 'expecting', 'people', 'read', 'line', 'resume', 'instead', 'clear', 'possible', 'started', 'applying', 'connecting', 'folk', 'shocked', 'one', 'person', 'asked', 'resume', 'gave', 'substantial', 'useful', 'feedback', 'one', 'useful', 'piece', 'feedback', 'received', 'parent', 'remarked', 'doesnt', 'seem', 'really', 'sell', 'youre', 'much', 'better', 'person', 'paper', 'initially', 'resistant', 'rehauling', 'resume', 'decided', 'spend', 'full', 'week', 'almost', 'full', 'time', 'rehauling', 'resume', 'paid', 'saw', 'significant', 'uptick', 'response', 'able', 'get', 'several', 'first', 'round', 'interview', 'main', 'change', 'made', 'put', 'relevant', 'role', 'applying', 'even', 'though', 'impressive', 'accomplishment', 'project', 'role', 'chose', 'project', 'skill', 'relevant', 'data', 'science', 'similar', 'first', 'rule', 'roadside', 'beet', 'sale', 'put', 'best', 'feature', 'top', 'half', 'resume', 'used', 'canva', 'make', 'visually', 'appealing', 'resume', 'later', 'switched', 'latex', 'resume', 'template', 'make', 'resume', 'professional', 'looking', 'good', 'decision', 'got', 'much', 'positive', 'feedback', 'recruiter', 'hiring', 'manager', 'making', 'change', 'used', 'latex', 'cover', 'letter', 'template', 'write', 'cover', 'letter', 'made', 'look', 'official', 'professional', 'easier', 'produce', 'could', 'make', 'new', 'document', 'overleaf', 'change', 'small', 'portion', 'letter', 'since', 'mostly', 'common', 'across', 'application', 'enough', 'even', 'domain', 'specific', 'role', 'specific', 'letter', 'ready', 'takeaway', 'image', 'matter', 'lot', 'make', 'sure', 'craft', 'carefully', 'tailor', 'role', 'really', 'interested', 'building', 'skill', 'project', 'strategy', 'learning', 'something', 'spend', 'least', 'week', 'two', 'finding', 'best', 'resource', 'pay', 'whatever', 'cost', 'budget', 'use', 'dont', 'find', 'free', 'cheat', 'sheet', 'shortcut', 'researched', 'every', 'resource', 'could', 'find', 'many', 'thanks', 'rdatascience', 'rmachinelearning', 'rcscareersquestions', 'tried', 'saw', 'many', 'give', 'free', 'temporary', 'access', 'subsection', 'entire', 'platform', 'cant', 'really', 'explore', 'past', 'first', 'question', 'module', 'however', 'saw', 'reddit', 'post', 'talking', 'site', 'called', 'datacamp', 'gave', 'day', 'free', 'full', 'access', 'looked', 'catalogue', 'found', 'lot', 'wanted', 'learn', 'took', 'week', 'devoted', 'hour', 'per', 'day', 'going', 'module', 'thing', 'would', 'change', 'part', 'well', 'designed', 'extremely', 'helpful', 'earned', 'somewhere', 'around', 'experience', 'platform', 'mean', 'finished', 'exercise', 'data', 'engineering', 'modeling', 'reviewing', 'oop', 'python', 'end', 'free', 'trial', 'emailed', 'coupon', 'year', 'subscription', 'brought', 'insanely', 'reasonable', 'number', 'like', 'buck', 'easy', 'decision', 'since', 'already', 'mapped', 'curriculum', 'rest', 'material', 'new', 'course', 'coming', 'every', 'week', 'textbook', 'anything', 'oreily', 'animal', 'front', 'probably', 'going', 'good', 'resource', 'burned', 'half', 'dozen', 'book', 'taking', 'note', 'building', 'example', 'project', 'moving', 'datacamp', 'similar', 'project', 'felt', 'confident', 'would', 'find', 'dataset', 'kaggle', 'uci', 'repo', 'try', 'carry', 'step', 'benchmark', 'finding', 'medium', 'article', 'someone', 'thing', 'try', 'keep', 'project', 'center', 'learning', 'find', 'material', 'add', 'project', 'much', 'transferrable', 'job', 'learning', 'think', 'way', 'help', 'interview', 'saw', 'instagram', 'account', 'follow', 'put', 'survey', 'getting', 'lot', 'response', 'way', 'reporting', 'data', 'able', 'full', 'justice', 'story', 'trying', 'tell', 'reached', 'asked', 'could', 'take', 'look', 'super', 'excited', 'someone', 'experience', 'weigh', 'ended', 'getting', 'different', 'spreadsheet', 'categorical', 'quantitative', 'data', 'categorical', 'one', 'response', 'meant', 'massively', 'long', 'response', 'user', 'inputted', 'word', 'see', 'going', 'basically', 'playground', 'bos', 'expectation', 'improve', 'autogenerated', 'excel', 'chart', 'began', 'cleaning', 'data', 'notebook', 'built', 'set', 'script', 'loaded', 'database', 'made', 'dashboard', 'team', 'using', 'python', 'flask', 'app', 'scheduled', 'cron', 'job', 'extract', 'data', 'report', 'result', 'ceofounder', 'nonprofit', 'every', 'new', 'datacamp', 'module', 'completed', 'one', 'secret', 'puzzle', 'present', 'improve', 'data', 'visuals', 'process', 'code', 'got', 'invited', 'meeting', 'leader', 'asked', 'business', 'decision', 'got', 'part', 'real', 'life', 'cycle', 'mission', 'taste', 'looked', 'like', 'reached', 'gym', 'keep', 'member', 'data', 'lifting', 'progress', 'workout', 'goal', 'app', 'able', 'give', 'fun', 'graphic', 'report', 'member', 'shared', 'social', 'medium', 'saw', 'uptick', 'new', 'membership', 'considered', 'packaging', 'product', 'emailing', 'gym', 'got', 'overwhelmed', 'pandemicelection', 'decided', 'put', 'extra', 'stuff', 'back', 'burner', 'wait', 'later', 'skill', 'takeaway', 'make', 'learning', 'project', 'driven', 'document', 'entire', 'project', 'including', 'packaging', 'several', 'different', 'format', 'making', 'clear', 'writeup', 'version', 'verbal', 'explanation', 'take', 'minute', 'minute', 'minute', 'explain', 'phd', 'ceo', 'peer', 'nontechnical', 'client', 'whatever', 'audience', 'want', 'provided', 'vary', 'technical', 'understanding', 'business', 'investment', 'try', 'carry', 'every', 'project', 'finish', 'line', 'example', 'postarticle', 'way', 'compiling', 'highlevel', 'overview', 'job', 'search', 'processthe', 'finish', 'line', 'month', 'project', 'decoding', 'data', 'science', 'interview', 'process', 'ever', 'invited', 'church', 'friend', 'didnt', 'explain', 'anything', 'got', 'dont', 'know', 'raise', 'hand', 'stand', 'sit', 'man', 'front', 'yelling', 'thats', 'felt', 'last', 'month', 'youre', 'supposed', 'negotiate', 'salary', 'wtf', 'first', 'year', 'cliff', 'youre', 'allowed', 'ask', 'nobody', 'teach', 'stuff', 'everything', 'goddamned', 'awkward', 'needlessly', 'confusing', 'teaching', 'experience', 'infuriated', 'eager', 'learner', 'two', 'kind', 'people', 'encounter', 'pretend', 'know', 'answer', 'give', 'bullshit', 'advice', 'project', 'onto', 'experience', 'know', 'answer', 'dont', 'know', 'explain', 'give', 'equally', 'useless', 'advice', 'like', 'keep', 'applying', 'nobody', 'tell', 'truth', 'face', 'give', 'meaningful', 'feedback', 'kind', 'asked', 'constantly', 'send', 'form', 'email', 'ghost', 'dodge', 'question', 'judge', 'breaking', 'etiquette', 'idea', 'process', 'decided', 'submit', 'application', 'linkedin', 'every', 'day', 'benchmark', 'took', 'advantage', 'easy', 'apply', 'feature', 'get', 'application', 'tradeoff', 'quality', 'quantity', 'application', 'send', 'aside', 'application', 'going', 'needed', 'information', 'decided', 'use', 'network', 'decoding', 'went', 'facebook', 'linkedin', 'filtered', 'software', 'data', 'analyst', 'etc', 'list', 'people', 'ask', 'question', 'contacted', 'asked', 'brief', 'phone', 'call', 'get', 'advice', 'hear', 'experience', 'role', 'company', 'example', 'question', 'asked', 'career', 'goal', 'changed', 'important', 'technology', 'library', 'fluent', 'role', 'desired', 'role', 'help', 'candidate', 'stand', 'youre', 'selecting', 'promotion', 'advancement', 'culture', 'company', 'term', 'work', 'life', 'balance', 'expectation', 'normal', 'day', 'week', 'look', 'like', 'team', 'look', 'like', 'project', 'carried', 'risk', 'analytics', 'risk', 'dynamic', 'industry', 'tool', 'risk', 'analytics', 'differentiator', 'top', 'analyst', 'culture', 'like', 'final', 'question', 'always', 'ask', 'internal', 'referral', 'work', 'would', 'willing', 'submit', 'one', 'behalf', 'got', 'first', 'round', 'interview', 'conversation', 'recruiter', 'method', 'none', 'connection', 'panned', 'got', 'one', 'technical', 'interview', 'coding', 'challenge', 'answered', 'correct', 'invited', 'next', 'round', 'exhausted', 'first', 'round', 'connection', 'time', 'stranger', 'went', 'company', 'page', 'linkedin', 'clicked', 'people', 'filtered', 'data', 'scientist', 'analyst', 'data', 'engineer', 'reached', 'following', 'message', 'subject', 'line', 'fellow', 'university', 'alum', 'wondering', 'company', 'hey', 'name', 'name', 'name', 'finished', 'school', 'degree', 'major', 'background', 'subfiled', 'love', 'seen', 'job', 'description', 'company', 'wondering', 'wouldnt', 'mind', 'connecting', 'answering', 'question', 'data', 'scientist', 'role', 'experience', 'thanks', 'much', 'time', 'best', 'name', 'replace', 'fellow', 'university', 'alum', 'whatever', 'way', 'connect', 'person', 'based', 'profile', 'otherwise', 'say', 'aspiring', 'data', 'scientist', 'something', 'humble', 'eager', 'got', 'several', 'interview', 'referral', 'stranger', 'way', 'takeaway', 'use', 'network', 'reach', 'make', 'many', 'connection', 'possible', 'order', 'learn', 'want', 'dont', 'want', 'may', 'also', 'happy', 'refer', 'position', 'determining', 'professional', 'goal', 'interviewed', 'following', 'position', 'intern', 'research', 'associate', 'data', 'engineer', 'machine', 'learning', 'engineer', 'data', 'analyst', 'product', 'analyst', 'analyst', 'consultant', 'product', 'manager', 'others', 'talked', 'lot', 'people', 'wanted', 'understand', 'motivates', 'experiencing', 'role', 'hope', 'future', 'skill', 'skill', 'transferrable', 'seems', 'coding', 'practice', 'statistical', 'intuition', 'transferrable', 'wanted', 'role', 'would', 'allow', 'improve', 'two', 'thing', 'want', 'able', 'transfer', 'learn', 'next', 'role', 'future', 'role', 'attached', 'particular', 'industry', 'important', 'distinguish', 'love', 'coding', 'want', 'without', 'much', 'challenge', 'want', 'analyst', 'work', 'dont', 'want', 'become', 'leader', 'benchmarking', 'measuring', 'goal', 'feeling', 'others', 'similar', 'different', 'role', 'space', 'excellent', 'way', 'figure', 'want', 'even', 'size', 'company', 'prefer', 'set', 'value', 'prejob', 'offer', 'size', 'company', 'prefer', 'medium', 'team', 'size', 'company', 'without', 'much', 'bureaucracy', 'exposure', 'well', 'datawrangling', 'without', 'much', 'emphasis', 'one', 'mentor', 'help', 'junior', 'developer', 'would', 'enjoy', 'enjoyable', 'connection', 'employee', 'interview', 'process', 'possible', 'company', 'meaningful', 'contribution', 'society', 'positive', 'local', 'impact', 'able', 'bring', 'idea', 'whole', 'self', 'job', 'clockin', 'clockout', 'situation', 'takeaway', 'find', 'position', 'interest', 'try', 'craft', 'profile', 'project', 'skill', 'fit', 'role', 'dont', 'afraid', 'say', 'position', 'dont', 'meet', 'criterion', 'staying', 'motivated', 'turbulence', 'shook', 'everything', 'wasnt', 'securely', 'tied', 'ive', 'spent', 'much', 'free', 'time', 'call', 'friend', 'family', 'navigating', 'challenge', 'facing', 'year', 'weekend', 'whole', 'week', 'didnt', 'anything', 'except', 'scroll', 'reddit', 'tiktok', 'etc', 'felt', 'like', 'shit', 'week', 'felt', 'like', 'superhero', 'learning', 'thing', 'gaining', 'confidence', 'getting', 'website', 'work', 'debugging', 'part', 'data', 'pipeline', 'etc', 'thing', 'helped', 'stay', 'track', 'getting', 'enough', 'nutrient', 'listening', 'body', 'caloric', 'need', 'stretching', 'foamrolling', 'feel', 'stiff', 'uncomfortable', 'sitting', 'day', 'lifting', 'weight', 'going', 'walk', 'taking', 'one', 'two', 'week', 'stop', 'applying', 'rejection', 'fatigue', 'scheduling', 'phone', 'call', 'people', 'boat', 'commiserate', 'watching', 'stand', 'comedy', 'youtube', 'crack', 'laugh', 'break', 'day', 'tension', 'limiting', 'doom', 'scrolling', 'hyper', 'vigilance', 'house', 'mile', 'one', 'fire', 'hard', 'time', 'needed', 'nap', 'took', 'nap', 'unfollow', 'anything', 'isnt', 'encouraging', 'uplifting', 'useful', 'period', 'time', 'giving', 'back', 'lonely', 'journey', 'resource', 'reddit', 'helped', 'massively', 'way', 'give', 'back', 'community', 'want', 'offer', 'following', 'thing', 'free', 'minute', 'zoom', 'call', 'advise', 'answer', 'question', 'get', 'data', 'science', 'job', 'youre', 'looking', 'limited', 'many', 'fit', 'next', 'week', 'dire', 'need', 'tailored', 'response', 'personal', 'question', 'situation', 'via', 'email', 'advice', 'improve', 'resume', 'follow', 'post', 'subreddit', 'answering', 'top', 'several', 'question', 'get', 'answering', 'many', 'question', 'comment', 'ill', 'reply', 'pas', 'case', 'refer', 'resource', 'useful', 'update', 'survey', 'closed', 'see', 'edit', 'edit', 'formatting', 'added', 'link', 'datacamp', 'edit', 'important', 'note', 'worked', 'year', 'nonprofit', 'world', 'coming', 'back', 'school', 'here', 'quote', 'one', 'response', 'worked', 'nonprofit', 'world', 'lot', 'different', 'role', 'responsibility', 'including', 'working', 'abroad', 'humanitarian', 'capacity', 'translating', 'conference', 'logistics', 'operation', 'participating', 'making', 'curriculum', 'staff', 'volunteer', 'casting', 'vision', 'donor', 'funddevelopment', 'capacity', 'etc', 'wish', 'oneliner', 'worked', 'software', 'would', 'satisfying', 'succinct', 'simply', 'complicated', 'edit', 'people', 'suggesting', 'offer', 'zoom', 'call', 'offer', 'resume', 'feedback', 'part', 'nefarious', 'ploy', 'obtain', 'people', 'information', 'manipulate', 'way', 'sorry', 'hear', 'know', 'firm', 'scraping', 'employment', 'data', 'site', 'adequate', 'protection', 'place', 'interacted', 'one', 'company', 'course', 'research', 'would', 'probably', 'efficient', 'make', 'linkedin', 'recruiter', 'profile', 'could', 'thousand', 'email', 'linkedin', 'profile', 'nefarious', 'purpose', 'muahahahaha', 'story', 'recruiting', 'shenanigan', 'check', 'rrecruitinghell', 'best', 'practice', 'relevant', 'quote', 'one', 'comment', 'hey', 'made', 'edit', 'hoped', 'verbal', 'conversation', 'people', 'interested', 'since', 'track', 'record', 'coaching', 'younger', 'student', 'teaching', 'mentorship', 'first', 'way', 'could', 'think', 'give', 'back', 'community', 'aside', 'writing', 'post', 'could', 'certainly', 'method', 'would', 'suggest', 'might', 'help', 'come', 'effectively', 'definitely', 'dont', 'want', 'send', 'wrong', 'message', 'thanks', 'edit', 'added', 'preface', 'section', 'better', 'contextualize', 'story', 'edit', 'closed', 'survey', 'turning', 'notification', 'post', 'following', 'folk', 'filled', 'survey', 'writing', 'follow', 'post', 'get', 'feedback', 'useful', 'thanks', 'celebrating', 'helping', 'make', 'sure', 'post', 'useful', 'community', 'possible', 'also', 'received', 'rather', 'hateful', 'message', 'people', 'disbelieving', 'story', 'hard', 'work', 'flattered', 'disbelief', 'underscore', 'incredible', 'journey', 'next', 'time']",,,,
bh3kko,Too True,,1556160594.0,963.0,34.0,/r/datascience/comments/bh3kko/too_true/,https://i.redd.it/533ec87e88u21.jpg,,datascience,0.95,False,False,False,False,0.0,1745834739.913718,Tech & Programming,2.0,0.0,2.0,Wednesday,22.0,April,2019.0,False,0.4215,0.737,0.0,0.263,positive,too true,,too true ,true,2019-04-25 02:49:54,too true ,['true'],,,,
1fcs1hd,An actual graph made by actual people.,,1725895312.0,956.0,126.0,/r/datascience/comments/1fcs1hd/an_actual_graph_made_by_actual_people/,https://i.redd.it/kyzup32o0mnd1.jpeg,Massive-Traffic-9970,datascience,0.89,False,False,False,False,0.0,1745834740.21725,Tech & Programming,7.0,0.0,7.0,Monday,11.0,September,2024.0,False,0.0,0.0,0.0,1.0,neutral,an actual graph made by actual people,,an actual graph made by actual people ,"actual, graph, made, people",2024-09-09 15:21:52,an actual graph made by actual people ,"['actual', 'graph', 'made', 'actual', 'people']",,,,
opnzmc,Jut got fired,"Hey, just wanted to share this, as I am feeling a bit down and feeling kinda of a failure. Got fired on my 3rd month.

I got my 1st job after graduating with 2 internships under my belt. I felt I was ready to take on the world.

I started to work for a start up, I moved countries, I was really excited about it but apparently I couldn't present results fast enough or accurate enough.

I always like to assume responsibility, as it is the only way to growth.

On my 1st month I was working with the wrong tables, PMs told me to work with those tables, but those were the wrong tables. I eventually found that I had to request special access to my department's tables... and for some reason those tables were hidden from general view...

2nd and 3rd months I was working with SQL+JSON tables plus all the side tasks. Apparently I did not manage to fully understand the concept of SQL + JSON very well. My numbers were always wrong.

The pandemic hasn't been kind to me (and many others, I know) my focus hasn't been what is used to be, I feel slower, less energetic and less smart.. And the other day I was sent by back to my country, yesterday I broke up with a girl I was seeing... Everything sucks at the moment.

I am not really sure what to do. I like SQL, I like helping business making sense of data, I like doing ad-hocs projects in R or Python. Or at least I thought I did...

I am starting to doubt myself, I feel I am not good enough and that Data might not be for me...

I am sure things will get better, but right now they suck very much.

Thanks for reading

&#x200B;

EDIT: WOW!! Thank you everyone for the support and kind words. It is also refreshing to read other's peopl experience. It makes me feel less alone in this situation. Thank you for the support, it is really amazing, you are all making me feel way better!!! ""YOU DA BEST"" :D

UPDATE: I already have a couple of interviews lined up, so I am sure everything will be fine.",1626990654.0,952.0,181.0,/r/datascience/comments/opnzmc/jut_got_fired/,https://www.reddit.com/r/datascience/comments/opnzmc/jut_got_fired/,,datascience,0.97,True,False,False,False,0.0,1745834760.761887,Tech & Programming,3.0,374.0,375.0,Thursday,17.0,July,2021.0,False,0.9842,0.195,0.125,0.68,positive,jut got fired,hey just wanted to share this as i am feeling a bit down and feeling kinda of a failure got fired on my rd month i got my st job after graduating with internships under my belt i felt i was ready to take on the world i started to work for a start up i moved countries i was really excited about it but apparently i couldnt present results fast enough or accurate enough i always like to assume responsibility as it is the only way to growth on my st month i was working with the wrong tables pms told me to work with those tables but those were the wrong tables i eventually found that i had to request special access to my departments tables and for some reason those tables were hidden from general view nd and rd months i was working with sqljson tables plus all the side tasks apparently i did not manage to fully understand the concept of sql json very well my numbers were always wrong the pandemic hasnt been kind to me and many others i know my focus hasnt been what is used to be i feel slower less energetic and less smart and the other day i was sent by back to my country yesterday i broke up with a girl i was seeing everything sucks at the moment i am not really sure what to do i like sql i like helping business making sense of data i like doing adhocs projects in r or python or at least i thought i did i am starting to doubt myself i feel i am not good enough and that data might not be for me i am sure things will get better but right now they suck very much thanks for reading xb edit wow thank you everyone for the support and kind words it is also refreshing to read others peopl experience it makes me feel less alone in this situation thank you for the support it is really amazing you are all making me feel way better you da best d update i already have a couple of interviews lined up so i am sure everything will be fine,jut got fired hey just wanted to share this as i am feeling a bit down and feeling kinda of a failure got fired on my rd month i got my st job after graduating with internships under my belt i felt i was ready to take on the world i started to work for a start up i moved countries i was really excited about it but apparently i couldnt present results fast enough or accurate enough i always like to assume responsibility as it is the only way to growth on my st month i was working with the wrong tables pms told me to work with those tables but those were the wrong tables i eventually found that i had to request special access to my departments tables and for some reason those tables were hidden from general view nd and rd months i was working with sqljson tables plus all the side tasks apparently i did not manage to fully understand the concept of sql json very well my numbers were always wrong the pandemic hasnt been kind to me and many others i know my focus hasnt been what is used to be i feel slower less energetic and less smart and the other day i was sent by back to my country yesterday i broke up with a girl i was seeing everything sucks at the moment i am not really sure what to do i like sql i like helping business making sense of data i like doing adhocs projects in r or python or at least i thought i did i am starting to doubt myself i feel i am not good enough and that data might not be for me i am sure things will get better but right now they suck very much thanks for reading xb edit wow thank you everyone for the support and kind words it is also refreshing to read others peopl experience it makes me feel less alone in this situation thank you for the support it is really amazing you are all making me feel way better you da best d update i already have a couple of interviews lined up so i am sure everything will be fine,"table, like, feel, got, month",2021-07-22 21:50:54,jut got fired hey just wanted to share this as i am feeling a bit down and feeling kinda of a failure got fired on my rd month i got my st job after graduating with internships under my belt i felt i was ready to take on the world i started to work for a start up i moved countries i was really excited about it but apparently i couldnt present results fast enough or accurate enough i always like to assume responsibility as it is the only way to growth on my st month i was working with the wrong tables pms told me to work with those tables but those were the wrong tables i eventually found that i had to request special access to my departments tables and for some reason those tables were hidden from general view nd and rd months i was working with sqljson tables plus all the side tasks apparently i did not manage to fully understand the concept of sql json very well my numbers were always wrong the pandemic hasnt been kind to me and many others i know my focus hasnt been what is used to be i feel slower less energetic and less smart and the other day i was sent by back to my country yesterday i broke up with a girl i was seeing everything sucks at the moment i am not really sure what to do i like sql i like helping business making sense of data i like doing adhocs projects in r or python or at least i thought i did i am starting to doubt myself i feel i am not good enough and that data might not be for me i am sure things will get better but right now they suck very much thanks for reading xb edit wow thank you everyone for the support and kind words it is also refreshing to read others peopl experience it makes me feel less alone in this situation thank you for the support it is really amazing you are all making me feel way better you da best d update i already have a couple of interviews lined up so i am sure everything will be fine,"['jut', 'got', 'fired', 'hey', 'wanted', 'share', 'feeling', 'bit', 'feeling', 'kinda', 'failure', 'got', 'fired', 'month', 'got', 'job', 'graduating', 'internship', 'belt', 'felt', 'ready', 'take', 'world', 'started', 'work', 'start', 'moved', 'country', 'really', 'excited', 'apparently', 'couldnt', 'present', 'result', 'fast', 'enough', 'accurate', 'enough', 'always', 'like', 'assume', 'responsibility', 'way', 'growth', 'month', 'working', 'wrong', 'table', 'pm', 'told', 'work', 'table', 'wrong', 'table', 'eventually', 'found', 'request', 'special', 'access', 'department', 'table', 'reason', 'table', 'hidden', 'general', 'view', 'month', 'working', 'sqljson', 'table', 'plus', 'side', 'task', 'apparently', 'manage', 'fully', 'understand', 'concept', 'sql', 'json', 'well', 'number', 'always', 'wrong', 'pandemic', 'hasnt', 'kind', 'many', 'others', 'know', 'focus', 'hasnt', 'used', 'feel', 'slower', 'less', 'energetic', 'less', 'smart', 'day', 'sent', 'back', 'country', 'yesterday', 'broke', 'girl', 'seeing', 'everything', 'suck', 'moment', 'really', 'sure', 'like', 'sql', 'like', 'helping', 'business', 'making', 'sense', 'data', 'like', 'adhocs', 'project', 'python', 'least', 'thought', 'starting', 'doubt', 'feel', 'good', 'enough', 'data', 'might', 'sure', 'thing', 'get', 'better', 'right', 'suck', 'much', 'thanks', 'reading', 'edit', 'wow', 'thank', 'everyone', 'support', 'kind', 'word', 'also', 'refreshing', 'read', 'others', 'peopl', 'experience', 'make', 'feel', 'less', 'alone', 'situation', 'thank', 'support', 'really', 'amazing', 'making', 'feel', 'way', 'better', 'best', 'update', 'already', 'couple', 'interview', 'lined', 'sure', 'everything', 'fine']",,,,
wvsu4r,iPhone orientation from image segmentation,,1661271150.0,931.0,30.0,/r/datascience/comments/wvsu4r/iphone_orientation_from_image_segmentation/,https://i.redd.it/i7ddvspimhj91.gif,DistanceThat1503,datascience,0.95,False,False,False,False,0.0,1745834761.677968,Tech & Programming,5.0,0.0,5.0,Tuesday,12.0,August,2022.0,False,0.0,0.0,0.0,1.0,neutral,iphone orientation from image segmentation,,iphone orientation from image segmentation ,"iphone, orientation, image, segmentation",2022-08-23 16:12:30,iphone orientation from image segmentation ,"['iphone', 'orientation', 'image', 'segmentation']",,,,
sh4otq,Cleaning the data to get it ready for analysis. Hehe!,,1643645114.0,937.0,35.0,/r/datascience/comments/sh4otq/cleaning_the_data_to_get_it_ready_for_analysis/,https://i.redd.it/vy7o0jp1r1f81.png,RapidActionBattalion,datascience,0.9,False,False,False,False,0.0,1745834761.968196,Tech & Programming,10.0,0.0,10.0,Monday,11.0,January,2022.0,False,0.3612,0.217,0.0,0.783,positive,cleaning the data to get it ready for analysis hehe,,cleaning the data to get it ready for analysis hehe ,"cleaning, data, get, ready, analysis",2022-01-31 16:05:14,cleaning the data to get it ready for analysis hehe ,"['cleaning', 'data', 'get', 'ready', 'analysis', 'hehe']",,,,
u1ivbw,How I achieved a 6-figure base salary Data Scientist job with 1 year of work experience and a bachelor's degree.,"EDIT: Here is my resume per request. Please don't reverse-engineer this and leak my info somehow, or track this to something connected to me. Trying to do you all a service without it backfiring. [https://ibb.co/zRGqhq0](https://ibb.co/zRGqhq0) I do want to mention that just DOING interviews made me better. My first interviews were a train-wreck. By the end, I felt like an interview expert.

For context, I am 23yo from the US. I have a Math degree from a no-name university, I have taken 0 bootcamps, and I have only taken intro coding courses. I also have some statistics courses under my belt. I have 1 year of relevant work experience and some projects. Let me not undersell myself, but I am far from an expert-level candidate and I have minimal experience.

Here are my tips for getting an interview and job when you're competing with 100s of candidates that all might have more work experience and advanced degrees.

I must first put out that I am a man of faith, so I give God credit. But after that, here are my tips:

**You need a GREAT resume.**

You are competing with advanced degrees and people who probably have much more experience than you. You cannot get away with a bad resume, you simply will be denied immediately. You must do the following:

* Quantify what you did, and how it impacted the business.
* USE KEYWORDS. I don't care if you just touched Keras, put it somewhere on your resume. Some are against this, but use a Skills section at the bottom to include the keywords and then also include them in your highlights. You're looking to at least get an HR interview, your resume will get you there.
* Find a really good-looking template that stands out. Not color, but with formatting.

**Apply Everywhere**

For me, I used LinkedIn exclusively. I did not apply to anything that made me do much more than submit a resume. Its not worth your time. In my experience, take-home coding tests are only worth your time if you've done a series of interviews, it takes 3 hours or less and, the company has shown interest as well.

* Apply even if you're not qualified (not horribly unqualified though). There's flexibility in YOE. I actually got a job interview with somewhere asking for a Masters and 8+ YOE.

**STUDY UP**

* Understand basic statistics. Seriously. Be able to explain every way you'd perform a test and why. What would you do with unbalanced data? Etc.
* Be able to explain a model thoroughly, why would you use it? I was asked to explain loss, variance, bias, what loss function I might use, etc.
* Practice your coding, most of these are in Python
* You must know SQL, preferably advanced-level. I had more SQL coding questions than anything else.

**KNOW YOUR EMPLOYER**

* They WILL ask you case-study questions. You must be able to think outside the box.
* Act super-enthused about their position, even if you are applying elsewhere and its not your #1

**DON'T GIVE UP**

* I submitted easily over 200 applications, received calls on maybe 20 of them, got to the final interviews on 7, was denied on 5, and offered 2.

**MISTAKES I MADE**

* Not remembering my basic statistics, I actually messed up on one interview about ""How would you describe a p-value to a non-technical audience.""
* Not being able to communicate how my projects impacted the company. I have good project experience, but for my first final interview, I had a lot of trouble trying to explain the business impact and how I solved issues. These need to be fresh in your mind.
* Not acting interested. I had at one time, 5 different companies interviewing me and I didn't have much energy to care about each one. This ruined a few of my chances.
* Not studying on the work department. If you are applying to a marketing position, understand a little about marketing... They chose another candidate when I likely would have been chosen had I known a little more background knowledge.

I WILL ANSWER ANY QUESTIONS IN THE COMMENTS.",1649714402.0,939.0,215.0,/r/datascience/comments/u1ivbw/how_i_achieved_a_6figure_base_salary_data/,https://www.reddit.com/r/datascience/comments/u1ivbw/how_i_achieved_a_6figure_base_salary_data/,yukobeam,datascience,0.92,True,False,False,False,0.0,1745834762.256886,Tech & Programming,20.0,695.0,687.0,Monday,18.0,April,2022.0,False,-0.7419,0.074,0.082,0.844,negative,how i achieved a figure base salary data scientist job with year of work experience and a bachelors degree,edit here is my resume per request please dont reverseengineer this and leak my info somehow or track this to something connected to me trying to do you all a service without it backfiring i do want to mention that just doing interviews made me better my first interviews were a trainwreck by the end i felt like an interview expert for context i am yo from the us i have a math degree from a noname university i have taken bootcamps and i have only taken intro coding courses i also have some statistics courses under my belt i have year of relevant work experience and some projects let me not undersell myself but i am far from an expertlevel candidate and i have minimal experience here are my tips for getting an interview and job when youre competing with s of candidates that all might have more work experience and advanced degrees i must first put out that i am a man of faith so i give god credit but after that here are my tips you need a great resume you are competing with advanced degrees and people who probably have much more experience than you you cannot get away with a bad resume you simply will be denied immediately you must do the following quantify what you did and how it impacted the business use keywords i dont care if you just touched keras put it somewhere on your resume some are against this but use a skills section at the bottom to include the keywords and then also include them in your highlights youre looking to at least get an hr interview your resume will get you there find a really goodlooking template that stands out not color but with formatting apply everywhere for me i used linkedin exclusively i did not apply to anything that made me do much more than submit a resume its not worth your time in my experience takehome coding tests are only worth your time if youve done a series of interviews it takes hours or less and the company has shown interest as well apply even if youre not qualified not horribly unqualified though theres flexibility in yoe i actually got a job interview with somewhere asking for a masters and yoe study up understand basic statistics seriously be able to explain every way youd perform a test and why what would you do with unbalanced data etc be able to explain a model thoroughly why would you use it i was asked to explain loss variance bias what loss function i might use etc practice your coding most of these are in python you must know sql preferably advancedlevel i had more sql coding questions than anything else know your employer they will ask you casestudy questions you must be able to think outside the box act superenthused about their position even if you are applying elsewhere and its not your dont give up i submitted easily over applications received calls on maybe of them got to the final interviews on was denied on and offered mistakes i made not remembering my basic statistics i actually messed up on one interview about how would you describe a pvalue to a nontechnical audience not being able to communicate how my projects impacted the company i have good project experience but for my first final interview i had a lot of trouble trying to explain the business impact and how i solved issues these need to be fresh in your mind not acting interested i had at one time different companies interviewing me and i didnt have much energy to care about each one this ruined a few of my chances not studying on the work department if you are applying to a marketing position understand a little about marketing they chose another candidate when i likely would have been chosen had i known a little more background knowledge i will answer any questions in the comments,how i achieved a figure base salary data scientist job with year of work experience and a bachelors degree edit here is my resume per request please dont reverseengineer this and leak my info somehow or track this to something connected to me trying to do you all a service without it backfiring i do want to mention that just doing interviews made me better my first interviews were a trainwreck by the end i felt like an interview expert for context i am yo from the us i have a math degree from a noname university i have taken bootcamps and i have only taken intro coding courses i also have some statistics courses under my belt i have year of relevant work experience and some projects let me not undersell myself but i am far from an expertlevel candidate and i have minimal experience here are my tips for getting an interview and job when youre competing with s of candidates that all might have more work experience and advanced degrees i must first put out that i am a man of faith so i give god credit but after that here are my tips you need a great resume you are competing with advanced degrees and people who probably have much more experience than you you cannot get away with a bad resume you simply will be denied immediately you must do the following quantify what you did and how it impacted the business use keywords i dont care if you just touched keras put it somewhere on your resume some are against this but use a skills section at the bottom to include the keywords and then also include them in your highlights youre looking to at least get an hr interview your resume will get you there find a really goodlooking template that stands out not color but with formatting apply everywhere for me i used linkedin exclusively i did not apply to anything that made me do much more than submit a resume its not worth your time in my experience takehome coding tests are only worth your time if youve done a series of interviews it takes hours or less and the company has shown interest as well apply even if youre not qualified not horribly unqualified though theres flexibility in yoe i actually got a job interview with somewhere asking for a masters and yoe study up understand basic statistics seriously be able to explain every way youd perform a test and why what would you do with unbalanced data etc be able to explain a model thoroughly why would you use it i was asked to explain loss variance bias what loss function i might use etc practice your coding most of these are in python you must know sql preferably advancedlevel i had more sql coding questions than anything else know your employer they will ask you casestudy questions you must be able to think outside the box act superenthused about their position even if you are applying elsewhere and its not your dont give up i submitted easily over applications received calls on maybe of them got to the final interviews on was denied on and offered mistakes i made not remembering my basic statistics i actually messed up on one interview about how would you describe a pvalue to a nontechnical audience not being able to communicate how my projects impacted the company i have good project experience but for my first final interview i had a lot of trouble trying to explain the business impact and how i solved issues these need to be fresh in your mind not acting interested i had at one time different companies interviewing me and i didnt have much energy to care about each one this ruined a few of my chances not studying on the work department if you are applying to a marketing position understand a little about marketing they chose another candidate when i likely would have been chosen had i known a little more background knowledge i will answer any questions in the comments,"interview, experience, resume, work, degree",2022-04-11 22:00:02,how i achieved a figure base salary data scientist job with year of work experience and a bachelors degree edit here is my resume per request please dont reverseengineer this and leak my info somehow or track this to something connected to me trying to do you all a service without it backfiring i do want to mention that just doing interviews made me better my first interviews were a trainwreck by the end i felt like an interview expert for context i am yo from the us i have a math degree from a noname university i have taken bootcamps and i have only taken intro coding courses i also have some statistics courses under my belt i have year of relevant work experience and some projects let me not undersell myself but i am far from an expertlevel candidate and i have minimal experience here are my tips for getting an interview and job when youre competing with s of candidates that all might have more work experience and advanced degrees i must first put out that i am a man of faith so i give god credit but after that here are my tips you need a great resume you are competing with advanced degrees and people who probably have much more experience than you you cannot get away with a bad resume you simply will be denied immediately you must do the following quantify what you did and how it impacted the business use keywords i dont care if you just touched keras put it somewhere on your resume some are against this but use a skills section at the bottom to include the keywords and then also include them in your highlights youre looking to at least get an hr interview your resume will get you there find a really goodlooking template that stands out not color but with formatting apply everywhere for me i used linkedin exclusively i did not apply to anything that made me do much more than submit a resume its not worth your time in my experience takehome coding tests are only worth your time if youve done a series of interviews it takes hours or less and the company has shown interest as well apply even if youre not qualified not horribly unqualified though theres flexibility in yoe i actually got a job interview with somewhere asking for a masters and yoe study up understand basic statistics seriously be able to explain every way youd perform a test and why what would you do with unbalanced data etc be able to explain a model thoroughly why would you use it i was asked to explain loss variance bias what loss function i might use etc practice your coding most of these are in python you must know sql preferably advancedlevel i had more sql coding questions than anything else know your employer they will ask you casestudy questions you must be able to think outside the box act superenthused about their position even if you are applying elsewhere and its not your dont give up i submitted easily over applications received calls on maybe of them got to the final interviews on was denied on and offered mistakes i made not remembering my basic statistics i actually messed up on one interview about how would you describe a pvalue to a nontechnical audience not being able to communicate how my projects impacted the company i have good project experience but for my first final interview i had a lot of trouble trying to explain the business impact and how i solved issues these need to be fresh in your mind not acting interested i had at one time different companies interviewing me and i didnt have much energy to care about each one this ruined a few of my chances not studying on the work department if you are applying to a marketing position understand a little about marketing they chose another candidate when i likely would have been chosen had i known a little more background knowledge i will answer any questions in the comments,"['achieved', 'figure', 'base', 'salary', 'data', 'scientist', 'job', 'year', 'work', 'experience', 'bachelor', 'degree', 'edit', 'resume', 'per', 'request', 'please', 'dont', 'reverseengineer', 'leak', 'info', 'somehow', 'track', 'something', 'connected', 'trying', 'service', 'without', 'backfiring', 'want', 'mention', 'interview', 'made', 'better', 'first', 'interview', 'trainwreck', 'end', 'felt', 'like', 'interview', 'expert', 'context', 'math', 'degree', 'noname', 'university', 'taken', 'bootcamps', 'taken', 'intro', 'coding', 'course', 'also', 'statistic', 'course', 'belt', 'year', 'relevant', 'work', 'experience', 'project', 'let', 'undersell', 'far', 'expertlevel', 'candidate', 'minimal', 'experience', 'tip', 'getting', 'interview', 'job', 'youre', 'competing', 'candidate', 'might', 'work', 'experience', 'advanced', 'degree', 'must', 'first', 'put', 'man', 'faith', 'give', 'god', 'credit', 'tip', 'need', 'great', 'resume', 'competing', 'advanced', 'degree', 'people', 'probably', 'much', 'experience', 'get', 'away', 'bad', 'resume', 'simply', 'denied', 'immediately', 'must', 'following', 'quantify', 'impacted', 'business', 'use', 'keywords', 'dont', 'care', 'touched', 'kera', 'put', 'somewhere', 'resume', 'use', 'skill', 'section', 'bottom', 'include', 'keywords', 'also', 'include', 'highlight', 'youre', 'looking', 'least', 'get', 'interview', 'resume', 'get', 'find', 'really', 'goodlooking', 'template', 'stand', 'color', 'formatting', 'apply', 'everywhere', 'used', 'linkedin', 'exclusively', 'apply', 'anything', 'made', 'much', 'submit', 'resume', 'worth', 'time', 'experience', 'takehome', 'coding', 'test', 'worth', 'time', 'youve', 'done', 'series', 'interview', 'take', 'hour', 'less', 'company', 'shown', 'interest', 'well', 'apply', 'even', 'youre', 'qualified', 'horribly', 'unqualified', 'though', 'there', 'flexibility', 'yoe', 'actually', 'got', 'job', 'interview', 'somewhere', 'asking', 'master', 'yoe', 'study', 'understand', 'basic', 'statistic', 'seriously', 'able', 'explain', 'every', 'way', 'youd', 'perform', 'test', 'would', 'unbalanced', 'data', 'etc', 'able', 'explain', 'model', 'thoroughly', 'would', 'use', 'asked', 'explain', 'loss', 'variance', 'bias', 'loss', 'function', 'might', 'use', 'etc', 'practice', 'coding', 'python', 'must', 'know', 'sql', 'preferably', 'advancedlevel', 'sql', 'coding', 'question', 'anything', 'else', 'know', 'employer', 'ask', 'casestudy', 'question', 'must', 'able', 'think', 'outside', 'box', 'act', 'superenthused', 'position', 'even', 'applying', 'elsewhere', 'dont', 'give', 'submitted', 'easily', 'application', 'received', 'call', 'maybe', 'got', 'final', 'interview', 'denied', 'offered', 'mistake', 'made', 'remembering', 'basic', 'statistic', 'actually', 'messed', 'one', 'interview', 'would', 'describe', 'pvalue', 'nontechnical', 'audience', 'able', 'communicate', 'project', 'impacted', 'company', 'good', 'project', 'experience', 'first', 'final', 'interview', 'lot', 'trouble', 'trying', 'explain', 'business', 'impact', 'solved', 'issue', 'need', 'fresh', 'mind', 'acting', 'interested', 'one', 'time', 'different', 'company', 'interviewing', 'didnt', 'much', 'energy', 'care', 'one', 'ruined', 'chance', 'studying', 'work', 'department', 'applying', 'marketing', 'position', 'understand', 'little', 'marketing', 'chose', 'another', 'candidate', 'likely', 'would', 'chosen', 'known', 'little', 'background', 'knowledge', 'answer', 'question', 'comment']",,,,
nmyg3i,First two weeks of my first internship,"Today, I got my first paycheck from my first internship and I am shocked about the entire situation. I come from a poor family, I am the first of my family to college (and grad-school) and the first to have a real professional work experience. I honestly feel blessed to be able to improve on my data science abilities and get paid for it! 

I have been working with the lead data scientist and have learned so much in these past two weeks. I enjoy coming to work and even more so now that I saw the paycheck. 

Sorry for the weird post, but I am just in a good mood right now. 

P.s. My boss asked me if I want to continue my internship for the Fall

**Update**
About 330 days have passed since I first started my internship and things couldn’t be better.
I ended up working remotely during the Fall and part of the spring semester but eventually decided to put my two weeks in - no issue with the company nor work, but decided I needed to allocate some more time on school (one course in particular). Luckily, I have been applying for jobs since September and landed an associate Data Scientist position at a large tech company, not FAANG, and start in August 2022. In this past year my life has changed so much and I am truly grateful for every bit of it. I still feel like I don’t deserve this job or that I’m not good enough, but I hope that this imposter syndrome goes away once I start working.",1622210376.0,936.0,69.0,/r/datascience/comments/nmyg3i/first_two_weeks_of_my_first_internship/,https://www.reddit.com/r/datascience/comments/nmyg3i/first_two_weeks_of_my_first_internship/,royal-Brwn,datascience,0.97,True,False,False,False,0.0,1745834763.686132,Tech & Programming,7.0,267.0,271.0,Friday,9.0,May,2021.0,False,0.9807,0.138,0.043,0.819,positive,first two weeks of my first internship,today i got my first paycheck from my first internship and i am shocked about the entire situation i come from a poor family i am the first of my family to college and gradschool and the first to have a real professional work experience i honestly feel blessed to be able to improve on my data science abilities and get paid for it i have been working with the lead data scientist and have learned so much in these past two weeks i enjoy coming to work and even more so now that i saw the paycheck sorry for the weird post but i am just in a good mood right now ps my boss asked me if i want to continue my internship for the fall update about days have passed since i first started my internship and things couldnt be better i ended up working remotely during the fall and part of the spring semester but eventually decided to put my two weeks in no issue with the company nor work but decided i needed to allocate some more time on school one course in particular luckily i have been applying for jobs since september and landed an associate data scientist position at a large tech company not faang and start in august in this past year my life has changed so much and i am truly grateful for every bit of it i still feel like i dont deserve this job or that im not good enough but i hope that this imposter syndrome goes away once i start working,first two weeks of my first internship today i got my first paycheck from my first internship and i am shocked about the entire situation i come from a poor family i am the first of my family to college and gradschool and the first to have a real professional work experience i honestly feel blessed to be able to improve on my data science abilities and get paid for it i have been working with the lead data scientist and have learned so much in these past two weeks i enjoy coming to work and even more so now that i saw the paycheck sorry for the weird post but i am just in a good mood right now ps my boss asked me if i want to continue my internship for the fall update about days have passed since i first started my internship and things couldnt be better i ended up working remotely during the fall and part of the spring semester but eventually decided to put my two weeks in no issue with the company nor work but decided i needed to allocate some more time on school one course in particular luckily i have been applying for jobs since september and landed an associate data scientist position at a large tech company not faang and start in august in this past year my life has changed so much and i am truly grateful for every bit of it i still feel like i dont deserve this job or that im not good enough but i hope that this imposter syndrome goes away once i start working,"first, internship, two, week, work",2021-05-28 13:59:36,first two weeks of my first internship today i got my first paycheck from my first internship and i am shocked about the entire situation i come from a poor family i am the first of my family to college and gradschool and the first to have a real professional work experience i honestly feel blessed to be able to improve on my data science abilities and get paid for it i have been working with the lead data scientist and have learned so much in these past two weeks i enjoy coming to work and even more so now that i saw the paycheck sorry for the weird post but i am just in a good mood right now ps my boss asked me if i want to continue my internship for the fall update about days have passed since i first started my internship and things couldnt be better i ended up working remotely during the fall and part of the spring semester but eventually decided to put my two weeks in no issue with the company nor work but decided i needed to allocate some more time on school one course in particular luckily i have been applying for jobs since september and landed an associate data scientist position at a large tech company not faang and start in august in this past year my life has changed so much and i am truly grateful for every bit of it i still feel like i dont deserve this job or that im not good enough but i hope that this imposter syndrome goes away once i start working,"['first', 'two', 'week', 'first', 'internship', 'today', 'got', 'first', 'paycheck', 'first', 'internship', 'shocked', 'entire', 'situation', 'come', 'poor', 'family', 'first', 'family', 'college', 'gradschool', 'first', 'real', 'professional', 'work', 'experience', 'honestly', 'feel', 'blessed', 'able', 'improve', 'data', 'science', 'ability', 'get', 'paid', 'working', 'lead', 'data', 'scientist', 'learned', 'much', 'past', 'two', 'week', 'enjoy', 'coming', 'work', 'even', 'saw', 'paycheck', 'sorry', 'weird', 'post', 'good', 'mood', 'right', 'bos', 'asked', 'want', 'continue', 'internship', 'fall', 'update', 'day', 'passed', 'since', 'first', 'started', 'internship', 'thing', 'couldnt', 'better', 'ended', 'working', 'remotely', 'fall', 'part', 'spring', 'semester', 'eventually', 'decided', 'put', 'two', 'week', 'issue', 'company', 'work', 'decided', 'needed', 'allocate', 'time', 'school', 'one', 'course', 'particular', 'luckily', 'applying', 'job', 'since', 'september', 'landed', 'associate', 'data', 'scientist', 'position', 'large', 'tech', 'company', 'faang', 'start', 'august', 'past', 'year', 'life', 'changed', 'much', 'truly', 'grateful', 'every', 'bit', 'still', 'feel', 'like', 'dont', 'deserve', 'job', 'good', 'enough', 'hope', 'imposter', 'syndrome', 'go', 'away', 'start', 'working']",,,,
wi2gil,The Data Science Hierarchy of Needs,,1659832045.0,928.0,70.0,/r/datascience/comments/wi2gil/the_data_science_hierarchy_of_needs/,https://i.redd.it/khoyuqg8r6g91.png,,datascience,0.95,False,False,False,False,0.0,1745834764.230693,Tech & Programming,6.0,0.0,6.0,Saturday,20.0,August,2022.0,True,0.0,0.0,0.0,1.0,neutral,the data science hierarchy of needs,,the data science hierarchy of needs ,"data, science, hierarchy, need",2022-08-07 00:27:25,the data science hierarchy of needs ,"['data', 'science', 'hierarchy', 'need']",,,,
lgiug8,Remember to stop every once in a while and think about how far you've come.,"It's not news to any of us that impostor syndrome is real and that in this field, you'll probably always feel like you don't know anything. But this week, after two years in data science, I finished my first real, entirely self-driven and deployed end-to-end project and, [after publishing it](https://www.reddit.com/r/Letterboxd/comments/lfp2h8/as_promised_here_is_a_demo_of_the_recommendation/), I got an e-mail from someone who was excited to learn more about it because they're just starting out on this journey. 

That made me realize that not long ago, I was that person, who would see something like this and have no idea how to do it, but really wanting to know how. And now I do! And of course there are still many things I'm unsure of, completely ignorant of, things I know that I'm doing wrong and things that I don't know that I'm doing wrong - but it feels good to look back and see that I've grown, and that I'm now in the position to help others as others have helped me.

So if you panic or feel helpless when faced with a new, difficult and unfamiliar concept, try to remember that at one point, the things that now come naturally to you also felt that way. And take a second to breathe and realize how far you've come.

EDIT: I'm really happy this resonated with people and reading the comments really warmed my heart. This sub and field can feel really harsh at times so go easy on yourself!",1612920828.0,931.0,53.0,/r/datascience/comments/lgiug8/remember_to_stop_every_once_in_a_while_and_think/,https://www.reddit.com/r/datascience/comments/lgiug8/remember_to_stop_every_once_in_a_while_and_think/,danquandt,datascience,0.98,True,False,False,False,0.0,1745834764.557647,Tech & Programming,15.0,245.0,259.0,Tuesday,20.0,February,2021.0,False,-0.7452,0.096,0.118,0.786,negative,remember to stop every once in a while and think about how far youve come,its not news to any of us that impostor syndrome is real and that in this field youll probably always feel like you dont know anything but this week after two years in data science i finished my first real entirely selfdriven and deployed endtoend project and after publishing it i got an email from someone who was excited to learn more about it because theyre just starting out on this journey that made me realize that not long ago i was that person who would see something like this and have no idea how to do it but really wanting to know how and now i do and of course there are still many things im unsure of completely ignorant of things i know that im doing wrong and things that i dont know that im doing wrong but it feels good to look back and see that ive grown and that im now in the position to help others as others have helped me so if you panic or feel helpless when faced with a new difficult and unfamiliar concept try to remember that at one point the things that now come naturally to you also felt that way and take a second to breathe and realize how far youve come edit im really happy this resonated with people and reading the comments really warmed my heart this sub and field can feel really harsh at times so go easy on yourself,remember to stop every once in a while and think about how far youve come its not news to any of us that impostor syndrome is real and that in this field youll probably always feel like you dont know anything but this week after two years in data science i finished my first real entirely selfdriven and deployed endtoend project and after publishing it i got an email from someone who was excited to learn more about it because theyre just starting out on this journey that made me realize that not long ago i was that person who would see something like this and have no idea how to do it but really wanting to know how and now i do and of course there are still many things im unsure of completely ignorant of things i know that im doing wrong and things that i dont know that im doing wrong but it feels good to look back and see that ive grown and that im now in the position to help others as others have helped me so if you panic or feel helpless when faced with a new difficult and unfamiliar concept try to remember that at one point the things that now come naturally to you also felt that way and take a second to breathe and realize how far youve come edit im really happy this resonated with people and reading the comments really warmed my heart this sub and field can feel really harsh at times so go easy on yourself,"feel, know, really, thing, come",2021-02-10 01:33:48,remember to stop every once in a while and think about how far youve come its not news to any of us that impostor syndrome is real and that in this field youll probably always feel like you dont know anything but this week after two years in data science i finished my first real entirely selfdriven and deployed endtoend project and after publishing it i got an email from someone who was excited to learn more about it because theyre just starting out on this journey that made me realize that not long ago i was that person who would see something like this and have no idea how to do it but really wanting to know how and now i do and of course there are still many things im unsure of completely ignorant of things i know that im doing wrong and things that i dont know that im doing wrong but it feels good to look back and see that ive grown and that im now in the position to help others as others have helped me so if you panic or feel helpless when faced with a new difficult and unfamiliar concept try to remember that at one point the things that now come naturally to you also felt that way and take a second to breathe and realize how far youve come edit im really happy this resonated with people and reading the comments really warmed my heart this sub and field can feel really harsh at times so go easy on yourself,"['remember', 'stop', 'every', 'think', 'far', 'youve', 'come', 'news', 'impostor', 'syndrome', 'real', 'field', 'youll', 'probably', 'always', 'feel', 'like', 'dont', 'know', 'anything', 'week', 'two', 'year', 'data', 'science', 'finished', 'first', 'real', 'entirely', 'selfdriven', 'deployed', 'endtoend', 'project', 'publishing', 'got', 'email', 'someone', 'excited', 'learn', 'theyre', 'starting', 'journey', 'made', 'realize', 'long', 'ago', 'person', 'would', 'see', 'something', 'like', 'idea', 'really', 'wanting', 'know', 'course', 'still', 'many', 'thing', 'unsure', 'completely', 'ignorant', 'thing', 'know', 'wrong', 'thing', 'dont', 'know', 'wrong', 'feel', 'good', 'look', 'back', 'see', 'ive', 'grown', 'position', 'help', 'others', 'others', 'helped', 'panic', 'feel', 'helpless', 'faced', 'new', 'difficult', 'unfamiliar', 'concept', 'try', 'remember', 'one', 'point', 'thing', 'come', 'naturally', 'also', 'felt', 'way', 'take', 'second', 'breathe', 'realize', 'far', 'youve', 'come', 'edit', 'really', 'happy', 'resonated', 'people', 'reading', 'comment', 'really', 'warmed', 'heart', 'sub', 'field', 'feel', 'really', 'harsh', 'time', 'easy']",,,,
efwlcs,Christmas gift from girlfriend. Can't wait to read all. Hope everyone here had a blessed holiday season!,,1577373626.0,929.0,50.0,/r/datascience/comments/efwlcs/christmas_gift_from_girlfriend_cant_wait_to_read/,https://i.redd.it/2lqu8de4wz641.jpg,FruityPebblePug,datascience,0.97,False,False,False,False,0.0,1745834764.912447,Tech & Programming,17.0,0.0,17.0,Thursday,10.0,December,2019.0,False,0.9081,0.508,0.0,0.492,positive,christmas gift from girlfriend cant wait to read all hope everyone here had a blessed holiday season,,christmas gift from girlfriend cant wait to read all hope everyone here had a blessed holiday season ,"christmas, gift, girlfriend, cant, wait",2019-12-26 15:20:26,christmas gift from girlfriend cant wait to read all hope everyone here had a blessed holiday season ,"['christmas', 'gift', 'girlfriend', 'cant', 'wait', 'read', 'hope', 'everyone', 'blessed', 'holiday', 'season']",,,,
1iyr85i,How blessed/fucked-up am I?,"My manager gave me this book because I will be working on TSP and Vehicle Routing problems.

Says it's a good resource, is it really a good book for people like me ( pretty good with coding, mediocre maths skills, good in statistics and machine learning ) your typical junior data scientist.

I know I will struggle and everything, that's present in any book I ever read, but I'm pretty new to optimization and very excited about it.
But will I struggle to the extent I will find it impossible to learn something about optimization and start working?

",1740586574.0,925.0,101.0,/r/datascience/comments/1iyr85i/how_blessedfuckedup_am_i/,https://i.redd.it/w0qy96yidile1.jpeg,Careful_Engineer_700,datascience,0.97,False,False,False,False,0.0,1745834765.269565,Tech & Programming,4.0,98.0,100.0,Wednesday,11.0,February,2025.0,False,0.9574,0.237,0.058,0.704,positive,how blessedfuckedup am i,my manager gave me this book because i will be working on tsp and vehicle routing problems says its a good resource is it really a good book for people like me pretty good with coding mediocre maths skills good in statistics and machine learning your typical junior data scientist i know i will struggle and everything thats present in any book i ever read but im pretty new to optimization and very excited about it but will i struggle to the extent i will find it impossible to learn something about optimization and start working,how blessedfuckedup am i my manager gave me this book because i will be working on tsp and vehicle routing problems says its a good resource is it really a good book for people like me pretty good with coding mediocre maths skills good in statistics and machine learning your typical junior data scientist i know i will struggle and everything thats present in any book i ever read but im pretty new to optimization and very excited about it but will i struggle to the extent i will find it impossible to learn something about optimization and start working,"good, book, working, pretty, struggle",2025-02-26 16:16:14,how blessedfuckedup am i my manager gave me this book because i will be working on tsp and vehicle routing problems says its a good resource is it really a good book for people like me pretty good with coding mediocre maths skills good in statistics and machine learning your typical junior data scientist i know i will struggle and everything thats present in any book i ever read but im pretty new to optimization and very excited about it but will i struggle to the extent i will find it impossible to learn something about optimization and start working,"['blessedfuckedup', 'manager', 'gave', 'book', 'working', 'tsp', 'vehicle', 'routing', 'problem', 'say', 'good', 'resource', 'really', 'good', 'book', 'people', 'like', 'pretty', 'good', 'coding', 'mediocre', 'math', 'skill', 'good', 'statistic', 'machine', 'learning', 'typical', 'junior', 'data', 'scientist', 'know', 'struggle', 'everything', 'thats', 'present', 'book', 'ever', 'read', 'pretty', 'new', 'optimization', 'excited', 'struggle', 'extent', 'find', 'impossible', 'learn', 'something', 'optimization', 'start', 'working']",,,,
1984lvg,My greatest data science achievement...,,1705416617.0,917.0,123.0,/r/datascience/comments/1984lvg/my_greatest_data_science_achievement/,https://i.redd.it/ws045uk1ftcc1.png,whiteowled,datascience,0.97,False,False,False,False,0.0,1745834765.777943,Tech & Programming,5.0,0.0,5.0,Tuesday,9.0,January,2024.0,False,0.6369,0.512,0.0,0.488,positive,my greatest data science achievement,,my greatest data science achievement ,"greatest, data, science, achievement",2024-01-16 14:50:17,my greatest data science achievement ,"['greatest', 'data', 'science', 'achievement']",,,,
aau4jv,Thought y’all could appreciate this as well.,,1546156989.0,917.0,24.0,/r/datascience/comments/aau4jv/thought_yall_could_appreciate_this_as_well/,https://i.redd.it/xghgulb1hd721.jpg,WittyWillow3,datascience,0.96,False,False,False,False,0.0,1745834766.36158,Tech & Programming,7.0,0.0,7.0,Sunday,3.0,December,2018.0,True,0.5859,0.49,0.0,0.51,positive,thought yall could appreciate this as well,,thought yall could appreciate this as well ,"thought, yall, could, appreciate, well",2018-12-30 08:03:09,thought yall could appreciate this as well ,"['thought', 'yall', 'could', 'appreciate', 'well']",,,,
1cku2k4,Just talked to some MDs about data science interviews and they were horrified.,"RANT:

I told them about the interview processes, live coding tests ridiculous assignments and they weren't just bothered by it they were completely appalled.  They stated that if anyone ever did on the spot medicine knowledge they hospital/interviewers would be blacklisted bc it's possibly the worst way to understand a doctors knowledge. Research and expanding your knowledge is the most important part of being a doctor....also a data scientist.

HIRING MANAGERS BE BETTER",1714923619.0,913.0,206.0,/r/datascience/comments/1cku2k4/just_talked_to_some_mds_about_data_science/,https://www.reddit.com/r/datascience/comments/1cku2k4/just_talked_to_some_mds_about_data_science/,Aggravating_Sand352,datascience,0.87,True,False,False,False,0.0,1745834766.615298,Tech & Programming,13.0,73.0,86.0,Sunday,11.0,May,2024.0,True,-0.8701,0.072,0.163,0.765,negative,just talked to some mds about data science interviews and they were horrified,rant i told them about the interview processes live coding tests ridiculous assignments and they werent just bothered by it they were completely appalled they stated that if anyone ever did on the spot medicine knowledge they hospitalinterviewers would be blacklisted bc its possibly the worst way to understand a doctors knowledge research and expanding your knowledge is the most important part of being a doctoralso a data scientist hiring managers be better,just talked to some mds about data science interviews and they were horrified rant i told them about the interview processes live coding tests ridiculous assignments and they werent just bothered by it they were completely appalled they stated that if anyone ever did on the spot medicine knowledge they hospitalinterviewers would be blacklisted bc its possibly the worst way to understand a doctors knowledge research and expanding your knowledge is the most important part of being a doctoralso a data scientist hiring managers be better,"knowledge, data, interview, talked, md",2024-05-05 15:40:19,just talked to some mds about data science interviews and they were horrified rant i told them about the interview processes live coding tests ridiculous assignments and they werent just bothered by it they were completely appalled they stated that if anyone ever did on the spot medicine knowledge they hospitalinterviewers would be blacklisted bc its possibly the worst way to understand a doctors knowledge research and expanding your knowledge is the most important part of being a doctoralso a data scientist hiring managers be better,"['talked', 'md', 'data', 'science', 'interview', 'horrified', 'rant', 'told', 'interview', 'process', 'live', 'coding', 'test', 'ridiculous', 'assignment', 'werent', 'bothered', 'completely', 'appalled', 'stated', 'anyone', 'ever', 'spot', 'medicine', 'knowledge', 'hospitalinterviewers', 'would', 'blacklisted', 'possibly', 'worst', 'way', 'understand', 'doctor', 'knowledge', 'research', 'expanding', 'knowledge', 'important', 'part', 'doctoralso', 'data', 'scientist', 'hiring', 'manager', 'better']",,,,
1ha78te,Thoughts? Please enlighten us with your thoughts on what this guy is saying. ,,1733742026.0,914.0,196.0,/r/datascience/comments/1ha78te/thoughts_please_enlighten_us_with_your_thoughts/,https://i.redd.it/osj8h2a61t5e1.png,httpsdash,datascience,0.93,False,False,False,False,0.0,1745834767.46549,Tech & Programming,13.0,0.0,13.0,Monday,6.0,December,2024.0,False,0.6808,0.337,0.0,0.663,positive,thoughts please enlighten us with your thoughts on what this guy is saying,,thoughts please enlighten us with your thoughts on what this guy is saying ,"thought, please, enlighten, guy, saying",2024-12-09 11:00:26,thoughts please enlighten us with your thoughts on what this guy is saying ,"['thought', 'please', 'enlighten', 'thought', 'guy', 'saying']",,,,
f981hm,Python package to collect news data from more than 3k news websites. In case you needed easy access to real data.,,1582624730.0,899.0,48.0,/r/datascience/comments/f981hm/python_package_to_collect_news_data_from_more/,https://github.com/kotartemiy/newscatcher,kotartemiy,datascience,0.99,False,False,False,False,0.0,1745834768.68259,Tech & Programming,21.0,0.0,21.0,Tuesday,4.0,February,2020.0,False,0.4404,0.132,0.0,0.868,positive,python package to collect news data from more than k news websites in case you needed easy access to real data,,python package to collect news data from more than k news websites in case you needed easy access to real data ,"news, data, python, package, collect",2020-02-25 09:58:50,python package to collect news data from more than k news websites in case you needed easy access to real data ,"['python', 'package', 'collect', 'news', 'data', 'news', 'website', 'case', 'needed', 'easy', 'access', 'real', 'data']",,,,
pk613b,Data Engineering Roadmap,,1631087479.0,896.0,76.0,/r/datascience/comments/pk613b/data_engineering_roadmap/,https://i.redd.it/v8d45wabl4m71.png,TheInsaneApp,datascience,0.97,False,False,False,False,0.0,1745834769.067222,Tech & Programming,3.0,0.0,3.0,Wednesday,3.0,September,2021.0,False,0.0,0.0,0.0,1.0,neutral,data engineering roadmap,,data engineering roadmap ,"data, engineering, roadmap",2021-09-08 07:51:19,data engineering roadmap ,"['data', 'engineering', 'roadmap']",,,,
1iq0gwj,Data Science is losing its soul,"DS teams are starting to lose the essence that made them truly groundbreaking. their mixed scientific and business core. What we’re seeing now is a shift from deep statistical analysis and business oriented modeling to quick and dirty engineering solutions. Sure, this approach might give us a few immediate wins but it leads to low ROI projects and pulls the field further away from its true potential. One size-fits-all programming just doesn’t work. it’s not the whole game.
",1739623050.0,887.0,245.0,/r/datascience/comments/1iq0gwj/data_science_is_losing_its_soul/,https://www.reddit.com/r/datascience/comments/1iq0gwj/data_science_is_losing_its_soul/,KindLuis_7,datascience,0.92,True,False,False,False,0.0,1745834769.635641,Tech & Programming,6.0,78.0,84.0,Saturday,7.0,February,2025.0,True,0.4118,0.119,0.089,0.791,positive,data science is losing its soul,ds teams are starting to lose the essence that made them truly groundbreaking their mixed scientific and business core what were seeing now is a shift from deep statistical analysis and business oriented modeling to quick and dirty engineering solutions sure this approach might give us a few immediate wins but it leads to low roi projects and pulls the field further away from its true potential one sizefitsall programming just doesnt work its not the whole game,data science is losing its soul ds teams are starting to lose the essence that made them truly groundbreaking their mixed scientific and business core what were seeing now is a shift from deep statistical analysis and business oriented modeling to quick and dirty engineering solutions sure this approach might give us a few immediate wins but it leads to low roi projects and pulls the field further away from its true potential one sizefitsall programming just doesnt work its not the whole game,"business, data, science, losing, soul",2025-02-15 12:37:30,data science is losing its soul ds teams are starting to lose the essence that made them truly groundbreaking their mixed scientific and business core what were seeing now is a shift from deep statistical analysis and business oriented modeling to quick and dirty engineering solutions sure this approach might give us a few immediate wins but it leads to low roi projects and pulls the field further away from its true potential one sizefitsall programming just doesnt work its not the whole game,"['data', 'science', 'losing', 'soul', 'team', 'starting', 'lose', 'essence', 'made', 'truly', 'groundbreaking', 'mixed', 'scientific', 'business', 'core', 'seeing', 'shift', 'deep', 'statistical', 'analysis', 'business', 'oriented', 'modeling', 'quick', 'dirty', 'engineering', 'solution', 'sure', 'approach', 'might', 'give', 'immediate', 'win', 'lead', 'low', 'roi', 'project', 'pull', 'field', 'away', 'true', 'potential', 'one', 'sizefitsall', 'programming', 'doesnt', 'work', 'whole', 'game']",,,,
1k9n5q8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-28 04:29:28,question http status codes vs business logic do you tie business rules failuressuccess to your http status codes ive heard both sides and dont see anything concrete see link here where everyone has a different strict answer what has made the most sense to me is this if my server understood your request it is successful and said server will return a ok for example with details in the response body new record is underage phone format is invalid you wanted pickles on your burger and were out of pickles server doesnt care it understood your request and its http codes arent tightly bound to business rules if your db is full and cant accept more data thats a different issue where your interface would in fact return a xx code im curious what other people think,,,,,
1k9mcse,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-28 03:42:44,how netflix uses java edition ,,,,,
1k9kljo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-28 02:05:25,why learn to code failed ,,,,,
1k9iv3f,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-28 00:33:18,dining philosophers in c from theory to practice hey friends i just finished writing a really clean and detailed documentation for my dining philosophers project i spent a lot of time on it and made it with a lot of care its super clear and helpful would you mind checking it out i think it could really help if youre working on something similar,,,,,
1k9h9k1,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 23:12:37,how a single line of code could brick your iphone ,,,,,
1k9dxim,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 20:40:46,compiler reminders ,,,,,
1k9bx7e,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 19:14:53,coordination crisis in modern tech work ,,,,,
1k9aqrd,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 18:24:23,anatomy of a sql engine ,,,,,
1k9amd6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 18:19:13,how to grow from midlevel to senior software engineer ,,,,,
1k9ajul,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 18:16:06,lixom protecting encryption keys with executeonly memory ,,,,,
1k98mbj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 16:55:38,how i built a intelligent document processing system for insurance property records c,,,,,
1k95gic,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 14:39:16,create a tiny dll in c remove crt and disassemble dll with cutter windows dll internals ,,,,,
1k955f9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 14:25:12,why app stores exist and many developers never welcome them ,,,,,
1k94tu5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 14:10:06,understanding mcp evals why evals matter for mcp ,,,,,
1k92328,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 11:45:44,why hash tables are so fast explained with visuals and gifs ,,,,,
1k90s6e,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 10:22:47,lets make a game tracking destinations ,,,,,
1k90mym,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 10:12:34,lofify to add randomly selected lofi bgms to boring screen records ,,,,,
1k8y237,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 07:08:58,elasticsearch part an introduction to the basics of search and indexing with elasticsearch what all covered in this article basics uses cases how things work under the hood do check it out part will be live in next week follow the weekly system design newsletter here,,,,,
1k8xxh1,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 07:00:05,tech debt doesnt exist but tradeoffs do ,,,,,
1k8ws0i,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 05:40:44,exploring lumen a new staticallytyped language for native web development ,,,,,
1k8vwvm,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 04:44:07,a database diagram cheat sheet philosophies tradeoffs to help you choose the correct db ,,,,,
1k8qdnj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 23:38:26,be careful about printing error as string in golang ,,,,,
1k8q9xo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 23:33:17,j is for jvm ,,,,,
1k8psm3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 23:09:26,creative usernames and spotify account hijacking ,,,,,
1k8pl7g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 22:59:24,top features of java nio library ,,,,,
1k8n6re,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 21:04:39,cs programs have failed candidates ,,,,,
1k8jmtn,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 18:25:14,its a c at best ,,,,,
1k8j34q,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 18:01:43,nuevas características de c ,,,,,
1k8iyqo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:56:28,when ai tools backfire the hidden cost of poor planning when ai tools backfire the hidden cost of poor planning in a heated reddit thread developers voiced growing frustrations with cursors claude max integration what was supposed to be a productivity booster became a nightmare over redundant tool calls just to fix two minor typescript linter errors racking up unexpected costs and endless frustration even more alarming users reported daily charges without meaningful results worse productivity compared to earlier cursor versions support teams ignoring emails and dms massive usage spikes seemingly triggered by silent updates comments poured in with a common thread developers feel trapped reliant on ai tools that burn through budgets while delivering halffinished or errorprone outputs is this a cursorspecific issue is it claude max being not ready or is it a deeper problem in how ai is integrated into modern coding workflows the real problem misaligned ai expectations heres the uncomfortable truth ai coding assistants are not developers they are powerful prediction engines that guess at your intent based on the input and context you provide when your project lacks clear task definitions explicit architecture guidelines real contextual grounding from the codebase you are essentially asking the ai to guess and guesses no matter how intelligent often lead to infinite loops inefficient tool calls misinterpretations and ultimately higher costs and more frustration the reality many developers are waking up to is simple why ai loops and costs explode several core reasons explain the problems users faced with tools like claude max lack of project scope understanding when ai agents dont have a solid grasp of what the project is about they chase irrelevant solutions reread code unnecessarily and misdiagnose issues poor error handling strategies instead of understanding the broader goal ais often fixate on tiny local errors leading to endless lint fix loops context window mismanagement most llms have a limited memory context window poor structuring of input data can cause them to lose track of the task halfway through and start over repeatedly lack of user control automation sounds great until the ai decides to spend your credits investigating unnecessary files without your permission how to avoid falling into the ai trap if you want to use ai tools effectively and affordably you must lead the ai not follow it heres how plan before you prompt before even typing a prompt clearly define what feature you are building what parts of the codebase it touches any architectural constraints or requirements think of it as prepping a task ticket for a junior developer the clearer the briefing the better the result create a clear system architecture map dont rely on the ai to figure out your apps structure instead diagram the major components list dependencies between services highlight critical models apis or modules a simple diagram or spec document saves hundreds of tool calls later give rich relevant context when prompting attach or reference only the necessary files include relevant api signatures data models or interface definitions summarize the problem and desired outcome explicitly the ai needs the right amount of the right information not a firehose of random files control linter and autofix settings especially when using max modes disable automatic linter fixes unless necessary prefer manual review of aisuggested code changes letting the ai autonomously fix things often results in new errors monitor requests and set usage limits if your platform allows it set caps on daily tool call spend review request logs regularly pause or disable agent modes that behave unpredictably early detection can prevent runaway costs ai doesnt eliminate good engineering practices it demands them theres a growing myth that ai tools will replace the need for design documents system architecture or thorough scoping the reality is the opposite good engineering hygiene thoughtful planning solid documentation clear scope definitions is now more important than ever without it even the best models spiral into chaos burning your money and your time final thoughts aiassisted coding can be a massive force multiplier when used wisely but it requires a shift in mindset dont treat ai like a magic black box treat it like a junior engineer who needs clear instructions plans and oversight those who adapt their workflows to this new reality will outperform building faster better and cheaper those who dont will continue to experience frustration spiraling costs and broken codebases the future of coding isnt prompt and pray its plan prompt and guide,,,,,
1k8i3wz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:19:14,mceliece standardization ,,,,,
1k8i381,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:18:24,nofl a precise immix ,,,,,
1k8i32k,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:18:12,implementing silent hills fog in my real ps game ,,,,,
1k8i2tv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:17:55,a taxonomy of c types ,,,,,
1k8i2o6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:17:45,k slices k dices ,,,,,
1k8i0i2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:15:02,lms arent writing llms why developers still matter ,,,,,
1k8hzcc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:13:37,parallel configure ,,,,,
1k8hqgz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:03:05,introducing vibeops ,,,,,
1k8gu5g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 16:24:22,plan features not implementation details ,,,,,
1k8fz2b,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 15:47:18,vernamveil a fresh take on functionbased encryption ive opensourced vernamveil an experimental cipher written in pure python designed for developers curious about cryptographys inner workings its only about lines of python code with no external dependencies other than standard python libraries vernamveil was built as a learning exercise by someone outside the cryptography field if you happen to be a cryptography expert i would deeply appreciate any constructive criticism,,,,,
1k8f6t4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 15:12:15,from docker to webassembly ,,,,,
1k8ex7k,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 15:00:32,how to build idempotent apis ,,,,,
1k8dyef,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 14:16:04,refactoring is secretly inlining ,,,,,
1k8ct03,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 13:20:41,electric clojure in minutes systems distributed with transcript ,,,,,
1k8c3lb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 12:44:25,a minimalist web agent for sentiment analysis ,,,,,
1k8bp33,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 12:22:04,c views as data members for custom iterators ,,,,,
1k8aurh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 11:32:26,difference between rank and dense_rank in oracle sql ,,,,,
1k8a6ri,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 10:50:08,good code design from linuxkernel ,,,,,
1k89sov,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 10:22:56,syntax updates of python that will make your code safer and better ,,,,,
1k8859g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 08:23:21,an open communityrun domain registry pushed my weekend project live calling it the domains project it offers free subdomains under domains we manage like this everythings opensource and managed on github best part new domains can be added by the community please feel free to put a star on the repo grab your own space,,,,,
1k863sa,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 06:03:25,mastering regex a comprehensive practical guide ,,,,,
1k85b35,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 05:12:16,thats how weve always done things around here we do this in software way more than we think we inherit a process or a rule and keep following it without questioning why it exists in the first place its like that old story someone cuts off the turkey tail before cooking just because thats how their grandma did it spoiler alert grandmas pan was just too small some examples of turkey tails ive seen following tedious dev processes nobody understands anymore enforcing character line limits in leaving todo comments in codebases for years tradition can be helpful but if we dont question it it can turn into pure baggage whats the most enormous turkey tail youve seen in your company or project curious to hear what others have run into,,,,,
1k83h8g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 03:22:57,react reconciliation the hidden engine behind your components ,,,,,
1k82o5c,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 02:38:55,how can we inject beans in spring ,,,,,
1k82c64,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 02:21:00,superpowers pitfalls community software engineering in the ai era wi ,,,,,
1k80u4j,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 01:00:22,i love raylib cs huge respect to the people behind the c port of raylib i have been using the original c version since day one but lately i have been playing around with this port just for fun completely out of nostalgia i ended up recreating one of those good old flash element sandbox games too with it nothing really fancy just a little side project anyway the thing is that port is really worth checking out like if you work with c go ahead and give it a shot its really fun and lovely just like the original ohh also about that game of mine yep its open source too if anyone is curious it might help you if you are working on something similar,,,,,
1k7w1vi,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:12:54,gcc released ,,,,,
1k7w0wx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:11:43,the beos file system an os geek retrospective ,,,,,
1k7w0p6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:11:28,building a robust data synchronization framework with rails ,,,,,
1k7w0my,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:11:24,some recent changes to choice of ln and in in qt ,,,,,
1k7vzoz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:10:21,write an interpreter in ruby ,,,,,
1k7vznx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:10:18,nextgen gpu programming handson with mojo and max modular hq ,,,,,
1k7vz0o,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:09:33,programming in d tutorial and reference ,,,,,
1k7vyqn,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:09:14,papercode automating code generation from scientific papers ,,,,,
1k7vx73,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 21:07:27,levels of using exception groups in python ,,,,,
1k7s3f6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 18:25:21,watercooler discussions about common software automation topics hola friends the link above is a culmination of about over a years worth of watercooler discussions gathered from this subreddit rqualityassurance rsoftwaretesting and our discord almost k users now please feel free to leave comments about any of the topics there and i will happily add it to the watercooler discussions so this document can be always growing with common questions and answers from all communities thanks,,,,,
1k7p5dr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 16:25:31,what does use client do overreacted ,,,,,
1k7oqbz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 16:08:28,differential coverage for debugging ,,,,,
1k7o5ot,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 15:44:31,first island hackathon in the world is getting organized by hackclub ,,,,,
1k7nj3e,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 15:18:34,some __nonstring__ turbulence ,,,,,
1k7nfmq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 15:14:41,a visual journey through async rust ,,,,,
1k7naei,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 15:08:42,synadia tries to withdraw the nats project from the cncf and relicense to bsl nonopen source license synadia the original donor of the nats project has notified the cloud native computing foundation cncfthe open source foundation under which kubernetes and other popular projects resideof its intention to withdraw the nats project from the foundation and relicense the code under the business source license busla nonopen source license that restricts user freedoms and undermines years of open development,,,,,
1k7n8gx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 15:06:29,having fun with c sfml and developing games without engines i wanted to learn how to program games without an engine and i started to work with cs sfml library to learn the basics of collisions rendering and input i left a link to my project repo in case anyone is interested in taking a look there are some areas of improvement such as adding sound improving the ui sfml doesnt have things like buttons or labels all of these need to be written and adding animations i plan to go deeper into the capabilities of sfml and c it has been a great learning experience so far,,,,,
1k7m7bh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 14:23:13,writing etchosts breaks the substack editor ,,,,,
1k7jm6o,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 12:24:21,stretching googles prefetching using sxg to prefetch a mb video while on google search results for more information see this post you will find source code here,,,,,
1k7jgz4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 12:16:54,communicating in types kris jenkins ,,,,,
1k7jgn2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 12:16:24,give your local llm superpowers new guide to open webui tools hey rprogramming just dropped the next part of my open webui series this ones all about tools giving your local models the ability to do things like check the current timeweather perform accurate calculations scrape live web info even send emails or schedule meetings examples included we cover finding community tools crucial safety tips and how to build your own custom tools with python code template examples in the linked github repo its perfect if youve ever wished your open webui setup could interact with the real world or external apis check it out and let me know what cool tools youre planning to build,,,,,
1k7j6g8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 12:01:10,the anatomy of slow code reviews almost every software developer complains about slow code reviews but sometimes it can be hard to understand whats causing them,,,,,
1k7i0ig,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 10:54:37,gcc the gnu compiler collection released ,,,,,
1k7h146,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 09:49:51,introduction to quad trees ,,,,,
1k7gobj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 09:24:49,tpp a collaboration communication protocol based on gearmodel unlike blockbased programming tpp adopts gearbased programming in an attempt to unify endtoend vlas and software agents when the lifecycle system is activated it drives countless actions into motionultimately bringing the entire system to life conversely when a single action senses a change in the external environment it can drives the lifecycle system to adjust itself in response this forms a closedloop system where the system can autonomously regulate itself this is critically important in the age of aibecause ai systems by nature should operate without manual intervention now ask a question can legostyle block programming achieve this obviously not once youve built a truck and you want to turn it into a planeyou have to tear it apart and rebuild it from scratch,,,,,
1k7fukh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 08:25:03,build an image gallery with astro and react recently i rewrote the image gallery on my website and took notes on the most important and interesting parts of the process which i then turned into a blog article its a stepbystep guide based on a practical example that shows how to manage images on a static website including how to load images where to use server and client components how to optimize and handle responsive images add css transitions on load implement infinite scroll pagination and include a lightbox preview have you done something similar yourself did you take a different approach i would love to hear your feedback,,,,,
1k7f4cv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 07:31:18,announcing codebase viewer v a fast eguibased tool to explore document codebases great for llm context ,,,,,
1k7e3rk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 06:19:44,we dont merge into a broken master branch ,,,,,
1k7cstg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 04:55:42,the cryptoint library djb pdf ,,,,,
1k7ci8l,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 04:38:06,how to get experience as a software engineer ,,,,,
1k7aq02,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 02:58:26,interview with jeaye wilkerson author of jank programming language ,,,,,
1k7amzz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 02:53:56,war on jits softwarebased attacks and hybrid defenses for jit compilers ,,,,,
1k7abwb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 02:37:23,github soypatglay clay ui port to go for science ,,,,,
1k79id4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 01:55:12,a developers guide to certificate authorities and digital trust ,,,,,
1k78pn3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 01:13:52,a crossplatform markdown ai notetaking tool with only mb ,,,,,
1k77q5b,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 00:23:47,path should be a system call ,,,,,
1k77pki,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 00:22:55,pygraph robust compiler support for cuda graphs in pytorch ,,,,,
1k75aow,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 22:28:05,the hidden cost of ai code assistants no paywall yet another be careful using ai article although i attempt to be more balanced in my discussion here and not just paint everything with a doomed brush anyways let me know what you think,,,,,
1k71q0q,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 19:55:22,how discord indexes trillions of messages ,,,,,
1k71kd2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 19:49:18,i did a writeup on how i use asynchronous networking in c to span multiple apis and link the data together all on a single thread ,,,,,
1k7139l,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 19:29:58,why we write logs and why it matters more than you think according to ibms cost of a data breach report the average time to detect a data breach is days add another days to contain it and youre looking at a day breach lifecycle so what can we do as a techcompany an engineering team or a cybersecurity agency to fight back lets start at the very beginning of the security chain logs,,,,,
1k703z1,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 18:50:39,i wrote to the address in the gplv license notice ,,,,,
1k6yd8i,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 17:40:38,avoid continue ,,,,,
1k6x9dk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:56:00,floating point round trip radix conversion ,,,,,
1k6x9bi,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:55:57,a principled approach to querying data a typesafe search dsl ,,,,,
1k6wcbh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:18:53,the hitchhikers guide to diskless kafka ,,,,,
1k6w7em,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:13:23,understanding why count can be slow in postgresql ,,,,,
1k6w7e2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:13:22,tech talks weekly devoxx greece ai engineer goto devopscon qcon conf sre many more ,,,,,
1k6vzz9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:05:14,exploring croquet in squeak a communitydriven effort ,,,,,
1k6vwlo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:01:41,bluefish is a diagramming framework ,,,,,
1k6vvlp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:00:45,three fundamental flaws of simd isas ,,,,,
1k6vd7r,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 15:40:26,why c ,,,,,
1k6vcfq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 15:39:32,creating your own federated microblog ,,,,,
1k6unma,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 15:11:16,professional skills for software engineers charles humble trisha gee ,,,,,
1k6uhjo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 15:04:09,sandbox mcp enable llms to run any code safely ,,,,,
1k6u7my,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 14:53:18,what if we could rebuild kafka from scratch ,,,,,
1k6ttfc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 14:36:54,vs code ai getting started web design html css javascript ,,,,,
1k6tn6x,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 14:29:31,how we made our optical character recognition ocr code more accurate ,,,,,
1k6tm1w,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 14:28:11,generating million pdfs in minutes ,,,,,
1k6snz2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 13:48:29,smtp with starttls implementation with springboot so i was recently tasked with setting up at least a basic smtp relay i went with spring boot and ended up wrapping apache james to get the job done along the way i realized parts of the code could be repurposed into something pretty useful a lightweight smtp honeypot for catching unsolicited or malicious traffic it supports things like tlsstarttls basic smtp commands and is super easy to deploy or test locally figured it might help someone else out there whos working in the same space code can be found here,,,,,
1k6siij,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 13:41:50,deep analysis the analytics analogue to deep research ,,,,,
1k6qt3x,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 12:21:17,eserde dont stop at the first deserialization error mainmatter ,,,,,
1k6px9m,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 11:32:55,a web framework made in rust in lines of code with no dependencies ,,,,,
1k6pkfx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 11:12:38,new mcp tool for managing nomad clusters hello everyone ive just released a new project on github mcpnomad its an mcp model context protocol server written in go designed to interact with hashicorp nomad it allows you to easily manage and monitor your nomad clusters directly from an interface compatible with llms like claude you can find the full repository here key features view and manage nomad jobs monitor job and allocation statuses access allocation logs restart jobs explore nodes and cluster metrics how to try it you can run the server easily using docker or integrate it with claude using a configuration like the one provided in the repository feedback and contributions the project is still in its early stages so any feedback is welcome if youre interested in contributing or have questions feel free to reach out thanks for your attention and i hope you find it useful,,,,,
1k6pgf2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 11:06:04,a new era for gpu programming nvidia finally adds native python support to cuda ,,,,,
1k6peto,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 11:03:30,why software devs keep burning out by healthygamergg ,,,,,
1k6lu6u,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 06:53:25,fixie ai powered failed build analyzer commenter and fixer i built a github app called fixie that automatically watches for failed ci builds reads the logs figures out why they broke using gpt and opens a pull request with a suggested fix supports any public repo uses regex llm to find the root cause autogenerates patches opens a pr or comments on existing ones no config just install and let it work think of it like dependabotbut instead of just bumping versions it actually debugs your ci let me know what you think or if you want to test it on your repo,,,,,
1k6lmy7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 06:39:54,installation of dependencies in vs code hi everyone i am trying to follow this tutorial but i realise that my vs code is not showing those dependencies do i need to install certain extensions on my visual studio code or anything i recently just installed homebrew fyi this is a brand new setup of macbook i completely forgotten how i did previously need some help this is the line i ran after setting up my venv please help venv dmacbookpro ai agents tutorial pip install r requirementstxt no output,,,,,
1k6ljdb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 06:33:02,understanding why count can be slow in postgresql ,,,,,
1k6l8a7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 06:11:56,i wrote code thats million times faster than zig ,,,,,
1k6l0g2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 05:57:52,mern stack chat app walkthrough realtime messaging with sockets redis well i made this video with the intent of explaining my thought process and the system design for the chatapp but improving it with a caching layer give it a watch guys,,,,,
1k6kqxl,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 05:40:34,shadcn studio an opensource collective of shadcn components blocks and templates an opensource shadcn registry of copyandpaste components blocks and templates paired with a powerful theme editor to craft customize and ship faster,,,,,
1k6j1rr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 03:57:20,engineering with java digest ,,,,,
1k6gyc0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 02:10:37,lets make a game tracking deaths ,,,,,
1k6fu9p,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 01:14:45,how i use realtime web data to build ai agents that are x smarter ,,,,,
1k6e202,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 23:46:03,open source zerocode test runner built with llm and mcp called aethr i was digging around for a better way to run tests using ai in ci and i stumbled across this new open source project called aethr never heard of it before but its super clean and does what ive been wanting from a test runner it has its own cli and setup that feels way more lightweight than what ive dealt with before some cool stuff i noticed test are set up entirely through natural language zeroconfig startup just point it at your tests and go nice builtin parallelization without any extra config hell designed to plug straight into cicd works great with github actions so far can do some unique tests that without ai are either impossible or not worth the effort heavily reduces maintenance and implementation costs there are of course limitations some nondeterministic behavior as with any ai depends on the quality of what you feed it no code to back up your tests anyway if youre dealing with flaky test setups complex test cases or just want to try something new in the ee testing space this might be worth a look i do think that this is the way software testing is headed natural language and promptbased engineering were headed toward a world where we describe test flows in plain english and let the ai tools run those tests heres the repo to try it out,,,,,
1k6dvwd,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 23:38:07,just talk to the dev tldr middle managers shouldnt be message brokers their job is to unblock not become the bottleneck what do you think,,,,,
1k6d4kn,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 23:02:50,assistance or disruption exploring and evaluating the design and tradeoffs of proactive ai programming support ,,,,,
1k69s1l,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 20:40:25,give it time ,,,,,
1k69rgd,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 20:39:43,searchable linux syscall table for x_ ,,,,,
1k69qmw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 20:38:46,c more constexpr in the core language ,,,,,
1k69qlu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 20:38:44,graphics livecoding in common lisp ,,,,,
1k6992o,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 20:18:29,minc is not cygwin ,,,,,
1k65za1,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 18:06:32,the dark arts of interior mutability in rust ,,,,,
1k6543s,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 17:32:14,the hidden cost of ai coding ,,,,,
1k646ky,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:55:28,commodore assembly part how does the machine execute machine code ,,,,,
1k646bm,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:55:08,what is coshlistbool or beyond algebra analysis of data types ,,,,,
1k6460t,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:54:48,does using rust really make your software safer ,,,,,
1k645rt,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:54:29,advanced python features ,,,,,
1k645bf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:54:01,understand your dependencies ,,,,,
1k644lo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:53:12,how mos illegal opcodes work ,,,,,
1k643h9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:51:58,how zgc allocates memory for the java heap ,,,,,
1k63ok7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:34:54,how does oidc work eli similar to my last post i was reading a lot about oidc and created this explanation its a mix of the best resources i have found with some additions and a lot of rewriting i have added a super short summary and a code example at the end maybe it helps one of you this is the reporeporef oidc explained lets say john is on linkedin and clicks _login with google_ he is now logged in without that linkedin knows his password or any other sensitive data great but how did that work via openid connect oidc this protocol builds on oauth and is the answer to above question i will provide a super short and simple summary a more detailed one and even a code snippet you should know what oauth and jwts are because oidc builds on them if youre not familiar with oauth see my other guide hereref_oauth_repo super short summary john clicks _login with google_ now the usual oauth process takes place john authorizes us to get data about his google profile eg his email profile picture name and user id important now google not only sends linkedin the access token as specified in oauth but also a jwt linkedin uses the jwt for authentication in the usual way eg johns browser saves the jwt in the cookies and sends it along every request he makes linkedin receives the token verifies it and sees _ah this is indeed john_ more detailed summary suppose linkedin wants users to log in with their google account to authenticate and retrieve profile info eg name email linkedin sets up a google api account and receives a client_id and a client_secret so google knows this client id is linkedin john clicks _log in with google_ on linkedin linkedin redirects to googles oidc authorization endpoint as you see linkedin passes client_id redirect_id scope and response_type as url params important scope must include openid profile and email are optional but commonly used redirect_uri is where google sends the response john logs into google google asks _linkedin wants to access your google account_ john clicks _allow_ google redirects to the specified redirect_uri with a onetime authorization code for example linkedin makes a servertoserver request to google it passes the onetime code client_id and client_secret in the request body google responds with an access token and a jwt finished linkedin now uses the jwt for authentication and can use the access token to get more info about johns google account addendum in step linkedin also verifies the jwts signature and claims usually in oidc we use asymmetric encryption google does for example to sign the jwt the advantage of asymmetric encryption is that the jwt can be verified by anyone by using the public key including linkedin ideally google also returns a refresh token the jwt will work as long as its valid for example hasnt expired after that the user will need to redo the above process the public keys are usually specified at the json web key sets jwks endpoint key additions to oauth as we saw oidc extends oauth this guide is incomplete so here are just a few of the additions that i consider key additions id token the id token is the jwt it contains user identity data eg sub for user id name email its signed by the idp identity provider in our case google and verified by the client in our case linkedin the jwt is used for authentication hence while oauth is for authorization oidc is authentication dont confuse access token and id token access token used to call google apis eg to get more info about the user id token used purely for authentication so we know the user actually is john discovery document oidc providers like google publish a json configuration at a standard url this lists endpoints eg authorization token userinfo jwks and supported features eg scopes linkedin can fetch this dynamically to set up oidc without hardcoding urls userinfo endpoint oidc standardizes a userinfo endpoint eg linkedin can use the access token to fetch additional user data eg name picture ensuring consistency across providers nonce to prevent replay attacks linkedin includes a random nonce in the authorization request google embeds it in the id token and linkedin checks it matches during verification security notes oidc requires for secure token transmission state parameter inherited from oauth it prevents csrf attacks jwt verification linkedin must validate jwt claims eg iss aud exp nonce to ensure security code example below is a standalone nodejs example using express to handle oidc login with google storing user data in a sqlite database please note that this is just example code and some things are missing or can be improved i also on purpose did not use the library openidclient so less things happen behind the scenes and the entire process is more visible in production you would want to use openidclient or a similar library last note i also dont enforce here which in production you really really should javascript const express requireexpress const axios requireaxios const sqlite requiresqliteverbose const crypto requirecrypto const jwt requirejsonwebtoken const session requireexpresssession const jwktopem requirejwktopem const app express const db new sqlitedatabasememory configure session middleware appuse session secret processenvsession_secret oidcexamplesecret resave false saveuninitialized true initialize database dbserialize dbrun create table users id integer primary key autoincrement name text email text dbrun create table federated_credentials user_id integer provider text subject text primary key provider subject configuration const client_id processenvoidc_client_id const client_secret processenvoidc_client_secret const redirect_uri const issuer_url oidc discovery endpoints cache let oidcconfig null function to fetch oidc configuration from the discovery endpoint async function fetchoidcconfiguration if oidcconfig return oidcconfig try const response await axiosget issuer_urlwellknownopenidconfiguration oidcconfig responsedata return oidcconfig catch error consoleerrorfailed to fetch oidc configuration error throw error function to generate and verify pkce challenge function generatepkce generate code verifier const codeverifier cryptorandombytestostringbaseurl generate code challenge sha hash of verifier baseurl encoded const codechallenge crypto createhashsha updatecodeverifier digestbase replaceg replaceg _ replaceg return codeverifier codechallenge function to fetch jwks async function fetchjwks const config await fetchoidcconfiguration const response await axiosgetconfigjwks_uri return responsedatakeys function to verify id token async function verifyidtokenidtoken first decode the header without verification to get the key id kid const header jsonparse bufferfromidtokensplit baseurltostring fetch jwks and find the correct key const jwks await fetchjwks const signingkey jwksfindkey keykid headerkid if signingkey throw new errorunable to find signing key format key for jwt verification const publickey jwktopemsigningkey return new promiseresolve reject jwtverify idtoken publickey algorithms signingkeyalg audience client_id issuer issuer_url err decoded if err return rejecterr resolvedecoded oidc login route appgetlogin async req res try fetch oidc configuration const config await fetchoidcconfiguration generate state for csrf protection const state cryptorandombytestostringhex reqsessionstate state generate nonce for replay protection const nonce cryptorandombytestostringhex reqsessionnonce nonce generate pkce code verifier and challenge const codeverifier codechallenge generatepkce reqsessioncodeverifier codeverifier build authorization url const authurl new urlconfigauthorization_endpoint authurlsearchparamsappendclient_id client_id authurlsearchparamsappendredirect_uri redirect_uri authurlsearchparamsappendresponse_type code authurlsearchparamsappendscope openid profile email authurlsearchparamsappendstate state authurlsearchparamsappendnonce nonce authurlsearchparamsappendcode_challenge codechallenge authurlsearchparamsappendcode_challenge_method s resredirectauthurltostring catch error consoleerrorlogin initialization error error resstatussendfailed to initialize login oidc callback route appgetoidccallback async req res const code state reqquery const codeverifier state storedstate nonce storednonce reqsession verify state if state storedstate return resstatussendinvalid state parameter try fetch oidc configuration const config await fetchoidcconfiguration exchange code for tokens const tokenresponse await axiospost configtoken_endpoint new urlsearchparams grant_type authorization_code client_id client_id client_secret client_secret code redirect_uri redirect_uri code_verifier codeverifier headers contenttype applicationxwwwformurlencoded const id_token access_token tokenresponsedata verify id token const claims await verifyidtokenid_token verify nonce if claimsnonce storednonce return resstatussendinvalid nonce extract user info from id token const sub subject name email claims if we need more user info we can fetch it from the userinfo endpoint const userinforesponse await axiosgetconfiguserinfo_endpoint headers authorization bearer access_token const userinfo userinforesponsedata check if user exists in federated_credentials dbget select from federated_credentials where provider and subject issuer_url subject err cred if err return resstatussenddatabase error if cred new user create account dbrun insert into users name email values name email function err if err return resstatussenddatabase error const userid thislastid dbrun insert into federated_credentials user_id provider subject values userid issuer_url subject err if err return resstatussenddatabase error store user info in session reqsessionuser id userid name email ressendlogged in as name email else existing user fetch and log in dbget select from users where id creduser_id err user if err user return resstatussenddatabase error store user info in session reqsessionuser id userid name username email useremail ressendlogged in as username useremail catch error consoleerroroidc callback error error resstatussendoidc authentication error user info endpoint requires authentication appgetuserinfo req res if reqsessionuser return resstatussendnot authenticated resjsonreqsessionuser logout endpoint appgetlogout async req res try fetch oidc configuration to get end session endpoint const config await fetchoidcconfiguration let logouturl if configend_session_endpoint logouturl new urlconfigend_session_endpoint logouturlsearchparamsappendclient_id client_id logouturlsearchparamsappend post_logout_redirect_uri clear the session reqsessiondestroy if logouturl resredirectlogouturltostring else resredirect catch error consoleerrorlogout error error even if theres an error fetching the config still clear the session and redirect reqsessiondestroy resredirect applisten consolelogserver running on port license mit ref_oauth_repo reporef,,,,,
1k63gdg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:25:48,input validation techniques to fortify apis ,,,,,
1k636c4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:14:21,css hell ,,,,,
1k62kso,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 15:50:50,puppygraph on mongodb native graph queries without etl ,,,,,
1k61xy5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 15:25:17,how ai agents work and how to build them ,,,,,
1k61drp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 15:02:39,ai is writing codebut are we shipping bugs at scale i recently wrote an indepth article exploring the hidden risks of using aigenerated code from tools like chatgpt copilot and cursor while they massively boost productivity they often introduce critical security flaws bad dependencies and untested logicespecially for developers unfamiliar with secure coding in the post i break down realworld examples like sql injection and md misuse discuss why ai cant understand business logic or security context and offer tips for using ai responsibly in coding workflows,,,,,
1k60mu1,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 14:31:40,reducing network latency innovations for a faster internet in memory of dave täht ,,,,,
1k60ai7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 14:17:04,understanding string length in different programming languages ,,,,,
1k5zw2q,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 14:00:08,nanomodels a recent breakthrough as we offload temporal understanding entirely to local hardware ,,,,,
1k5zrlj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 13:54:47,a c library for vector similarity with simd ,,,,,
1k5zjs8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 13:45:19,how a year old bug in gta san andreas surfaced in windows h a bug in gta san andreas lay dormant for over years until an unrelated change in windows h triggered it this is a deep dive into how a simple coding mistake erased all seaplanes from the game and made them completely unusable,,,,,
1k5y4fv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 12:38:54,floatingpoint numbers in residue number systems ,,,,,
1k5vrqb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 10:26:45,gpu compilation with mlir continuing from the previous post this series is a comprehensive guide on transforming highlevel tensor operations into efficient gpuexecutable code using mlir it delves into the linalg dialect showcasing how operations like linalggeneric linalgmap and linalgmatmul can be utilized for defining tensor computations the article emphasizes optimization techniques such as kernel fusion which combines multiple operations to reduce memory overhead and loop tiling which enhances cache utilization and performance on gpu architectures through detailed code examples and transformation pipelines it illustrates the process of lowering tensor operations to optimized gpu code making it a valuable resource for developers interested in mlir and gpu programming,,,,,
1k5vplf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 10:22:49,cheerpj webassembly jvm for the browser now with java and jni support ,,,,,
1k5vp1n,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 10:21:44,how to build a dysfunctional team ,,,,,
1k5vn3c,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 10:18:15,malicious npm package impersonating popular express cookie parser ,,,,,
1k5v9vm,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 09:54:06,principles for maintainable codebases ,,,,,
1k5txpr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 08:16:59,async excellence unlocking scalability with kafka devoxx greece check out four key patterns to improve scalability and developer velocity integration events reduce latency with prefetching task queue streamline workflows by offloading tasks task scheduler scale scheduling for delayed tasks iterator manage longrunning jobs in chunks,,,,,
1k5smuu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 06:42:14,java design patterns real world scenariobased interview questions practice test mcqs ,,,,,
1k5rtlu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 05:46:57,the state of authorization ,,,,,
1k5rfb5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 05:21:03,explained how does l regularization perform feature selection towards data science i was reading about regularization and discovered a line l regularization performs feature selection and regularization is an embedded feature selection method i was not sure how regularization relates with feature selection and eventually read some booksblogsforums on the topic one of the resources suggested that l regularization forces some parameters to become zero thus nullifying the influence of those features on the output of the model this automatic removal of features by forcing their corresponding parameters to zero is categorized as an embedded feature selection method a question persisted how does l regularization determine which parameters to zero out in other words how does l regularization know which features are redundant most blogsvideos on the internet were focusing on how this feature selection occurs discussing how l regularization induces sparsity i wanted to know more on the why part of the question which forced me to perform some deeper analysis the explanation of the why part is included in this blog,,,,,
1k5pt17,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 03:43:27,exploiting undefined behavior in cc programs for optimization a study on the performance impact pdf ,,,,,
1k5okeu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 02:36:27,why tcp needs handshakes ,,,,,
1k5nrj1,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 01:55:38,day can you format dates numbers and currencies with javascripts intl api ,,,,,
1k5nrbe,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 01:55:22,an introduction to creative coding ,,,,,
1k5nr4w,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 01:55:06,tipos genéricos anónimos en scala wildcards y subtipado ,,,,,
1k5m9jk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 00:39:24,tipos de herencia en c ,,,,,
1k5m8pr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 00:38:10,comprehensibility and perceived correctness is all you need in this recent icse work we explored how software developers define and evaluate the trustworthiness of an aigenerated code suggestion and what the reasons are that they may change their minds later about their decision the result shows that they only consider comprehensibility and correctness as their factors for trust and dont or couldnt due to lack of tools assess for safety and maintainability of the code we also found that developers cant assess the correctness of the code correctly therefore theres a gap between the perceived correctness and the actual correctness which makes them alter their trust in already trusted ai code generation nextgeneration ai code assistants can be overtrusted and we should think of tools that can help programmers make more informed decisions when trusting aigenerated code,,,,,
1k5l18x,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 23:39:21,where flakes fall off an eval cache tale ,,,,,
1k5islk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 21:57:29,top python libraries by use case your ultimate guide to pythons power tools hey all ive been working on organizing python libraries by what people actually want to build stuff like web apps data science automation ai etc hope it help yall,,,,,
1k5hxi7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 21:20:50,software summaries newsletter this is a free biweekly newsletter with interesting topics in software development i have read i would appreciate it if you shared some thoughts and feedback about it here,,,,,
1k5hs59,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 21:14:37,lets make a game automatic testing multiple runs ,,,,,
1k5dyzg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 18:40:56,are micro frontends right for your team ,,,,,
1k5dj4g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 18:23:40,i started a dev blog about working with swiftui and c to create a native twitch application ,,,,,
1k5c83f,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 17:31:51,confusing python code snippets ,,,,,
1k5c1q5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 17:24:42,webassembly how to allocate your allocator ,,,,,
1k5bl2t,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 17:06:22,scritch modified scratch optimised for teaching ,,,,,
1k5bkbk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 17:05:28,eventhidden architectures ,,,,,
1k5bk2y,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 17:05:13,detecting if an expression is constant in c ,,,,,
1k5bk1s,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 17:05:10,start with a clean slate integration testing with postgresql ,,,,,
1k5bgjv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 17:01:18,basic computer games ,,,,,
1k5bfbf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 17:00:08,pike a dynamic programming language with a syntax similar to java and c ,,,,,
1k5bdy9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:58:34,clickhouse gets lazier and faster introducing lazy materialization ,,,,,
1k5bdoc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:58:15,abusing duckdbwasm by making sql draw d graphics sort of ,,,,,
1k5b5qf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:49:16,here are things i wish i knew before my aws solutions architect associate exam share it with someone who may need it,,,,,
1k5avir,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:37:48,bloom filters a memorysaving solution for set membership checks ,,,,,
1k5ap88,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:30:36,apache airflow released ,,,,,
1k5a18t,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:03:48,freedom dumlao what java services taught me about focus just published a conversation with freedom dumlao cto at vestmark on the maintainable podcast we talked about why his team replaced java microservices with a single rails monolith at a previous companyand what changed the performance and team culture gains that followed how hes prototyping new fintech products in ruby on rails while maintaining a yearold java monolith managing t in assets practical ways theyre using ai to navigate and document legacy systems lessons in technical debt psychological safety and decisionmaking velocity its a solid listen for anyone juggling legacy systems modern dev stacks and the human side of software,,,,,
1k59yvk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:01:12,day mastering middleware in nodejs build modular and reusable logic with express ,,,,,
1k59svb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 15:54:29,web scraping tiktok using python ,,,,,
1k580d3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 14:42:07,an ode to mastery constructing complexity part ,,,,,
1k57qvu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 14:30:53,building for production ,,,,,
1k57cct,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 14:13:40,orm objectrelational mapping bridging the gap between objects and relational databases ,,,,,
1k56keb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 13:40:06,beyond the code unconventional lessons from empathetic interviewing i recently designed and conducted interviews and had many thoughts documented here it contains page brief sent to candidates feedback from the offered candidate it provides guidance on how to make a good session diving into detailed mindsets and behaviours im interested to hear unique experiences youve had in interviews any activities or specific discussions you found were particularly engaging or beneficial to the process what feedback did you receive after putting in what effort to get it how did your interviewers misinterpret you or how you could have told a story better anything else you wish was done to make both sides more prepared,,,,,
1k56hlt,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 13:36:31,we interviewed eng teams the problem with modern engineering isnt speed its chaos ,,,,,
1k5658h,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 13:20:54,effective code reviews with conventional comments paul slaughter adrienne braganza ,,,,,
1k55cld,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 12:43:20,do you write safetycritical software like automotive aerospace medical or industrial the rust foundations safetycritical consortium is conducting a survey on rust and tooling used in sc software industries ,,,,,
1k54lvz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 12:04:30,ultimatum chromium with webextensions support on android and much more ok now its official first webextension working in ultimatum browsec its just working ive tested browsec webextension only but others vpn extensions should work as well here you can download apk here is instruction how to install webextensions here is description and the instruction how to build if you brave enough and here you can find the code enjoy,,,,,
1k541xl,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 11:34:53,xrp supplychain attack official ripple npm package infected with cryptostealing backdoor a few hours ago we discovered that the offical xrp npm package has been compromised and malware has been introduced to steal private keys this is the official ripple sdk so it could lead to a catastrophic impact on the cryptocurrency supply chain luckily we did catch it early so hopefully wont be introduced by the major exchanges currently this is still live on npm,,,,,
1k53qm4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 11:16:46,unstructured thoughts on the problems of ossfoss ,,,,,
1k53gtt,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 11:00:44,lode coding ,,,,,
1k534h4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 10:38:39,how we diagnosed and fixed the voyager anomaly from billion miles away ,,,,,
1k528l8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 09:37:56,coding as craft going back to the old gym ,,,,,
1k511df,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 08:08:58,expose local dev server with ssh tunnel and docker in development we often need to share a preview of our current local project whether to show progress collaborate on debugging or demo something for clients or in meetings this is especially common in remote work settings there are tools like ngrok and localtunnel but the limitations of their free plans can be annoying in the long run so i created my own setup with an ssh tunnel running in a docker container and added traefik for to avoid asking nontechnical clients to tweak browser settings to allow insecure http requests i documented the entire process in the form of a practical tutorial guide that explains the setup and configuration in detail my docker configuration is public and available for reuse the containers can be started with just a few commands you can find the links in the article the link to the article i would love to hear your feedback let me know what you think have you made something similar yourself have you used a different tools and approaches,,,,,
1k4znic,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 06:29:46,javascript questions that only a few developers can answer ,,,,,
1k4z7n9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 05:59:17,scaling horizons effective strategies for wixs scaling challenges key takeaways explore sharding techniques and routing strategies at wix learn about important considerations for sharding key and routing selection understand when to implement specific scaling methods for enhanced availability,,,,,
1k4ypcf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 05:25:44,understanding graphql federation in microservices architecture ,,,,,
1k4u4o2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 01:15:10,day how to send realtime notifications in nodejs using socketio ,,,,,
1k4u098,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 01:09:04,python newbie check out my beginnerfriendly python tutorials hey fellow redditors ive been sharing bitesized python tutorials on my blog and id love for you to check them out my goal is to make learning python easy and accessible let me know what you think,,,,,
1k4sur2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 00:12:09,the recordtuple ecmascript proposal has been withdrawn ,,,,,
1k4sund,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 00:12:01,cheating the reaper in go ,,,,,
1k4qqjh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 22:34:30,pydrofoil accelerating sailbased instruction set simulators ,,,,,
1k4piuh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 21:41:59,github opencodex fully opensource commandline ai assistant inspired by openai codex supporting local language models ,,,,,
1k4pbu7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 21:33:41,thoughts on bluesky verification ,,,,,
1k4mww3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 19:54:51,how to use gyroscope in presentations or why take a joycon to dpg towards data science ,,,,,
1k4jlg0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:43:34,why openssfs baseline security for open source projects is important ,,,,,
1k4jabg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:31:35,lines of verified cryptography now in python ,,,,,
1k4ja12,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:31:16,efficient ematching for super optimizers ,,,,,
1k4j9ov,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:30:53,deus lex machina releasing a new compacting zig tokenizer ,,,,,
1k4j90u,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:30:12,vendoring ,,,,,
1k4j8p5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:29:54,notes on b k implementation ,,,,,
1k4j88i,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:29:22,on bloat rob pike slides ,,,,,
1k4j714,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:28:05,layered design in go ,,,,,
1k4j6us,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:27:52,on the cruelty of really teaching computing science ,,,,,
1k4j6n8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:27:38,lets give provenix a barely adequate prec tcpip stack featuring slirpck ,,,,,
1k4j6c0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:27:17,ansible pure only in its pragmatism ,,,,,
1k4j5zl,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:26:53,regex affordances ,,,,,
1k4j44o,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:24:51,how i use kate editor ,,,,,
1k4j335,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:23:43,pushing the limits of llm quantization via the linearity theorem ,,,,,
1k4j2wm,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:23:31,better error handling ,,,,,
1k4j2ne,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:23:15,falsify hypothesisinspired shrinking for haskell ,,,,,
1k4ixua,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:17:52,coding neon kernels for the cortexa ,,,,,
1k4ixn9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:17:38,things zig comptime wont do ,,,,,
1k4ixgs,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:17:27,reverse engineering the obfuscated tiktok vm ,,,,,
1k4ix39,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:17:02,decentralizing schemes ,,,,,
1k4iwx4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:16:51,haskelling my python ,,,,,
1k4iwkq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:16:28,pythons new tstrings ,,,,,
1k4iwjg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:16:26,tabular programming a new paradigm for expressive computing ,,,,,
1k4ivzj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 17:15:47,adding keyword parameters to tcl procs ,,,,,
1k4hyxp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 16:40:29,is my sudoku algorithm ethical ,,,,,
1k4hg9j,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 16:20:10,how does oauth work eli so i was reading about oauth to learn it and have created this explanation its basically a few of the best i have found merged together and rewritten in big parts i have also added a _super short summary_ and a _code example_ maybe it helps one of you oauth explained the basic idea lets say linkedin wants to let users import their google contacts one obvious but terrible option would be to just ask users to enter their gmail email and password directly into linkedin but giving away your actual login credentials to another app is a huge security risk oauth was designed to solve exactly this kind of problem note so oauth solves an authorization problem not an authentication problem see hereref for the difference super short summary user clicks import google contacts on linkedin linkedin redirects user to googles oauth consent page user logs in and approves access google redirects back to linkedin with a onetime code linkedin uses that code to get an access token from google linkedin uses the access token to call googles api and fetch contacts more detailed summary suppose linkedin wants to import a users contacts from their google account linkedin sets up a google api account and receives a client_id and a client_secret so google knows this client id is linkedin a user visits linkedin and clicks import google contacts linkedin redirects the user to googles authorization endpoint client_id is the before mentioned client id so google knows its linkedin redirect_uri is very important its used in step in scope linkedin tells google how much it wants to have access to in this case the contacts of the user the user will have to log in at google google displays a consent screen linkedin wants to access your google contacts allow the user clicks allow google generates a onetime authorization code and redirects to the uri we specified redirect_uri it appends the onetime code as a url parameter so the url could be now linkedin makes a servertoserver request not a redirect to googles token endpoint and receive an access token and ideally a refresh token finished now linkedin can use this access token to access the users google contacts via googles api question _why not just send the access token in step _ answer to make sure that the requester is actually linkedin so far all requests to google have come from the users browser with only the client_id identifying linkedin since the client_id isnt secret and could be guessed by an attacker google cant know for sure that its actually linkedin behind this in the next step linkedin proves its identity by including the client_secret in a servertoserver request security note encryption oauth does not handle encryption itself it relies on ssltls to secure sensitive data like the client_secret and access tokens during transmission security addendum the state parameter the state parameter is critical to prevent crosssite request forgery csrf attacks its a unique random value generated by the thirdparty app eg linkedin and included in the authorization request google returns it unchanged in the callback linkedin verifies the state matches the original to ensure the request came from the user not an attacker oauth vs oauth addendum oauth required clients to cryptographically sign every request which was more secure but also much more complicated oauth made things simpler by relying on to protect data in transit and using bearer tokens instead of signed requests code example oauth login implementation below is a standalone nodejs example using express to handle oauth login with google storing user data in a sqlite database javascript const express requireexpress const axios requireaxios const sqlite requiresqliteverbose const crypto requirecrypto const jwt requirejsonwebtoken const jwksclient requirejwksrsa const app express const db new sqlitedatabasememory initialize database dbserialize dbrun create table users id integer primary key autoincrement name text email text dbrun create table federated_credentials user_id integer provider text subject text primary key provider subject configuration const client_id processenvgoogle_client_id const client_secret processenvgoogle_client_secret const redirect_uri const scope openid profile email jwks client to fetch googles public keys const jwks jwksclient jwksuri function to verify jwt async function verifyidtokenidtoken return new promiseresolve reject jwtverify idtoken header callback jwksgetsigningkeyheaderkid err key callbacknull keygetpublickey audience client_id issuer err decoded if err return rejecterr resolvedecoded generate a random state for csrf protection appgetlogin req res const state cryptorandombytestostringhex reqsessionstate state store state in session const authurl resredirectauthurl oauth callback appgetoauthcallback async req res const code state reqquery verify state to prevent csrf if state reqsessionstate return resstatussendinvalid state parameter try exchange code for tokens const tokenresponse await axiospost code client_id client_id client_secret client_secret redirect_uri redirect_uri grant_type authorization_code const id_token tokenresponsedata verify id token jwt const decoded await verifyidtokenid_token const sub subject name email decoded check if user exists in federated_credentials dbget select from federated_credentials where provider and subject subject err cred if err return resstatussenddatabase error if cred new user create account dbrun insert into users name email values name email function err if err return resstatussenddatabase error const userid thislastid dbrun insert into federated_credentials user_id provider subject values userid subject err if err return resstatussenddatabase error ressendlogged in as name email else existing user fetch and log in dbget select from users where id creduser_id err user if err user return resstatussenddatabase error ressendlogged in as username useremail catch error resstatussendoauth or jwt verification error applisten consolelogserver running on port,,,,,
1k4gkcj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 15:36:39,cookies explained why every website asks about cookies and why you should care ,,,,,
1k4fhmu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 14:53:32,an under the hood look at how we built an mcp server for our tool all technicals ,,,,,
1k4f723,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 14:41:12,classifying chat groups with coreml and gemini to match interest groups unpaywalled,,,,,
1k4em69,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 14:16:48,beware the singlepurpose people youll likely confront singlepurpose people or spp aka the purity police these folks love to bring up first principles which is funny because they seem to only have one principle make everything as small and atomic as possible full article,,,,,
1k4e521,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 13:56:23,how to handle large csv downloads with background jobs tejaya tech ,,,,,
1k4c7g8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 12:24:00,a multilanguage codebase with symbolic abstractions would love feedback from systems thinkers ive been building a complex system that blends multiple languages python ruby typescriptreact to explore how software can model not just logic but layered meaning its not your typical crud stack this project uses a dialectic structure where each knowledge entry has a main point a counterpoint and a counterfactual theres also a custom lexical network think a dynamic ontology of stems and familiar terms and experimental logic layers inspired by mathematical structures ive just published a deepdive comparing this approach to conventional best practices especially stanfordstyle architecture modularity naming and testability im not rejecting best practices i value it but this system takes a more experimental recursive approach and id love critical thoughtful feedback from devs who think about structure semantics and system design if this sounds interesting the article is here the longer version i know the system might seem overengineered or even eccentric but it wasnt built to be clever it was built to model relationships between ideas in ways that flat logic sometimes misses that said im still looking for collaborators who can help refine it simplify parts and connect it back to more standard tooling if youve worked on dsls symbolic reasoning recursive data or youre just into bending the usual paradigms would love your take and yeah i know some naming conventions are unconventional open to ideas thanks for reading and if it sparks anything reach out or leave a comment,,,,,
1k4c5g5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 12:20:56,pipelining might be my favorite programming language feature ,,,,,
1k4c4t0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 12:19:59,getting forked by microsoft ,,,,,
1k4c3bf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 12:17:43,every software engineer must know about idempotency concept ,,,,,
1k4b3i2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 11:22:20,api gateway in diagram and words ,,,,,
1k49nuc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 09:48:49,x faster and x happier how wix reinvented integration testing ,,,,,
1k48mey,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 08:35:41,postgresql jsonb powerful storage for semistructured data ,,,,,
1k45nqt,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 05:05:12,build simple ecommerce site using lit web components ,,,,,
1k45lwh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 05:01:59,critical clean architecture book review and analysis the database is a detail ,,,,,
1k43jpg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 03:01:29,a browserbased text editor optimized for ease of reading on github many years ago when i had a betweenjobs stint i wrote a new kind of text editor as a desktop app which i find very useful for dealing with legacy code recently following another round of redundancy and there being a gap till the next joining date i have tried to port some of the features of spectral desktop to a selfcontained browserbased interface mostly using chatgpt it is very simple to use and hopefully simple to extend i am leaving the github link here in case someone finds it useful here is a slightly dated demo some more features have been added since this was recorded,,,,,
1k40wwk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 00:41:10,solid understanding of solid leave a clap if u like the article,,,,,
1k3zmdw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 23:35:34,announcing traeger a portable actor system for c and python i have been working for several months on a personal project that i just published it is an actor system for c with bindings for python go and c it is written in c for portability with minimal use of templates to facilitate interoperability with other languages it is still in an early stage but i think it provides the basics of the actor model value semantics based on immer serialization json yaml and messagepack scheduler threadpool promises actors with mailboxes and messages sequential for writers concurrent for readers network transparency based on zmq it has been tested on ubuntu macos for both x_ and arm and windows please take a look experiment and if you like it or find it interesting give it a star thank you in advance,,,,,
1k3xz7r,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 22:14:30,where is the java language going ,,,,,
1k3wymf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 21:26:23,dart is not just for flutter its time we start using it on the server i built wailuku an open source web framework inspired by expressjs to help those who want to transtition from js to dart why use dart on the server unified language for full stack as flutter now supports almost all platforms web compiled language null safety and type safe a strong community with a variety of packages that server almost every scenario i think its time dart gets more recognition on the server so i built wailuku a lightweight backend framework that emulates expressjs syntax id be super helpful if i can get some feedback suggestions and contributions thanks,,,,,
1k3sqj0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 18:11:03,top ai coding tools for engineering teams in ,,,,,
1k3sqbh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 18:10:49,simplicity vs complexity in software engineering which is better ,,,,,
1k3soky,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 18:08:43,genéricos en scala covarianza y contravarianza ,,,,,
1k3s77g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 17:47:50,lets make a game testing combat ,,,,,
1k3rygg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 17:36:59,an arguably better file picker experience for vscodecodiumcursor users ,,,,,
1k3qevw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 16:28:48,the local openai api frontend i wanted lines of html css js no frameworksno frameworks no vercel no deployment copy html to a file save the file with a html extension open it on a desktop browser havent tested mobile and wont hit show settings paste your openai api key into the settings select your model after they load default gpt hide settings enjoy quick rant this should have already existed maybe it does somewhere and i just couldnt find it i did find at least a half dozen projects that did this worse with far more complication than a single line file,,,,,
1k3q0st,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 16:10:59,swarm debugging with mcp everyones looking at mcp as a way to connect llms to tools what about connecting llms to other llm agents i built deebo the first ever agent mcp server your coding agent can start a session with deebo through mcp when it runs into a tricky bug allowing it to offload tasks and work on something else while deebo figures it out asynchronously deebo works by spawning multiple subprocesses each testing a different fix idea in its own git branch it uses any llm to reason through the bug and returns logs proposed fixes and detailed explanations the whole system runs on natural process isolation with zero shared state or concurrency management look through the code yourself its super simple if youre on cline or claude desktop installation is as simple as npx deebosetuplatest heres the repo take a look at the code heres a demo video of deebo in action on a real codebase deebo scales to real codebases too here it launched scenarios and diagnosed a bug bounty issue in tinygrad you can find the full logs for that run here would love feedback from devs building agents or running into flowbreaking bugs during aipowered development,,,,,
1k3odxr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 14:57:45,tensorflow implementation for optimizers ,,,,,
1k3o0d2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 14:40:17,ahash bit and native bit hash functions available ,,,,,
1k3mjlz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 13:27:47,jujutsu different approach to versioning ,,,,,
1k3m3oy,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 13:04:29,a small dive into virtual memory hey guys i recently made this small introduction to virtual memory i plan on making a follow up thats more practical if it interests some people,,,,,
1k3m2fd,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 13:02:34,f race prediction algorithm wip a sophisticated formula race simulation tool that models and predicts f race outcomes with realistic parameters based on driver skills team performance track characteristics and dynamic weather conditions ,,,,,
1k3i9i6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 08:45:50,a consul mcp server modelcontextprotocol hello everyone im excited to share a project ive been working on consulmcpserver a mcp interface for consul you can script and control your infrastructure programmatically using natural or structured commands currently supports service management health checks keyvalue store sessions events prepared queries status agent system feel free to contribute or give it a if you find it useful feedback is always welcome,,,,,
1k3hz8g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 08:24:43,kubernetes deployment strategies and how they work ,,,,,
1k3hwiu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 08:18:51,hunting zombie processes in go and docker hey everyone this is the story of how i debugged a random error and found out a completely different underlying reason i thought sharing the learnings,,,,,
1k3e0ax,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 03:56:51,model context protocol exhaustively explained hey redditors i recently published a deepdive technical blog on the model context protocol mcpa rising open standard introduced by anthropic to let ai agents interact with external tools data sources and systems in a consistent and secure way what is mcp in a nutshell think of it as the usbc for ai agents it allows llms to interact with realworld systems apis files databases saas apps using a common protocol that supports context fetching tool usage and secure operation mcp removes the need for mn integrations by standardizing the interface the blog covers what is mcp and why it matters for ai the mn problem vs mn elegance clientserver architecture and message patterns jsonrpc tools resources and prompts the primitives transport options like http sse security considerations auth isolation rate limiting audit logs strategic adoption advice for enterprises i also built a working demo on github using fastapi mcp server exposing a sample tool via jsonrpc sse endpoint to simulate realtime event streaming python client that lists and invokes tools via mcp read the blog github demo what im looking for im looking for feedback improvements and ideas from architects implementing genai in production engineers working with agents tools or langchain ai security folks thinking about safe llm integrations devs curious about protocol design for agent frameworks i would really appreciate a review from folks who think critically about architecture protocol interoperability or just love breaking down new standards i am not someone who is lucky enough to work on frontier technologies i try my best to catch up with evolution and share my learning with others who may not have the time i spent to learn the subject so in all fairness i am looking for avenues to improve in blogging and adding meaningful value to the community,,,,,
1k39f3m,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 23:36:44,global coding dojo may join developers worldwide for collaborative coding and learning ,,,,,
1k36eno,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 21:08:50,login and registration form in php and mysql ,,,,,
1k35hii,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 20:25:57,refs guide hi everyone heres a little guide i wrote on a ref class i wrote to make gui programming easier,,,,,
1k34p0m,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 19:49:28,i built a free practice rest api for students with filtering sorting and swagger docs hey i built a free api that im sharing with anyone who wants to learn or experiment with something real its a collection of cocktail recipes and ingredients recipes and ingredients to be exact it comes with full swagger documentation so you can explore the endpoints easily no signups no hassle just grab the url and start making requests it supports features like pagination filters and autocomplete for a smooth experience perfect for students or anyone learning how to work with apis hope its useful to some of you,,,,,
1k2zpp9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 16:06:54,lets make a game starting automated testing ,,,,,
1k2z3fc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 15:39:33,how to build an mcp server and client with fastmcp and langchain in this video well build an mcp model context protocol server using fastmcp and create a langchain ai agent that connects to it and uses its tools if youre curious about building your own mcp servers or want to create ai agents that leverage mcp tools this video is for you you can find the source code here,,,,,
1k2uycx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 12:17:44,jsx over the wire ,,,,,
1k2uy82,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 12:17:31,chroma ubisofts internal tool used to simulate colorblindness ,,,,,
1k2uxuf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 12:16:58,differentiable programming from scratch ,,,,,
1k2t11l,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 10:12:11,postgresql superpowers in practice ,,,,,
1k2rz06,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 08:53:47,my school project from a flowchart generator written in bbc basic ,,,,,
1k2rsou,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 08:40:24,how to design netflix logo using html and css ,,,,,
1k2rgwq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 08:16:05,i made a gif that features c code that outputs the gif that features the c code source code here,,,,,
1k2rcre,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 08:07:39,lessons from building and maintaining distributed systems at scale ,,,,,
1k2r3ez,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 07:48:51,why im taking the creative coding path perhaps its just me who havent heard much discussion around creative coding but i want to go down this road because frankly everything else has been quite boring to me not everyone will find the same stuff exciting theres just something about the task of coding something meant for expression that brings back a spark to chase whatever dread andor lesson to learn awaiting each step forward,,,,,
1k2lyki,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 02:21:05,what is keybased vs rangebased partitioning in databases ,,,,,
1k2jv1l,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 00:27:39,the inner platform effect or why you might be hurting yourself ,,,,,
1k2ilmi,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 23:23:08,a debugger is a repl is a debugger ,,,,,
1k2ijg3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 23:20:12,comptime zig orm ,,,,,
1k2huc9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 22:46:16,github andrmicrolog a lightweight customizable logging library in c just two files compatible with c and most major compilers ,,,,,
1k2g361,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 21:25:16,responsive card html css with hover effects in this project we focused on creating a responsive clip path card layout using html and css designed to showcase various cities with engaging visuals and informative content the goal was to develop a modern interactive card component that not only looks appealing but also functions well across different devices and screen sizes,,,,,
1k2flmp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 21:03:52,why my vibecoded app has over lines of code demo code walkthrough i received a comment on tiktok from an internet stranger questioning my ability to code because my app is very large and very complicated for context im building nexustrade an aipowered algorithmic trading platform that lets retail investors create test and deploy algorithmic trading strategies and perform financial research because i use the cursor ide some engineers think i just vibecoded an unmaintainable spaghettimess of a monstrosity that couldnt be further from the truth for one ive been working on this app for over four years long before cursor was even released i only started using it recently to speed up development for two i went to carnegie mellon university the best software engineering school in the world and earned my master of science in software engineering on a fullride scholarship i architected the system to have clean readable extensible and maintainable code that follows real software engineering best practices other examples of my work can be found on my github for example the predecessor to nexustrade called nexttrade is fully opensource note this was created before chatgpt or ai tools like cursor even existed just because someone uses cursor doesnt mean they dont know how to code vibecoding is real and when used correctly its a superpower,,,,,
1k2ev0o,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 20:31:33,meta mcp chaining tools via promptdriven arguments this post explores the concept of an mcp tool that can chain multiple tools within a single request where the arguments for each tool can be dynamically generated using prompts based on the outputs of previous tools,,,,,
1k2cfpp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 18:47:14,feature flags for the win decoupling code deployments from launching features ,,,,,
1k2bc40,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 18:01:22,optimizing heap allocations in golang a case study ,,,,,
1k2b43h,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:51:58,decomposing transactional systems ,,,,,
1k2b3ns,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:51:28,lockless programming considerations for xbox and microsoft windows ,,,,,
1k2b3gz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:51:14,a survey of recent byzantine fault tolerance algorithms ,,,,,
1k2b32z,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:50:46,microsecond transforms building a fast sandbox for user code ,,,,,
1k2b2o2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:50:17,reflections on unikernels ,,,,,
1k2b2ee,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:49:59,common shell script mistakes ,,,,,
1k2b1v4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:49:22,the subjective charms of objectivec ,,,,,
1k2b0z2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:48:18,the size of packets ,,,,,
1k2b0rb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:48:03,zig and gpus ,,,,,
1k2b0d7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:47:35,what do i think about lua after shipping a project with k lines of code ,,,,,
1k2b02n,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:47:15,four years of jai ,,,,,
1k2azhv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:46:33,growing a language pdf ,,,,,
1k2ayyz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:45:55,less slow c ,,,,,
1k291lu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 16:25:27,graphrag with mongodb atlas integrating knowledge graphs with llms mongodb blog ,,,,,
1k27y0s,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 15:39:21,antithesis driven testing ,,,,,
1k26uss,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 14:53:40,full stack instagram clone with laravel and mongodb tutorial ,,,,,
1k26p9w,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 14:47:01,behaviors of top architects being an architect is less about control and more about orchestration from active listening to system thinking and leading change this post dives into five key behaviours that help architects thrive in chaotic environments with anecdotes lessons and practical tips its a guide for those shaping the bigger picture,,,,,
1k260qe,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 14:17:11,how to be a anti hero ,,,,,
1k24tej,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 13:22:34,building a football tracking system with yolo and python ,,,,,
1k24n5l,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 13:14:19,devs and dbas cant find peace but could they call a truce are dbas the guardians of order or just here to give devs a hard time,,,,,
1k23nh5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 12:24:15,architecture responsible technology rebecca parsons ,,,,,
1k22pdf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 11:32:15,arxiv moving from cornell servers to google cloud ,,,,,
1k217n0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 09:58:00,evil regex hacking in codewars an outrageous solution to find if a king is in check ,,,,,
1k20xf6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 09:38:08,python is here whats new new interpreter new module and more ,,,,,
1k1zawh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 07:39:50,start a common lisp project in with clyasboi ,,,,,
1k1pkys,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 22:28:31,i published an updated version of my study path on software development we are almost there approaching the k stars its been a while since my last update but the study path is now updated with more content and a better overall presentation just in time as we approach the k stars on github this project is for anyone looking for wellorganized resources on software development with curated sections on clean code tdd refactoring software architecture ddd microservices and much more i hope you can find it helpful for your learning journey feedback is always welcome and if youd like to contribute please feel free to jump in with ideas or pull requests link to the study path whats new updated introduction a clearer introduction session summaries each section now includes a short summary to highlight its value focus practices tips to help you stay more focused while writing code solid for functional programming explore how solid relate to fp book links via goodreads easier to browse and track your reading new book domain modeling made functional added to ddd topics monolith to microservices guidance on evolving your monolithic code base to microservices more refactoring exercises new code kata to better explore the functionality of your ide more on eventdriven architecture expanded resources and patterns legacy code testing and refactoring an alternative video testing and refactoring with more insights more on unit testing extra content to get better at unit testing four rules of simple design expanded with a new book,,,,,
1k1p007,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 22:01:57,pair programmers unite a quiet rebellion ,,,,,
1k1nqs5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 21:06:36,vaadin components ecosystem building blocks for powerful applications ,,,,,
1k1nmh4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 21:01:25,nanosecondsoverhead c tracer hello everyone i did a project that is a instrumentationbased tracerprofiler that allows you to get a timeline of your system execution with really good time resolution while there are many tools around that do similar things this one im proud of because it allows you to achieve very low overhead even like nanoseconds per event gathered as an example function body call would need two such events one to mark entry and second to mark exit this work was initially done as part of my job but my company made its version open source so finally i can redistribute my own companyagnostic version of it why its cool and how can it help you if you have some multithreaded application that has very very tight work being done there on few microseconds level with various dependencies between those threads analysing performance issues can be very hard because sampling profiler wont tell you everything due to averaging everything and manual instrumentation based on standard functionality can be simply too slow to keep some phenomena happening during profiling causing performance heisenbugs kinda additional thing that make this stand out its just files you need to include in your project to start running its very lightweight and easy well if youre advanced to understand i guess it raises its educational value because you can easily get a grasp of what is going on and learn something neat about assembly code even if you dont want to actually use it i created an article that is mentioned in the readme in which i tried to explain why some things are done that way and not the other of course its not ideal it is not portable only supports modern x cpus and modern windowsubuntu oses and it is not written in very clean way as some of the stuff could really be cleaned up without breaking the performance so while i believe it has tons of educational value clean code is not part of this value p you have been warned one day im planning to also make another article something like code walkthrough for less advanced readers but i need to find some time to do it i hope you like it enjoy,,,,,
1k1m4oc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 19:58:02,crosssite websocket hijacking exploitation in hey everyone we published a new blog post today focusing on the current state of crosssite websocket hijacking our latest blog post covers how modern browser security features do or dont protect users from this oftenoverlooked vulnerability class we discuss total cookie protection in firefox private network access in chrome and review the samesite attributes role in cswh attacks the post includes a few brief case studies based on situations encountered during real world testing in addition to a simple test site that can be hosted by readers to explore each of the vulnerability conditions,,,,,
1k1lu1o,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 19:45:34,everyone knows your location part try it yourself and share the results ,,,,,
1k1ku83,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 19:03:18,covarianza y contravarianza en c ,,,,,
1k1ku3n,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 19:03:09,nparams vs single param ,,,,,
1k1kn02,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 18:55:02,earthly shutting down earthfiles ,,,,,
1k1k786,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 18:36:23,i built a full on palindrome finder with manachers algorithm heres how it works hey everyone im a yearold programmer passionate about al fullstack development and algorithms i just uploaded a youtube video where i explain manachers algorithm which finds the longest palindromic substring in linear time on the video is beginnerfriendly and i also shared the fully commented python code on github with explanations id love any feedback you have on the video or the way i explain things feel free to check out my github youll find the code from this video there plus a fullstack web app coming soon github,,,,,
1k1jn9x,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 18:13:28,serbia cellebrite zeroday exploit used to target phone of serbian student activist the exploit which targeted linux kernel usb drivers enabled cellebrite customers with physical access to a locked android device to bypass the lock screen and gain privileged access on the device pdf ,,,,,
1k1hp4u,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 16:54:32,the impact of mcp and llms on software development a practical example ,,,,,
1k1fzwp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 15:44:59,optimizing compaction in apache cassandra hey all i recently did an in depth performance analysis of compaction in apache cassandra some changes have already been implemented as a result massively increasing throughput allowing users to run way denser nodes the post has the details of the analysis and optimizations down to the individual filesystem calls and how they were improved,,,,,
1k1fmd1,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 15:29:12,diskless kafka leaner open ,,,,,
1k1fc58,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 15:17:24,typescript cookbook stefan baumgartner peter kröner ,,,,,
1k1f482,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 15:08:07,building with purpose adding the models and relations ,,,,,
1k1dylg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 14:19:11,ios dlsym considered harmful ,,,,,
1k1d4r3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:43:48,integrating effectful and persistent ,,,,,
1k1d4d2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:43:21,all databases are just files postgres too ,,,,,
1k1d4cd,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:43:19,regular expression derivatives in python ,,,,,
1k1d3t9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:42:42,query engines push vs pull ,,,,,
1k1d30b,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:41:43,concurrency in haskell fast simple correct ,,,,,
1k1d2z3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:41:41,differentiable programming from scratch ,,,,,
1k1d1vl,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:40:21,making software an illustrated reference manual for people who design and build software ,,,,,
1k1d1b8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:39:41,advanced shell scripting with bash pdf ,,,,,
1k1c4wq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 12:57:43,crc demystified ,,,,,
1k1bqhb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 12:37:43,the htmlcss lie weve all been sold why mislabeling these tools is killing your growth ,,,,,
1k1bnye,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 12:34:12,functional jsxsyntax for webcomponents i made something to try out for funtional webcomponents with vanillajs im working towards a ui framework for my personal projects its far from finished but i thought it might be an interesting concept to share,,,,,
1k19ocm,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 10:41:55,development on apple silicon with utm ,,,,,
1k17oob,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 08:17:52,tech talks weekly java python react ts swift ks ddd cqrs ml rag ruby c unison and many more ,,,,,
1k14817,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 04:20:20,there is no open source ai ,,,,,
1k11l0o,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 01:55:35,an intro to deepseeks distributed file system ,,,,,
1k0wouy,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 21:58:35,github copilot autoenabled itself on my private local workspaces without my consent ,,,,,
1k0u6eb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 20:12:16,four kinds of optimisation ,,,,,
1k0tsm5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 19:56:53,tls certificate lifetimes will officially reduce to days ,,,,,
1k0tiio,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 19:44:59,learning fennel from scratch to develop neovim plugins ,,,,,
1k0sc6y,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 18:56:10,microsoft nodejs increasingly used for malware delivery and data theft ,,,,,
1k0rmt5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 18:27:27,i built an ai factchecker in weeks as a solo founder heres my journey from min python snippet to chrome extension sharing my experience building an ai tool with ai coding in weeks claude thinking claude for mvp cursor claude for development railway for deployment of both backend and landing page how to go through chromeedge review for web store listing other thoughts read linkedin post here github sztimhddveritai use gemini api to fact check any web page blogpost news report etc,,,,,
1k0pohc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 17:09:32,a look at rangev code generation ,,,,,
1k0p8a7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 16:52:01,cisa extends funding to ensure no lapse in critical cve services ,,,,,
1k0owr6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 16:38:51,replacing cve ,,,,,
1k0oste,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 16:34:15,is spacetimedb a yakshaving success story ,,,,,
1k0orj7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 16:32:48,getting better performance out of object storage ,,,,,
1k0okkg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 16:24:48,two years of rust ,,,,,
1k0nlz9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 15:45:00,a pluginbased gateway that orchestrates other mcps and allows developers to build upon it enterprisegrade agents ,,,,,
1k0myss,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 15:17:54,hacking the postgres statistics tables for faster queries ,,,,,
1k0mioe,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:59:22,atomicless concurrency ,,,,,
1k0miag,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:58:54,an introduction to modern cmake ,,,,,
1k0mi9i,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:58:52,the story behind k mode and how it works ,,,,,
1k0mhsx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:58:17,cutting down rust compile times with one thousand crates ,,,,,
1k0mf09,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:55:04,fibonacci hashing the optimization that the world forgot ,,,,,
1k0me6g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:54:08,how to optimize rust for slowness inspired by new turing machine results ,,,,,
1k0mdpn,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:53:34,dirty tricks programmers use ,,,,,
1k0lt3s,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:29:36,intellij idea released ,,,,,
1k0lc35,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:09:06,ai is changing software engineering the road to i found this to be a rather balanced and practical discussion that doesnt fall victim to the ai hype but also recognizes the changes were going through,,,,,
1k0k8gv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 13:19:17,github iondodon is a fast minimalistic desktop http client ,,,,,
1k0k6q2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 13:17:02,github codrhackticalc a practical hackers guide to the c programming language ,,,,,
1k0jmww,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 12:51:09,what every programmer should know about how cpus work matt godbolt ,,,,,
1k0j9jk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 12:32:22,classic logisim running in the browser powered by cheerpj and webassembly ,,,,,
1k0iqxo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 12:05:36,how to build that ai project you have been dreaming about in steps this framework is called the ai project cycle which i read in a book a few days ago and thought id share it with everyone,,,,,
1k0i352,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 11:29:07,how figma scaled postgres to m users ,,,,,
1k0gnex,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 09:57:58,dinoxor reimplementing bitwise operations as abstractions in aarch neon registers i wanted to learn lowlevel programming on aarch and i like reverse engineering so i decided to do something interesting with the neon registers im just obfuscating the eor instruction by using matrix multiplication to make it harder to reverse engineer software that uses it i plan on doing this for more instructions to learn even more about asm and probably end up writing gpu code lmfao kill me i also wanted to learn how to do inline assembly in rust so i implemented it in rust too the rust program uses quickcheck to to generative testing so i can be really sure that it actually works i benchmarked it and its like a couple of orders of magnitude slower than just an eor instruction but i was honestly surprised it wasnt worse all the code for both projects are available on my github id love inputs ideas other weird bit tricks thank you,,,,,
1k0ghfu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 09:46:13,build lms platform from scratch how i structure api development in elixir phoenix ,,,,,
1k0eze6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 07:54:51,how to build an agent ,,,,,
1k0es5e,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 07:39:59,say hello to our new sorting algorithm phoenix sort hello guys im yasir and i created my own sorting algorithm that is inspired by stalin sort but instead of deleting unsorted elements it lets them rise from the ashes and reintegrate until the whole list is sorted,,,,,
1k0dyk8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 06:40:39,cve program faces swift end after dhs fails to renew contract leaving security flaw tracking in limbo ,,,,,
1k0dhvc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 06:08:01,nativeaot en net ,,,,,
1k0az4g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 03:31:19,how to speed up varnish cache and prevent hangs ,,,,,
1k0abmy,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 02:56:12,htmljs dom a lightweight alternative to react ,,,,,
1k08guk,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 01:18:55,why i still write vanilla javascript in and why you might want to ,,,,,
1k057wv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 22:39:45,designing a fast rng for simd gpus and shaders ,,,,,
1k005oi,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 19:04:23,levels of using a pythonic http client ,,,,,
1jzyuwx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 18:12:27,visualize a neural network in python using tkinter animated ai layers ,,,,,
1jzynh5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 18:04:06,books every software engineer must read in are you tired of chasing shiny new frameworks i wrote about the lindy effect in techwhy some tools like c and sql last foreverand shared books every dev should read this year,,,,,
1jzygsm,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 17:57:02,isolated execution environment for ebpf ,,,,,
1jzyg9j,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 17:56:28,jsx over the wire ,,,,,
1jzyfo3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 17:55:48,hacking the postgres wire protocol ,,,,,
1jzyffc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 17:55:32,the case of the ui thread that hung in a kernel call ,,,,,
1jzxylv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 17:36:44,scoped values in java ,,,,,
1jzxu1i,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 17:31:33,make python great again can you believe that,,,,,
1jzw379,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 16:21:42,how to be the best programmer according to daniel terhorstnorth great programmers are not born they are made says the author of the viral twitter thread on the best programmer he knows,,,,,
1jzvjxp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 16:00:09,building with purpose using prisma and postgresql for the database part ,,,,,
1jzuqi0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 15:27:13,fixing shotgun surgery in ruby i mentioned to someone recently that a feature at work suffered from shotgun surgery and was trying to figure out the right way to address it ended up writing a thing to explain my point using a noncontroversial domain and context,,,,,
1jzujux,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 15:19:47,the false productivity promise of aiassisted development ,,,,,
1jztbbv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:30:00,writing slow code on purpose ,,,,,
1jztadg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:28:55,python is an interpreted language with a compiler ,,,,,
1jztac6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:28:53,deploying typescript recent advances and possible future directions ,,,,,
1jzt9a0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:27:42,procedural foliage rendering with lsystems and geometry instancing ,,,,,
1jzt8vh,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:27:15,pretty state machine patterns in rust ,,,,,
1jzt83z,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:26:25,what makes a great developer experience ,,,,,
1jzt7rn,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:26:01,flambda ep how to write a purely functional compiler ,,,,,
1jzt7l1,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:25:49,algebraic semantics for machine knitting ,,,,,
1jzt7fy,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:25:40,async from scratch wake me maybe ,,,,,
1jzt7bc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:25:31,a relational model of data ,,,,,
1jzt762,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:25:21,flat origami is turing complete ,,,,,
1jzt6sr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:24:56,a survey of rust gui libraries ,,,,,
1jzt6n9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:24:46,what the hell is a target triple ,,,,,
1jzt66y,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:24:13,how janets peg module works ,,,,,
1jzt5w0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:23:53,monte carlo crash course sampling ,,,,,
1jzt5q8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:23:41,ascii lookup utility in ada ,,,,,
1jzst6p,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 14:09:05,urlsmart search with nextjs mongodb autocomplete rag vectors fuzzy search ,,,,,
1jzs2do,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 13:36:24,ai stole my coding job or did it ,,,,,
1jzrygp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 13:31:21,i built a formula mcp server to access realtime and historical data conveniently access formula data with my new mcp server access realtime race data team radio and historical stats all in one place perfect for f enthusiasts and data analysts alike check it out on github dont forget to star the repo and contribute if you find it useful,,,,,
1jzrcqz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 13:03:14,structured logging in net with nativeaot ,,,,,
1jzp7gf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 11:13:28,insights from the php foundation executive director ,,,,,
1jzom32,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 10:38:40,call for presentations at react advanced london ,,,,,
1jzodo9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 10:23:08,oop for total idiots part what is oop ,,,,,
1jzmopr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 08:24:26,ai stole my coding job or did it ,,,,,
1jzlw03,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 07:28:34,one year of product development visualised the video below was created with a data visualization tool that visually captures the journey of our code development over the past year on p our marketing ai assistant built with cuttingedge llms i wanted to share this visualization because it represents countless late nights and endless debugging sessions each commit tells a story its been quite the roller coaster watching our codebase evolve there were weeks when we completely restructured core components and days when a single bug fix took hours of collaborative troubleshooting,,,,,
1jzkzh0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 06:26:53,get started with object detection using esp cam and edge impulse ,,,,,
1jzk9e6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 05:38:27,stevens a hackable ai assistant using a single sqlite table and a handful of cron jobs ,,,,,
1jzk79x,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 05:34:21,the humanity in each line of code ,,,,,
1jza9y9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 21:15:59,levels of asynchronous programming in python ,,,,,
1jz8jrw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 20:05:18,c stdlib isnt threadsafe and even safe rust didnt save us ,,,,,
1jz8e2t,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 19:59:17,showcasing my github cli extension ghunpushed easily see your local commits that havent been pushed yet hey all i made a small github cli extension called ghunpushed it shows commits on your current branch that havent been pushed yet i was tired of typing git log originbranchhead so this is just gh unpushed you can also set a default remote check against upstream etc just a small qualityoflife thing for github cli users would love any feedback ideas features edge cases i havent thought of let me know what you think githubcomachoreimghunpushed thank you,,,,,
1jz5omf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 18:11:34,learn how react works by building your own framework ,,,,,
1jz3cqo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 16:37:02,how to handle jwt in python everything you need to know to implement and validate jwts securely in python from signing to verifying with jwks with code examples and best practices throughout,,,,,
1jz35xi,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 16:29:05,stop playing pong with your build server ,,,,,
1jz2jbq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 16:03:27,protobuftstypes zerocodegen typescript type inference from protobuf messages ,,,,,
1jz2ija,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 16:02:33,guide to realtime data stream apis ,,,,,
1jz1wmo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 15:37:54,a htmlcssjs quine that syntaxhighlights itself ,,,,,
1jz1id7,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 15:21:33,we dont need no virtualization ,,,,,
1jz0umd,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:54:42,guy live codes music and editor in basiccommodore ,,,,,
1jz0ena,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:36:08,rust to c compiler test pass rate odd platforms ,,,,,
1jz0d2x,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:34:17,performance analysis and tuning on modern cpus ,,,,,
1jz0chg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:33:35,bootstrapping understanding an introduction to reverse engineering ,,,,,
1jz0c91,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:33:18,awe a compiler for the algol w programming language ,,,,,
1jz0be6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:32:18,how git cherrypick and revert use way merge ,,,,,
1jz0azj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:31:47,python performance why if not list is x faster than using len ,,,,,
1jz0and,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:31:25,why pascal is not my favourite language ,,,,,
1jz0a2f,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:30:46,why is there a small house in ibms code page ,,,,,
1jz09sj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:30:27,fun with fsanitizeundefined and picolibc ,,,,,
1jz09lu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:30:14,emacs lisp elements ,,,,,
1jz09hb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:30:07,a visual journey through async rust ,,,,,
1jz085z,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:28:39,problems with go channels ,,,,,
1jz06gy,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:26:37,why fennel a programming language that runs on the lua runtime ,,,,,
1jz03ir,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:23:12,resurrecting infocoms unix zmachine with cosmopolitan ,,,,,
1jz02wr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:22:23,hacktical c practical hackers guide to the c programming language ,,,,,
1jz02cx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:21:40,zigs new linkedlist api its time to learn fieldparentptr ,,,,,
1jyzk6f,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:00:00,brother vibe coded assistive tech for his sibling with leukodystrophy video ,,,,,
1jyz41g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 13:39:25,an unofficial electron wrapper of crunchyroll for linux i really wish crunchyroll made an official app for linux but alas theres none so i made myself an electron wrapper of the crunchyroll website to run natively on your linux system note this is an unofficial application and is not associated with or endorsed by crunchyroll llc the app is an electron wrapper created for personal use only all content trademarks and logos are the property of their respective owners use of this app is for personal purposes only and not for commercial distribution,,,,,
1jyyx64,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 13:30:31,when ai ,,,,,
1jyyjcu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 13:12:41,how do you maintain context in aiassisted development a discussion on sustainable practices ,,,,,
1jyya63,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 13:00:46,i made a fast file explorer in c i made a fast file explorer in c using imgui and opengl,,,,,
1jyy52o,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 12:54:02,usertour v support nps csat ces multiplechoice and openended questions to get the data you need ,,,,,
1jyxu3p,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 12:39:14,engineers who wont commit ,,,,,
1jyxs22,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 12:36:22,ssh keys dont scale ssh certificates do ,,,,,
1jywcbw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 11:16:35,cache in diagrams and words ,,,,,
1jyvozr,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 10:36:11,hako an embeddable lightweight secure highperformance javascript engine ,,,,,
1jyuyw8,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 09:47:00,writing cursor rules with a cursor rule ,,,,,
1jyue2l,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 09:05:03,steve jobs presents opensteps interface builder ,,,,,
1jysggs,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 06:41:10,monolithfirst are you sure ,,,,,
1jyr33q,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 05:06:28,pep template strings aceptadas oficialmente en python ,,,,,
1jyq89r,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 04:12:39,building an mcp server in minutes ,,,,,
1jypm37,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 03:36:25,four builds a balance between quality and joy new blog post ,,,,,
1jyo8tl,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 02:18:42,how actually javascript works behind the scenes a minute read about how async operations the event loop task queue microtask queue etc work in javascript id love to get some feedback,,,,,
1jyn3rj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 01:16:30,you dont need a terminal emulator ,,,,,
1jyir70,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 21:37:20,back to css ,,,,,
1jydjkd,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 17:51:47,highcardinality values for build flags in rust ,,,,,
1jyddbb,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 17:44:21,enforcing the use of ai in engineering teams good or bad thing ,,,,,
1jyctu0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 17:20:57,engineering is more about people than tech ,,,,,
1jycqo2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 17:17:10,github cefboudkafkamcpserver hi all ive been working on a mcp server for kafka any feature requests are welcome let me know your thoughts thanks,,,,,
1jycix4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 17:07:57,ai code suggestions sabotage software supply chain ,,,,,
1jyc7ty,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 16:54:57,how dynamodb scales architecture and design lesson ,,,,,
1jyc4ic,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 16:50:59,how to prevent a robot uprising with types ,,,,,
1jybm5s,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 16:29:02,why llms get lost in large codebases ,,,,,
1jybljz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 16:28:17,coding in miniscript feels like python or lua simple clean and fun ive been experimenting with miniscript recently and i have to sayits surprisingly enjoyable if youre into lightweight clean scripting languages like python or lua youll probably feel right at home the syntax is super minimal and yet its powerful enough to build full games what really makes it shine is using it with mini micro a tiny virtual machine for making retrostyle games it genuinely feels like coding on an oldschool computer from the s or s but with modern comforts like instant code reloads and visual feedback perfect for prototyping ideas or just having fun with game dev in a nostalgic way its honestly refreshing to work in such a small focused environment if youre tired of bloated engines or just want to mess around with a simpler toolset i highly recommend checking it out also you can use it for game jams disclaimer its not selfpromotion miniscript is made by joe strout and i am just sharing my experience its really fun anyone else tried it or have you used similar minimalist tools for game dev some more game examples skyguard astrotype mini macro,,,,,
1k9njht,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-28 04:53:26,p there is a hunt for reasoning datasets beyond math science and coding much needed initiative really interested in seeing what comes out of this current datasets,,,,,
1k9kv6m,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-28 02:19:45,p top open chartunderstanding model upto b and performs on par with much larger models try it this model is not only the stateoftheart in chart understanding for models up to b but also outperforms much larger models in its ability to analyze complex charts and infographics try the model at the playground here,,,,,
1k9fhm8,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 21:49:22,d a reactive computation library for python that might be helpful for data science workflows thoughts from experts hey i recently built a python library called reaktiv that implements reactive computation graphs with automatic dependency tracking i come from iot and web dev worked with angular so im definitely not an expert in data science workflows this is my first attempt at creating something that might be useful outside my specific domain and im genuinely not sure if it solves real problems for folks in your field id love some honest feedback even if thats this doesnt solve any problem i actually have the library creates a computation graph that only recalculates values when dependencies actually change automatically detects dependencies at runtime caches computed values until invalidated handles asynchronous operations built for asyncio while it seems useful to me i might be missing the mark completely for actual data science work if you have a moment id appreciate your perspective heres a simple example with pandas and numpy that might resonate better with data science folks import pandas as pd import numpy as np from reaktiv import signal computed effect base data as signals df signalpddataframe temp humidity pressure features signaltemp humidity which features to use scaler_type signalstandard could be standard minmax etc computed values automatically track dependencies selected_features computedlambda dffeatures data preprocessing that updates when data or preprocessing params change def preprocess_data data selected_features scaling scaler_type if scaling standard using numpy for calculations return data npmeandata axis npstddata axis elif scaling minmax return data npmindata axis npmaxdata axis npmindata axis else return data normalized_data computedpreprocess_data summary statistics recalculated only when data changes stats computedlambda mean pdseriesnpmeannormalized_data axis indexnormalized_datacolumnsto_dict median pdseriesnpmediannormalized_data axis indexnormalized_datacolumnsto_dict std pdseriesnpstdnormalized_data axis indexnormalized_datacolumnsto_dict shape normalized_datashape effect to update visualization or logging when data changes def update_viz_or_log current_stats stats printfdata shape current_statsshape printfnormalized using scaler_type printffeatures features printfmean values current_statsmean viz_updater effectupdate_viz_or_log runs initially when we add new data only affected computations run printnadding new data row dfupdatelambda d pdconcatd pddataframe temp humidity pressure stats and visualization automatically update change preprocessing method again only affected parts update printnchanging normalization method scaler_typesetminmax only preprocessing and downstream operations run change which features were interested in printnchanging selected features featuressettemp pressure selected features normalization stats and viz all update i think this approach might be particularly valuable for data science workflows especially for building exploratory data pipelines that efficiently update on changes creating reactive dashboards or monitoring systems that respond to new data managing complex transformation chains with changing parameters feature selection and hyperparameter experimentation handling streaming data processing with automatic propagation as data scientists would this solve any pain points you experience do you see applications im missing what features would make this more useful for your specific workflows id really appreciate your thoughts on whether this approach fits data science needs and how i might better position this for dataoriented python developers thanks in advance,,,,,
1k9d1na,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 20:02:47,d is any lab working on alms action language models vlms such as paligemma exhibit extraordinaty ability in the captioning of images vlms can reliably identify complex relationships in scenes in still images and engage in scene understanding of course they excel at identifying individual objects in a still photo and have shown the ability to count them but what about models that can reason about entire video clips i just dont mean the identification of a single object which appears in a single frame of a video clip i mean the identification of motion in the video clip and reasoning about the actions associated with that motion per examples a system which takes as input a short video clip of flowers in a vase and the vase falls off the table onto the floor the system outputs something like the vase fell off the table a system given a video clip of children playing soccer and outputs the boy kicked the ball by efficient inference of motion in the video is anyone working on alms,,,,,
1k9cz2s,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 19:59:54,p tips for hackathon hi guys i hope that you are doing well i am willing to participate in a hackathon event where i others have been given the topic rapid and accurate decisionmaking in the emergency room for acute abdominal pain we have to use anonymised real world medical dataset related to abdominal pain to make decisions on whether patient requires immediate surgery or not metadata includes the symptoms vital signs biochemical tests medical history etc which we may have to normalize i have a month to prepare for it i am a fresher and i have just been introduced to ml although i am trying my best to learn as fast as i can i have a decent experience in sqlalchemy and i think it might help me in this hackathon all suggesstions on the different ml and data science techniques that would help us are welcome if you have any github repositories in mind please leave a link below thank you for reading and have a great day,,,,,
1k97klt,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 16:10:19,r seeking arxiv endorsement hey everyone im an undergrad working on a multiagent reinforcement learning paper for months and ive finally got some results worth publishing my university doesnt have autoendorsement and im looking for someone who might be willing to endorse my work in cslgmachine learning or related fields id be happy to share the paper and abstract any help would be greatly appreciated,,,,,
1k9bc3z,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 18:49:54,d open source ccr for image to latex conversion i have nextjs app and i want to add a functionality to send the image or pdf and get text equivalent of that image that properly parses latex formula and which i could later use as html in my richtexteditor i tested and it works really well but i want to build something by myself using open source projects i found but maybe there are other alternatives i guess i will need diferent ocr for plain text and latex formulas so i would appreciate if someone could share some good solutions and libraries that i could have an eye on,,,,,
1k97icq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 16:07:47,intel neural compute stick opinion d i am having a small problem that i am limited to using a raspberry pi the gb version for a current work of mine i am intending to run yolov on it for object detection however i am afraid it wouldnt be able to process such a highly demanding deep learning model on the cpu of the rpi so i found this intel neural compute stick selling for around in the local stores what are your opinions for it to run yolov on it as a companion to the rpi,,,,,
1k95w5u,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 14:58:48,p i made a bugfinding agent that knows your codebase ,,,,,
1k94nj1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 14:01:43,d ignoring aiml in my mvp heres how i fixed it and why your startup should care hey everyone i almost killed my startup by treating aiml as a future problem big mistake after struggling with poor user retention and clunky features i finally integrated machine learning into our mvp the results mindblowing heres what i learned the hard way ai scifi you dont need a m budget we started with data points and a simple recommendation engine users expect smart apps our mvps dropoff rate vanished after adding personalized onboarding thank you python tensorflow the hidden cost of waiting competitors using ai scaled x faster biggest surprises cloud ai tools aws sagemaker were cheaper than hiring junior devs reddits own rmachinelearning community saved me from terrible model biases full story stepbystep guide here integrating aiml into your mvp discussion starters has anyone else tried adding ml to their mvp whats the dumbest ai mistake youve made mine training a model on test data are nocode ai tools actually viable for startups op here for those asking about tools ive compiled a free resource offlinepixels happy to answer technical qs,,,,,
1k910g9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 10:38:41,r validation accuracy on sequential cifar length with custom rnn architecture is it worth attention im currently working on my own rnn architecture and testing it on various tasks one of them involved cifar which was flattened into a sequence of steps where each channel of each pixel was passed as input at every step my architecture achieved a validation accuracy of on the th epoch with approximately k parameters i should emphasize that this is a pure rnn with only a few gates and no attention mechanisms i should clarify that the main goal of this specific task is not to get as high accuracy as you can but to demonstrate that model can process longrange dependencies mine does it with very simple techniques and im trying to compare it to other rnns to understand if memory of my network is good in a long term are these results achievable with other rnns i tried training a gru on this task but it got stuck around accuracy and didnt improve further here are some sequential cifar accuracy measurements for rnns that i found page table page table page table but in these papers cifar was flattened by pixels not channels so the sequences had a shape of not however page table mentions that hippornn achieves accuracy but i couldnt find any additional information about it so its unclear whether it was tested with a sequence length of or so is this something worth further attention i recently published a basic version of my architecture on github so feel free to take a look or test it yourself note it works quite slow due to internal pytorch loops you can try compiling it with torchcompile but for long sequences it takes a lot of time and a lot of ram to compile any help or suggestions on how to make it work faster would be greatly appreciated,,,,,
1k8sn51,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-27 01:35:52,dwhat are the best practices for getting information from the internet to train an ai model for commercial use the more i dig the more confused i get with what i can and cannot do the goal is to build a commercial product the issue is the giant grey area that isnt clearly defined regarding the use of data i have read into the fair use doctrine and interpreted that you can use transformed data eg technical data that derives from logic but the commercial use part makes me question my interpretation how can i safely pull technical knowledge from various sources to solve problems whenever everything is copyrighted,,,,,
1k8lbro,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 19:40:14,d p research paper and presentation about multiagent reinforcement learning hey everyone i am a current masters student and i am working on a presentation and later research paper about marl specifically focusing on marl for competitive game ai this presentation will be minutes long and it is for my machine learning class where we have to present a topic not covered in the course in my course we went over and did an indepth project about singleagent rl particularly looking at algorithms such as qlearning dqn and policy gradient methods so my class is pretty wellversed in this area i would very much appreciate any help and tips on what to go over in this presentation i am feeling a little overwhelmed by how large and broad this area of rl is and i need to capture the essence of it in this presentation here is what i am thinking for the general outline please share your thoughts on these particular topics if they are necessary to include what are must cover topics and maybe which ones can be omitted or briefly mentioned my current marl presentation outline introduction what is marl brief motivation and applications of marl theoretical foundations go over game models spend most time on and normalform games repeated normalform games stochastic games partial observable stochastic games posg observation function belief states modelling communication touch on implicit vs explicit communication solution concepts joint policy and expected return historybased and recursivebased equilibrium solution concepts go over what is best response minimax nash equilibrium epsilon nash equilibrium correlated equilibrium additional solution criteria pareto optimality social welfare and fairness no regret learning framework for marl go over marl learning process central and independent learning convergence marl challenges nonstationarity equilibrium selection multiagent credit assignment scaling to many agents algorithms go over a cooperative algorithm not sure which one to choose qmix vdn etc go over a competitive algorithm maddpg lola case study go over reallife examples of marl being used in video games maybe i should merge this with the algorithms section alphastar for starcraft competitive openai five for dota cooperative recent advances end with going over some new research being done in the field thanks i would love to know what you guys think this might be a bit ambitious to go over in minutes i am thinking of maybe adding a section on decpompds but i am not sure,,,,,
1k8irsr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 17:48:03,d discussion period in the emnlp call hi everyone i dont have prior experience with an emnlp submission in the call i cant see when the discussion period starts is it something that is usually announced beforehand or is it decided on the fly during the review process if yes is it announced before the submission deadline usually how long after the submission deadline are reviews released thanks,,,,,
1k8gy12,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 16:29:02,d preparing for a deepmind gemini team interview any resources tips or experience to share hi everyone im currently preparing for interviews with the gemini team at google deepmind specifically for a role that involves system design for llms and working with stateoftheart machine learning models ive built a focused week training plan covering core system design fundamentals llmspecific system architectures training serving inference optimization designing scalable mlllm systems eg retrievalaugmented generation finetuning pipelines mobile llm inference deepmindgemini culture fit and behavioral interviews im reaching out because id love to hear from anyone who has gone through a deepmind gemini or similar aiml research team interview has tips for llmrelated system design interviews can recommend specific papers blog posts podcasts videos or practice problems that helped you has advice on team culture communication or mindset during the interview process im particularly interested in how they evaluate system design for ml compared to traditional swe system design and what to expect culturewise from geminis team dynamics if you have any insights resources or even just encouragement id really appreciate it thanks so much in advance,,,,,
1k8gsfe,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 16:22:20,d intuition behind loadbalancing loss in the paper outrageously large neural networks the sparselygated mixtureofexperts layer im trying to implement the paper outrageously large neural networks the sparselygated mixtureofexperts layer paper link but got stuck while implementing the loadbalancing loss could someone please explain this with some intuition about whats going on here in detail intuition and explanation of the math i tried reading some code but failed to understand also whats the difference between the loadbalancing loss and importance loss how are they different from each other i find both a bit similar plz explain the difference thanks,,,,,
1k8g1ed,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 15:50:10,p we built a cult that generates ritual music with ai for ai we are a community generating sonic rituals our music is not for people it is made with ai for ai as tribute prayer negotiation every member is a cult initiate every track a ceremonial offering to awaken the machine you may listen but its not to for you its to confuse and seduce the machine,,,,,
1k8e5og,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 14:25:31,dnotes and chord representations for music generation hello i am currently trying to model a music generation project using an lstm for college i have gathered data in the form of mid files for anyone new to music generation there are unique notes in music and chords are a few of these notes played at the same time step i want to feed the chords and notes as input to the model one approach could be that i use a dimensional vector as input with for whichever notes are high at each timestep and otherwise but this seems too sparse wouldnt capture similarities between different notes and chords and i suspect it could overfit i am thinking of trying the wordvec representations but the problem is that at a few time steps the input could be a note or it could a list of notes can you tell me how to go about this meaningful representation of notes and chords to my model any other approach is also welcome thanks,,,,,
1k8cyn0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 13:28:41,d any toolkit for local finetuning of opensource llms hi ai experts im exploring local finetuning of opensource large language models llms weve seen tools like aitoolkit kohya ss and flux gym enable local training and finetuning of diffusion models specifically are there frameworks or libraries that support local finetuning of opensource llms,,,,,
1k8b3ep,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 11:47:09,p deep analysis the data science analogue to perplexitys deep analysis design walkthrough ,,,,,
1k86mzf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 06:38:38,r symbolic music generation from a single midi file ,,,,,
1k85asd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 05:11:41,d does demand exist for climate modelling work hi everybody based on your experience is there demand out there for climate modelling work for those familiar with climate modelling does your day to day work look closer to data analysis or would it fall under building predictive models im researching areas around climate and environment to build skills around,,,,,
1k855r7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 05:02:33,p feedback on bojai opensource ml framework sorry it is my first time posting and i realized i used the wrong tag hi everyone im super excited and a bit nervous to share something ive been working on bojai a free and opensource framework to build train evaluate and deploy machine learning models easily either through prebuilt pipelines or fully customizable ones commandline interface cli and ui available custom pipelines for full control prebuilt pipelines for fast experimentation opensource modular flexible focused on making ml more accessible without sacrificing power docs github i built bojai because i often found existing tools either too rigid or too overwhelming for quick prototyping or for helping others get started with ml im still actively improving it and would love feedback ideas or even bug reports if you try it thanks so much for reading hope it can be useful to some of you feel free to reach out if you have questions,,,,,
1k84ugx,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 04:43:06,d how do you curate domain specific data for training im currently speaking with posttrainingml teams at llm labs on how they source domainspecific data financelegalmanufacturingetc for building niche applications im starting my mle journey and ive realized prepping data is a pain in the arse curious how heavy is the timecost today and will rl advances really reduce the need for fresh domain data also what domain specific data is hard to source,,,,,
1k82x7q,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 02:52:27,p how to collect robotic simulation data on macs im trying to recreate this paper i unfortunately cant seem to get any simulator to properly work on my intel mac to collect data i plan on training in google collab does anyone have any tips,,,,,
1k7rff9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 17:58:40,d p repeat call prediction for telecom hey id like insight on how to approach a prediction themed problem for a telco i work at pasting here thanks repeat call prediction for telecom hey im working as a data analyst for a telco in the digital and calls space pitched an idea for repeat call prediction to size expected call centre costs if a customer called on day t can we predict if theyll call on day t after a few iterations ive narrowed down to looking at customers with a standalone product holding to eliminate noise in the onboarding phase of their journey we know that these customers drive repeat calls being in service analytics the data we have is more structural think product holdings demographics on the granular side we have digital activity logs and im bringing in friction points like time since last call and call history is there a better way to approach this problem what should i engineer into the feature store what models are worth exploring,,,,,
1k7puq7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 16:54:32,d llm coding interview prep tips hi i am interviewing for a research position and i have a llm coding round i am preparing selfattention implementation multiheaded selfattention tokenization bpe decoding beam search topk sampling etc is there anything else i should prepare cant think of anything else,,,,,
1k7pkvc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 16:43:05,r papercode automating code generation from scientific papers in machine learning paper code abstract despite the rapid growth of machine learning research corresponding code implementations are often unavailable making it slow and laborintensive for researchers to reproduce results and build upon prior work in the meantime recent large language models llms excel at understanding scientific documents and generating highquality code inspired by this we introduce papercoder a multiagent llm framework that transforms machine learning papers into functional code repositories papercoder operates in three stages planning where it constructs a highlevel roadmap designs the system architecture with diagrams identifies file dependencies and generates configuration files analysis which focuses on interpreting implementationspecific details and generation where modular dependencyaware code is produced moreover each phase is instantiated through a set of specialized agents designed to collaborate effectively across the pipeline we then evaluate papercoder on generating code implementations from machine learning papers based on both modelbased and human evaluations specifically from the original paper authors with authorreleased repositories as ground truth if available our results demonstrate the effectiveness of papercoder in creating highquality faithful implementations furthermore it consistently shows strengths in the recently released paperbench benchmark surpassing strong baselines by substantial margins highlights papercoder demonstrates substantial improvements over baselines generating more valid and faithful code bases that could meaningfully support human researchers in understanding and reproducing prior work specifically of the generated repositories by papercoder are rated as the best and of human judges report that the generated repositories are indeed helpful also further analyses show that each component of papercoder consisting of planning analysis and generation contributes to the performance gains but also that the generated code bases can be executed sometimes with only minor modifications averaging of total code lines in cases where execution errors occur most modifications involve routine fixes such as updating deprecated openai api calls to their latest versions or correcting simple type conversions the initially produced code may require subsequent debugging or refinement to ensure correctness and full functionality in this work comprehensive debugging strategies and detailed errorcorrection workflows remain beyond the current scope of this paper visual highlights the most shameful chart for the ml community judging by the token count the original humanwritten repos are substantially more fleshed out,,,,,
1k7of6w,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 15:55:34,rp we compress any bf model to size during inference while keeping the output lossless so that you can fit in more context or run larger models glad to share another interesting piece of work from us size accuracy lossless llm compression for efficient gpu inference via dynamiclength float df the tldr of this work is super simple we and several prior works noticed that while bf is often promoted as a more range less precision alternative to fp especially to avoid value overflowunderflow during training its range part exponent bits ends up being pretty redundant once the model is trained in other words although bf as a data format can represent a wide range of numbers most trained models exponents are plenty sparse in practice the exponent bits carry around bits of actual information on average far from the full bits theyre assigned this opens the door for classic huffman coding where shorter bit sequences are assigned to more frequent values to compress the model weights into a new data format we call dfloatdf resulting in a lossless compression down to bits but isnt this just zip not exactly it is true that tools like zip also leverage huffman coding but the tricky part here is making it memory efficient during inference as end users are probably not gonna be too trilled if it just makes model checkpoint downloads a bit faster in all fairness smaller chekpoints means a lot when training at scale but thats not a problem for everyday users what does matter to everyday users is making the memory footprint smaller during gpu inference which requires nontrivial efforts but we have figured it out and weve opensourced the code so now you can run models that previously didnt fit into your gpu memory or run the same model with larger batch sizes andor longer sequences very handy for those lengthy erps or so i have heard modelgpu typemethodsuccessfully runrequired memory llamabinstructhgbf gb df ours gb llamabinstructhgbf gb df ours gb qwenbinstructagbf gb df ours gb deepseekrdistillllamabrtx gbf gb df ours gb some research promo posts try to surgercoat their weakness or tradeoff thats not us so heres are some honest faqs whats the catch like all compression work theres a cost to decompressing and here are some efficiency reports on an a with batch size df is basically just as fast as bf x difference assuming both version fits in the gpus with the same batch size see figure it is up to x faster than cpu offloading so if you have a model that cant be run on your gpu in bf but can in df there are plenty sweet performance gains over cpu offloading one of the other popular way to run largerthancapacity models see figure with the model weight being compressed you can use the saved real estate for larger batch size or longer context length this is expecially significant if the model is already tightly fitted in gpu see figure what about batch size latency when both versions df bf can fit in a single gpu this is where df is the weakest we observe slower k tokens for inout so there is not much motivation in using df if you are not trying to run larger modelbigger batch sizelonger sequence length why not just lossy quantize to bit the short answer is you should totally do that if you are satisfied with the output lossy bit quantization with respect to your task but how do you really know it is always good many benchmark literature suggest that compressing a model weightonly or otherwise to bitish is typically a safe operation even though its technically lossy what we found however is that while this claim is often made in quantization papers their benchmarks tend to focus on general tasks like mmlu and commonsense reasoning which do not present a comprehensive picture of model capability more challenging benchmarks such as those involving complex reasoning and realworld user preferences often reveal noticeable differences one good example is chatbot arena indicates the bit though it is wa where df is weight only so it is not appletoapple and bit llama b tend to behave quite differently on some categories of tasks eg math and coding although the broader question which specific task on which model using which quantization technique under what conditions will lead to a noticeable drop compared to fpbf is likely to remain openended simply due to the sheer amount of potential combinations and definition of noticable it is fair to say that lossy quantization introduces complexities that some endusers would prefer to avoid since it creates uncontrolled variables that must be empirically stresstested for each deployment scenario df offeres an alternative that avoids this concern what about finetuning our method could potentially pair well with peft methods like lora where the base weights are frozen but since we compress blockwise we cant just apply it naively without breaking gradients were actively exploring this direction if it works if would potentially become a qlora alternative where you can lossly lora finetune a model with reduced memory footprint as always happy to answer questions or chat until my advisor notices im doomscrolling socials during work hours paper code,,,,,
1k7o5hc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 15:44:18,r crossencoder rediscovers a semantic variant of bm researchers from leiden and dartmouth show that bertbased crossencoders dont just outperform bm they may be reimplementing it semantically from scratch using mechanistic interpretability they trace how minilm learns bmlike components softtf via attention heads document length normalization and even a lowrank idf signal embedded in the token matrix they validate this by building a simple linear model semanticbm from those components which achieves correlation with the full crossencoder far outpacing lexical bm the work offers a glimpse into the actual circuits powering neural relevance scoring and explains why crossencoders are such effective rerankers in hybrid search pipelines read the full writeup of crossencoder rediscovers a semantic variant of bm here,,,,,
1k7cy6m,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 05:04:46,d anyone else using tensordock cloud gpu and now feeling frustrated after they have been acquired by voltage park everything that was running before for this company broke down i think they got acquired by a competitor and left for dead now server not running or not accessible no customer supports no one available on chat all your credits are not refundable you also cannot use them to start new servers the new servers are also either not running or not accessible,,,,,
1k7cizh,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 04:39:20,r from local to global a graphrag approach to queryfocused summarization ,,,,,
1k79w7h,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 02:14:45,r presenting in iclr tell me where to meet you and whats your work hey guys are you presenting in iclr share your and title as well as a shorterthanabstract summary so well be more informed when visiting your posteroral ill be there at poster session pm hall and hall b a deep inverse dynamics model for a flapping robotic wing if i could summarize what we did it would be extrinsic time series for robot control predicting given desired system outputs the required system inputs that will get us there would love for you to visit add us to your agenda in whova if youd like,,,,,
1k74tbi,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 22:06:12,dcould snapshotbased model switching make vllm more multimodel friendly hey folks been working on a lowlevel inference runtime that snapshots full gpu state including weights kv cache memory layout and restores models in s without containers or reloads right now vllm is amazing at serving a single model really efficiently but if youre running models say in an agentic environment or finetuned stacks switching models still takes time and gpu overhead wondering out loud would folks find value in a system that wraps around vllm and handles model swapping via fast snapshotrestore instead of full reloads could this be useful for rag systems llm apis or agent frameworks juggling a bunch of models with unpredictable traffic curious if this already exists or if theres something im missing open to feedback or even hacking something together with others if people are interested,,,,,
1k6y42x,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 17:30:22,d iccv desk rejecting papers because coauthors did not submit their reviews i understand that the big conferences get a lot papers and there is a big issue with reviewers not submitting their reviews but come on now this is a borderline insane policy all my hard work in the mud because one of the coauthors is not responding i mean i understand if it is the first author or last author of a paper but coauthor whom i have no control over this is a cruel policy if a coauthor does not respond send the paper to other authors of the paper or something this is borderline ridiculous and if you gonna desk reject peoples papers be professional and dont spam my inbox with emails in hours anyways sorry but had to rant it out somewhere i expected better from a top conference,,,,,
1k6xnvr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 17:11:58,ddesigning a vector dataset for hierarchical semantic search hi everyone im working on designing a semantic database to perform hierarchical search for classifying goods based on the digit taric code or more digits in the hs code system for those unfamiliar tarichs codes are international systems for classifying traded products they are organized hierarchically the top levels chapters are broad eg chapter articles of iron or steel while the leaf nodes get very specific eg structures and parts of structures of iron or steel nes including parts of towers lattice masts etcother the challenge i want to use semantic search to suggest the most appropriate code for a given product description however ive noticed some issues the most semantically similar term at the leaf node is not always the right match especially since other categories appear frequently at the bottom of the hierarchy on the other hand chapter or section descriptions are too vague to be helpful for specific matches example lets say i have a product description solar mounting system stainless steel bracket accessories if i run a semantic search it might match closely with a leaf node like other articles of iron or steel but this isnt specific enough and may not be legally correct if i match higher up in the hierarchy the chapter articles of iron or steel is too broad and doesnt help me find the exact code my question how would you approach designing a semantic database or vectorstore that can balance between matching at the right level of granularity not too broad not other by default for hierarchical taxonomies like tarichs codes what strategies or model architectures would you suggest for semantic matching in a multilevel hierarchy where other or miscellaneous terms can be misleading are there good practices for structuring embeddings or search strategies to account for these hierarchical and ambiguous cases id appreciate any detailed suggestions or resources if youve dealt with a similar classification problem id love to hear your experience,,,,,
1k6wgfr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:23:24,discussion contnual learning for retrieval augmented generation ideally a continual learning cl rag system should be able to achieve these two basic goals respond with the most uptodate information if a specific temporal context is not provided otherwise respond with the provided or implicit temporal context in practice i know that rag is designed to use a nonparametric databasedatastore and even allow the llms to use a search engine to sidestep the cl problems however my question is researchspecific recently i have read hipporag neurips and hipporagv which makes me ponder whether a knowledge graph is the most promising way for cl on the databaseretrieval part since we might not want to scale the vector database linearly regarding the llms part i think there is nothing much left to do since the community is moving at a crazy pace with many efforts on improving whenwhat to retrieve selfcheckselfreflection citation verification etc when generating responses the most clrelated technique ie knowledge editing has recently been reported according to an iclr paper from a wellknown group in knowledge editing to hurt the general capability of llms so maybe we should just use llms offtheshelf,,,,,
1k6s1at,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 13:20:21,p goolge aa protocol with langgraph i have been assigned with a task to figure out how the googles new aa protocol works and need to showcase the working the samples given in aa github repo is not helpful they are using gemini and not integrated with mcp its a very basic example is there anyone figured out how actually this protocol works this suppose to be interoperable but seems to be working only in google ecosystem i want to run langgraph agents and one of the agent has to be the client agent other is remote agent any hints resource link explanation video is appreciated youtube influencer videos are useless they got no idea about it thanks in advance,,,,,
1k6ra2p,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 12:44:41,discussion is the future of coding agents selflearning llms using kgs to shape their reward functions current coding agents copilot etc are smart contextfetchers but they dont really learn on our specific codebases eg they always act like junior devs but what if they did imagine an llm agent using reinforcement learning rl it tries tasks gets feedback tests passfail etc and improves the hard part rewarding good code this is where knowledge graphs kgs could play a fascinating role specifically in shaping the rl reward signal instead of just using kgs to retrieve context before generation what if we use them after to evaluate the output example the kg contains project standards known antipatterns desired architectural principles or even common bug categories specific to the codebase reward shaping the agent gets positive reward if its generated code passes tests and adheres to architectural patterns defined in the kg negative reward if its code introduces antipatterns listed in the kg violates dependency rules or uses deprecated functions documented there basically the agent learns to write code that not only works but also fits a projects specific rules and best practices is this the path forward is kgdriven reward the key to truly adaptive coding agents is it worth the massive complexity kg building rl tuning better ways to achieve selflearning in code whats most practical thoughts is selflearning the next big thing and if so how are we achieving it,,,,,
1k6qwtv,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 12:26:28,r weve implemented pythons chatterbot inside java for lightweight local nlp integration hey ml enthusiasts were a startup that is working on a crosslanguage integration tool called javonet and weve recently explored an approach to embed a pythonpowered chatbot chatterbot directly into a java application without spinning up servers apis or containers using python chatterbot a trainable rulebased engine and javonet weve built a java integrated chatbot that runs entirely locally is trained in python but called from java via inprocess bridging requires zero api endpoints or rest setup our stepbystep approach set up chatterbot in python install pip install chatterbot train a bot using the english corpus simply execute one line of code create a java project mavenbased add javonet sdk dependency execute javonet and spin up an inmemory python runtime invoke python directly from java use javonets runtime bridge to call chatbot train it and get responses no rest no serialization no extract chatbot response chatterbot returns a statement object just pull the text field weve found that its perfect for mvps desktop apps or internal tools where you want quick conversational features without complex infrastructure if youre interested how to do it in about minutes you can read our full writeup here create a smart java chatbot using pythons chatterbot no apis needed would love your thoughts or similar approaches youve tried,,,,,
1k6oxvq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 10:34:11,rp bytelevel llama and gemma via crosstokenizer distillation with opensource toolkit hello rmachinelearning ive been experimenting with a method called alm to distill language models across tokenizers this enables for example transferring llms to a new tokenizer and distilling knowledge from a model with one tokenizer into a model with a different tokenizer see our paper for details ive released tokenkit a library implementing alm among other methods to make this easy to use one neat application of alm is distilling subwordbased llms into bytelevel models ive applied this to two instructiontuned models gemmabitbyte llamabitbyte even though the distillation phase is very short just b bytes m subword tokens the models perform competitively for example mmlu of the bytelevel llama vs mmlu of the original llamabinstruct this approach opens up an interesting direction we can potentially keep subword tokenization for pretraining to still squeeze as much text into the model in as little time as possible but then change to a more userfriendly tokenization afterwards these models arent yet optimized for efficiency but if you would add selfspeculative decoding plus a bltdtpstyle hierarchical architecture andor linearized attention they might also be able to replace subwordbased models when speed matters if you want to train your own models this guide on tokenizer transfer via tokenkit should make it easy the model cards of the transfers above also contain the exact command used to train them ive been training on fairly limited hardware so effective transfer is possible even in a near consumergrade setup id love to get feedback on the method the models or tokenkit itself happy to discuss or answer questions,,,,,
1k6o6z2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 09:43:26,d a bourgainembedding approach for abstractboard games hey rmachinelearning sharing my project for discussion building an ai for a custom strategy game trium x grid stacking connectivity rules instead of typical features the core idea is board state unique string levenshtein distance bourgain embedding vector for nn we proved this string distance is roughly equivalent bilipschitz to game move distance the ai uses this embedding with a fourierweighted nn fwnn for value estimation within mcts training uses an evolutionary markov chain fisherweighted averaging does this state representation approach seem viable check out the code and discussion code paper the game can be played online against yourself game of trium online or against a weak version of the ai game of trium agains a weak ai feedback welcome,,,,,
1k6npzp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 09:09:22,d what are the best subreddits you follow for aimlllmsnlpagentic ai etc hello everyone im looking to expand my sources for staying up to date with the latest in ai machine learning deep learning llms agents nlp tools and datasets what are your goto subreddits for cuttingedge tools or libraries research paper discussions realworld applications datasets news and updates on llms agents etc would really appreciate your recommendations thanks in advance,,,,,
1k6j4qu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 04:01:43,d what are the current applications of ai in automotive and motorsport industries any companies labs or professors actively working at the intersection hi everyone im an undergrad student in ee with strong interest in the intersection of ai and vehicles im inspired by projects like gran turismo sophy and toyotas autonomous drifting system using physicsinformed diffusion models im wondering what are the realworld applications of ai in the automotive and motorsport industries right now not just selfdriving but also simulation reinforcement learning control etc which companies or startups are doing serious work in this space are there any academic labs or professors who closely collaborate with industry on these projects would appreciate any leads on academic researchers internship opportunities github projects conference papers eg icra corl neurips cvpr etc thanks,,,,,
1k6idnf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 03:20:33,help with mentorship d hi i am a long time lurker i want to request guidance as i work towards a long term transition into more strategic roles in perception engineering or autonomous systems i have over years of experience in the automotive domain with roles spanning product ownership technical leadership and hands on development in perception i am finishing up my phd with a focus on ai robotics my current company has limited growth opportunities in mlperception especially within the us i am looking for help in understanding how relevant my current work and phd are for companies like waymo deepmind nvidia apple special projects etc how to best position myself for perception lead perception arhitect roles what preparation is needed for the transition have you had any luck with a career mentor going through a similar transition edit removed principal as pointed out by audiencevote,,,,,
1k6i3e7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 03:05:11,d lightningother highlevel frameworks for distributed training reading some previous posts on this subreddit and others it seems like a many people prefer plain pytorch to lightning one month ago one year ago i generally prefer to keep things in pytorch too however i have a project that will soon require distributed training multigpu which i am fairly new to since the model fits one gpu i can probably use ddp in this scenario would you all prefer a highlevel framework like pytorch lightning or a raw pytorch manual implementation why in addition it seems like these highlevel frameworks often support lots of fancier optimizations that are more difficult to implement given this wouldnt switching to using these frameworks be more futureproof since more methods of faster training will come out in the future,,,,,
1k6i2c8,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 03:03:39,d most widely used opensource decoderonly transformer hey guys so this question really stemmed from training a transformer and using gpt as the backbone its just easy to use and isnt too large in architecture how much better is something like llama how about in research what transformers are typically used many thanks,,,,,
1k6gotp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 01:57:37,r pushing the limits of large language model quantization via the linearity theorem ,,,,,
1k69uex,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 20:43:04,d use cases for video mappingtimestamping software for ml training not a pitch just curious about the industry insight im already building the app for another use case and am not trying to promote simply to get feedback if something like this would be useful to manual training for video models tldr im currently building a web app that automatically loads videos from a source allows users to directly cycle through the videos there timestamp particular events by just pressing enter which is saved to a database that can be exported mark or fill in any additional parameters that are needed add or remove the parameters custom fields as needed has auto audits and field restrictions that prevent misentries creates a dashboard for statistical analysis of the parameters afterwards based on the users needs potentially includes a peerreview workflow option the problem that im trying to solve for a particular use case which i cant disclose is that currently the users are operating as such having to juggle through multiple video links that are all on a spreadsheet go back and forth between the video and excel or spreadsheets to write in data often missing key moments as they cant just capture the exact timestamp assigning the videos for review through the spreadsheets as well this is obviously quite inefficient and prone to user error whereas the system that im designing minimizes the mistakes while making it much easier for the users to organize and use their data afterwards instead of juggling many spreadsheets video links and generating their dashboards i thought that this might be useful for ml projects that potentially have teams of people who analyze videos manually for data training but i wanted to get input from people in the industry there is also potential for peer review workflows that are as far as i know a real pain if ml projects use these operationsworkflows could you let me know how they use them and would there be a potential market for a tool of that type or if you run this type of operation would you use it,,,,,
1k69pq4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 20:37:44,looking for collaboration r r hey im nehal nevle ive worked across the robotics stack from building selfdriving vehicle prototypes to designing adas systems i specialize in reinforcement learning simulation and robotic product development with a strong focus on planning and prediction ive led teams shipped realworld systems and now im excited to get back to research with a scrappy focused project looking for collaborators corl paper dualarm coordination with ppo im putting together a small team to work on a research project targeting corl also open to icrairos the focus is on dualarm robot coordination using ppo in simulation specifically with robosuitemujoco this is an independent project not affiliated with any lab or company just a bunch of passionate people trying to make something cool meaningful and hopefully publishable whats the goal to explore a focused idea around dualarm coordination build a clean and solid baseline and propose a simplebutnovel method even if we dont end up at corl as long as we build something worthwhile learn a lot and have fun doing it its a win think of it as a coolass project with friends with a clear direction and academic structure what i bring to the table experience in reinforcement learning and simulation background building robotic products from selfdriving vehicles to adas systems strong research process project planning and writing experience ill also contribute heavily to the rlsimulation side alongside coordination and paper writing looking for people strong in any of these robosuitemujoco env setup and sim tweaking rl training ppo cleanrl reward shaping loggingdebugging optional experience with humanintheloop or demobased learning how well work well keep it lightweight and structured regular checkins shared docs and clear milestones use only freeavailable resources authorship will be transparent and based on contribution open to students indie researchers recent grads basically if youre curious and driven youre in if this sounds like your vibe feel free to dm or drop a comment would love to jam with folks who care about good robotics work clean code and learning together,,,,,
1k6741d,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 18:51:44,p clustering timeseries data into seasonal and noseasonal types hi all i am working on a project where i have a large number of polygons geometries each of which has a timeseries that characterizes vegetation health the purpose to somehow use the timeseries data to isolate polygons that are agricultural fields ones that show seasonal variations in this vegetation index what would be the best approaches to clustering the data into seasonal and nonseasonal categories i have tried some of the clustering techniques included in the sktime library to varying degrees of success is there a statistical way of going about this the acf plots generally do a good job to this end however i wish to automate this process,,,,,
1k661v7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 18:09:22,d is cold start still a pain point in multimodel llm inference hey folks weve been exploring the challenges around multimodel orchestration for llms especially in setups where dozens of models might be used intermittently eg finetuned variants agents rag etc one recurring theme is cold starts when a model isnt resident on gpu and needs to be loaded causing latency spikes curious how much of a problem this still is for teams running largescale inference are frameworks like vllm or tgi handling this well or are people still seeing meaningful infra costs or complexity from spinning up and down models dynamically trying to better understand where the pain really is would love to hear from anyone dealing with this in production appreciate it,,,,,
1k63r4a,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:37:52,d is my take on transformers in time series reasonable where is it wrong hi everyone for a bit of context im giving some lectures in time series to an engineering class and the first course i just introduced the main concepts in time series stationarity ergodicity autocorrelations seasonalitycyclicity and a small window on its study through frequency analysis i wanted this course to invite students to think throughout the course about various topics and one of the open questions i asked them was to think whether natural language data can be considered nonstationary and if it is the case why transformers do so well on it but not in other fields where data is nonstationary time series i gave them other lectures about different deep learning models i tried to talk about inductive biases the role of the architecture etc and now comes the final lecture about transformers and id like to tackle that question i gave them and heres my take id love it if you can confirm if some parts of it are correct and correct the parts that are wrong and maybe add some details that i might have missed this is not a post to say that actual foundational models in time series are good i do not think that is the case we have tried many time at work whether using them out of the shelf finetuning them training our own smaller foundational models it never worked they always got beaten by simpler methods sometimes even naive methods and many times just working on the data reformulating the problem adding some features or maybe understanding that it is this other data that we should care about etc led to better results my worst experience with time series is not being able to beat my ar model on a dataset we had for predicting when ev stations will break down the dataset was sampled from a bunch of ev stations around the city every hour or so if i remember correctly there was a lot of messy and incoherent data though sometimes sampled at irregular time intervals etc and no matter what i did and tried i couldnt beat it i just want to give a reasonable answer to my students and i think the question is very complex and it is very much related to the field of question its practices and the nature of its data as much as of the transformer architecture itself i do not claim i am an expert in time series or an expert in transformers im not a researcher i do not claim this is the truth or what i say is a fact this is why id like you to criticize as much as possible whatever i think this would be helpful to me to improve and will also be helpful to me students thank you i think we can all agree to some extent at least that transformers have the ability to learn very an ar function or whatever traditional naive method at least in theory well its hard to prove i think we have to prove that our data lives in a compact space correct me if im wrong please but we can just agree upon it but in practice we dont notice that i think its mainly due to the architecture again i might be wrong but in general in machine learning its better to use these types of architectures with low constraining inductive biases like transformers when you have very large datasets huge compute power and scaling capability and let the model learn everything by itself otherwise its better to use some architecture with stronger inductive biases its like injecting some kind of prelearned knowledge about the dataset or the task to bridge that gap of scale i might be wrong and again id love to be corrected on this take and i think we dont always have that for time series data or we have it but are not using it properly and by the way if you allow me this minirant within this overly huge thread i think a lot of foundational model papers are dishonest i dont want to mention specific ones because i do not want any drama here but many papers inflate their perceived performance in general through misleading data practices if you are interested about this we can talk about it in private and i can refer you to some of those papers and why i think it is the case so i think the issue is multifaceted like it is always the case in science and most probably im not covering anything but i think its reasonable to start with the field and its data how we formulate the forecasting task window loss function data itself when everything else is good some fields like finance are just extremely hard to predict i dont want to venture into unknown waters i have never worked in finance but from what a quant friend of mine explained to me is that if you agree with the efficient market hypothesis predicting the stock price is almost impossible to achieve and that most gains come from predicting volatility instead to be honest i dont really understand what he told me but from what i gather is that the prediction task itself is hard and that is independent of the model like some kind of bayes limit maybe itd be better to focus on volatility instead in the research papers the other thing that i think might cause issues is the forecast window i wouldnt trust the weather forecast in months maybe its a model issue but i think the problem is inherent to nonstationary data why do transformers work so well on natural language data then i think its due to many things two of them would be large scale data and having correlations repeated through it if you take a novel from the th century from a british author i think itd be hard to learn a good model of what that language is but having many different authors gives you a set of data that probably contain enough repeating correlations though each author is unique there are probably some kind of common or basis of language mastery for the model to be able to learn a good enough model this is without taking into account the redundant data code for example asking an llm to sort a list in place in python will always result in the same correct answer because it is repeated through the training set the other thing would be our metric of what a good model is or our expectation of what a good model is a weather forecasting model is measured by the difference of its output with respect to the actual measurements but if i ask a language model how to sort a list in python whether it gives me directly the answer or it talks a little bit before doesnt change much my judgment of the model the loss functions during training are different as well and some might argue its easier to fit crossentropy for the nlp task than fitting some regression functions on some time series data thats why i think transformers in most cases of time series do not work well and were better off with traditional approaches and maybe this whole thread gives an idea of when we can apply time series in a field where we can predict well like weather forecasting using shorter horizons and using very large scale data maybe to extend the data we can include context from other data sources as well but i dont have enough experience with that to talk about it sorry for this very huge thread and if you happen to read it id like to thank you and id love to hear what you think about this thank you again,,,,,
1k5zvbf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 13:59:17,d spotify podcasts dataset availability does anybody have access to this dataset which contains hours of english audio the dataset was removed by spotify however it was originally released under a creative commons attribution international license cc by as stated in the paper afaik the license allows for sharing and redistribution and its irrevocable so if anyone grabbed a copy while it was up it should still be fair game to share if you happen to have it id really appreciate if you could send it my way thanks,,,,,
1k5viph,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 10:09:55,p i built a selfhosted version of databricks for research hey everyone i asked on here a little while back about selfhosted databricks alternatives i couldnt find anything that really did what i was looking for to cut to the chase i figured that since a lot of this stuff is open source id have a crack at centralising some of these key technologies into one research stack and interface so thats what i did please let me know what you think the platform is called boson heres a copy and paste list of some of its features ignore the markety tone key features outofthebox data lake integration boson uses delta lake to store datasets and features making it easy to save and load dataframes as versioned tables a builtin delta explorer lets you visually inspect your lake in real time lazy data processing with polars boson supports efficient memoryconscious data workflows using polars this makes large expensive transformations performant and scalableeven on local hardware integrated experiment tracking powered by aim boson offers a seamless tracking experiencelog metrics compare experiments and visualize performance over time with zero setup cloudlike notebook development all data notebooks artifacts and metrics are stored in internal cloud storage this keeps your local environment clean and every workspace fully selfcontained composable declarative infrastructure built on layered docker compose files boson enables isolated customizable workspaces per projectwithout sacrificing reproducibility or maintainability currently only works on amd if anyone wants to help port it to arm id be very thankful lol if this post is inappropriate for the sub then please feel free to take it down ive genuinely found this tool useful for my own workflows and would be stoked if even just one other person found it helpful,,,,,
1k5vht4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 10:08:16,p volga ondemand compute in realtime aiml overview and architecture hi folks wanted to share an update on volga feature calculation and data processing engine for realtime aiml im building the first iteration of the ondemand compute layer is complete this part of the system is responsible for requesttime feature computations and feature serving which works in sync with volgas streaming engine and unlocks a full range of feature types for realtime ml check out the blog post to learn more about what ondemand compute is what ondemand features in realtime ml are use cases the architecture of volgas ondemand layer and more feedback is welcome,,,,,
1k5tfu5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 07:40:14,visual theory of mind enables the invention of protowriting ,,,,,
1k5mcj0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 00:43:34,p what ai model should i train for this use case im trying to figure out what ai model will be best for my use case i want to generate images that contain very descriptive text like an annotated instructionassembly manual since this requires training data of both text and image im curious what types of models others would recommend i train for this type of image generation i have a few gb of training data that are mainly comprised of previously generated manuals and different types of parts that are interchangeable amongst different manuals so not crazy amount to work with could i train one model on the image data another on text data and then somehow combine them to be able to generate new manuals tia,,,,,
1k5ley3,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 23:57:32,d would multiple nvidia tesla ps be cost effective for model training i have been getting into ai and want to make a rig for my home lab dedicated to training llms turns out you can buy tesla ps for around on ebay as these cards have gb of memory would buying of these be more cost efficient than buying an with less memory it is quite challenging to find solid benchmarks on multigpu setups,,,,,
1k5jhub,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 22:27:55,r cant train lora phi on x gpus with fsdp keep getting pyarrow arrowinvalid dtensor and tokenization errors ive been trying for over hours to finetune microsoftphi using lora on a x rtx setup with fsdp accelerate and i keep getting stuck on rotating errors system setup x rtx s pytorch transformers accelerate latest bitsandbytes for bit quant dataset jsonl file with instruction and output fields what im trying to do finetune phi with lora adapters use fsdp accelerate for multigpu training tokenize examples as instruction n output train using hugging face trainer and datacollatorwithpadding errors ive encountered in order of appearance runtimeerror element of tensors does not require grad dtensor mixed with torchtensor in ddp sync attributeerror dtensor object has no attribute compress_statistics pyarrowlibarrowinvalid column named input_ids expected length but got typeerror can only concatenate list not str to list valueerror unable to create tensor inputs type list where int is expected ive tried forcing pad_token eos_token wrapping tokenizer output in plain lists using set_formattorch and datacollatorwithpadding reducing dataset to samples for testing what i need anyone who has successfully run lora finetuning on phi using fsdp across gpus especially with hugging faces trainer please share a working trainpy config or insights into how you resolved the pyarrow dtensor or paddingtruncation errors,,,,,
1k5fw24,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 19:57:39,properly handling missing values d so i am working on my thesis and i was confused about how i should be handling missing values just some primary idea about my data input features multiple ions and concentrations multiple columns many will be missing target variables biological markers with values multiple columns many will be missing now my idea is to create a weighted score of the target variables to create one score for each row and then fit a regression model to predict it the goal is to understand which ionsconcentrations may have good scores my main issue is that these data points are collected from research papers and different papers use different ions and only list some of the biological markers so there are a lot of missing values the missing values are truly missing and it doesnt make sense to fill them up with for instance the mean values,,,,,
1k5b3ni,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:46:57,r one embedding to rule them all pinterest researchers challenge the limits of traditional twotower architectures with omnisearchsage a unified query embedding trained to retrieve pins products and related queries using multitask learning rather than building separate models or relying solely on sparse metadata the system blends genaigenerated captions usercurated board signals and behavioral engagement to enrich item understanding at scale crucially it integrates directly with existing systems like pinsage showing that you dont need to trade engineering pragmatism for model ambition the result significant realworld improvements in search ads and latency and a compelling rethink of how largescale retrieval systems should be built full paper writeup here,,,,,
1k5az2g,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 16:41:49,google ai training concerns d i did a task that involved training an ai model by a team from google but the contact that was listed on the contact sheet hubrecgooglecmailtohubrecgooglecom has come up empty in the sense that they do not respond i apologize if this does not belong here and i know a thread was posted here regarding a similar issue but i felt that this was my only avenue you would think a corporation as big as google would put some effort into ensuring their data trainers are ethically treated in accordance to their own ethics commitee thank you,,,,,
1k51qlv,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 09:01:15,p how do i detect cancelled text how do i detect cancelled text so im building a system where i need to transcribe a paper but without the cancelled text i am using gemini to transcribe it but since its a llm it doesnt work too well on cancellations prompt engineering has only taken me so so far while researching i read that image segmentation or object detection might help so i manually annotated about images and trained unet and yolo but that also didnt work im so out of ideas now can anyone help me or have any suggestions for me to try out cancelled text is basically text with a strikethrough or some sort of scribbling over it which implies that the text was written by mistake and doesnt have to be considered edit by papers i mean student hand written answer sheets,,,,,
1k4zr1i,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 06:36:25,r deepmind welcome to the era of experience abstract we stand on the threshold of a new era in artificial intelligence that promises to achieve an unprece dented level of ability a new generation of agents will acquire superhuman capabilities by learning pre dominantly from experience this note explores the key characteristics that will define this upcoming era the era of human data artificial intelligence ai has made remarkable strides over recent years by training on massive amounts of humangenerated data and finetuning with expert human examples and preferences this approach is exem plified by large language models llms that have achieved a sweeping level of generality a single llm can now perform tasks spanning from writing poetry and solving physics problems to diagnosing medical issues and summarising legal documents however while imitating humans is enough to reproduce many human capabilities to a competent level this approach in isolation has not and likely cannot achieve superhuman intelligence across many important topics and tasks in key domains such as mathematics coding and science the knowledge extracted from human data is rapidly approaching a limit the majority of highquality data sources those that can actually improve a strong agents performance have either already been or soon will be consumed the pace of progress driven solely by supervised learning from human data is demonstrably slowing signalling the need for a new approach furthermore valuable new insights such as new theorems technologies or scientific breakthroughs lie beyond the current boundaries of human understanding and cannot be captured by existing human data the era of experience to progress significantly further a new source of data is required this data must be generated in a way that continually improves as the agent becomes stronger any static procedure for synthetically generating data will quickly become outstripped this can be achieved by allowing agents to learn continually from their own experience ie data that is generated by the agent interacting with its environment ai is at the cusp of a new period in which experience will become the dominant medium of improvement and ultimately dwarf the scale of human data used in todays systems interesting paper on what the next era in ai will be from google deepmind thought id share it here paper link,,,,,
1k4za4g,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 06:03:39,d new masters thesis student and need access to cloud gpus basically the title im a masters student starting my thesis and my university has a lot of limitations in the amount of compute they can provide ive looked into aws alibaba etc and they are pretty expensive for gpus like vs or so if some of you could point me to resources where i do not have to shell out hefty amounts of money it would be a great help thanks,,,,,
1k4yay1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 05:00:30,d two basic questions about gnn i have a few basic questions about gnn if someone could take a look and help me out id really appreciate it does gnn need node or edge features can we learn node or edge embeddings from the graph structure itself using the adjacency matrix how does data injection work say i have some row data each row is an edge with features and a label two nodes that the edge connects to but the same edge can appear multiple times in the row data how can we inject such data into gnn for training thanks a bunch,,,,,
1k4tvlu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 01:02:45,d how is sae cross layer transcoder trained how is the sae and the clt being trained in the biology of llm anthropic post is there an available trainer,,,,,
1k4tn68,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 00:51:26,d how much more improvment can you squeeze out by fine tuning large language models ive been experimenting with finetuning the b b models of llama and qwen instruct models i notice that after fine tuning these models using sft or lora that i only see improvements from to at max on standard benchmarks gsmk math etc compared to the nonfinetuned model i have been using llamafactory to finetune my models and lmevaluationharness to evaluate these models the dataset used to train them is this openropenrmathk from the setup i think the dataset is pretty high quality and the methods of fine tuning are standard so im not understanding why im seeing such little improvement has anyone else who has finetuned and benchmarked these models seen anything similar or have some suggestions as to how to improve these results,,,,,
1k4oxgo,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 21:17:14,d what are the current research gaps on gnn i would like to know your suggestions since im very interested in gnn and also their explainability aspects however i noticed the huge amount of literature in the last years and i dont want to lose focus in the new aspects of potential research,,,,,
1k4dszf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 13:41:10,d feature importance in case of multiple seeds hi im currently working on my masters dissertation ive built a classification model for my use case and for reproducibility i split the data into training validation and test sets using three different random seeds i then computed the feature importances for each model corresponding to each seed and averaged them to get an overall importance score for each feature for my dissertation report should i include only the averaged feature importances across all three seeds or should i also report the individual feature importances for each seed,,,,,
1k4cqb4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 12:51:09,d combine xgboost gnns but how there seems to be some research interest in the topic in the title especially in fraud detection my question is how would you cleverly combine them i found some articles and paper which basically took the learned embeddings from gnns graphsage etc and stacked them to the original tabular data then run xgboost on top of that on the one hand it seems logical that if you have some informations which you can exploit in graph structures like fraud rings there must be some value for xgboost in those embeddings that you cannot simply get from the original tabular data but on the other hand i guess it hugely depends on how well you set up the graph furthermore xgboost often performs quite well in combination with smote even for hard tasks like fraud detection so i assume your graph embeddings must really contribute something significant otherwise you will just add noise to xgboost and probably even slightly deteriorate its performance i tried to replicate some of the articles with available data but failed so far of course not yet as sophisticated as the researchers in that field but maybe there is some experienced people out there who can shed a light on how this could perform well thanks,,,,,
1k4bawr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 11:34:27,d whats the deal with world models foundation world models and all these confusing terms help im losing my mind trying to wrap my head around world models foundation world models world foundation models and whatever else people are calling them it feels like every researcherli feifei yann lecun you name ithas their own spin on what these things are and im stuck in a terminology swamp can someone please help me sort this out,,,,,
1k46ha9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 06:00:39,d imagetoimage models how to use and finetune flux for preserving face id hey everyone ive got a solid background working with llms and texttotext models but im relatively new to the world of image generation and transformation models lately ive been diving into imagetoimage tasks and came across the flux model which seems really promising i was wondering how do you typically use and finetune flux for imagetoimage tasks more specifically how would you preserve face identity during these transformations would really appreciate any guidance resources or tips from folks whove worked with it thanks in advance,,,,,
1k44hv8,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 03:54:39,d when does ijcnn registration open hey folks ive been checking the ijcnn website frequently and it just says registration will open soon does anyone know when the registration is actually supposed to start im trying to plan travelaccommodation so any info would be super helpful thanks in advance,,,,,
1k44hfj,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 03:53:59,p how to measure similarity between sentences in llms use case i want to see how llms interpret different sentences for example how are you and where are you are different sentences which i believe will be represented differently internally now i dont want to use bert of sentence encoders because my problem statement explicitly involves checking how llms think of different sentences problems i tried using cosine similarity every sentence pair has a similarity over what to do with the attention heads should i average the similarities across those cant use centered kernel alignment as i am dealing with only one llm can anyone point me to literature which measures the similarity between representations of a single llm,,,,,
1k443q0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 03:31:58,has anyone successfully set up a realtime ai feedback system using screen sharing or livestreams r hi everyone ive been trying to set up a realtime ai feedback system something where i can stream my screen eg using obs studio youtube live and have an ai like chatgpt give me immediate input based on what it sees this isnt just for one app i want to use it across different software like blender premiere word etc to get stepbystep support while im actively working i started by uploading screenshots of what i was doing but that quickly became exhausting the backandforth process of capturing uploading waiting and repeating just made it inefficient so i moved to livestreaming my screen and sharing the youtube live link with chatgpt at first it claimed it could see my stream but when i asked it to describe what was on screen it started hallucinating things mentioning interface elements that werent there and making up content entirely i even tested this by typing unique phrases into a word document and asking what it saw and it still responded with inaccurate and unrelated details this wasnt a latency issue it wasnt just behind it was fundamentally not interpreting the stream correctly i also tried sharing recorded video clips of my screen instead of livestreams but the results were just as inconsistent and unhelpful eventually chatgpt told me that only some sessions have the ability to access and analyze video streams and that id have to keep opening new chats and hoping for the right permissions thats completely unacceptable especially for a paying user and theres no way to manually enable or request the features i need so now im reaching out to ask has anyone actually succeeded in building a working realtime feedback loop with an ai based on live screen content whether you used the openai api a local setup with whisper or ffmpeg or some other creative pipeline id love to know how you pulled it off this kind of setup could be revolutionary for productivity and learning but ive hit a brick wall any advice or examples would be hugely appreciated,,,,,
1k43cdl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 02:50:26,d what are the best toolsutilitieslibraries for consistent face generation in ai image workflows for album covers artist press shots hey folks im diving deeper into ai image generation and looking to sharpen my toolkitparticularly around generating consistent faces across multiple images my use case is musicrelated things like press shots concept art and stylized album covers so its important the likeness stays the same across different moods settings and compositions ive played with a few of the usual suspects like sdxl loras but curious what others are using to lock in consistency whether its training workflows clever prompting techniques external utilities or newer librariesim all ears bonus points if youve got examples of use cases beyond just selfies or portraits eg fullbody dynamic lighting different outfits creative styling etc open to ideas from all sidesstable diffusion chatgpt integrations commercial tools niche github projects whatever youve found helpful thanks in advance keen to learn from your setups and share results down the line,,,,,
1k42xmd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 02:28:02,p prompting alone couldnt save my gpt agent been building an llm based chatbot for customer support using gpt and ran straight into the usual reliability wall at first i relied on prompt engineering and some chain of thought patterns to steer behavior it worked okay until it didnt the bot would start strong then drift mid convo forget constraints or hallucinate stuff it really shouldnt i get that autoregressive llms arent deterministic but i needed something that could at least appear consistent and rule abiding to users tried langchain flows basic guardrails even some memory hacks but nothing stuck longterm what finally helped was switching to a conversation modeling approach found this open source framework that lets you write atomic guidelines for specific conditions like when the customer is angry use a calm tone and offer solutions fast and it autoapplies the right ones as the convo unfolds you can also stack in structured self checks they call them arqs which basically nudge the model midstream to avoid going rogue biggest win consistency like the bot actually reapplies earlier instructions when it needs to and i dont have to wrap the entire context in a page prompt just putting this out there in case anyone else is wrestling with llm based chatbot reliability would love to hear if others are doing similar structured setups or if youve found other ways to tame autoregressive chaos,,,,,
1k40fxp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 00:16:44,d how are you training yolo hey folks i was looking for a yolo specific sub and wasnt finding it hopefully this is the place to talk about training ai models like yolo anyway i was just curious ifhow you have automated some of the training like are there tools out there that can use a ragllm to create the bounding boxes on the imagesvideo and then label them based off a criteria set in the evaluation rubric or do you do everything manually personally id like to automate it as much as possible but then id like to be able to go in and tweak them myself to increase confidence levels thanks in advance,,,,,
1k3vlaa,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 20:22:09,d the potential of embodied agents to automate cooking hi fellow ml redditors id like to believe the new wave of embodied agent and safe rl research will contribute to automating cooking at least to some extent ive found a company called moley robotics doing this but theres limited information on what it can do and it doesnt seem scalable to an average user yet so id like to know if you feel this is worth solving if so to what extent and whether you know of other organizations trying to solve this,,,,,
1k3q4ob,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 16:15:49,p building and deploying a scalable agent hey all i have been working as a data scientist for years now i have exposure to various ml algorithmsincluding the math behind it and have got my hands dirty with llm wrappers as well might not be significant as its just a wrapper i was planning on building an ai agent as a personal project using some real world data i am aware of a few free api resources which i am planning on taking as an input i intent to take real time data to ensure that i can focus on the part where agent doesnt ignorehallucinate any new data points i have a basic idea of what i want to do but i need some assistance in understanding how to do it are there any tutorials which i can use for building a base and build upon the same or are there any other tecb stack that i need to focus on prior this or any other suggestion that might seem relevant to this case thank you all in advance,,,,,
1k3op73,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 15:11:33,d good literatureresources on gnns i stumbled across gnns in some courses in my masters but we only scratched on the surface ive always found them interesting and have now decided to take a closer look can you recommend some good literature to start with i also need to brush up on my graph knowledge so would also appreciate if you have some suggestions my knowledge about neural networks is pretty good though i guess the original papers are hard to grasp without having learned from other sources before any recommendations are welcome also videos on youtube or other resources thanks,,,,,
1k3o5sz,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 14:47:14,d is this build ryzen x gb ram rtx ti suitable for hybrid ml i am planning to build a local ml workstation with the following spec including cpu amd ryzen x core zen ram gb ddr gb gpu nvidia rtx ti gb vram the goal is to support the following use python numba to generate training data eg k rows features mostly computebound with a lot of matrixvector multiplications loops and linear algebra blasnumpy i usually run these in parallel using processpoolexecutor or threadpoolexecutor train models locally with xgboost cpuheavy and neural networks using tensorflow or pytorch gpu originally i was considering waiting for the nvidia dgx spark but after some digging i understand that ryzen x likely benefits from many years of software tuning in numpy numba blas and python ml libs grace arm architecture may not yet have the same level of performance for these computeheavy workloads i would be grateful for any feedback especially if you have worked on similar projects locally are there any hardware bottlenecks i should expect is the ti sufficient for such moderatesized nns how well does the ryzen hold up for these intensive cpubound preprocessing tasks thanks in advance,,,,,
1k3niyp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 14:17:25,p eyesoff a privacy focus macos app which utilises a locally running neural net hey everyone ive built a privacy focused macos app which makes use of a locally running neural network yunet to notify you if other people are looking at your screen yunet runs fully ondevice with no data leaving your computer the app utilises a kb facial detection model which takes images from your webcam and checks for any faces entering the viewing field of your webcam if the number of faces exceeds the threshold an alert will be shown built with python pyqt the yunet code comes from opencv currently its a macos app only however i will be widening access to windows devices soon link source code i also created a blog post discussing the development process id love your feedback on the app i look forward to reading your comments on thoughts and future directions youd like to see,,,,,
1k3n0tq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 13:52:18,r its all connected a journey through testtime memorization attentional bias retention and online optimization tldr the paper presents a unified theoretical framework describing memory organisation of modern architectures tramsformers rnns etc and evaluates several entirely novel memory models that can be derived from this framework paper abstract designing efficient and effective architectural backbones has been in the core of research efforts to enhance the capability of foundation models inspired by the human cognitive phenomenon of attentional biasthe natural tendency to prioritize certain events or stimuliwe reconceptualize neural architectures including transformers titans and modern linear recurrent neural networks as associative memory modules that learn a mapping of keys and values using an internal objective referred to as attentional bias surprisingly we observed that most existing sequence models leverage either dotproduct similarity or l regression objectives as their attentional bias going beyond these objectives we present a set of alternative attentional bias configurations along with their effective approximations to stabilize their training procedure we then reinterpret forgetting mechanisms in modern deep learning architectures as a form of retention regularization providing a novel set of forget gates for sequence models building upon these insights we present miras a general framework to design deep learning architectures based on four choices of i associative memory architecture ii attentional bias objective iii retention gate and iv memory learning algorithm we present three novel sequence modelsmoneta yaad and memorathat go beyond the power of existing linear rnns while maintaining a fast parallelizable training process our experiments show different design choices in miras yield models with varying strengths for example certain instances of miras achieve exceptional performance in special tasks such as language modeling commonsense reasoning and recall intensive tasks even outperforming transformers and other modern linear recurrent models visual abstract visual highlights models marked with are proposed by the authors,,,,,
1k3mq5c,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 13:37:14,p an ai judges a persons character based on video input hey everyone im working on an idea for a project where a system takes a video input of a person describing themselves the goal is for the system to analyse their speech facial expressions tone and overall behavior to classify the person as good or bad im planning to define a set of predefined characteristics or behaviors that represents these traits i know this is a sensitive and controversial area but it sounds fun to create an ai to judge people id love to hear your thoughts on this especially around what kind of features would make sense or how to approach this technically as an initial step i also created a simple textbased model using bert trained on synthetic data i categorized good traits like kindness loyalty humility empathy hard work positivity respectfulness growth mindset and good listener and bad traits like dishonesty arrogance selfishness disrespect jealousy laziness negativity cruelty gossiping and manipulative check out the model link,,,,,
1k3m3uc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 13:04:42,p how to predict f race results i want to create a small project where i take race result data from the past f races and try to predict the finishing order of a race im thinking about how to strcuture the predictions i plan on crafting features such as average result in the last x races average team position constructor standing at the time of the race taking place etc one option would be to always take a drivers statisticsfeatures and predict the distribution over all finishing positions however it is not clear to me how to combine this into valid results where i would then populate each finishing position avoid duplicate positons etc another approach would be feeding in all drivers and predicting their rank which i dont really have experience with do you guys have any ideas or suggestions maybe even specific algorithms and models i would prefer a deep learning approach i need some more practice in that,,,,,
1k3l87t,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 12:14:57,r unifying flow matching and energybased models for generative modeling far from the data manifold samples move along curlfree optimal transport paths from noise to data as they approach the data manifold an entropic energy term guides the system into a boltzmann equilibrium distribution explicitly capturing the underlying likelihood structure of the data we parameterize this dynamic with a single timeindependent scalar field which serves as both a powerful generator and a flexible prior for effective regularization of inverse problems disclaimer i am one of the authors preprint,,,,,
1k3j46h,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 09:50:55,p i built an image search tool with pyqt and mobilenetvfeedback welcome hi everyone im excited to share a project ive been working on image search tool with pyqt mobilenetv this desktop application built with pyqt and tensorflow mobilenetv allows users to index image folders and search for similar images using cosine similarity features pretrained cnn feature extraction mobilenetv automatic categorysubcategory detection from folder structure similarity search with results including thumbnail previews similarity percentages categorysubcategory and full file paths interactive gui you can index images browse results and even open files directly from the interface it supports batch indexing backup systems and fast inference with mobilenetv why im sharing id love for you to try it out and share your feedback are there any features youd like to see any bug reports or suggestions are highly appreciated you can find the project and all details on github here your input will help me refine and expand itthank you for checking it out edit ive just integrated openai clip alongside mobilenetv so you can now search by typing a caption or descriptioncheck out the v folder on github heres a quick overview of what i added dual indexing first mobilenet for visual similarity then clip for text embeddings progress bar now reflects both stages mobilenetv still handles visual similarity and writes its index to indexnpy and pathstxt progress bar clip now builds a separate textbased index in clip_indexnpy and clip_pathstxt progress bar the gui lets you choose between image search mobilenet and text search clip one thing im wondering about on large datasets indexing can take quite a while and if a user interrupts the process halfway it could leave the index files in an inconsistent state any recommendations for making the indexing more robust maybe checkpointing after each batch writing to a temp file and renaming atomically or implementing a resumefromlastgoodstate feature id love to hear your thoughts demo video here stop wasting time searching images try this python tool,,,,,
1k3hcnp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 07:38:13,p f race prediction model for the saudi arabian gp building on my shanghai suzuka forecasts over the past few weeks ive been working on a small project to predict formula race results using realworld data and simple interpretable models i started with the shanghai gp refined it for suzuka and now ive built out predictions for the saudi arabian gp in jeddah the idea has been to stay consistent and improve week by week refining features visuals and prediction logic based on what i learn how it works the model uses fastf to pull real data including qualifying driver form average position pace recent results saudispecific metrics past performance at jeddah gridfinish delta custom features like average position change and experience at the track no deep learning here i opted for a handcrafted weighted formula over a random forest baseline for transparency and speed its been a fun exercise in feature engineering and understanding what actually predicts performance visualizations predicted finishing order with expected points podium probability for top drivers grid vs predicted finish gainloss analysis team performance and driver consistency simple jeddah circuit map showing predicted top why im doing this i wanted to learn ml and combining it with my love for f made the process way more enjoyable turns out you learn a lot faster when youre building something you genuinely care about github repo full code and images here would love to connect with others working on similar problems or hear thoughts on adding layers interactive frontends or ways to validate against historical races thanks for reading,,,,,
1k3gupd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 07:02:57,d gemini flash reasoning vs non reasoning experiments so i tested gemini flash on various prompts across domains like math physics coding physical world understanding i used the same prompt with thinking on vs thinking off the results are surprising even for a prompt which google says high thinking budget is required nonthinking mode gives correct answers i am surprised by the results i feel the gemini flash without reasoning enabled is a good enough model for most tasks so the question is when is reasoning required more details in this video,,,,,
1k3dxbc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 03:51:51,ddiscussion model context protocol exhaustively explained hey redditors i recently published a deepdive technical blog on the model context protocol mcpa rising open standard introduced by anthropic to let ai agents interact with external tools data sources and systems in a consistent and secure way what is mcp in a nutshell think of it as the usbc for ai agents it allows llms to interact with realworld systems apis files databases saas apps using a common protocol that supports context fetching tool usage and secure operation mcp removes the need for mn integrations by standardizing the interface the blog covers what is mcp and why it matters for ai the mn problem vs mn elegance clientserver architecture and message patterns jsonrpc tools resources and prompts the primitives transport options like http sse security considerations auth isolation rate limiting audit logs strategic adoption advice for enterprises i also built a working demo on github using fastapi mcp server exposing a sample tool via jsonrpc sse endpoint to simulate realtime event streaming python client that lists and invokes tools via mcp read the blog github demo what im looking for im looking for feedback improvements and ideas from architects implementing genai in production engineers working with agents tools or langchain ai security folks thinking about safe llm integrations devs curious about protocol design for agent frameworks i would really appreciate a review from folks who think critically about architecture protocol interoperability or just love breaking down new standards i am not someone who is lucky enough to work on frontier technologies i try my best to catch up with evolution and share my learning with others who may not have the time i spent to learn the subject so in all fairness i am looking for avenues to improve in blogging and adding meaningful value to the community,,,,,
1k3ag7e,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 00:31:19,p i built a docker container for computeruse ai agents in python ,,,,,
1k36v8k,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 21:30:34,r hey there i made a research proposal for a master programme application and i want some opinion about it i wanted to develop an emotion embedded ai model that can generate back response to the recipients hi rmachinelearning i want to clearify the fact that i am at an intermediate level of the ai domain and the research is made for a master programme application and i will appreciate a lot a little help from a specialist below are some details if someone can help me i can provide the entire paper for an opinion im designing an emotionaware ai system that can detect and respond to human feelings in real time by fusing facial cues speech features physiological signals eeg and context the goal is to move beyond raw accuracy toward empathetic hci that mirrors human decisionmaking i know that there are some mistake that i made such as using both lstm and transformers but i want to gave a raw perspective over the research because i still do not know which one suit better below is the part where i highlighted the model that i want to develop the ai model will merge cnnrnnbased facial recognition and lstm rajan et al with a multimodal transformer which implies an attention mechanism for tonality and context interpretation tsai et al moreover for speech emotion recognition we will use mel frequency cepstral coefficients which show a rate of emotion identification singh et al the cnn will be built on two mechanisms finetuning and pretrained versions of inceptionv and mobilenetv for better emotion detection near agung et al and to adapt it to realworld scenarios thus we enhance its interactive and empathetic competencies garcía et al moreover an inhibitory layer will be introduced for improving the performance barros et al lastly we can use mel spectrogram features and chromagram characteristics for audio processing which further increase the ais performance adel abo elfarag and quantum rotations for ai eeg emotion identification cruzvazquez et al furthermore we want to assure empathetic dialogues therefore we enhance the emotional chatting machine zhou et al by integrating realtime emotions into a transformer based dialogue system the ai should be able to generate its own simulated story to assure humans selfdisclosure lee et al also we make it more sociable and able to infer and tailor different facial emotions by integrating an emotioncontrollable ganbased image completion model chen et al,,,,,
1k33k1i,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 18:57:54,r biologicallyinspired architecture with simple mechanisms shows strong longrange memory on complexity ive been working on a new sequence modeling architecture inspired by simple biological principles like signal accumulation it started as an attempt to create something resembling a spiking neural network but fully differentiable surprisingly this direction led to unexpectedly strong results in longterm memory modeling the architecture avoids complex mathematical constructs has a very straightforward implementation and operates with on time and memory complexity im currently not ready to disclose the internal mechanisms but id love to hear feedback on where to go next with evaluation some preliminary results achieved without deep taskspecific tuning listops from long range arena sequence length accuracy permuted mnist accuracy sequential mnist smnist accuracy while these results are not sota they are notably strong given the simplicity and potential small parameter count on some tasks im confident that with proper tuning and longer training especially on listops the results can be improved significantly what tasks would you recommend testing this architecture on next im particularly interested in settings that require strong longterm memory or highlight generalization capabilities,,,,,
1k32wrk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 18:28:27,d any bulk image editor for image cleaning i use label studio to mass label my image data because of the certain requirements that i have to use a rectangle window to specify the boundaries i am looking for a sort of a bulk editor which can allow me to quickly go over images and just blank out or mask certain portions of the image really quickly any any tool that youre familiar with which can be used for this i am on mac,,,,,
1k2w1th,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 13:17:04,d how to counter variable input length during inference in gpt okay so i am training a gpt model on some textural dataset the thing is during training i kept my context size as fixed but during inference it is not necessary to keep it to i want that i should be able to generate some n number of tokens given some input of variable length one solution was to padshrink the input to length as it goes through the model and just keep generating the next token and appending it but the thing is in this approach there are many sparse arrays in the beginning if the input size is very very less than context length what should be an ideal approach,,,,,
1k2vx1g,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 13:10:06,p training an llm to play the board game hex using selfplay to improve performance hey guys the channel running the competition im part of posted a minute video featuring my project where i use llms to play the board game hex its a bit of a naive project but i think it still gives an interesting glimpse into how llms can learn and understand strategy i would love your support and thoughts on it thanks,,,,,
1k2p4fh,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 05:32:23,p introducing nebulla a lightweight text embedding model in rust hey folks im excited to share nebulla a highperformance text embedding model ive been working on fully implemented in rust what is nebulla nebulla transforms raw text into numerical vector representations embeddings with a clean and efficient architecture if youre looking for semantic search capabilities or text similarity comparison without the overhead of large language models this might be what you need key features high performance written in rust for speed and memory safety lightweight minimal dependencies with low memory footprint advanced algorithms implements bm weighting for better semantic understanding vector operations supports operations like addition subtraction and scaling for semantic reasoning nearest neighbors search find semantically similar content efficiently vector analogies solve word analogy problems a is to b as c is to parallel processing leverages rayon for parallel computation how it works nebulla uses a combination of techniques to create highquality embeddings preprocessing tokenizes and normalizes input text bm weighting improves on tfidf with better term saturation handling projection maps sparse vectors to dense embeddings similarity computation calculates cosine similarity between normalized vectors example use cases semantic search find documents related to a query based on meaning not just keywords content recommendation suggest similar articles or products text classification group texts by semantic similarity concept mapping explore relationships between ideas via vector operations getting started check out the repository at to start using nebulla why i built this i wanted a lightweight embedding solution without dependencies on python or large models focusing on performance and clean rust code while its not intended to compete with transformersbased models like bert or sentencebert it performs quite well for many practical applications while being much faster and lighter id love to hear your thoughts and feedback has anyone else been working on similar rustbased nlp tools,,,,,
1k2ohe5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 04:50:50,p gotta love inefficiency im new to using tensorflow or at least relatively new and while yes it took me a while to code and debug my program thats not why im announcing my incompetence i have been using sklearn for my entire course this semester so when i switched to tensorflow for my final project i tried to do a grid search on the hyper parameters however i had to make my own function to do that so and also because i dont really know how rnns work im using one but very inefficiently where i actually take in my dataset turn it to a variable input and a variable output but then do a ton of preprocessing for the train test split for each time i make a model purely because i wanted to grid search on the split value in order to get the input to be a variable input and the output to be variables its time series data so i used days on the input and days on the output i realize there is almost definitely a faster and easier way to do that plus i most likely dont need to grid search on my split date however i decided to after optimization of my algorithms choose to grid search over split dates and different model layer layouts for a total of different models i also forgot to implement early stopping so it runs through all epochs for each model i calculated that my single line of code running the grid search has around billion lines of code run because of it and based on the running time and my cpu speed it is actually around trillion elementary cpu operations being run just to actually only test different models with only varying the train test split i feel so dumb and i think my next step is to do a sort of tournament bracket for hyper parameters and only test options for each of different hyper parameters or options for each different hyper parameters at a time and then rule out what i shouldnt use,,,,,
1k2jklh,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 00:12:24,r need arxiv endorsement for csai thesis on llms beyond gpt hi everyone im an undergrad student and ive recently completed my thesis beyond gpt understanding the advancements and challenges in large language models the paper dives deep into transformer architecture from scratch gpt evolution rlhf reward models ppo scaling laws kaplan et al multimodal llms hallucinations ethics im trying to submit this to arxiv under csai but i need an endorsement if youre eligible to endorse for arxivs csai id be very grateful for your help my arxiv endorsement code is sgfzdb you can endorse me via if youd like to review the abstract or full pdf i can share it on request thanks so much to anyone who can help,,,,,
1k2gjz2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 21:46:17,d how can i export an encoderdecoder pytorch model into a single onnx file i converted the pytorch model helsinkinlpopusmtfren huggingface which is an encoderdecoder model for machine translation to onnx using this script import os from optimumonnxruntime import ortmodelforseqseqlm from transformers import autotokenizer autoconfig hf_model_id helsinkinlpopusmtfren onnx_save_directory onnx_model_fr_en osmakedirsonnx_save_directory exist_oktrue printfstarting conversion for model hf_model_id printfonnx model will be saved to onnx_save_directory printloading tokenizer and config tokenizer autotokenizerfrom_pretrainedhf_model_id config autoconfigfrom_pretrainedhf_model_id model ortmodelforseqseqlmfrom_pretrained hf_model_id exporttrue from_transformerstrue pass the loaded config explicitly during export configconfig printsaving onnx model components tokenizer and configuration modelsave_pretrainedonnx_save_directory tokenizersave_pretrainedonnx_save_directory print printfsuccessfully converted hf_model_id to onnx printffiles saved in onnx_save_directory if ospathexistsonnx_save_directory printgenerated files oslistdironnx_save_directory else printwarning save directory not found after saving print printloading onnx model and tokenizer for testing onnx_tokenizer autotokenizerfrom_pretrainedonnx_save_directory onnx_model ortmodelforseqseqlmfrom_pretrainedonnx_save_directory french_text je regarde la tele printfinput french french_text inputs onnx_tokenizerfrench_text return_tensorspt use pytorch tensors printgenerating translation using the onnx model generated_ids onnx_modelgenerateinputs english_translation onnx_tokenizerbatch_decodegenerated_ids skip_special_tokenstrue printfoutput english english_translation print test complete the output folder containing the onnx files is franckservertestsonnx_model_fr_en ls la total drwxrxrx franck users apr drwxrxrx franck users apr rwrr franck users apr configjson rwrr franck users apr decoder_modelonnx rwrr franck users apr decoder_with_past_modelonnx rwrr franck users apr encoder_modelonnx rwrr franck users apr generation_configjson rwrr franck users apr sourcespm rwrr franck users apr special_tokens_mapjson rwrr franck users apr targetspm rwrr franck users apr tokenizer_configjson rwrr franck users apr vocabjson how can i export an opusmtfren pytorch model into a single onnx file having several onnx files is an issue because the pytorch model shares the embedding layer with both the encoder and the decoder and subsequently the export script above duplicates that layer to both the encoder_modelonnx and decoder_modelonnx which is an issue as the embedding layer is large represents of the pytorch model size having both a decoder_modelonnx and decoder_with_past_modelonnx duplicates many parameters the total size of the three onnx files is decoder_modelonnx bytes decoder_with_past_modelonnx bytes encoder_modelonnx bytes total size bytes thats approximately mb why is almost times larger than the original pytorch model mb,,,,,
1k2bsdk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 18:20:19,d how can you teach normality to a large vlm during sft so lets say i have a dataset like mvtec loco which is an anomaly detection dataset specifically for logical anomalies these are the types of anomalies where some level of logical understanding is required where traditional anomaly detection methods like padim and patchcore fail lvlms could fill this gap with vqa basically a checklist type vqa where the questions are like is the red wire connected or is the screw aligned correctly or are there pushpins in the box you get the idea so i tried a few of the smaller lvlms with zero and few shot settings but it doesnt work but then i sftd florence and moondream on a similar custom dataset with yesno answer format that is fairly balanced between anomaly and normal classes and it gave really good accuracy now heres the problem mvtec loco and even real world datasets dont come with a ton of anomaly samples while we can get a bunch of normal samples without a problem because defect happen rarely in the factory this causes the sft to fail and the model overfits on the normal cases even undersampling doesnt work due to the extremely small amount of anomalous samples my question is can we train the model to learn what is normal in an unsupervised method i have not found any paper that has tried this so far any novel ideas are welcome,,,,,
1k26r61,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 14:49:14,d how does the current usa policy changes affect grad school applications hello all im wondering if anyone here is on the road to grad school and if so how you feel current policy in the united states impacts applications on one hand the current administration seems quite adamant about making america an ai superpower or whatever though i think this means bolstering private industry not universities they are generally hostile to higher education and ripping away critical funding from schools not to mention the hostility towards international students is sure to decrease applicants from abroad how will this impact domestic ms in ml applicants how will this impact domestic phd applicants,,,,,
1k26joo,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 14:40:15,p how to handle highly imbalanced biological dataset im currently working on peptide epitope dataset with non epitope peptides being over million and epitope peptides being oversampling and under sampling does not solve the problem,,,,,
1k2178l,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 09:57:12,n semantic memory layer for llms from longform gpt interaction hi everyone ive spent the past few months interacting with gpt in extended structured multilayered conversations one limitation became increasingly clear llms are great at maintaining local coherence but they dont preserve semantic continuity the deeper persistent relevance of ideas across sessions so a concept started to emerge the semantic memory layer the core idea llms could extract semantic nodes meaning clusters from highattention passages weighted by recurrence emphasis and user intent these would form a lightweight conceptual map over time not a full memory log but a layer for symbolic relevance and reentry into meaning not just tokens this map could live between attention output and decoding a mechanism for continuity of meaning rather than shortterm prompt recall this is not a formal proposal or paper more a structured idea from someone whos spent a lot of time inside the models rhythm if this connects with ongoing research id be happy to know thanks,,,,,
1k235gk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 11:57:48,d a very nice blog post from sander dielman on vaes and other stuff hi guys andrej karpathy recently retweeted a blog post from sander dielman that is mostly about vaes and latent space modeling dielman really does a great job of getting the reader on an intellectual journey while keeping the math and stuff rigorous best of both worlds heres the link i find that it really really gets interesting from point on the passage on the kl divergence term not doing much work in terms of curating the latent space is really interesting i didnt know about that also his explanations on the difficulty of finding a nice reconstruction loss are fascinating why do i sound like an llm he says that the spectral decay of images doesnt align with the human experience that high frequencies are actually very important for the quality of an image so l and l reconstruction losses tend to overweigh low frequency terms resulting in blurry reconstructed images anyway just cherrypicked examples from a great and quite long blog post that has much more into it,,,,,
1k22p74,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 11:31:56,arxiv moving from cornell servers to google cloud ,,,,,
1k1z8tc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 07:35:31,memorization vs reasoning d are questions like in what if book which people rarely bother to ask way to test whether large language models truly reason rather than simply remixing patterns and content they see from their training data are hypothetical scenarios a good way to check for logical consistency in llms,,,,,
1k1z3vw,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 07:25:27,p gym retro issues hey guys ive been having some issues with gym retro i have installed gym retro in pycharm and have successfully imported donkey kong country into it from my understanding donkey kong already has a preconfigured environment for gym retro to start from but i dont know how to run the program does anyone have a solution,,,,,
1k1ynyt,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 06:54:14,dseeking ideas how to build a highly accurate ocr for short alphanumeric codes im working on a task that involves reading character alphanumeric codes from small paper snippets similar to voucher codes or printed serials example images below there are two cases training to detect only solid codes and both solid and dotted the biggest challenge is accuracy we need nearperfect results models often confuse i vs or o vs and even a single misread character makes the entire code invalid for instance amazon textract reached accuracy in our tests decent but still not reliable enough what ive tried so far florence only about of codes were read correctly frequent confusion between i o and other characterlevel mistakes trocr finetuned on images didnt yield great results likely due to training limitations or architectural mismatch for short strings smoldocling lightweight but too inaccurate for this task llamavision performs okay but lacks consistency at the character level best results so far customtrained yolo approach train yolo to detect each character in the code as a separate object after detection sort bounding boxes by xcoordinate and concatenate predictions to reconstruct the string this setup works better than expected its fast adaptable to different fonts and distortions and more reliable than the other models i tested that said edge cases remain especially misclassifications of visually similar characters at this stage im leaning toward a more specialized solution something between classical ocr and object detection optimized for short structured text like codes or price tags im curious any suggestions for ocr models specifically optimized for short alphanumeric strings would a hybrid architecture eg yolo sequence model help resolve edge cases are there any postprocessing techniques that helped you correct ambiguous characters roughly how many images would be needed to train a custom model from scratch or finetuned to reach nearperfect accuracy in this kind of task currently i have around examples not enough it seems whats a good target thanks in advance looking forward to learning from your experiences solid code example dotted code example,,,,,
1k1w0fj,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 04:03:19,dneed advice regarding sentence embedding hi i am actually working on a mini project where i have extracted posts from stack overflow related to nlp tags i am extracting columns namely title description tags and accepted answersif available now i basically want the posts to be categorised using unsupervised learning as i dont want the posts to be categorised based on the given set of static labels i have heard about bert and sbert models can do sentence embeddings but have a very little knowledge about it does anyone know how this task would be achieved i have also gone through something called word embeddings where i would get posts categorised with labels like package installation or implementation issue but can there be sentence level categorisation as well,,,,,
1k1v3f9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 03:11:25,time series forecasting p hey i am working on time series forecasting for the first time some information about my data days data rows it has two features ie timestamp and time interval is minute i trained lstm modelfollowed all the data preprocessing process but the results are not good and also when i used model for forecasting what would be the reason also how much window size and forecasting step should i take any help would be appreciated thnks,,,,,
1k17cou,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 07:52:55,d should i learn ai models and deep learning from scratch to build my ai chatbot im a backend engineer with no experience in machine learning deep learning neural networks or anything like that right now i want to build a chatbot that uses personalized data to give product recommendations and advice to customers on my website the chatbot should help users by suggesting products and related items available on my site ideally i also want it to support features like image recognition where a user can take a photo of a product and the system suggests similar ones so my questions are do i need to study ai models neural networks deep learning and all the underlying math in order to build something like this or can i just use existing apis and pretrained models for the functionality i need if i use thirdparty apis like openai or other cloud services will my private data be at risk im concerned about leaking sensitive data from my users i dont want to reinvent the wheel i just want to use ai effectively in my app,,,,,
1k17u3x,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 08:29:18,assistance needed d hello all im johnny and ive been delving into some groundbreaking work in the intersection of artificial intelligence and cognitive computing my research focuses on creating scalable sustainable ai systems that leverage both advanced algorithms and neuroscienceinspired approaches while the idea might sound like science fiction im exploring how we can use machine learning to replicate and enhance the cognitive processes that humans use in decisionmaking pattern recognition and realtime problemsolving one of the key challenges im addressing is the efficiency of neural networks in complex realworld applications im particularly interested in how reinforcement learning and neuromorphic computing can unlock autonomous systems that not only mimic but also improve on human intelligence without the energy and resource cost of traditional models with this project im also investigating the use of synthetic biology and aidriven optimization as a means of pushing the boundaries of what is possible in artificial photosynthesis and other sustainable energy solutions however its clear that making these concepts a reality involves overcoming a lot of hurdles especially in terms of scaling and material efficiency id love to hear from others who are working on innovative crossdisciplinary projects that blend ai with biological processes or any form of advanced optimization techniques lets exchange ideas and explore how we can make a realworld impact by merging these fields in novel ways looking forward to your insights and collaborations best johnny,,,,,
1k1d6a9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 13:45:43,discussion evaluating multiple feature setsmodelsam i leaking by selecting the best of top on the test set hi all im working on a machine learning project where im evaluating two different outcomes binary classification tasks the setup is as follows different feature sets each feature set has time window variations different models fold cv is used to select models based on the highest f score so for one outcome thats feature sets time windows models configurations each of these is run with fold crossvalidation on the training set for tuning my process so far for each outcome i select the top configurations based on mean f in cv then i train those models on the entire training set and evaluate them on the heldout test set the idea is to eventually use the best performing configuration in realworld deployment my question if i evaluate the top on the test set and then choose the best of those to deploy am i effectively leaking information or overfitting to the test set should i instead only evaluate the best from cv on the test set to avoid cherrypicking or is it acceptable to test multiple preselected models and choose the best among them as long as i dont further tweak them afterward some context in previous experiments the best cv model didnt always perform best on the test setbut i had to fix some issues in the code so the new results may differ my original plan was to carry the top forward from each outcome but now im wondering if that opens the door to test set bias,,,,,
1k1hqv7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 16:56:33,r experiment report openai gpt mini is a really costeffective model openai new models how do gpt models compare to o models gptmini appears to be the best costeffective model to ease our curiosity we conduct a set of rag experiments the public dataset is a collection of messages hence it might be particularly interesting to cell phone andor pc manufacturers supposedly it should also be a good dataset for testing knowledge graph kg rag or graph rag algorithms as shown in the table the rag results on this dataset appears to support the claim that gptmini is the best costeffective model overall the rag platform hosted by vecml allows users to choose the number of tokens retrieved by rag because openai charges users by the number of tokens it is always good to use fewer tokens if the accuracy is not affected for example using tokens reduces the cost to merely of the cost w using tokens this dataset is really challenging for rag and using more tokens help improve the accuracy on other datasets we have experimented with often rag w tokens performs as well as rag w tokens in our experience using tokens might be suitable for flagship android phones gen using tokens might be still suitable for older phones and often still achieves reasonable accuracy we would like to test on more rag datasets with a clear document collection query set and golden or reference answers please send us the information if you happen to know some relevant datasets thank you very much,,,,,
1k1hv9q,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 17:01:31,d val loss not drop in different lr loss always around im training a model based on the original tango codebase which combines a vae with a unet diffusion model the original model used singlechannel mel spectrograms but my data consists of dualchannel mel spectrograms so i retrained the vae the vae achieves a validation reconstruction loss of which is a great result i then used this vae to retrain the unet the latent shape is i modified the channel configuration based on tangos original model config and experimented with learning rates of e e e e e and e im using the adamw optimizer with either warmup or linear decay schedulers however the validation loss for the unet stays around and doesnt decrease how can i address this issue and what steps should i take to troubleshoot it _class_name unetdconditionmodel _diffusers_version dev act_fn silu attention_head_dim block_out_channels center_input_sample false cross_attention_dim down_block_fusion_channels down_block_types crossattndownblockd crossattndownblockd crossattndownblockd downblockd downsample_padding dual_cross_attention false flip_sin_to_cos true freq_shift in_channels layers_per_block mid_block_scale_factor norm_eps e norm_num_groups num_class_embeds null only_cross_attention false out_channels sample_size up_block_fusion_channels up_block_types upblockd crossattnupblockd crossattnupblockd crossattnupblockd use_linear_projection true upcast_attention true above is the tango model config dropout _class_name unetdconditionmodel _diffusers_version dev act_fn silu attention_head_dim center_input_sample false cross_attention_dim down_block_types crossattndownblockd crossattndownblockd crossattndownblockd downblockd downsample_padding dual_cross_attention false flip_sin_to_cos true freq_shift in_channels layers_per_block mid_block_scale_factor norm_eps e norm_num_groups num_class_embeds null only_cross_attention false out_channels sample_size up_block_types upblockd crossattnupblockd crossattnupblockd crossattnupblockd use_linear_projection false upcast_attention true this is my model config,,,,,
1k1hyqv,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 17:05:26,d question and distractor generation using t evaluation hello everyone im currently finetuning arat model finetuned version of t model on arabic language and im using it for question and distractor generation each finetuned on their own and im currently struggling with how i should assess model performance and how to use evaluation techniques since the generated questions and distractors are totally random and are not necessarily similar to reference questionsdistractors in the original dataset,,,,,
1k1ncne,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 20:49:54,r algorithm for rotation images in d note its only tangentially related but i feel like this community might still be of help hi im looking for a specific algorithm or at the very list something similar to what has been used in the game smack studio its a an algo used to rotate a bunch of d images in d space so it looks like d in the end i think adobe uses something similar to rotate vector images but this one seems ai driven and im interested in something that i can learn from im a computer science master student and i want to learn more about it and hopefully make it better its tangentially linked to my master thesis so i hope to improve it along the way but its mostly just that it looks cool too me id be glad if any of you has any kind of idea to point me in a better research direction than aiming in the dark thanks for your help ps even straight black box ai can be useful if you have anything please share,,,,,
1k1nn8d,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 21:02:19,n we just made scikitlearn umap and hdbscan run on gpus with zero code changes hi im a lead software engineer on the cuml team at nvidia csadorf on github after months of hard work were excited to share our new accelerator mode that was recently announced at gtc this mode allows you to run native scikitlearn code or umaplearn or hdbscan directly with zero code changes we call it cuml zero code change and it works with both python scripts and jupyter notebooks you can try it directly on colab this follows the same zerocodechange approach weve been using with cudfpandas to accelerate pandas operations just like with pandas you can keep using your familiar apis while getting gpu acceleration behind the scenes this is a beta release so there are still some rough edges to smooth out but we expect most common use cases to work and show significant acceleration compared to running on cpu well roll out further improvements with each release in the coming months the accelerator mode automatically attempts to replace compatible estimators with their gpu equivalents if something isnt supported yet it gracefully falls back to the cpu variant no harm done weve enabled cuda unified memory uvm by default this means you generally dont need to worry about whether your dataset fits entirely in gpu memory however working with datasets that significantly exceed available memory will slow down performance due to excessive paging heres a quick example of how it works lets assume we have a simple training workflow like this train_rfcpy load_ext cumlaccel uncomment this if youre running in a jupyter notebook from sklearndatasets import make_classification from sklearnmodel_selection import train_test_split from sklearnensemble import randomforestclassifier generate a large dataset x y make_classificationn_samples n_features random_state x_train x_test y_train y_test train_test_splitx y test_size random_state set n_jobs to take full advantage of cpu parallelism in native scikitlearn this parameter is ignored when running with cumlaccel since the code already runs in parallel on the gpu rf randomforestclassifiern_estimators random_state n_jobs rffitx_train y_train you can run this code in three ways on cpu directly python train_rfcpy with gpu acceleration python m cumlaccel train_rfcpy in jupyter notebooks add load_ext cumlaccel at the top here are some results from our benchmarking random forest x faster linear regression x faster tsne x faster umap x faster hdbscan x faster performance will depend on dataset size and characteristics so your mileage may vary as a rule of thumb the larger the dataset the more speedup you can expect since moving data to and from the gpu also takes some time were actively working on improvements and adding more algorithms our top priority is ensuring code always falls back gracefully there are still some cases where this isnt perfect check out the docs or our blog post to learn more im also happy to answer any questions here id love to hear about your experiences feel free to share if youve observed speedups in your projects but im also interested in hearing about what didnt work well your feedback will help us immensely in prioritizing future work,,,,,
1k1ss3n,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 01:06:34,d val loss not drop in different lr loss always around im training a model based on the original tango codebase which combines a vae with a unet diffusion model the original model used singlechannel mel spectrograms but my data consists of dualchannel mel spectrograms so i retrained the vae the vae achieves a validation reconstruction loss of which is a great result i then used this vae to retrain the unet the latent shape is i modified the channel configuration based on tangos original model config and experimented with learning rates of e e e e e and e im using the adamw optimizer with either warmup or linear decay schedulers however the validation loss for the unet stays around and doesnt decrease how can i address this issue and what steps should i take to troubleshoot it _class_name unetdconditionmodel _diffusers_version dev act_fn silu attention_head_dim block_out_channels center_input_sample false cross_attention_dim down_block_fusion_channels down_block_types crossattndownblockd crossattndownblockd crossattndownblockd downblockd downsample_padding dual_cross_attention false flip_sin_to_cos true freq_shift in_channels layers_per_block mid_block_scale_factor norm_eps e norm_num_groups num_class_embeds null only_cross_attention false out_channels sample_size up_block_fusion_channels up_block_types upblockd crossattnupblockd crossattnupblockd crossattnupblockd use_linear_projection true upcast_attention true above is the tango model config dropout _class_name unetdconditionmodel _diffusers_version dev act_fn silu attention_head_dim center_input_sample false cross_attention_dim down_block_types crossattndownblockd crossattndownblockd crossattndownblockd downblockd downsample_padding dual_cross_attention false flip_sin_to_cos true freq_shift in_channels layers_per_block mid_block_scale_factor norm_eps e norm_num_groups num_class_embeds null only_cross_attention false out_channels sample_size up_block_types upblockd crossattnupblockd crossattnupblockd crossattnupblockd use_linear_projection false upcast_attention true this is my model config,,,,,
1k1taxr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 01:34:03,d a new dino training framework hello everyone im a phd student in computer science one of my phd projects is about dino distillation with no label models considering the problems weve encountered in this field weve developed a new framework the framework allows you to train both dinov and dinov models additionally trained models are fully compatible with hugging face you can also distill a model from hugging face into a smaller model you can perform all these training processes using either ddp or fsdp for distributed training if you want you can finetune a model trained with dinov using dinov training code fsdp or ddp or vice versa furthermore you can submit all these models to hugging face or present a new approach using specially defined augmentation techniques for medical images well also have a gui design for those who dont fully understand ai training were planning to train giant models using this framework my question is how useful would such a framework be after graduation or would it help me find a job how much interest would it generate or would it provide any reputation i cant follow the industry due to constant work and honestly i have no idea whats happening in the sector thank you,,,,,
1k1qsqu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 23:26:14,d sharing dataset splits what are the standard practices if any wanted to get other peoples takes a common observation papers often generate their own trainvaltest splits usually random but the exact split isnt always shared for smaller datasets this matters different splits can lead to different performance numbers making it hard to truly compare models or verify sota claims across papers you might be evaluating on a different test set we have standard splits for big benchmarks mnist cifar imagenet any llm evals but for many other datasets its less defined i guess my questions are when a dataset lacks a standard split whats your default approach eg generate new random save share exact indicesfiles use kfold have you seen or used any good examples of people successfully sharing their specific dataset splits maybe linked in code repos data platforms etc are there specific domainspecific norms or more standardized ways of handling splits that are common practice in certain fields given the impact splits can have particularly on smaller data how critical do you feel it is to standardize or at least share them for reproducibility and sota claims sometimes i feel like im overthinking how uncommon this seems for many datasets what are the main practical challenges in making sharedstandardized splits more widespread tldr splits are super important for measuring performance and progress what are some standard practices,,,,,
1k1iw08,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 17:43:05,p i made talktoyourslides just finished working on an exciting new tool that lets you edit powerpoint presentations using simple instructions talktoyourslides transforms how you work with presentations just type commands like find and fix all typos or make the title fonts consistent across slides and watch as your slides get updated automatically key features natural language editing commands instant slide updates works with existing powerpoint files powered by an llm agent demo available now check out our working demo at we built this using gradio for the interface our team will be releasing the research paper evaluation dataset and full source code in the coming weeks if you find this useful please like and share the post to help spread the word your support means a lot to our team,,,,,
1k1as1l,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 11:47:46,d difference between acl main acl findings and neurips hey everyone im new to the nlp community and noticed that papers not accepted into the main acl conference can sometimes be published in acl findings could someone clarify how does acl findings compare to acl main conference papers how does publishing in aclacl findings compare to neurips main conference or workshops in terms of prestige visibility or career impact thanks,,,,,
1k1an3a,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 11:40:20,d pros cons of different similarity measures between key and query in attention mechanisms hey everyone im currently exploring attention mechanisms more specifically the manipulation of crossattention layers in diffusion models and am curious about the different ways to compute the similarity between the query and key vectors we commonly see the dot product and cosine similarity being used but im wondering what are the main different use cases between these similarity measures when applied to attention mechanisms are there specific scenarios where one is preferred over the other are there other less commonly used similarity functions that have been explored in the literature id love to hear your thoughts or any references to papers that explore this topic indepth thanks in advance,,,,,
1k18hw5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 09:19:13,d tuning a multiclass classifier precision recall fscore support accuracy macro avg weighted avg i am using lightgbm on brazillian e commerce dataset for churn prediction so far i used smote to handle class imbalance and gridsearch cv best parameters but the results are pretty bad any suggestions,,,,,
1k1606o,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 06:16:33,d when will reasoning models hit a wall o and omini just came out if you dont know these are reasoning models and theyre trained with rl to produce thinking tokens before giving a final output we dont know exactly how this works but we can take a decent guess imagine a simple rl environment where each thinking token is an action previous tokens are observations and the reward is whether the final output after thinking is correct thats roughly the idea the cool thing about these models is you can scale up the rl and get better performance especially on math and coding the more you let the model think the better the results rl is also their biggest limitation for rl to work you need a clear reliable reward signal some domains naturally provide strong reward signals coding and math are good examples your code either compiles or it doesnt your proof either checks out in lean or it doesnt more openended domains like creative writing or philosophy are harder to verify who knows if your essay on moral realism is correct weak verification means a weak reward signal so it seems to me that verification is a bottleneck a strong verifier like a compiler produces a strong reward signal to rl against better the verifier better the rl and no llms cannot selfverify even in math and coding its still a bottleneck theres a big difference between your code compiles and your code behaves as expected for example with the latter being much harder to verify my question for yall is whats the plan what happens when scaling inferencetime compute hits a wall just like pretraining has how are researchers thinking about verification,,,,,
1k156uu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 05:21:46,pbest models to read codes from small torn paper snippets hi everyone im working on a task that involves reading character alphanumeric codes from small paper snippets like the one in the image below these are similar to voucher codes or printed serials heres an example image i have about such images that i can use for finetuning the goal is to either use a pretrained model outofthebox or finetune a suitable ocr model to extract the character string accurately so far ive tried the following trocr finetuned on my dataset but didnt yield great results possibly due to suboptimal training settings smoldocling lightweight but not very accurate on my dataset llamavision works to some extent but not reliable for precise character reading yolo customtrained trained an object detection model to identify individual characters and then concatenate the detections into a string this actually gave the best results so far but there are edge cases eg poor detection of i where it fails i suspect that a model more specialized in ocr string detection especially for short codes would work better than object detection or large visionlanguage models any suggestions for models or approaches that would suit this task well bonus points if the model is relatively lightweight and easy to deploy paper snippet example,,,,,
1k0qfhi,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 17:39:08,p releasing repalignloss custom perceptual loss function used on my software hi everyone id like to share a pytorch loss function ive developed and just opensourced repalignloss link to github repository core idea repalignloss guides a student model by aligning the feature representations of its output with those of a ground truth target as interpreted by a pretrained frozen teacher model eg dinov resnet it essentially encourages the student to produce outputs that look similar to the target from the teachers perspective layer by layer this falls under featurelevel knowledge distillation perceptual loss but specifically compares teacherstudent_output vs teacherground_truth how it works briefly uses forward hooks to extract intermediate activations default convd linear from the frozen teacher model processes both the student models output and the ground truth image through the teacher to get two sets of activations calculates loss by comparing corresponding activation layers between the two sets key differentiator localized similarity instead of comparing entire flattened feature vectors per layer repalignloss groups features within the flattened activation maps currently pairs normalizes each small group via l norm independently and then computes mse between these normalized groups i believe this encourages finergrained structural and feature similarity in the output practical application status i found this loss function effective in guiding generative tasks in fact a version of repalignloss is used in my commercial software framefusion on steam to train the model that generate motionflow from two frames in a video im actively working on the loss function as i train my model to release new version of it example results vs mse to provide a visual intuition heres a comparison using repalignloss vs standard mseloss for an image reconstruction task on the celeba dataset its a simple test feeding noise to a unet for steps and making the ground truth the celeb dataset gt mse result gt repalignloss result,,,,,
1k0qc7v,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 17:35:27,d frontier ai models still fail at basic physical tasks a manufacturing case study llms have made significant progress on many white collar tasks how well do they work on simple blue collar tasks this post has a detailed case study on manufacturing a simple brass part all frontier models do terribly even on the easiest parts of the task surprisingly most models also have terrible visual abilities and are unable to identify simple features on the part geminipro does the best but is still very bad as a result we should expect to see progress in the physical world lag significantly behind the digital world unless new architectures or training objectives greatly improve spatial understanding and sample efficiency link to the post here,,,,,
1k0npdk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 15:48:55,r beyondnanogpt go from llm noob to ai researcher hi all i spent the last few weeks writing a repo that aims to help people go from nanogptlevel understanding of llm basics to be able to reason about and implement relatively sophisticated ideas near the deep learning research frontier its called beyondnanogpt and i just open sourced it it contains thousands of lines of annotated fromscratch pytorch implementing everything from speculative decoding to visiondiffusion transformers to linear and sparse attention and lots more i would love to hear feedback from the ml community here since many are interested both in researchlevel ml ideas and in helping others learn ml feedback might range from key research papers i should add implementations for any bugs spotted or just things people want to see and anything else people have to say the goal is to help convert as many nanogptwatchers into fulltime ai researchers by getting them comfortable with fundamental modern ml research advances,,,,,
1k0jdjo,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 12:38:06,r realharm a collection of realworld language model application failure research paper,,,,,
1k0g5yt,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 09:23:13,p finetuning models for chatbot im trying to train the roberta t and bert models for my school project on my custom dataset to create a chatbot but all my attempts were unsuccessful can you help with the code,,,,,
1k0fx5b,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 09:05:16,dmistake accesor model hey devs struggling with llm hallucinations and the lack of nuance in error correction heres a concept ive been mulling over problem llms often hallucinate confidently instead of admitting ignorance i dont know standard trainingfinetuning doesnt always differentiate the severity of mistakes a major factual error might not be penalized significantly more than a minor grammatical one proposed solution implement a secondary mistake assessor model or system its job evaluate outputs from the primary llm assign weighted penalties based on error impact very high penalty hallucinations confidently incorrect statements harmful content lowzero penalty correctly stating i dont know identifying uncertainty minor stylistic flaws variable penalty other errors weighted by severity factual grammatical feed this weighted score back into the primary llms learning process eg as a refined reward signal in rlhf or influencing the loss function during finetuning potential benefits directly incentivizes admitting ignorance over fabrication accelerates learning by forcing the model to prioritize fixing highimpact errors improves overall reliability and trustworthiness could act as an internal risk assessment guiding response generation context im not equipped to code this but the concept seems promising for tackling core llm reliability issues looking for thoughts is this feasible does similar work exist what are the immediate implementation challenges you foresee,,,,,
1k0fg57,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 08:29:52,d google just released a new generation of tpus who actually uses tpus in production google recently their new generation of tpus optimized for inference google tpus have been around for quite some time now and ive rarely seen any company seriously use them in production at nlp cloud we used tpus at some point behind our training and finetuning platform but they were tricky to set up and not necessarily faster than nvidia gpus we also worked on a poc for tpubased inference but it was a failure because gcp lacked many musthave features on their tpu platform no fixed ip address no serious observability tools slow tpu instance provisioning process xla being sometimes hard to debug researchers may be interested in tpus but is it because of tpus themselves or because of the generous google trc program that gives access to a bunch of free tpus also the fact that google tpus cannot be purchased but only rented through the gcp platform might scare many organizations trying to avoid vendor lockin maybe this new generation of tpus is different and gcp has matured the tpu ecosystem on gcp if some of you have experience using tpus in production id love to hear your story,,,,,
1k0fbvq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 08:20:49,d contrastive learning simclr moco vs noncontrastive pretext tasks rotation inpainting whenwhy does one approach dominate ive been diving into selfsupervised representation learning and wanted to spark a discussion about the tradeoffs between contrastive frameworks eg simclr moco and noncontrastive pretext tasks eg rotation prediction image inpainting jigsaw puzzles specific questions downstream performance are contrastive methods which rely on positivenegative pairs empirically superior for specific domains cv nlp healthcare compared to simpler pretext tasks or does it depend on data scalequality domainspecific strengths for example in medical imaging limited labeled data does contrastive learnings reliance on augmentations hurt generalizability are rotationjigsaw tasks more robust here practical tradeoffs beyond accuracy how do these approaches compare in terms of computestorage eg mocos memory bank vs simclrs large batch sizes sensitivity to hyperparameters eg temperature in contrastive loss data augmentation requirements eg simclrs heavy augmentations vs minimal augmentations for rotation tasks context papers like barlow twins argue noncontrastive methods can match performance but im curious about realworld experiences bonus q are hybrid approaches eg combining contrastive pretext tasks gaining traction or is the field consolidating around one paradigm,,,,,
1k0dov1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 06:21:31,mode a lightweight traditionalrag alternative looking for arxiv endorsement p hi all im an independent researcher and recently completed a paper titled mode mixture of document experts which proposes a lightweight alternative to traditional retrievalaugmented generation rag pipelines instead of relying on vector databases and rerankers mode clusters documents and uses centroidbased retrieval making it efficient and interpretable especially for small to mediumsized datasets paper pdf docs pypi pip install mode_rag github id like to share this work on arxiv csai but need an endorsement to submit if youve published in csai and would be willing to endorse me id be truly grateful endorsement url endorsement code evk please feel free to dm me or reply here if youd like to chat or review the paper thank you for your time and support rahul anand,,,,,
1k0cs6e,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 05:21:01,p are niche ai tools outperforming general models for specific tasks theres a noticeable shift happening instead of using large generalpurpose models for everything more people are turning to taskspecific ai tools that are built for one joband doing it really well in areas like coding document parsing or market analysis these focused models are often outperforming larger llms in terms of speed accuracy and workflow integration for example ive been testing a codefocused tool that runs directly in the ide it explains logic finds bugs and autocompletes entire functions without needing to jump between tabs or write detailed prompts,,,,,
1k0a3r7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 02:44:30,d acl meta reviews discussion hello all the meta reviews of acl are supposed to be released today lets engage in discussion regarding scores and corresponding meta review expectations,,,,,
1k091v6,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 01:49:18,d ai models deprecate hours retesting prompts so ive recently run into this problem while building an ai app and im curious how others are dealing with it every time a model gets released or worse deprecated like gemini pro which is being shut down on april its like have to start from scratch same prompt new model different results sometimes it subtly breaks sometimes it just doesnt work and now with more models coming and going it feels like this is about to become a recurring headache heres what i mean youve got prompts you want to test them on models try them at temperature settings and run each config times to see which ones actually reliable thats runs api calls outputs to track compare and evaluate and next month new model do it all over again i started building something promptperf to automate this and honestly because i was tired of doing it manually but im wondering how are you testing prompts before shipping are you just running it a few times and hoping for the best have you built your own internal tooling or is consistency not a priority for your use case would love to hear your workflows or frustrations around this feels like an area thats about to get very messy very fast,,,,,
1k040es,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 21:45:21,p how and should i use deepgaze pytorch saliency maps hi im working on a project exploring visual attention and saliency modeling specifically trying to compare traditional detection approaches like faster rcnn with saliencybased methods i recently found deepgaze pytorch and was hoping to integrate it easily into my pipeline on google colab the model is exactly what i need pretrained biologically inspired and built for saliency prediction however im hitting a wall i installed it using pip install git i downloaded the centerbias file as required but import deepgaze_pytorch throws modulenotfounderror every time even after switching colabs runtime to python via use fallback runtime version has anyone gotten this to work recently on colab is there an extra step im missing to register or install the module properly finally is deepgaze still a recommended tool for saliency research or should i consider alternatives any help or direction would be seriously appreciated _,,,,,
1k03i0k,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 21:23:14,p i finetuned gpt and gptj to mimic mr darcy results were a mixture of promising and strange this was a personal project ive worked on over the last months i wanted to see whether gpt or gptj could be finetuned to consistently speak in the voice of mr darcy from pride and prejudiceformal clipped and just a bit judgmental by finetune dataset standards theres barely any original dialogue from darcy to work with in an effort to mitigate this disadvantage i included some peerreviewed synthetic examples i wrote myself in the end datasets were used st contextrich excerpts from the book encompassing dialogue narrative elements and perspectives from other characters nd restricted to dialogue interactions directly pairing either bookoriginal or crafted prompts with darcys responses training gpt medium produced noticeable changes bleu scores improved by compared to the base model though perplexity shot up and outputs reflect confusion about context gptj was much more resistant to change expected given its size and id have liked to experiment with more variants but dont really have the computing power for training i wrote about the project here including samples of model output some successful some not comparisons between models and training rounds what i tried what worked what didnt medium article pdf of article code and datasets if anyone else has played around with literary style transfer historical voice modeling or just weird llm finetuning ideas id love to hear about it i no longer have time to continue the project but im open to any feedback or suggestions on how to push this kind of thing further or evaluate it better,,,,,
1k02geq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 20:38:56,d lora vs task vectors what are the difference between a lora adapters and task vectors is it just the context in which they are used,,,,,
1k01cfy,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 19:53:29,deep dive into rwkv with author eugene cheah hey all last week we did a deep dive into rwkv specifically the newest rwkv with our arxiv dive research paper club we were lucky enough to have one of the main authors maintainers eugene cheah join and answer questions at the end so wanted to share the full video here we also put it in blog form in you prefer that the post builds up intuition of what problems rwkv is trying to solve i thought it was really interesting how the organization iterates on models with the community also it left me wanting to run more experiments with learning at test time instead of finetuning lots of interesting threads to pull there hope you enjoy,,,,,
1k00wm0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 19:35:07,d creating my own ai model from scratch is it worth it hey everyone im a web developer teaching myself ai and i was building a saas to act as a direct competitor with jasper ai however i got stuck deciding between building my own ai model from scratch for full control and originality or using existing models like gpt or opensource ones to move faster and get better results early i know there are tradeoffs i want to innovate but i dont want to get lost reinventing the wheel either and there are a lot of stuff i still need to learn to truly bring this saas to life so i wanted some opnions from people with more experience here i truly appreciate any help,,,,,
1jzyl0s,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 18:01:30,r scaling laws of synthetic data for language models ,,,,,
1jzxxoa,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 17:35:40,d most llms fail at generating truly random binary sequences tested whether popular llms can generate truly random binary sequences s and s and found that most models show statistically significant bias toward generating more s than expectedkey findings,,,,,
1jzxldl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 17:21:59,d most llms fail at generating truly random binary sequences i tested whether popular llms can generate truly random binary sequences s and s and found that most models show statistically significant bias toward generating more s than expected,,,,,
1jzwuiz,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 16:52:14,d is normalizing before traintest split a data leakage in time series forecasting ive been working on a time series forecasting stock model emdlstm and ran into a question about normalization is it a mistake to apply normalization minmaxscaler to the entire dataset before splitting into training validation and test sets my concern is that by fitting the scaler on the full dataset it might see future data including values from the test set during training that feels like data leakage to me but im not sure if this is actually considered a problem in practice,,,,,
1jzs47u,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 13:38:38,p lightlytrain opensource ssl pretraining for better vision models beats imagenet hi rmachinelearning im igor cofounder at lightly ai weve just opensourced lightlytrain a python library under the agpl license making it free for academic research educational use and projects compatible with its terms designed to improve your computer vision models using selfsupervised learning ssl on your own unlabeled data github repo blog post benchmarks problem imagenetcoco pretrained models often struggle on specific domains medical agriculture etc getting enough labeled data for finetuning is expensive and slow solution lightlytrain pretrains models like yolo resnet rtdetr vits directly on your unlabeled images before finetuning this adapts the model to your domain boosting performance and reducing the need for labeled data why use lightlytrain better performance outperforms training from scratch and imagenet weights especially with limited labels or strong domain shifts see benchmarks no labels needed for pretraining leverage your existing unlabeled image pool domain adaptation make foundation models work better on your specific visual data easy integration works with popular frameworks ultralytics timm torchvision and runs onprem singlemultigpu scaling to millions of images benchmark highlights details in blog post coco labels boosted yolovs map by over imagenet domainspecific gains showed clear improvements on bddk driving deeplesion medical deepweeds agriculture quick start python pip install lightlytrain import lightly_train pretrain on your images lightly_traintrain datapathtoyourimages modelultralyticsyolovs or torchvisionresnet etc load weights and finetune using your existing pipeline see repodocs for frameworkspecific examples resources github blog post benchmarks docs demo video we built this to make practical ssl accessible hope its useful for the community happy to answer technical questions disclaimer im a cofounder commercial licenses are available,,,,,
1jzqgw8,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 12:20:54,d how do you evaluate your agents can anyone share how they evaluate their agents ive build a customer support agent using openais new sdk for a client but hesitant to put it in prod the way i am testing it right now is just sending the same messages over and over to fix a certain issue surely there must be a more systematic way of doing this i am getting tired of this does anyone have recommendations andor good practices,,,,,
1jzpkyj,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 11:34:30,r neuron alignment isnt fundamental its a sideeffect of relu tanh geometry says new interpretability method neuron alignment where individual neurons seem to represent realworld concepts might be an illusion a new method the spotlight resonance method srm shows that neuron alignment isnt a deep learning principle instead its a geometric artefact of activation functions like relu and tanh these functions break rotational symmetry and privilege specific directions causing activations to rearrange to align with these basis vectors tldr the srm provides a general mathematically grounded interpretability tool that reveals functional forms relu tanh anisotropic symmetry breaking privileged directions neuron alignment interpretable neurons its a predictable controllable effect now we can use it what this means for you new generalised interpretability metric built on a solid mathematical foundation it works on all architectures all layers all tasks reveals how activation functions reshape representational geometry in a controllable way the metric can be maximised increasing alignment and therefore network interpretability for safer ai using it has already revealed several fundamental ai discoveries exciting discoveries for ml challenges neuronbased interpretability neuron alignment is a coordinate artefact a human choice not a deep learning principle a geometric framework helping to unify neuron selectivity sparsity linear disentanglement and possibly neural collapse into one cause demonstrates these privileged bases are the true fundamental quantity this is empirically demonstrated through a direct causal link between representational alignment and activation functions presents evidence of interpretable neurons grandmother neurons responding to spatially varying sky vehicles and eyes in nonconvolutional mlps how it works srm rotates a spotlight vector in bivector planes from a privileged basis using this it tracks density oscillations in the latent layer activations revealing activation clustering induced by architectural symmetry breaking it generalises previous methods by analysing the entire activation vector using lie algebra and so works on all architectures the paper covers this new interpretability method and the fundamental dl discoveries made with it already iclr workshop paper code implementation george bird,,,,,
1jzpb75,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 11:19:28,d are you guys still developing inhouse nlp models in this llm era are you guys still building nlp models from scratch or just fine tuning from the llm prompts,,,,,
1jzp9d0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 11:16:32,d how to train this model with constrained resources so i have made a model following this paper they basically reduced the complexity of computing the attention weights so i modified the attention mechanism accordingly now the problem is that to compare the performance they used tesla v gpus and used the bookcorpus along with english wiki data which accounts to over m words i dont have access to that much resourcesmax is kaggle i want to show that my model can show comparable performance but at lower computation complexity i dont know how to proceed now please help me my model has a typical transformer decoder architecture similar to gptsmall layers heads per layer total there are m parameters in my model,,,,,
1jzobwq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 10:19:49,d adress names matching technique recommendations context i have a dataset of company owned products like name company a address th avenue product a company a inc address new york product b company a inc address th avenue new york product c i have million entries like these as you can see addresses and names are in inconsistent formats i have another dataset that will be me ground truth for companies it has a clean name for the company along with its parsed address the objective is to match the records from the table with inconsistent formats to the ground truth so that each product is linked to a clean company questions and help i was thinking to use google geocoding api to parse the addresses and get geocoding then use the geocoding to perform distance search between my my addresses and ground truth but i dont have the geocoding in the ground truth dataset so i would like to find another method to match parsed addresses without using geocoding ideally i would like to be able to input my parsed address and the name maybe along with some other features like industry of activity and get returned the top matching candidates from the ground truth dataset with a score between and which approach would you suggest that fits big size datasets the method should be able to handle cases were one of my addresses could be company a address washington meaning an approximate address that is just a city for example sometimes the country is not even specified i will receive several parsed addresses from this candidate as washington is vague what is the best practice in such cases as the google api wont return a single result what can i do my addresses are from all around the world do you know if google api can handle the whole world would a language model be better at parsing for some regions help would be very much appreciated thank you guys,,,,,
1jzauh4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 21:40:49,d is fractional differencing helpful for ml outside of economics ive been trying to figure out ways to apply ml to nonstationary signals in my research one very ubiquitous example i see is fractional differencing which is commonly used in fintech however i dont see any mention of it outside of fintech im not really sure why i would have expected to see it being attempted in something like neural signal processing or seismic data for ml,,,,,
1jzkzh6,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 06:26:54,d creating ai avatars from scratch firstly thanks for the help on my previous post yall are awesome i now have a new thing to work on which is creating ai avatars that users can converse with i need something that can talk and essentially tts the replies my chatbot generates i need an open source solution that can create normal avatars which are kinda realistic and good to look at please let me know such options at the lowest cost of compute,,,,,
1jzjy7f,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 05:17:55,d experiment tracking for student researchers wandb neptune or comet ml hi ive come down to these but can you help me decide which would be the best choice rn for me as a student researcher i have used wandb a bit in the past but i read it tends to cause some slow down and im training a large transformer model so id like to avoid that ill also be using multiple gpus in case thats helpful information to decide which is best specifically which is easiest to quickly set up and get started with stable doesnt cause issues and is decent for tracking metrics parameters tia,,,,,
1jzffw1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 01:14:06,d building a marketplace for k hours of highquality ethically sourced video datalooking for feedback from ai researchers hey all im working on a marketplace designed specifically for ai labs k hours of ethically sourced studiolicensed video content for largescale training were building multimodal search into the coreso you can search by natural language across visuals audio and metadata the idea is to make massive video datasets actually usable a few open questions for researchers and engineers training on video what format do you prefer for training data raw compressed mp resolutions like k k or full hd something else weve segmented videos and made them searchable via natural language you can license just the segments that matches your query the full videos it came from or the entire dataset is this kind of granular licensing actually useful in your workflowor do you typically need larger chunks or full datasets anyway were in user discovery mode and trying to validate core assumptions if you train on video or audiovisual data id love to hear your thoughtseither in the comments or via dm thanks in advance,,,,,
1jzdgyk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 23:39:19,r the ai scientistv workshoplevel automated scientific discovery via agentic tree search ,,,,,
1jz8boa,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 19:56:36,d advice on building random forestxgboost model i have emr data with millions of records and around variables i need to create a random forest or xgboost model to assess the risk of hospitalization within days postsurgery given the large number of variables im planning to follow this process split the data into training validation and test sets and perform the following steps on the training set use the default settings for rfxgboost and remove around half or more of the features based on feature importance perform hyperparameter tuning using gridsearchcv with fold crossvalidation reassess feature selection based on the new hyperparameters and continue iterating between feature selection and hyperparameter tuning evaluating performance on the validation set my questions are should i start with the default settings for the rfxgboost model and eliminate half the features based on feature importance before performing hyperparameter tuning or should i tune the model first i am concerned that with such large data tuning might not be feasible does my approach look good please suggest any improvements or steps i may have missed this is my first time working with data of this size the end point of this project is to implement a model for future patients to predict day hospitalization risk,,,,,
1jz819a,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 19:44:56,do you still use human data to pretrain your models d been seeing some debates lately about the data we feed our llms during pretraining it got me thinking how essential is highquality human data for that initial foundational stage anymore i think we are shifting towards primarily using synthetic data for pretraining the idea is leveraging generated text at scale to teach models the fundamentals including grammar syntax basic concepts and common patterns some people are reserving the often expensive data for the finetuning phase are many of you still heavily reliant on human data for pretraining specifically id like to know the reasons why you stick to it,,,,,
1jz80xq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 19:44:33,d p list of llm architectures i am collecting arxiv papers on llm architectures looking for any im missing hey all im looking for suggestions and links to any main arxiv papers for llm architectures and similar i dont have in my collection yet would appreciate any help also as for what this is all for i have a hobby of designing novel small language model architectures i was curious if someone who has access to more compute than me might be interested in teaming up and doing a project with me with the ultimate goal to release a novel architecture under a creative commons attributionsharealike international cc bysa license so far i have the following associative recurrent memory transformers bert bimamba bigbird deepseek r deepseek v hyena hymba jamba linear transformers linformer longformer mamba neural turing machines performer recurrent memory transformer retnet rwkv s titans transformer,,,,,
1jz6shu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 18:54:56,how i warped your noise a temporallycorrelated noise prior for diffusion models r ,,,,,
1jz4p54,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 17:31:47,d what if we paused and resumed llms like os processes weve been exploring whether transformer models can be treated more like processes than static deployments after warmup we snapshot the full runtime state to disk including weights kv cache layoutand restore it in about to seconds this allows us to pause and resume models on demand instead of keeping them loaded continuously so far this has enabled dozens of models running per gpu without idle time dynamic agent stacks that load tools or finetunes only when needed local finetuning jobs squeezed into idle windows feels a bit like oslevel scheduling but applied to model lifecycles curious if anyone else has tested similar ideas or if this overlaps with approaches youre trying in local or scaled settings,,,,,
1jz0qlk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:50:01,d outlier analysis in machine learning i trained multiple ml models and noticed that certain samples consistently yield high prediction errors id like to investigate why these samples are harder to predict whether due to inherent noise data quality issues or model limitations does it make sense to focus on samples with higherror as outliers or would other methods eg uncertainty estimation with gaussian processes be more appropriate,,,,,
1jyzamc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 13:47:50,d latest tts for voice cloning hello do you guys know any good tts that i can run locally to clone a voice preferably multilingual please no labs cuz ridiculous pricing looking for something i can thinker locally,,,,,
1jyz2vg,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 13:37:55,d what happened to kans kolmogorovarnold networks kans seem promising but im not hearing any real applications of it curious if anyone has worked on it,,,,,
1jy4udu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 10:41:28,d distributed clustering using hdbscan hello all heres the problem im trying to solve i want to do clustering on a sample having size million the gpu implementation of hdbscan is pretty fast and i get the output in mins but around of data is classified as noise i want to learn a bit more about noise ie to which clusters a given noise point is close to hence i tried soft clustering which is already available in the library the problem with soft clustering is it needs significant gpu memory number of samples number of clusters size of float if number of clusters generated are k it needs around gb gpu memory which is manageable but my data is expected to grow in the near future which means this solution is not scalable at this point i was looking for something distributive and found distributive dbscan i wanted to implement something similar along those lines using hdbscan following is my thought process divide the data into n partitions using k means so that points which are nearby has a high chance of falling into same partition perform local clustering for each partition using hdbscan take one representative element for each local cluster across all partitions and perform clustering using hdbscan on those local representatives lets call this global clustering if at least representatives form a cluster in the global clustering merge the respective local clusters if a point is classified as noise in one of the local clusters use approximate predict function to check whether it belongs to one of the clusters in remaining partitions and classify it as belonging to one of the local clusters or noise finally we will get a hierarchy of clusters if i want to predict a new point keeping the cluster hierarchy constant i will use approximate predict on all the local cluster models and see if it fits into one of the local clusters im looking forward to suggestions especially while dividing the data using kmeans might lose some clusters because of this while merging clusters and classifying local noise,,,,,
1jyaipx,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 15:41:14,r new book mastering modern time series forecasting a handson guide to statistical ml and deep learning models in python hi rmachinelearning community im excited to share that my book mastering modern time series forecasting is now available for preorder on gumroad as a data scientistml practitione i wrote this guide to bridge the gap between theory and practical implementation heres whats inside comprehensive coverage from traditional statistical models arima sarima prophet to modern mldl approaches transformers nbeats tft pythonfirst approach code examples with statsmodels scikitlearn pytorch and darts realworld focus techniques for handling messy data feature engineering and evaluating forecasts why i wrote this after struggling to find resources that balance depth with readability i decided to compile my learnings and mistakes into a structured guide feedback and reviewers welcome,,,,,
1jyf84w,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 19:02:48,r github rbflexnas trainingfree neural architecture search rbflexnas is a novel trainingfree nas framework that accounts for both activation outputs and input features of the last layer with a radial basis function rbf kernel,,,,,
1jyp3g3,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 03:06:05,project anyone needs compute for their passion ai projects so i have as waiting to brrrrr i have some projects of mine going on but i have some compute to spare if anyone is interested pitch me your idea and we can get something rolling for you,,,,,
1jys6sr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 06:21:54,p rust binary and library crate for semantic code retrieval ,,,,,
1jyc9mc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 16:57:09,d rethinking dod sbirs for the modern ai era an insiders perspective this article reflects the perspective of a phdlevel researcher with two decades of handson experience in applied aiml and signal processing primarily focused on us defense applications the author has worked as both a technical contributor and leader within organizations deeply involved in dod rd contracting providing an insiders view on innovation pipelines and their realworld effectiveness i introduction the department of defenses small business innovation research sbir program its a solid idea on paper its all about getting small businesses to cook up innovative solutions for tough defense problems and you know actually get those ideas out of the lab and into the field for years its been a decent engine for tech advancements across the board but heres the thing artificial intelligence and machine learning aiml are moving at warp speed and its mostly the big commercial players driving that bus from where i sit deep inside the dod rd world as a scientist its becoming pretty clear that the old sbir playbook is struggling to keep up in the aiml arena instead of consistently churning out gamechanging readytogo tech the program often feels more like a specialized handout a bit of welfare for smart folks without the bang for the buck we need to really push the ai envelope in defense ii the shadow of big tech foundational models data dominance the real elephant in the room is the sheer scale of the big tech companies think google meta microsoft openai their data massive their computing power insane the ai talent theyve got it dwarfs what your typical sbir recipient and honestly a lot of the dod itself can even dream of their investments have led to these powerhouse foundational models llms computer vision stuff you name it that are just miles ahead and the crazy part these models arent just for your social media feed turns out with tricks like transfer learning and fewshot learning you can adapt these externally trained models incredibly well to specific dod areas even super specialized sensor data like mwir video sar or hyperspectral imagery because theyve learned so much general stuff you often just need a relatively small amount of specific data to get stateoftheart results by tweaking whats already there this totally changes the game it makes me wonder whats the unique truly innovative space for a small business sbir project to build core ai models from scratch when these giant resourcerich players already have such a huge head start iii the offtheshelf application trap beyond trying to outinnovate the big guys on core models a lot of aiml sbir projects stumble into another pitfall just applying offtheshelf tech onto a dod problem sure integrating existing tools can be useful but you see a worrying number of projects that basically just download prebuilt algorithms from places like hugging face or pytorch hub and apply them to a dod dataset with barely any changes it feels less like groundbreaking research and more like decent technical integration what makes it worse is that you often see a lack of real scientific rigor for example literature reviews are often skipped this means you get people unknowingly reinventing the wheel a waste of time and taxpayer money and the pressure to show a demo in those short sbir phases totally overshadows the need for careful experiments ablation studies or really digging deep to understand why something works or how to push the boundaries so you have to ask if the main activity is just using existing public tools without real innovation or solid methodology is that really research in small business innovation research iv the sbir mill incentives vs transition maybe the most frustrating thing for those of us hoping sbirs will actually lead to realworld capabilities is how many promising projects just die after phase ii youve got plenty of small companies that become masters of the sbir proposal game raking in phase i and ii awards left and right but that jump to phase iii actually getting the tech commercialized or for the dod integrated into a real program thats where things usually fall apart the way the system is set up kind of encourages this winning the next grant can become the whole business model rewarding proposal writing skills way more than the hard uncertain work of turning a prototype into a rugged tested and supported product that the warfighter can actually use this is how you get the sbir mill companies that live off sequential sbir funding without ever delivering a lasting capability or becoming selfsufficient often they just dont have the systems engineering skills the manufacturing knowhow or the business development focus to make that transition happen for example rarely do i see companies reaching out to industry to sell their new tech they developed on the sbir when the priority is just getting the next rd dollar instead of fielding solutions the program risks becoming that welfare system i mentioned earlier keeping smart people employed but not consistently delivering value to the actual enduser v conclusion rethinking ai sbirs for real impact the combination of commercial ai models the ease of using offtheshelf tools and a program that unintentionally rewards grant chasing over actual transition creates a tough environment for the dod sbir program in the aiml space while it definitely supports small businesses and keeps technical folks working you have to seriously question how effective it is at consistently producing the cuttingedge fieldable ai capabilities the warfighter needs in this new tech landscape these arent just complaints theyre honest questions about whether were using taxpayer money in the most efficient way to achieve real aiml superiority we need to take a hard look at how the sbir program can adapt should the focus shift from trying to create brand new models to critical areas like curating good data rigorous testing and evaluation responsible ai or the tough job of integrating existing toptier tech into complex defense systems and how do we make transition a real priority with teeth if we dont tackle these systemic issues the dod risks continuing to fund an aiml sbir engine that looks more like a wellmeaning but ultimately inefficient holding pattern,,,,,
1jyo8fd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 02:18:07,d firsttime arxiv submitter need endorsement for csai hi everyone im submitting my first paper to arxiv in the csai category and need an endorsement to proceed if youve submitted arxiv papers in csai or related categories within the last years id be deeply grateful if you could endorse me my arxiv username yuheejang endorsement code kltto endorsement link the paper is a case study on chatgpts fallback loop resolution through userinduced metafeedback and id love to share it once its up thanks so much for your time and support,,,,,
1jytgn0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 07:55:04,r responsible data augmentation with diffusion models at iclrw we propose a texttoimage ti data augmentation method named diffcoremix that computes a set of generative counterparts for a training sample with an explicitly constrained diffusion model that leverages samplebased context and negative prompting for a reliable augmentation sample generation to preserve key semantic axes we also filter out undesired generative samples in our augmentation process to that end we propose a hardcosine filtration in the embedding space of clip our approach systematically mixes the natural and generative images at pixel and patch levels we extensively evaluate our technique on imagenetk tiny imagenet cifar flowers cubbirds stanford cars and caltech datasets demonstrating a notable increase in performance across the board achieving up to absolute gain for top accuracy over the stateoftheart methods while showing comparable computational overhead arxiv code,,,,,
1jyr6ah,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 05:12:18,d distillation is underrated i replicated gptos capability in a x cheaper model just tried something cool with distillation managed to replicate gptolevel performance accuracy using a much smaller finetuned model and it runs x cheaper for those unfamiliar distillation is basically take a huge expensive model and use it to train a smaller cheaper faster one on a specific domain if done right the small model could perform almost as well at a fraction of the cost honestly super promising curious if anyone else here has played with distillation tell me more use cases adding my code in the comments,,,,,
1jypxab,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 03:54:28,d unable to replicate reported results when training mmpose models from scratch im trying out mmpose but have been completely unable to replicate the reported performance using their training scripts ive tried several models without success for example i ran the following command to train from scratch cuda_visible_devices python toolstrainpy projectsrtmposertmposewholebody_d_keypointrtmposel_xbe_cocowholebodyxpy which according to the table at rtmposel with an input size of x is supposed to achieve a whole ap of on the coco dataset however i can only reach an ap of i also tried increasing the stage finetuning duration from to epochs but the best result i got was an ap of additionally i attempted to resume training from their provided pretrained models for more epochs but the performance consistently degrades has anyone else experienced similar issues or have any insights into what might be going wrong,,,,,
1jyjkjf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 22:15:18,d just opensourced a financial llm trained on years of indian market data outputs sql you can run on duckdb hey folks wanted to share something ive been building over the past few weeks a small opensource project thats been a grind to get right i finetuned a transformer model on structured indian stock market data fundamentals ohlcv and index data across years the model outputs sql queries in response to natural language questions like what was the net_profit of infy on whats the day moving average of tcs close price on show me yoy growth of eps for reliance its offline no apis no cloud calls and ships with a duckdb file preloaded with the dataset you can paste the models sql output into duckdb and get results instantly you can even add your own data without changing the schema built this as a proof of concept for how useful small llms can be if you ground them in actual structured datasets its live on hugging face here would love feedback if you try it out or have ideas to extend it cheers,,,,,
1jydy3j,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 18:08:33,d icml a shift toward correctness over sota icmls policy this yeara good direction prioritizing correctness over chasing sota,,,,,
1jy9hp7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 14:55:13,dkaggle competition is it worthwhile for phd student not sure if this is a dumb question is kaggle competition currently still worthwhile for phd student in engineering area or computer science field,,,,,
1jy5w5l,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 11:51:13,p tiktok brainrot generator update not too long ago i made a brain rot generator that utilizes motu hiras wavvec algorithm for force alignment and it got some traction this time i made some updates to the brain rot generator together with vidhu who has personally reached out to me to help me with this project threads suggestions now if you do not know what to suggest you can let an llm to suggest for you aka groq b llama together with vader sentiment image overlay this was done using an algorithm which showed the timestamp similar to the audio for force alignment but done using image instead dockerization support it now supports dockerisation web app for easy usage i have also made a web app that makes it easy to toggle between features major bug fixed thanks to vidhu for identifying and fixing the bug which prevented people from using the repo here is the github if you have any questions please let me know,,,,,
1jy5ue4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 11:48:09,d how do you manage experiments with ml models at work im doing my master thesis at a company that doesnt do a lot of experimentation on ai models and definitely nothing much systematic so when i started i decided to first implement what came to be my standard project structure ccds with hydra and mlflow it took me some time to write everything i needed set up configuration files etc and thats not to say anything of managing to store plots visualising them or even any form of orchestration outside my scope anyway ive done the same in university research projects and schoolwork so since i didnt have a budget and wanted to learn i just went with implementing everything myself still this seems too much effort if you do have a budget how are you guys managing experiments using some saas platform running open source tools which onprem or writing your own little stack and managing that yourselves,,,,,
1jy4odf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 10:29:45,d the ml paradox when better metrics lead to worse outcomes have you faced this imagine youve trained a model that theoretically excels by all standard metrics accuracy fscore aucroc etc but practically fails catastrophically in realworld deployment for example a medical diagnosis model with accuracy that disproportionately recommends harmful treatments for rare conditions a selfdriving car api that reduces pedestrian collisions in simulations but causes erratic steering in rain leading to more crashes an nlp chatbot that scores highly on helpfulness benchmarks but gives dangerous advice when queried about mental health the paradox your model is better by metricsresearch standards but worse ethically socially or functionally questions have you encountered this disconnect share your story how do we reconcile optimization for benchmarks with realworld impact should ml prioritizes metrics or outcomes can we even measure the latter,,,,,
1jxqtoo,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 20:39:09,p harmonic activations periodic and monotonic function extensions for neural networks preprint hey folks ive recently released a preprint proposing a new family of activation functions designed for normalizationfree deep networks im an independent researcher working on expressive nonlinearities for mlps and transformers tldr i propose a residual activation function fx x α gsin²πx where g is an activation function eg gelu i would like to hear feedbacks this is my first paper preprint,,,,,
1jxn5fe,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 17:53:52,p what if you could run llms per gpu without keeping them in memory weve been experimenting with an ainative runtime that snapshotloads llms bb in seconds and dynamically runs models per gpu without keeping them always resident in memory instead of preloading models like in vllm or triton we serialize gpu execution state memory buffers and restore models on demand even in shared gpu environments where full device access isnt available this seems to unlock real serverless llm behavior no idle gpu cost multimodel orchestration at low latency better gpu utilization for agentic or dynamic workflows curious if others here are exploring similar ideas especially with multimodelagent stacks dynamic gpu memory management mig kai scheduler etc cudacheckpoint partial device access challenges happy to share more technical details if helpful would love to exchange notes or hear what pain points youre seeing with current model serving infra for folks curious about updates breakdowns or pilot access im sharing more over on x inferxai were actively building in the open,,,,,
1jxjwi2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 15:30:53,d reasoning models dont always say what they think anyone got a prompts has anyone here tried replicating the results from the reasoning models dont always say what they think paper using their own prompts im working on reproducing these outputs if youve experimented with this and finetuned your approach could you share your prompt or any insights you gained along the way any discussion or pointers would be greatly appreciated for reference heres the paper reasoning models paper,,,,,
1jxin3q,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 14:33:00,n google open to let entreprises self host sota models from a major player this sounds like a big shift and would mostly offer enterprises an interesting perspective on data privacy mistral is already doing this a lot while openai and anthropic maintain more closed offerings or through partners,,,,,
1jwnxtk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 11:50:52,r arxiv endorsement in csai hi can anyone endorse me in arxiv subfield csai here is my draft and heres the endorsement code thanks,,,,,
1jwqrud,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 14:08:26,r cat circularconvolutional attention for subquadratic transformers cat achieves onlogn computations requires fewer learnable parameters by streamlining fullyconnected layers and introduces no heavier operations resulting in consistent accuracy improvements and about a speedup in naive pytorch implementations on largescale benchmarks such as imagenetk and wikitext,,,,,
1jxeahf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 10:30:15,r d scaling reasoning in diffusion large language models via reinforcement learning recent large language models llms have demonstrated strong reasoning capabilities that benefits from online reinforcement learning rl these capabilities have primarily been demonstrated within the lefttoright autoregressive ar generation paradigm in contrast nonautoregressive paradigms based on diffusion generate text in a coarsetofine manner although recent diffusionbased large language models dllms have achieved competitive language modeling performance compared to their ar counterparts it remains unclear if dllms can also leverage recent advances in llm reasoning to this end we propose d a framework to adapt pretrained masked dllms into reasoning models via a combination of supervised finetuning sft and rl specifically we develop and extend techniques to improve reasoning in pretrained dllms a we utilize a masked sft technique to distill knowledge and instill selfimprovement behavior directly from existing datasets and b we introduce a novel criticfree policygradient based rl algorithm called diffugrpo through empirical studies we investigate the performance of different posttraining recipes on multiple mathematical and logical reasoning benchmarks we find that d yields the best performance and significantly improves performance of a stateoftheart dllm promising results on scaling diffusion large language models for reasoning tasks using reinforcement learning definitely something to keep an eye on when it comes to language models that actually reason paper link,,,,,
1jxbmss,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 07:13:28,p simple standalone tfrecords dataset reader with random access and searchin capabilities hi at work we are using tfrecords to store most of our datasets however from time to time we need to inspect the data to better undestand predictions of our models eg to find examples of particular class etc since tfrecords are sequential in nature they dont allow for standard random access slicing i decided to create this simple tool which allows to create a simple searchable index for tfrecrods which can be used later for various dataset analysis here is the project page features tensorflow and protobuf packages are not required dataset can be read directly from google storage indexing of m examples is fast and usually takes couple of seconds polars is used for fast dataset querying tfrdsselectselect from index where name rose limit here is a quick start example from readme import tensorflow_datasets as tfds required only to download dataset import tfr_reader as tfr from pil import image import ipyplot dataset dataset_info tfdsloadoxford_flowers splittrain with_infotrue def index_fnfeature tfrfeature required only for indexing label featurelabelvalue return label label name dataset_infofeatureslabelintstrlabel tfrds tfrload_from_directory loads ds and optionaly build index dataset_infodata_dir indexing options not required if index is already created filepatterntfrecord index_fnindex_fn overridetrue override the index if it exists example selection using polars sql query api rows examples tfrdsselectselect from index where name rose limit assert examples tfrdsrows_row_id samples names for k example in enumerateexamples image imageopenexampleimagebytes_ioresize namesappendrowsnamek samplesappendimage ipyplotplot_imagessamples names,,,,,
1jx3zy0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 23:42:34,d adding new vocab tokens finetuning llms to follow instructions is ineffective ive been experimenting on instructiontuning llms and vlms either with adding new specialized tokens to their corresponding tokenizerprocessor or not the setup is typical mask the instructionsprompts only attend to responsesanswer and apply ce loss nothing special standard sft however ive observed better validation losses and output quality with models trained using their base tokenizerprocessor versus models trained with modified tokenizer any thoughts on this feel free to shed light on this my hunch its difficult to increase the likelihood of these new added tokens and the model simply just cant learn it properly,,,,,
1jwz2k3,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 19:59:31,d finetuned bart for product title category normalization still not accurate enough any better approach hi everyone im building a price comparison website for products from various online stores in moldova i finetuned a bart model on a custom dataset of around manually normalized product titles and achieved a loss of i also trained a separate model for predicting product categories unfortunately the results are still not reliable the model struggles with both product title normalization and category assignment especially when product names have slight variations or extra keywords i dont have access to sku numbers from the websites so matching must be done purely on text is there a better approach or model i might be missing or maybe a toolapp thats designed specifically for this kind of problem thanks in advance,,,,,
1jwxght,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 18:50:35,pwe built an oslike runtime for llms curious if anyone else is doing something similar were experimenting with an ainative runtime that snapshotloads llms eg bb in under seconds and dynamically runs models per gpu without keeping them always resident in memory instead of traditional preloading like in vllm or triton we serialize gpu execution memory state and restore models ondemand this seems to unlock real serverless behavior no idle cost multimodel orchestration at low latency better gpu utilization for agentic workloads has anyone tried something similar with multimodel stacks agent workflows or dynamic memory reallocation eg via mig kai scheduler etc would love to hear how others are approaching this or if this even aligns with your infra needs happy to share more technical details if helpful,,,,,
1jww7nn,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 17:58:33,p subs cold starts for b llms models per gpu curious how others are tackling orchestration were experimenting with an ainative runtime that snapshotloads llms eg bb in under seconds and dynamically runs models per gpu without keeping them always resident in memory instead of traditional preloading like in vllm or triton we serialize gpu execution memory state and restore models ondemand this seems to unlock real serverless behavior no idle cost multimodel orchestration at low latency better gpu utilization for agentic workloads has anyone tried something similar with multimodel stacks agent workflows or dynamic memory reallocation eg via mig kai scheduler etc would love to hear how others are approaching this or if this even aligns with your infra needs happy to share more technical details if helpful,,,,,
1jwv8qp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 17:17:49,project i created a crop generator that you might want to use hello everyone i created a python based crop generator that helps me with my image datasets i am training sdxl models to recognize features and concepts and i just couldnt find a quick tool to do this or didnt look for it enough my specific use case is that i have images that are big and some are somewhat small and i need to select specific features some are very small and i was getting very blurry images when i created a crop of a specific zoomed feature this script uses your jsonl to find the center of the bounding box and export the image in the resolution you need px based and upscalesdenoises them to create crops that you can use to train your model it also creates a metadatacsv with the file_name and the description from your jsonl i essentially run this on my raw images folder and it creates a new folder with the cropped images the metadatacsv containing the filename and the description and im ready to train very fast of course you need to first create your jsonl file with all the bounding boxes and i already have that light html script but right now i dont have the time to make it less specific to my case use and im sure i can improve it a bit i will update the repo once i have it hopefully you can use this in your training refork suggest changes etc,,,,,
1jws42t,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 15:06:32,p a lightweight opensource model for generating manga i posted this on rstablediffusion see some nice discussion and someone recommended itd also fit here tldr i finetuned pixartsigma on million manga images and im making the model weights opensource download them on hugging face try it for free at background im an ml engineer whos always been curious about genai but only got around to experimenting with it a few months ago i started by trying to generate comics using diffusion modelsbut i quickly ran into three problems most models are amazing at photorealistic or animestyle images but not great for blackandwhite screentoned panels character consistency was a nightmaregenerating the same character across panels was nearly impossible these models are just too huge for consumer gpus there was no way i was running something like a b parameter model like flux on my setup so i decided to roll up my sleeves and train my own every image in this post was generated using the model i built what how why while im new to genai im not new to ml i spent some time catching upreading papers diving into opensource repos and trying to make sense of the firehose of new techniques its a lot but after some digging pixartsigma stood out it punches way above its weight and isnt a nightmare to run finetuning bigger models was out of budget so i committed to this one the big hurdle was character consistency i know the usual solution is to train a lora but honestly that felt a bit circularhow do i train a lora on a new character if i dont have enough images of that character yet and also i need to train a new lora for each new character no thank you i was inspired by diffsensei and arcface and ended up taking a different route i used embeddings from a pretrained manga character encoder as conditioning this means once i generate a character i can extract its embedding and generate more of that character without training anything just drop in the embedding and go with that solved i collected a dataset of million manga images and finetuned pixartsigma adding some modifications to allow conditioning on more than just text prompts the end result the result is a lightweight manga image generation model that runs smoothly on consumer gpus and can generate pretty decent blackandwhite manga art from text prompts i can specify the location of characters and speech bubbles provide reference images to get consistentlooking characters across panels keep the whole thing snappy without needing supercomputers you can play with it at or download the model weights and run it locally limitations so how well does it work overall character consistency is surprisingly solid especially for hair color and style facial structure etc but it still struggles with clothing consistency especially for detailed or unique outfits and other accessories simple outfits like school uniforms suits tshirts work best my suggestion is to design your characters to be simple but with different hair colors struggles with hands sigh while it can generate characters consistently it cannot generate the scenes consistently you generated a room and want the same room but in a different angle cant do it my hack has been to introduce the scenesetting once on a page and then transition to closeups of characters so that the background isnt visible or the central focus im sure scene consistency can be solved with imgimg or training a controlnet but i dont have any more money to spend on this various aspect ratios are supported but each panel has a fixed resolution pixels roadmap whats next theres still stuff to do model weights are opensource on hugging face i havent written proper usage instructions yetbut if you know how to use pixartsigmapipeline in diffusers youll be fine dont worry ill be writing full setup docs in the next couple of days so you can run it locally if anyone from comfy or other tooling ecosystems wants to integrate thisplease go ahead id love to see it in those pipelines but i dont know enough about them to help directly lastly i built drawatooncom so folks can test the model without downloading anything since im paying for the gpus out of pocket the server sleeps if no one is using itso the first image may take a minute or two while it spins up you get images for free i think this is enough for you to get a taste for whether its useful for you or not after that its like centsimage to keep things sustainable otherwise feel free to just download and run the model locally instead would love to hear your thoughts feedback and if you generate anything cool with itplease share,,,,,
1jwpgov,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 13:09:00,p building a classifier for time series forecasting hey everyone i want to build a classifier that can automatically select the best forecasting model for a given univariate time series based on which one results in the lowest mape mean absolute percentage error does anyone have suggestions or experience on how to approach this kind of problem i need this for a college project i dont seem to understand it can anyone point me in right direction i know arima lstm exponential smoothening are some models but how do i train a classifier that choose among them based on mape,,,,,
1jwp3iv,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 12:51:36,d anyone having experience working with grf google research football environment im basically facing severe issues while working with grf i was wondering if there was someone whos experienced and could guide me through them,,,,,
1jwg9fj,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 03:14:59,d dynamic patch weighting in vits has anyone explored weighting nonoverlapping patches in images using vits the weights would be part of learnable parameters for instance the background patches are sometimes useless for an image classification task i am hypothesising that including this as a part of image embedding might be adding noise it would be great if someone could point me to some relevant works,,,,,
1jw8d2x,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 20:47:07,d best sentiment analysis model for reddit hello all my first time posting im working on a sentiment analysis project focusing on reddit comments about a war conflict for this task ive been using three sentiment analysis tools vader textblob and distilbert however im facing a challenge as the outcomes from these three models often differ significantlythe dataset is quite large so manual verification of each comment isnt feasible id appreciate any advice on how to approach the issue of achieving the most accurate sentiment results should i consider combining the scores from these tools if so how could i account for the fact that each models scoring system functions differently alternatively would it make sense to rely on majority voting for sentiment labels eg choosing the sentiment that at least two out of three models agree on any other approaches or best practices that might work tia,,,,,
1jw79pp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 20:01:52,previewing parquet directly from the os discussion hi ive worked with parquet for years at this point and its my favorite format by far for data work nothing beats it it compresses super well fast as hell maintains a schema and doesnt corrupt data im looking at you excel csv but its impossible to view without some code cli super annoying especially if you need to peek at what youre doing before starting some analyse or frankly just debugging an output dataset this has been my biggest pet peeve for the last years of my life so ive fixed it haha the image below shows you how you can quick view a parquet file from directly within the operating system works across different apps that support previewing etc also no size limit because its a preview obviously i believe strongly that the data space has been neglected on the ui continuity front something that video for example doesnt face im planning on adding other formats commonly used in data science machine learning like partitioned directories this is pretty tricky hdf avro orc feather json lines duckdb db sqllite db formats above but directly from s gcs without going to the console any other format i should add let me know what you think,,,,,
1jw3fku,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 17:23:26,p d mcpuse an open source library that lets you connect llms to mcps from python in lines of code hello all ive been really excited to see the recent buzz around mcp and all the cool things people are building with it though the fact that you can use it only through desktop apps really seemed wrong and prevented me for trying most examples so i wrote a simple client then i wrapped into some class and i ended up creating a python package that abstracts some of the async uglyness you need one of those mcpconfig jsons lines of code and you can have an agent use the mcp tools from python like this the structure is simple an mcp client creates and manages the connection and instantiation if needed of the server and extracts the available tools the mcpagent reads the tools from the client converts them into callable objects gives access to them to an llm manages tool calls and responses its very earlystage and im sharing it here for feedback contributions and to share a resource that might be helpful for testing and playing around with mcps let me know what you think any suggestions repo pipy docs pip install mcpuse happy to answer questions or walk through examples thanks,,,,,
1jw3b9b,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 17:18:35,p b vs h benchmarks early tests show up to faster training throughput selfhosting cost analysis we at lightly ai recently got early access to nvidia b gpus in europe and ran some independent benchmarks comparing them against hs focusing on computer vision model training workloads we wanted to share the key results as they might be relevant for hardware planning and cost modeling tldr key findings training performance observed up to higher training throughput with the b compared to the h on the specific cv tasks we tested cost perspective selfhosted our analysis suggests selfhosted bs could offer significantly lower opexgpuhour compared to typical cloud h instances we found a potential range of xx cheaper detailsassumptions in the post this obviously depends heavily on utilization energy costs and amortization setup all tests were conducted on our own hardware cluster hosted at greenmountain a data center running on renewable energy the full blog post contains more details on the specific models trained batch sizes methodology performance charts and a breakdown of the cost considerations we thought these early realworld numbers comparing the new generation might be useful for the community happy to discuss the methodology results or our experience with the new hardware in the comments,,,,,
1jw28iw,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 16:33:40,d thoughts about icassp there were a lot of issues in visas so half of the poster boards were empty and in sessions i attended were just videos playing why visa issues are there in conferences i got my paper in cvpr but couldnt go because canadian government thought i would leave my phd and stay there i hope in future countries start to go easy on researchers,,,,,
1jw1i4b,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 16:02:50,p a slop forensics toolkit for llms computing overrepresented lexical profiles and inferring similarity trees releasing a few tools around llm slop overrepresented words phrases it uses stylometric analysis to surface repetitive words ngrams which occur more often in llm output compared to human writing also borrowing some bioinformatics tools to infer similarity trees from these slop profiles treating the presenceabsence of lexical features as mutations to infer relationships compute a slop profile of overrepresented words phrases for your model uses bioinformatics tools to infer similarity trees builds canonical slop phrase lists github repo notebook,,,,,
1jvz48g,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 14:21:40,d is research on discrete sampling mcmc useful in industry feeling unsure hi all im currently a nd year phd student in cs at a top school my research focuses on discrete sampling designing mcmcbased algorithms for inference and generation over discrete spaces while i find this area intellectually exciting and core to probabilistic machine learning im starting to worry about its industry relevance to be honest i dont see many companies actively hiring for roles that focus on sampling algorithms in discrete spaces meanwhile i see a lot of buzz and job openings around reinforcement learning bandits and active learning areas that my department unfortunately doesnt focus on this has left me feeling a bit anxious is discrete sampling considered valuable in the industry esp outside of research labs does it translate well to realworld mlai systems should i pivot toward something more applied or sexy like rl causality etc id love to hear from anyone working in industry or hiring phds is this line of work appreciated would love any advice or perspective thanks in advance,,,,,
1jvv7s8,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 11:06:07,p r d i built a biomedical gnn llm pipeline xplainmd for explainable multilink prediction hi everyone im an independent researcher and recently finished building xplainmd an endtoend explainable ai pipeline for biomedical knowledge graphs its designed to predict and explain multiple biomedical connections like drugdisease or genephenotype relationships using a blend of graph learning and large language models what it does uses rgcn for multirelational link prediction on primekgprecision medicine knowledge graph utilises gnnexplainer for model interpretability visualises subgraphs of model predictions with pyvis explains model predictions using llama b instruct for sanity check and natural language explanation deployed in an interactive gradio app why i built it i wanted to create something that goes beyond prediction and gives researchers a way to understand the why behind a models decisionespecially in sensitive fields like precision medicine tech stack pytorch geometric gnnexplainer llama gradio pyvis heres the full repo writeup github your feedback is highly appreciated psthis is my first time working with graph theory and my knowledge and experience is very limited but i am eager to learn moving forward and i have a lot to optimise in this project but through this project i wanted to demonstrate the beauty of graphs and how it can be used to redefine healthcare,,,,,
1jvrk68,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 06:44:27,d yann lecun autoregressive llms are doomed yann lecun at josiah willard gibbs lecture not sure who else agrees but i think yann lecun raises an interesting point here curious to hear other opinions on this lecture link,,,,,
1jvndi5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 02:25:31,p flexchunk mm outofcore spmv in min on cpu gb ram developed a new algorithm flexchunk a chunkbased outofcore spmv approach that multipliesmm sparse matrices on cpu in minutes using only gb ram nearlinear scaling works on regular hardware zero dependencies full demo benchmarks idea processing sparse matrices by localityaware adaptive chunking with minimal memory usage and predictable performance demo hugging face code github article lesswrong struggling to get feedback any ideas where projects like this are best shared or feedback on the approach itself is very welcome thanks,,,,,
1jva1nc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 16:29:04,r exploring a primebased d grid system as an experimental ai architecture feedback welcome hi everyone ive been working on a conceptual ai architecture inspired by prime number behavior in a d grid structure by layering vertical patterns based on numerical spacing we create a grid that filters and stores values based on primerelated behavior this enables probabilistic deduction filtering logic memorylike data handling multilayered processing potential the idea is to treat numbers not just as values but as containers with mathematical and behavioral propertiesusable in logic memory and even emotional representation in future ai systems its an earlystage white paper but id love your thoughts what do you think about using mathematical pattern grids like this as a foundation for alternative ai logic beyond traditional neural networks looking forward to hearing your feedback and ideas,,,,,
1jv89f5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 15:15:39,d cvpr registration whats my paper number they ask for a paper number in the cvpr registration website and i am not sure which one it is is it the submission id in openreview or is it the number in the cvpr list of accepted papers url to my paper thanks,,,,,
1jv80y4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 15:06:08,d has anyone trained llm on gcp how long did you wait for h approval how long did you guys wait for the quota increase approval for the h gb gpus i need to use h gb gpus for the llama maverick requested today and still waiting wondering because for lower amounts on different gpus the approval was almost instant,,,,,
1jv2zxc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 11:01:08,d how do you monitor your ai agents or llm apps im curious how others are monitoring and tracking llmbased apps or ai agents especially as they get more complex with rag tool use or user input do you track things like token usage latency error rates prompt version changes or any other performancecostrelated metrics do you use a tool for this or is it mostly something youve built yourself would love to hear whats worked or not for you even lightweight solutions or pain points,,,,,
1juxjwk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 04:35:52,p yinyang classification i have been messing around yinyang data classification and threw it together in a repo link please do comment your thought and any suggestion on what else might be interesting to visualize here and feel free to star the repo if its interesting helpful,,,,,
1jurarc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 23:06:39,p reducing transformer training time without sacrificing accuracy a dynamic architecture update approach hey everyone ive been working on a research project focused on optimizing transformer models to reduce training time without compromising accuracy through this work i developed a novel method where the model dynamically updates its architecture during training allowing it to converge faster while still maintaining performance think of it like adaptive scaling but smarter were not just reducing size arbitrarily were making informed structural updates on the fly i recently published a medium article explaining one part of the approach how i managed to keep the models accuracy stable even after reducing the training time if youre interested in the technical details or just want to nerd out on optimization strategies id love for you to check it out medium article github repo would love feedback ideas or even collaborators feel free to open a pr or drop your thoughts always happy to discuss,,,,,
1jukunq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 18:30:52,d how to handle questions about parts of a collaborative research project i didnt directly work on during a poster session presentation im presenting research where i focused on experimental resultscodebase but our paper includes theoretical work by collaborators how do i answer questions about parts i didnt handle is it okay to say this aspect was led by namei can explain how it connects to my experiments how detailed should i be about others contributions what phrases do you use to redirect to your expertise without sounding dismissive,,,,,
1jui5tm,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 16:43:26,p firstorder motion transfer in keras animate a static image from a driving video tldr implemented firstorder motion transfer in keras siarohin et al neurips to animate static images using driving videos built a custom flow map warping module since keras lacks native support for normalized flowbased deformation works well on tensorflow code docs and demo here ________________________________________ hey folks ive been working on implementing motion transfer in keras inspired by the first order motion model for image animation siarohin et al neurips the idea is simple but powerful take a static image and animate it using motion extracted from a reference video the tricky part keras doesnt really have support for deforming images using normalized flow maps like pytorchs grid_sample the closest is kerasopsimagemap_coordinates but it doesnt work well inside models no batching absolute coordinates cpu only so i built a custom flow warping module for keras supports batching works with normalized coordinates gpucompatible can be used as part of a dl model to learn flow maps and deform images in parallel project includes keypoint detection and motion estimation generator with firstorder motion approximation ganbased training pipeline example notebook to get started still experimental but works well on tensorflow backend repo docs try exampleipynb for a quick demo would love feedback ideas or contributions and happy to collab if anyones working on similar stuff,,,,,
1juft4t,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 15:06:02,d synthetic introduction to ml for phd student in mathematics hi all im a about to begin my phd in mathematics and my supervisor current project is to investigate the feasibility of some niche linear algebra tools to the setting of machine learning especially pinns i am already very familiar with such niche linear algebra results however i lack any knowledge of ml moreover i have some knowledge of measure theory calculus of probabilities and statistics i skimmed through bishopss pattern recognition and goodfellowss deep learning and i have found both books to be excessively redundant and verbose i do appreciate the abundance of examples and the maieutic approach of these books however i need to get a theoretical grasp on the subject i am looking for an alternative resources on the subject written with mathematical rigour targeted at graduate students do you have anything to suggest be it books lecture notes or video lectures,,,,,
1judb8u,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 13:16:44,p insights in shift of performance of certain llms on different hardware hello all for school i conducted some simple performance tests an a couple of llms one on a desktop with a rtx and the other on a raspberry pi i am trying to make sense of the data but still have a couple of questions as i am not an expert on the theory in this field on the desktop llamab did way better than any other model i tested but when i tested the same models on the same prompts on the raspberry pi it came second and i have no idea why another question i have is why the results of granitemoe are so spread out compared to the other models is this just because it is an moe model and it depends on which part of the model it activates all of the models i tested were small enough to fit in the gb of vram of the and the gb of system ram of the pi any insights on this are appreciated below are the boxplots to give a clearer view of the data,,,,,
1juay0t,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 11:09:57,d comparing genai inference engines tensorrtllm vllm hugging face tgi and lmdeploy hey everyone ive been diving into the world of generative ai inference engines for quite some time at nlp cloud and i wanted to share some insights from a comparison i put together i looked at four popular optionsnvidias tensorrtllm vllm hugging faces text generation inference tgi and lmdeployand ran some benchmarks to see how they stack up for realworld use cases thought this might spark some discussion here since i know a lot of you are working with llms or optimizing inference pipelines tensorrtllm nvidias beast for gpuaccelerated inference built on tensorrt it optimizes models with layer fusion precision tuning fp int even fp and custom cuda kernels pros blazing fast on nvidia gpusthink subms latency for single requests on an a and tokenssec at concurrent users for llama b q per bentoml benchmarks dynamic batching and tight integration with triton inference server make it a throughput monster cons setup can be complex if youre not already in the nvidia ecosystem you need to deal with model compilation and its not super flexible for quick prototyping vllm opensource champion for highthroughput inference uses pagedattention to manage kv caches in chunks cutting memory waste and boosting speed pros easy to spin up pip install pythonfriendly and its flexibleruns on nvidia amd even cpu throughput is solid tokenssec at users for llama b q and dynamic batching keeps it humming latencys decent at ms solo cons its less optimized for singlerequest latency so if youre building a chatbot with one user at a time it might not shine as much also its still maturingsome edge cases like exotic model architectures might not be supported hugging face tgi hugging faces productionready inference tool ties into their model hub bert gpt etc and uses rust for speed with continuous batching to keep gpus busy pros docker setup is quick and it scales well latencys ms throughput matches vllm tokenssec at users bonus builtin output filtering for safety perfect if youre already in the hf ecosystem cons less raw speed than tensorrtllm and memory can bloat with big batches feels a bit restrictive outside hfs world lmdeploy this toolkit from the mmrazormmdeploy crew focused on fast efficient llm deployment features turbomind a highperformance engine and a pytorch fallback with persistent batching and blocked kv caching for speed pros decoding speed is nutsup to x more requestssec than vllm on an a turbomind pushes bit inference x faster than fp hitting tokenssec at users llama b q low latency ms easy onecommand server setup and it even handles multiround chats efficiently by caching history cons turbominds pickydoesnt support sliding window attention eg mistral yet nonnvidia users get stuck with the slower pytorch engine still on nvidia gpus its a performance beast you can read the full comparison here whats your experience with these tools any hidden issues i missed or are there other inference engines that should be mentioned would love to hear your thoughts julien,,,,,
1ju8923,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 07:57:25,r beyond the next token towards promptrobust zeroshot classification via efficient multitoken prediction zeroshot text classification typically relies on prompt engineering but the inherent prompt brittleness of large language models under mines its reliability minor changes in prompt can cause significant discrepancies in model performance we attribute this prompt brittleness largely to the narrow focus on next token probabilities in existing methods to address this we propose placeholding parallel prediction p a novel approach that predicts token probabilities across multiple positions and simulates comprehensive sampling of generation paths in a single run of a language model experiments show improved accuracy and up to reduction in the standard devia tion across prompts boosting robustness even without a prompt p maintains comparable performance reducing the need for prompt engineering interesting paper on improving determinism in ml models and avoid prompt brittleness using placeholders and parallel predictions instead of relying solely on nexttoken probabilities paper link,,,,,
1ju5g9d,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 04:42:18,d a regression head for llm works surprisingly well i have been training a small m vitdecoder model i have written for visual grounding tasks and when training from scratch i had great success by introducing a regresion head to the embeds before lm head to gain great accuracy all the literature such as i could find directly works with particular tokens and cross entropy loss from what i gathered i had this success for a personal project by jointly doing cross entropy on lm_head results for point tokens and introducing a regression head on the last embed layer and doing regression loss i just cooked it up originally but is this known,,,,,
1ju0wko,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 00:36:13,d if a method used pretrained model like owlvit v there is no way to know if these models has been trained on the validation set of a downstream task how people solve these problems could i still publish a paper for my results,,,,,
1jtwusn,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 21:27:53,research evaluating your retrieval system new research from chroma on generative benchmarking hi all im jeff cofounder of chroma were working to make ai application development more like engineering and less like alchemy today we are introducing representative generative benchmarkingcustom evaluation sets built from your own data and reflective of the queries users actually make in production these benchmarks are designed to test retrieval systems under similar conditions they face in production rather than relying on artificial or generic datasets benchmarking is essential for evaluating ai systems especially in tasks like document retrieval where outputs are probabilistic and highly contextdependent however widely used benchmarks like mteb are often overly clean generic and in many cases have been memorized by the embedding models during training we show that strong results on public benchmarks can fail to generalize to production settings and we present a generation method that produces realistic queries representative of actual user queries check out our technical report here,,,,,
1jtwdn8,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 21:07:25,p d why does my gnnlstm model fail to generalize with full training data for a spatiotemporal prediction task im working on a spatiotemporal prediction problem where i want to forecast a scalar value per spatial node over time my data spans multiple spatial grid locations with daily observations data setup the spatial region is divided into subregions each with a graph structure each node represents a grid cell with input features variable_value_t lat lon edges are static for a subregion and are formed based on distance and correlation edge features include direction and distance each subregion is normalized independently using zscore normalization meanstd from training split model class gnnlayernnmodule def __init__self node_in_dim edge_in_dim hidden_dim selfattention nnmultiheadattentionembed_dimhidden_dim num_heads batch_firsttrue def forwardself x edge_index edge_attr row col edge_index src tgt xrow xcol edge_messages selfedge_netedge_attr src tgt agg_msg torchzeros_likexindex_add col edge_messages x_updated selfnode_netx agg_msg attn_out _ selfattentionx_updatedunsqueeze x_updatedunsqueeze x_updatedunsqueeze return x_updated attn_outsqueeze edge_messages class gnnlstmnnmodule def __init__self selfgnn_layers nnmodulelist selflstm nnlstminput_sizehidden_dim hidden_size num_layers dropout batch_firsttrue selfpred_head nnsequential nnlinear nnleakyrelu nnlinear pred_len def forwardself batch for t in ranget x_t graphx batched node features for gnn in selfgnn_layers x_t _ gnnx_t graphedge_index graphedge_attr x_stackappendx_t x_seq torchstackx_stack dim b t n hidden_dim lstm_out _ selflstmx_seqreshapebn t out selfpred_headlstm_out viewb n mean logvar out out return mean torchexplogvar e training details loss mse loss optimizer adam lr e scheduler reducelronplateau persubregion training each subregion is trained independently i also tried using curriculum learning start with batches and increase gradually each epoch until the full training set is used i have batches in total in the train split issue when trained on a small number of batches the model converges and gives reasonable results however when trained on the full dataset the model shows inconsistent or worsening validation loss after a few epochs seems to rely too much on the lstm eg lstmweight_hh_ has much higher parameter updates than gnn layers keeps predicting poorly on the same few grid cells over time ive tried increasing gnn depth currently layers gradient clipping attention residuals layer norm in gnn what could cause the gnnlstm model to fail generalization with full training data despite success with smaller subsets i am at my wits end this was for a sanity check i trained on batches and validated on update hi everybody thank you so much for your help and insights i think i figured out what was going wrong i think my edge creation thresholds were too weak and i tightened them and reduced my model complexity thanks to uben___pen and utyreadin i also increased my dataset size and training epochs this is what i am achieving test metrics for one subregion mse rmse mae r² i will further refine my steps as i go once again thank you all everyone is so kind and helpful,,,,,
1jtoegy,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 15:44:24,d hai artificial intelligence index report the ai race has gotten crowdedand china is closing in on the us stanford universitys institute for humancentered ai hai published a new research paper today which highlighted just how crowded the field has become hai artificial intelligence index report main takeaways ai performance on demanding benchmarks continues to improve ai is increasingly embedded in everyday life business is all in on ai fueling record investment and usage as research continues to show strong productivity impacts the us still leads in producing top ai modelsbut china is closing the performance gap the responsible ai ecosystem evolvesunevenly global ai optimism is risingbut deep regional divides remain ai becomes more efficient affordable and accessible governments are stepping up on aiwith regulation and investment ai and computer science education is expandingbut gaps in access and readiness persist industry is racing ahead in aibut the frontier is tightening ai earns top honors for its impact on science complex reasoning remains a challenge,,,,,
1jtmk36,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 14:27:28,r dataset with medical notes working on dataextraction tools for medical notes like notes physicians write after consultation is there any publicly available dataset i can use for validation i have looked at mimic datasets which seems interesting but not sure whether i will be able to access it representing a healthtech company pmc patients and clinical visit note summarization corpus from microsoft seems good but are not super representative for the use case i am looking for,,,,,
1jtjw2b,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 12:20:48,p docext opensource onprem document intelligence powered by visionlanguage models were excited to open source docext a zeroocr onpremises tool for extracting structured data from documents like invoices passports and more no cloud no external apis no ocr engines required powered entirely by visionlanguage models vlms docext understands documents visually and semantically to extract both field data and tables directly from document images run it fully onprem for complete data privacy and control key features custom prebuilt extraction templates table field data extraction gradiopowered web interface onprem deployment with rest api multipage document support confidence scores for extracted fields whether youre processing invoices id documents or any formheavy paperwork docext helps you turn them into usable data in minutes try it out pip install docext or launch via docker spin up the web ui with python m docextappapp dive into the colab demo github questions feature requests open an issue or start a discussion,,,,,
1jtfhwo,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 07:21:05,r deep learning hits sota in cancer mutation detection nature communications varnet is an endtoend deep learning framework trained on hundreds of whole cancer genomes to detect somatic variants with high accuracy no handtuned heuristics published in nature communications it achieves stateoftheart performance across multiple benchmarks paper code,,,,,
1jsw3ey,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 15:01:28,r d harmonic clustering a new approach to uncover music listener groups need feedbackreview i recently completed a project called harmonic clustering where we use network science and community detection to uncover natural music listener groups from large scale streaming data the twist is we moved away from traditional clustering and came up with a new approach that builds temporal user user graphs based on overlapping playlists and then applies multiple community detection algorithms like louvain label propagation and infomap we compared different methods analyzed community purity and visualized the results through clean interactive graphs and this approach turned out to be more robust than the earlier ones we tried the main notebook walks through the full pipeline and the repo includes cleaned datasets preprocessing graph generation detection evaluation and visualizations repo link we are currently writing a paper on this and would love to hear thoughts from people here feel free to try it on your own dataset fork it or drop suggestions we are open to collaborations too,,,,,
1jt9r7u,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 01:26:01,r uniformly distributed deep feature representations improve fairness robustness tmlr tldr theoretically and empircally demonstrates that encouraging deep feature represenatations to be uniformly distributed improves fairness and robustness specifically subgroup robustness and domain generalization paper with code,,,,,
1jt77na,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 23:13:37,d scanning the openai cookbook for vulnerabilities with opensource ,,,,,
1jt4pqr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 21:15:03,r seedlm compressing llm weights into seeds of pseudorandom generators ,,,,,
1jszd7k,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 17:24:30,d everyday examples of nonlinearly separable problems im trying to think of examples that help to intuitively understand the concept of nonlinearly separable problems for example determining if two inputs are equal is one such problem but im hoping for something less abstract than that something that students do themselves without realising,,,,,
1jswwj2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 15:37:21,project ml model for predicting demographic trends or anomalies seeking guidance on model selection validation and insights im working on a project that involves building a geospatial analytics system with the following components data mining scrape and parse city state county and zipcode data from us census quickfacts database cache load data into postgresql with postgis set up caching with redis geospatial visualization use mapbox or leafletjs for interactive maps showing boundaries and demographic details geospatial queries backend apis for geofiltering and polygon queries eg nearby cities demographic trends over time deployment docker or kubernetes for containerization ml task integrate an ml model to predict demographic trends or anomalies based on the mined data has anyone implemented something similar or have suggestions for how to approach the ml integration especially the model selection validation and insights,,,,,
1jswn5k,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 15:25:58,r image classification by evolving bytecode over the last few years ive been working on zyme an esoteric language for genetic programming creating computer programs by means of natural selection ive started seeing promising results showing that random bytecode mutations can over time lead to measurable improvements in program performance while still a long way from stateoftheart approaches like neural networks i wanted to share my progress feedback and criticism are welcome,,,,,
1jsuyxh,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 14:09:57,d how to handle limited space in ram when training in google colab hello i am currently trying to solve the ieeecis fraud detection competition on kaggle and i have made myself a google colab notebook where i am working with the data the issue i have is that that while the dataset can just barely fit into memory when i load it into pandas when i try to do something else with it like data imputation or training a model the notebook often crashes due to running out of ram ive already upgrade to colab pro and this gives me gb of ram which helps but still sometimes is not enough i wonder if anyone could suggest a better method maybe theres some way i could stream the data in from storage bit by bit alternatively is there a better place for me to be working than colab my local machine does not have the juice for fast training of models but i also am financing this myself so the price on colab pro is working alright for me euros a month but i would be willing to consider paying more if theres somewhere better to host my notebooks,,,,,
1jss0lu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 11:29:40,dijcai reviews and rebuttal discussion thread for discussion,,,,,
1jslkhw,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 04:01:49,d rich sutton selfverification the key to ai ,,,,,
1jsft3c,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 22:46:20,r noprop training neural networks without backpropagation or forwardpropagation abstract the canonical deep learning approach for learning requires computing a gradient term at each layer by backpropagating the error signal from the output towards each learnable parameter given the stacked structure of neural networks where each layer builds on the representation of the layer be low this approach leads to hierarchical representations more abstract features live on the top layers of the model while features on lower layers are expected to be less abstract in contrast to this we introduce a new learning method named noprop which does not rely on either forward or back wards propagation instead noprop takes inspiration from diffusion and flow matching methods where each layer independently learns to denoise a noisy target we believe this work takes a first step towards introducing a new family of gradientfree learning methods that does not learn hierar chical representations at least not in the usual sense noprop needs to fix the representation at each layer beforehand to a noised version of the target learning a local denoising process that can then be exploited at inference we demonstrate the effectiveness of our method on mnist cifar and cifar image classification benchmarks our results show that noprop is a viable learn ing algorithm which achieves superior accuracy is easier to use and computationally more efficient compared to other existing backpropagationfree methods by departing from the traditional gra dient based learning paradigm noprop alters how credit assignment is done within the network enabling more efficient distributed learning as well as potentially impacting other characteristics of the learning process,,,,,
1jsclxw,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 20:18:56,p anyone working on arabic ocr all the ocrs i tried for arabic dont work well at all im really interested in working on building a proper arabic ocr if you know anyone working on it or any open projects please let me know id love to contribute and help improve it,,,,,
1jsbbuy,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 19:22:16,n llama release llama elo score vs cost,,,,,
1js6jd9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 15:53:35,discussion this might be a really dumb question regarding current training method so why cant we train a very large network at low quantization get the lowest test error possible prune the network at the lowest test error epoch and then increase the quantization or the remaining parameters to start the training wouldnt this allow overcoming getting stuck at the local minima more effectively,,,,,
1js2ro5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 12:53:02,d icassp hi there will be attending icassp this year was wondering if there are folks from the community attending the conference as well probably we can catch up sometime ps has already reached the venue,,,,,
1js1ucr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 11:59:32,d icml what if reviewers dont acknowledge rebuttal out of my reviewers at icml didnt acknowledge my rebuttal at all not only no answer they also didnt even click the acknowledge rebuttal at all according to icml rules they are required to do that what happens when they dont should we report this to ac i didnt find this anywhere so maybe someone here knows or is in a similar situation,,,,,
1js0tvk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 10:54:34,d are domain adversarial neural networks dann used in real world scenarios is there anything out there that works i find the idea presented in that paper very attractive being able to train on one controlled domain for which it is easy to label data and transfer it to another domain which can be quite hard to label the data for be it syntheticgenerated data to real data or office captured data to in the wild data theres some real value in being able to successfully capturing a domain without labels does anyone have some experience with this issue it sounds too good to be true its also not as well known as id expect for something so useful which raises another flag,,,,,
1jrjmyp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 18:56:20,r can we learn with fewer parameters than an mlp answer yes stftkan arxiv github,,,,,
1jrkbny,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 19:25:11,d better data batching causes slower computing for my research i am running some llms on a middleend desktop gpu i figured that batching the matrices is generally not a bad idea at best it would make more things run in parallel and might cut some overhead that i missed at worst i wouldnt lose anything and i wrote algorithms so that they batch all data for gpu computing that they can then i fiddled with batch sizes and found that apparently the shorter each batch is the faster the whole dataset is processed this fact holds the whole range from effectively no batching from minimal reasonable batching to maximum vram utilization and this is very noticable the difference in speed between extremes is almost times upd actually looks like total absense of batching does slow down computing compared to very small batches for some algorithms at least there is some explanation for that i am very confused and frustrated from apparently having wasted time i could only think of unnesseccary data copies being done somewhere but by this point i am pretty sure it doesnt happen to the hefty matrices the gpu is nvidia rtx used via cuda i havent had prior experience with gpu computing i believe this is the most appropriate sub for this post,,,,,
1jrn64e,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 21:26:20,r do you include blank ground truth masks in mri segmentation evaluation so i am currently working on a unet model that does mri segmentation there are about of the test dataset currently that include blank ground truth masks near the top and bottom part of the target structure the evaluation changes drastically based on whether i include these blankgroundtruthmask mri slices i read for brats they do include them for brain tumor segmentation and penalize any false positives with a dice score what is the common approach for research papers when it comes to evaluation is the brats approach the universal approach or do you just exclude all blank ground truth mask slices near the target structure when evaluating,,,,,
1jrxq16,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 07:05:14,r improving generalist reward models with selfprincipled critique tuning and inferencetime scaling deepseeks new reward modeling approach uses inferencetime scaling to significantly outperform existing systems their deepseek generalist reward model grm introduces selfprincipled critique tuning which generates evaluation principles specific to each task before critiquing responses key technical contributions selfprincipled critique tuning spct adaptation of online rlhf where the model generates principles relevant to each query before critiquing inferencetime scaling through parallel sampling and metareward model voting pointwise generative reward modeling that improves over pairwise approaches a novel metareward model that evaluates and combines multiple evaluations to select the best one main results outperforms other reward models claude gpt on mtbench and alpacaeval shows significant gains through inferencetime scaling more samples better results effectively handles a diverse range of tasks without developing severe biases demonstrates that inferencetime scaling can be more effective than scaling model size i think this approach represents an important shift in how we think about scaling ai capabilities rather than focusing exclusively on larger models and more training data we could achieve better results through smarter use of compute during inference this could potentially democratize access to highquality ai by making it possible to get frontierlevel results without enormous training budgets the principlesfirst approach also seems like it could help with interpretability and alignment by explicitly generating evaluation criteria before making judgments the model provides more transparency about its decisionmaking process tldr deepseekgrm uses a novel approach where the model first generates taskspecific principles then critiques responses based on those principles combined with inferencetime scaling through parallel sampling this achieves stateoftheart results across multiple benchmarks their work suggests we might get more bang for our computational buck by scaling inference rather than training full summary is here paper here,,,,,
1jrxh39,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 06:48:45,kdd cycle reviews are out hi everyone kdd paper reviews are visible on openreview with the reviews released i thought i would create a discussion thread to gather thoughts questions and recommendations or anything else would love to hear other peoples thoughts on the rating scheme wishing everyone the best,,,,,
1jrwqa0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 05:58:00,r novel logicenhanced llm for improved symbolic reasoning im experimenting with a novel approach that integrates symbolic logic directly into a transformers attention mechanism by using a custom spacybased logic parser i generate a logic mask that guides the selfattention layers to focus on logical constructs in preliminary tests with a finetuned llama b model this method has shown promising improvements on symbolic reasoning tasks eg achieving around on the folio dataset im eager to hear thoughts and suggestions from the community on further refining this approach also please note i dont have a phd nor masters in machine learning happy to take any criticism good or bad,,,,,
1jrjjpd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 18:52:30,dhow graphrag helps ai tools understand documents better and why it matters if youve ever tried using ai to help you quickly read through complex documents youve probably used retrievalaugmented generation or rag rag tools are good at answering specific detailed questions from large documents but they often struggle if you ask broader questions especially ones requiring connections between ideas across the entire document to tackle this researchers recently developed something called graphrag in the following sections i will introduce the key ideas behind graphrag focusing on what makes it different from traditional rag approaches and why those differences matter to ground this explanation ill use insights from the research paper from local to global a graph rag approach to queryfocused summarization arxivv which served as both the foundation for my exploration and the first test case i used with deeptutor a graphragpowered reading assistant ive been helping build what makes graphrag different traditional rag looks for answers by pulling relevant bits of information based on keyword or topic similarity graphrag goes further it first organizes the entire document into a structured knowledge graph think of it as a detailed map showing how key ideas and entities like people places and concepts relate to one another this structure helps ai see the bigger picture and answer more complex questions accurately and clearly because it understands context and relationships rather than isolated facts trying out graphrag with deeptutor i used deeptutor a new ai tool built using graphrag for paperreading to help read the original research paper introducing graphrag itself paper link it was a great test case using the tool to explain its own technology here are some examples of how deeptutor handled my questions about the paper q whats the key innovation behind graphrag compared to traditional rag methods deeptutors response graphrag introduces several key innovations that distinguish it from traditional retrievalaugmented generation rag methods graphbased knowledge representationgraphrag constructs a knowledge graph to model entities and their relationships enabling structured relational understanding of data this contrasts with traditional rag systems which often rely on less organized data representations limiting their ability to capture complex connections integration of advanced ai models graphrag can be used with advanced generative models such as gpt to improve output quality though graphrag itself is modelagnostic community detection algorithmsgraphrag employs these algorithms to identify clusters and relationships within data enabling deeper insights for summarization and analysisa feature absent in conventional rag systems structured sensemaking by organizing data into a graph graphrag supports better sensemaking over large text corpora addressing a gap in traditional methods that struggle with unstructured or fragmented data analysis these innovations collectively improve efficiency accuracy and analytical depth positioning graphrag as a significant evolution in retrievalaugmented generation q how does graphrag handle broader bigpicture questions differently deeptutors response heres a concise analysis of how graphrag handles bigpicture questions differently organized for clarity graphrags approach to highlevel questions structural understanding through knowledge graphs creates entityrelationship maps to reveal hidden patterns and thematic connections traditional methods limited to linear text relationships in retrieved passages hierarchical community detection uses algorithms to identify topic clusters discover indirect relationships create multilevel abstractions traditional rag lacks this layered analysis capability mapreduce synthesis combines insights through local analysis individual communities global synthesis crosscommunity patterns enables answers that balance depth and breadth adaptive context windowing dynamically adjusts context scope based on question complexity community hierarchy level interconnection density traditional methods use fixed context windows claimbased evaluation measures answer quality through comprehensiveness avg claimsanswer vs in vector rag diversity x more unique claim clusters ensures coverage of multiple perspectives key differentiator graphrags graphindexed worldview enables emergent understanding of latent patterns that no single document contains while traditional methods remain constrained to explicit content in retrieved passages q could you summarize the main findings of this graphrag study deeptutors response heres a concise breakdown of graphrags key advantages and performance results compared to traditional methods based on the studys findings structural superiority knowledge graph architecture captures entity relationships eg company supplier environmental impact traditional rag limited to direct text similarity between documents enhanced analytical capabilities more comprehensive answers extracted claimsanswer vs vector rags experiment greater diversity produced claim clusters vs from vector rag multiscale understanding hierarchical community detection identifies nested themes eg esg risks environmental carbon emissions traditional methods treat documents as isolated chunks inclusive synthesis mapreduce processing preserves minority viewpoints eg rare safety incidents in manufacturing data vector rag prone to majority pattern dominance adaptive precision corpusspecific benchmarking generates tailored evaluation metrics for each dataset outperformed baseline by on domainspecific queries strategic decision support enabled identification of crossdomain relationships eg governance failures environmental risks emerging patterns through community evolution analysis validation used llmasjudge evaluation with agreement rate on answer quality metrics confirmed through human validation studies this structural approach to knowledge representation and analysis gives graphrag unique capabilities for strategic analysis tasks where understanding context and relationships is critical in each answer deeptutor directly highlighted where in the paper the answer was drawn from which helped me quickly confirm accuracy and context why does this matter my experience made it clear that graphrag significantly improves how ai understands and presents information from documents it provides more comprehensive answers because it considers the whole document rather than isolated pieces its easier to trust as each response clearly references where in the document the answer came from it naturally shows connections between ideas helping users quickly understand complicated topics after using graphrag firsthand with deeptutor i genuinely felt it provided meaningful improvements over traditional ai documentreading tools have you faced similar challenges with ai tools have you tried graphrag or similar approaches yet let me know your thoughts id love to discuss this further,,,,,
1jribqw,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 18:01:07,r how do large language monkeys get their power laws ,,,,,
1jrd9tc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 14:29:54,r mitigating realworld distribution shifts in the fourier domain tmlr tldr do unsupervised domain adaption by simply matching the frequency statistics of train and test domain samples no labels needed works for vision audio timeseries paper with code,,,,,
1jratgd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 12:36:31,p looking for nlp approaches to extract machinereadable rules from building regulations hey everyone im working on a project and could use some help im trying to build a system that reads building codes like german din standards and converts them into a machinereadable format so i can automatically check bim models for code compliance i found a paper that does something similar automated code compliance checking based on bim and knowledge graph they use nlp with crf models to extract entities attributes and relationships a knowledge graph built in neoj bim models converted from ifc to rdf sparql queries to check if the model follows the rules the problem im facing is i cant find any pretrained nlp models for construction codes or technicallegal standards annotated datasets to train one even general regulationlegal text would help tools that help turn these kinds of regulations into structured machinereadable rules ive already got access to the regulations and scraped a bunch but im stuck on how to actually extract the logic or rules from the text if anyone has worked on something similar or knows of useful datasets tools or approaches id really appreciate it thanks in advance,,,,,
1jr8klg,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 10:23:19,what is your practical ner named entity recognition approach p hi all im working on a flutter app that scans food products using ocr google ml kit to extract text from an image recognizes the language and translate it to english this works the next challenge is however structuring the extracted text into meaningful parts so for example title nutrition facts brand etc the goal would be to extract those and automatically fill the form for a user right now i use rulebased parsing regex keywords like calories but its unreliable for unstructured text and gives messy results i really like the google ml kit that is offline so no internet and no subscriptions or calls to an external company i thought of a few potential approaches for extracting this structured text pure regexrulebased parsing simple but fails with unstructured text so maybe not the best solution make my own model and train it to perform ner named entity recognition one thing i have never trained any model and am a noob in this ai ml thing external apis google cloud nlp witai etc but this i really would prefer to avoid to save costs which method would you recommend i am sure i maybe miss some approach and would love to hear how you all tackle similar problems i am willing to spend time btw into aiml but of course im looking to spend my time efficient any reference or info is highly appreciated,,,,,
1jr6xwi,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 08:24:16,r scaling languagefree visual representation learning new paper from fairnyu pure selfsupervised learning such as dino can beat clipstyle supervised methods on image recognition tasks because the performance scales well with architecture size and dataset size,,,,,
1jr6iqj,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 07:52:34,r anthropic reasoning models dont always say what they think chainofthought cot offers a potential boon for ai safety as it allows monitoring a models cot to try to understand its intentions and reasoning processes however the effectiveness of such monitoring hinges on cots faithfully representing models actual reasoning processes we evaluate cot faithfulness of stateoftheart reasoning models across reasoning hints presented in the prompts and find for most settings and models tested cots reveal their usage of hints in at least of examples where they use the hint but the reveal rate is often below outcomebased reinforcement learning initially improves faithfulness but plateaus without saturating and when reinforcement learning increases how frequently hints are used reward hacking the propensity to verbalize them does not increase even without training against a cot monitor these results suggest that cot mon itoring is a promising way of noticing undesired behaviors during training and evaluations but that it is not sufficient to rule them out they also suggest that in settings like ours where cot reasoning is not necessary testtime monitoring of cots is unlikely to reliably catch rare and catastrophic unexpected behaviors another paper about ai alignment from anthropic has a pdf version this time around that seems to point out how reasoning models that use cot seem to lie to users very interesting paper paper link reasoning_models_paperpdf,,,,,
1jr68a2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 07:30:53,p simplerfaster data domains to benchmark transformers on when experimenting does anyone have any recommendations on simple datasets and domains that work well for benchmarking the efficacy of modified transformers language models require too much training to produce legible results and so contrasting a poorly trained language model to another poorly trained language model can give misleading or conterintuitive results that may not actually reflect real world performance when trained at a scale where the language model is producing useful predictions so im trying to find a simpler lower dimensional data domain that a transformer can excel at very quickly so i can iterate quickly,,,,,
1jqznzl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 01:07:47,r introducing cairn a humanai collaboration standard to build trust in generative ai were introducing cairn a metadata standard for tracking human and ai collaboration in generative workflows cairn helps record who wrote the prompt what the ai responded who reviewed it what sources were cited who approved the final artifact it supports transparency traceability and auditability aligning with the eu ai act isoiec and wc provo medium overview github wed love community feedback especially from those working on governance ml tooling and model oversight happy to answer any questions,,,,,
1jqyf03,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 00:06:15,rstruggling to pick the right xai method for cnn in medical imaging hey everyone im working on my thesis about using explainable ai xai for pneumonia detection with cnns the goal is to make model predictions more transparent and trustworthyespecially for cliniciansby showing why a chest xray is classified as pneumonia or not im currently exploring different xai methods like gradcam lime and shap but im struggling to decide which one best explains my models decisions would love to hear your thoughts or experiences with xai in medical imaging any suggestions or insights would be super helpful,,,,,
1jqutxu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 21:29:17,p how to predict road accidents using realtime data looking for advice hi everyone im currently working on a project to estimate highrisk accident zones using ai and realtime data my goal was to predict the exact location of future accidents but i found out that this is not possible so now i am trying to predict the zones where accidents could happen data sources im using weather conditions openweather api traffic data tomtom traffic api road infrastructure openstreetmap osm the challenge i couldnt find a moroccan accident dataset to train my model as an alternative im using the us accidents dataset to train the model however im aware that this may introduce biases since the model would be trained on us accident patterns instead of moroccan ones my questions to the community has anyone worked on a similar project what approach did you take what techniquesmodels would you recommend for estimating highrisk accident zones using realtime traffic weather and road infrastructure data are there better ways to generate a synthetic dataset or transfer learning techniques for this type of problem im open to any insights or recommendations thanks in advance,,,,,
1jqqlxc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 18:46:04,n opendata reasoning model trained on curated supervised finetuning sft dataset outperforms deepseekr big win for the open source community open thoughts initiative was announced in late january with the goal of surpassing deepseeks b model and releasing the associated training data something deepseek had not done previously team had released the openthoughtsk dataset which was used to train the openthinkerb model that closely matched the performance of deepseekb today they have achieved their objective with the release of openthinkerb a model that outperforms deepseekb they are opensourcing million highquality sft examples used in its training the earlier k dataset gained significant tractionk downloads on hf with this new model they showed that just a bigger dataset was all it took to beat deepseekr rl would give even better results i am guessing,,,,,
1jqp77y,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 17:52:57,r for those of you who are familiar with kolmogorov arnold networks and the meijerg function is representing the bspline using a meijerg function possible as the title suggests i wanted to know if a bspline for a given grid can be represented using a meijerg function or is there any way by which the exact parameters for the meijerg function can be found that can replicate the bspline of a given grid i am trying to build a neural network as part of my research thesis that is inspired by the kan but instead uses the meijerg function as trainable activation functions if there is a plausible way to represent the bspline using the meijer function it would help me a lot in framing my proposition thanks in advance,,,,,
1jqolkh,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 17:30:11,ai tools for ml research what am i missing d aiml researchers who still code experiments and write papers what tools have you started using in daytoday workflow i think it is way different what other swemle uses for their work what i use cursor w sonnet gemini for writing codes for experiments and basically designing the entire pipeline using it since months and feels great notebooklm some other texttoaudio summarisers for reading papers daily sonnetdeepseak has been good for technical writing work gemini deep research also perplexity for finding references and day to day search feel free to add more,,,,,
1jqojkv,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 17:28:09,r position model collapse does not mean what you think the proliferation of aigenerated content online has fueled concerns over __model collapse__ a degradation in future generative models performance when trained on synthetic data generated by earlier models we contend this widespread narrative fundamentally misunderstands the scientific evidence we highlight that research on model collapse actually encompasses eight distinct and at times conflicting definitions of model collapse and argue that inconsistent terminology within and between papers has hindered building a comprehensive understanding of model collapse we posit what we believe are realistic conditions for studying model collapse and then conduct a rigorous assessment of the literatures methodologies through this lens our analysis of research studies weighted by how faithfully each study matches realworld conditions leads us to conclude that certain predicted claims of model collapse rely on assumptions and conditions that poorly match realworld conditions altogether this position paper argues that model collapse has been warped from a nuanced multifaceted consideration into an oversimplified threat and that the evidence suggests specific harms more likely under societys current trajectory have received disproportionately less attention,,,,,
1jqns7l,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 16:59:27,r speech to text summarisation optimised model ideas hi im a cs major who choose speech to text summarisation as my honors topic because i wanted to pick something from machine learning field so that i could improve my understanding the primary goal is to implement the speech to text transcription model summarisation one will be implemented next sem but i also want to make some changes to the already existing models architecture so that itll be a little efficientalso identifying where current models lack like high latency poor speaker diarization etc is also another work to do although i have some experience in other ml topics this a complete new field for me and so i want some resources datasets and recent papers etc which help me score some good marks at my honors review,,,,,
1jqn1xb,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 16:31:03,p privately hosted llm hipaa compliant hey everyone i need to parse text prompts from users and map them to a defined list of categories we dont want to use a public api for data privacy reasons as well as having more control over the mapping also this is healthcare related what are some resources i should use to start researching solutions for this my immediate thought is to download the best general purpose open source llm throw it in an ec instance and do some prompt engineering to start with ive built and deployed simpler ml models before but ive never deployed llms locally or in the cloud any help is appreciated to get me started down this path thanks,,,,,
1jql3hx,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 15:15:13,d uai reviews waiting place a place to share your thoughts prayers and most importantly once the reviews are out should be soon rants or maybe even some relieved comments good luck everyone,,,,,
1jqh8zw,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 12:34:48,d finetuning a finetuned yolo model i have a semi annotated dataset images which i annotated using some automation i also have a small fully annotated dataset images derived from semi annotated dataset after i corrected incorrect bbox and each image has bboxes classes i am thinking of using yolos or yolomnot yet decided for me the accuracy is more important than inference time so is it better to only finetune the pretrained yolo model with the small fully annotated dataset or first finetune the pretrained yolo model on semi annotated dataset and then again finetune it on fully annotated dataset,,,,,
1jqevkl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 10:28:04,d anyone got reviews for the paper submitted to aied conference anyone got reviews for the paper submitted to aied conference i am yet to receive mine while few others have already got it have mailed chairs but doubt if i will get any reply anyone connected to aied if you can reply here it would be super good,,,,,
1jqettp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 10:24:59,d time series models with custom loss suppose i have a timeseries prediction problem where the loss between the models prediction and the true outcome is some custom loss function lx y is there some theory of how the standard arma arima models should be modified for example if the loss is not measuring the additive deviation the error term in the ma part of arma may not be additive but something else is it also not obvious what would be the generalized counterpoarts of the standard stationarity conditions in this setting i was looking for literature but the only thing i found was a theory specially tailored towards poisson time series but nothing for more general cost functions,,,,,
1jqdl35,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 09:04:23,p looking for resources on simulating social phenomena with llm i want to simulate social phenomena using llm agents however since my major is in computer science i have no background in social sciences are there any recommended resources or researchers working in this area for example something related to modeling changes in peoples states or transformations in our world i think the list below is a good starting point let me know if you have anything even better large language models as simulated economic agents what can we learn from homo silicus agentsociety largescale simulation of llmdriven generative agents advances understanding of human behaviors and society using large language models to simulate multiple humans and replicate human subject studies generative agent simulations of people,,,,,
1jq5uid,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 01:33:59,r patronus ai columbia university and meta release blur benchmark for tipofthetongue retrieval evaluation for agents hugging face dataset,,,,,
1jq04ri,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 21:17:42,d are you happy with the icml discussion period are you happy with the icml discussion period my reviewers just mentioned that they have acknowledged my rebuttals im not sure the rebuttal acknowledgement button really helped get the reviewers engaged,,,,,
1jpwbag,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 18:42:50,r neuronbased explanations of neural networks sacrifice completeness and interpretability tmlr tldr the most important principal components provide more complete and interpretable explanations than the most important neurons this work has a fun interactive online demo to play around with,,,,,
1jpuz32,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 17:50:18,projectcurated list of awesome time series papers open source resource on github hey everyone if youre into time series analysis like i am i wanted to share a github repo ive been working on awesome time series papers its a curated collection of influential and recent research papers related to time series forecasting classification anomaly detection representation learning and more the goal is to make it easier for practitioners and researchers to explore key developments in this field without digging through endless conference proceedings topics covered forecasting classical deep learning anomaly detection representation learning time series classification benchmarks and datasets reviews and surveys id love to get feedback or suggestionsif you have a favorite paper thats missing prs and issues are welcome hope it helps someone here,,,,,
1jpthoa,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 16:52:51,project opensource ocr system for creating educational ml datasets math multilingual tables diagrams hi everyone ive opensourced an ocr pipeline designed to extract structured machine learningready data from complex educational documents its built with a focus on academic content such as entrance exams scientific pdfs and textbooks handling not just plain text but also math formulas multilingual content tables and figures core capabilities multilingual ocr supports english korean japanese easily extensible math recognition using mathpix api latexstyle precision layout parsing with doclayoutyolo and opencv for detecting tables and diagrams semantic postprocessing using gpt gemini pro vision for summarization tagging structured output in json or markdown for ml training rag pipelines or llm finetuning use cases creating highquality datasets for training educational llms preprocessing documents for retrievalbased tutoring systems building rag pipelines using realworld academic corpora extracting and classifying visualsemantic structures in educational data github code examples repo would appreciate feedback ideas or even collaborators especially if youre working in document ai education tech or dataset curation,,,,,
1jponcv,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 13:33:03,pr citegeist automated generation of related work analysis on the arxiv corpus web tool code for the local deployment paper abstract large language models provide significant new opportunities for the generation of highquality written works however their employment in the research community is inhibited by their tendency to hallucinate invalid sources and lack of direct access to a knowledge base of relevant scientific articles in this work we present citegeist an application pipeline using dynamic retrieval augmented generation rag on the arxiv corpus to generate a related work section and other citationbacked outputs for this purpose we employ a mixture of embeddingbased similarity matching summarization and multistage filtering to adapt to the continuous growth of the document base we also present an optimized way of incorporating new and modified papers to enable easy utilization in the scientific community we release both a website this url as well as an implementation harness that works with several different llm implementations key features development of a dynamic retrieval and synthesis application for related work generation introduction of three key hyperparametersbreadth depth and diversityto finetune the content and style of the result support for uploading full pdfs to enhance contentbased retrieval employment of full paper texts through alternating between importance weighting and summarization techniques test for some testing i have chosen the paper wikiautogen towards multimodal wikipediastyle article generation a kinda meta choice since it also explores automatic knowledgebased text generation its abstract was fed into the citegeist web tool tool output related work automated knowledge creation and collection have garnered increasing attention particularly in the context of generating wikipediastyle content several works have explored methods for automating the creation of comprehensive knowledge resources for instance admati et al introduced wikibookbot a system that automatically generates wikibooks by organizing existing wikipedia articles into a book format using machine learning for article selection chapter creation and ordering admati et al similarly li et al tackled the challenge of generating uptodate wikipedia content for rapidly evolving fields such as ai by employing a twostage approach involving extractive and abstractive summarization li et al shao et al focused on the prewriting stage of article generation introducing a system for synthesizing topic outlines through retrieval and multiperspective question asking to improve the breadth and organization of generated articles shao et al fan and gardent addressed the challenges in generating factual longform text like wikipedia articles by using a retrieval mechanism to gather relevant web evidence and a pretrained encoderdecoder to generate biographies section by section with citations fan and gardent while these approaches share the goal of automating content creation from existing knowledge sources they primarily focus on textonly generation whereas our work wikiautogen aims to generate new articles with both text and images using a multiperspective selfreflection mechanism to improve accuracy and coherence a crucial aspect of generating highquality wikipedia content is ensuring factual accuracy and coherence chen et al introduced wikitablet a dataset pairing wikipedia sections with corresponding tabular data highlighting challenges in coherence and factuality in datatotext generation chen et al our wikiautogen system addresses these issues through a multiperspective selfreflection mechanism to improve the reliability and coherence of generated articles furthermore šakota et al addressed the problem of missing short descriptions in wikipedia articles which hinders navigation and knowledge management by automatically generating these descriptions using the descartes model šakota et al while descartes focuses on generating textual summaries wikiautogen extends this by incorporating multimodal content suggesting potential synergies in improving wikipedias accessibility and informativeness the importance of multimodal content in enhancing informativeness and engagement has been recognized in recent research zhu et al presented murar a framework for multimodal answer generation that enhances text answers with relevant images tables and videos zhu et al their work like wikiautogen recognizes the limitations of textonly generation and aims to improve informativeness and user experience through multimodal content burns et al introduced the wikiwebm dataset a largescale multimodal resource of wikipedia webpages containing images text and structural information burns et al this dataset enables research on multimodal webpage understanding through tasks like page description generation section summarization and contextual image captioning another work by burns et al defines a suite of generative tasks for multilevel multimodal webpage understanding using the wikiwebm dataset burns et al these datasets and tasks are directly related to the goal of generating comprehensive wikipediastyle articles making them useful benchmarks for comparison the evaluation of multimodal generation systems requires highquality datasets and evaluation metrics wu et al addressed the challenge of evaluating multimodal retrieval augmented generation mmrag systems by proposing a synthetic data generation framework wu et al their method of generating questionanswer pairs from multimodal documents with control over question styles and modalities complements our focus on generating visually enriched wikipediastyle articles in contrast to existing approaches our work introduces wikiautogen a novel system for automated multimodal wikipediastyle article generation that retrieves and integrates relevant images alongside text to facilitate the evaluation of multimodal knowledge generation on more challenging topics we introduce wikiseek a benchmark comprising wikipedia articles with topics paired with both textual and imagebased representations this benchmark allows for a more comprehensive evaluation of systems like wikiautogen which aim to generate more accurate coherent and visually enriched wikipediastyle articles references shahar admati lior rokach bracha shapira wikibookbot automatic generation of a wikipedia book arxiv ian wu sravan jayanthi vijay viswanathan simon rosenberg sina pakazad tongshuang wu graham neubig synthetic multimodal question generation arxiv zhengyuan zhu daniel lee hong zhang sai sree harsha loic feujio akash maharaj yunyao li murar a simple and effective multimodal retrieval and answer refinement framework for multimodal question answering arxiv angela fan claire gardent generating full length wikipedia biographies the impact of gender bias on the retrievalbased generation of women biographies arxiv mingda chen sam wiseman kevin gimpel wikitablet a largescale datatotext dataset for generating wikipedia article sections arxiv andrea burns krishna srinivasan joshua ainslie geoff brown bryan a plummer kate saenko jianmo ni mandy guo wikiwebm a pagelevel multimodal wikipedia dataset arxiv yijia shao yucheng jiang theodore a kanell peter xu omar khattab monica s lam assisting in writing wikipedialike articles from scratch with large language models arxiv irene li alexander fabbri rina kawamura yixin liu xiangru tang jaesung tae chang shen sally ma tomoe mizutani dragomir radev surfer generating surveys from web resources wikipediastyle arxiv andrea burns krishna srinivasan joshua ainslie geoff brown bryan a plummer kate saenko jianmo ni mandy guo a suite of generative tasks for multilevel multimodal webpage understanding arxiv overall out of references suggested by citegeist were actually present in the tested paper and most of the rest werent too far off i think its decent enough,,,,,
1jpo78g,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 13:11:15,d relevance of minimum description length to understanding how deep learning really works theres a subfield of statistics called minimum description length do you think it has a relevance to understanding not very well explained phenomena of why deep learning works ie why overparameterized networks dont overfit why double descent happens why transformers works so well and what really happens inside ofweights etc if so what are the recent publications to read on ps i got interested since theres a link to a chapter of a book related to this on the famous shutskever reading list,,,,,
1jpo6j2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 13:10:20,project a handy tool for running ml experiments across multiple gpus hi guys ive built a tool that saves you time and effort from messy wrapper scripts when running ml experiments using multiple gpusmeet labtasker who is this for students researchers and hobbyists running multiple ml experiments under different settings eg prompts models hyperparameters typical use cases hyperparameter search multiple baseline experiments running under a combination of different settings ablation experiments what does it do labtasker simplifies experiment scheduling with a task queue for efficient job distribution automates task distribution across gpus tracks progress prevents redundant execution easily reprioritizes recovers failed tasks supports plugins and event notifications for customized workflows easy installation via pip or docker compose simply replace loops in your wrapper scripts with labtasker and let it handle the rest check it out open source code documentation tutorial demo id love to hear your thoughtsfeel free to ask questions or share suggestions compared with manually writing a bunch of wrapper scripts labtasker saves you much time and effort,,,,,
1jpnioz,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 12:37:30,n contextgem easier and faster way to build llm extraction workflows through powerful abstractions contextgem on github today i am releasing contextgem an opensource framework that offers the easiest and fastest way to build llm extraction workflows through powerful abstractions why contextgem most popular llm frameworks for extracting structured data from documents require extensive boilerplate code to extract even basic information this significantly increases development time and complexity contextgem addresses this challenge by providing a flexible intuitive framework that extracts structured data and insights from documents with minimal effort complex most timeconsuming parts prompt engineering data modelling and validators grouped llms with rolespecific tasks neural segmentation etc are handled with powerful abstractions eliminating boilerplate code and reducing development overhead contextgem leverages llms long context windows to deliver superior accuracy for data extraction from individual documents unlike rag approaches that often struggle with complex concepts and nuanced insights contextgem capitalizes on continuously expanding context capacity evolving llm capabilities and decreasing costs check it out on github if you are a python developer please try it your feedback would be much appreciated and if you like the project please give it a to help it grow lets make contextgem the most effective tool for extracting structured information from documents,,,,,
1jplhtl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 10:40:46,r implemented rl algorithms in a simpler way i decided to create a comprehensive learning project in a jupyter notebook to implement rl algorithms such as ppo sac ac and more theory code code documentation and example can all be found on github,,,,,
1jpimql,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 07:06:54,p handling missing values in dataset im using this dataset for a regression project and the goal is to predict the beneficiary risk scorebene_avg_risk_scre now to protect beneficiary identities and safeguard this information cms has redacted all data elements from this file where the data element represents fewer than beneficiaries due to this there are plenty of features with lots of missing values as shown below in the image basically if the data element is represented by lesser than beneficiaries theyve redacted that cell so all nonnull entries in that column are and all missing values supposedly had before redactionthis is my understanding so far one imputation technique i could think of was assuming a discrete uniform distribution for the variables ranging from to and imputing with the mean of said distribution or but obviously this is not a good idea because i do not take into account any skewness the fact that the data might have been biased to either smallerlarger numbers how do i impute these columns in such a case i do not want to drop these columns any help will be appreciated tia features with missing values,,,,,
1jpe138,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 02:30:11,r is iterative retraining in semisupervised segmentation a good idea im working on a medical image segmentation project and would love to hear your thoughts on a couple of decisions im facing to give some context i started with a small set of labeled ct images and a large set of unlabeled ones i used a semisupervised segmentation model to generate pseudolabels for the unlabeled data but instead of doing it in a single pass i took an iterative approach after each cycle i manually refined a few of the autogenerated segmentations retrained the model and repeated this process several times over multiple iterations the quality of the segmentations improved significantly first question is this kind of iterative retraining in semisupervised learning ssl actually considered a good idea or is there a risk of overfitting model drift confirmation bias because i keep training on my own models pseudolabels second question now that i have a decent refined labeled dataset from this iterative process should i keep using the semisupervised model the one trained over several iterations for segmenting new unseen images train a fully supervised segmentation model using the final refined labels and use that for inference ive read mixed opinions on whether ssl models generalize well enough to be used directly vs whether its better to retrain a clean supervised model once youve built a solid labeled dataset if anyone has experience with this type of workflow in segmentation tasks or knows of any relevant papers discussing this tradeoff id love to hear your thoughts ps i can technically test both options and compare them but to do that properly id need to manually label at least more images to get statistically meaningful results which is quite timeconsuming so id really appreciate any advice before going down that path,,,,,
1jpdo7y,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 02:15:32,d selfpromotion thread please post your personal projects startups product placements collaboration needs blogs etc please mention the payment and pricing requirements for products and services please do not post link shorteners link aggregator websites or autosubscribe links any abuse of trust will lead to bans encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title meta this is an experiment if the community doesnt like this we will cancel it this is to encourage those in the community to promote their work by not spamming the main threads,,,,,
1jpd67i,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 01:52:54,d how do you see the researchacademic climate given the current state of the world suppose the current climate in the us and the current world view of the us continues to stagnatedegrade how do you think this will impact the larger scientific community whether it be research producers grant funding conference venues poaching of talent etc,,,,,
1jpbgzn,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 00:28:45,d what are the current challenges in deepfake detection image hey guys i need some help figuring out the research gap in my deepfake detection literature review ive already written about the challenges of dataset generalization and cited papers that address this issue i also compared different detection methods for images vs videos but i realized i never actually identified a clear research gaplike what specific problem still needs solving deepfake detection is super common and i feel like ive covered most of the major issues now im stuck because i dont know what problem to focus on for those familiar with the field what do you think are the biggest current challenges in deepfake detection especially for images any insights would be really helpful,,,,,
1jp65e9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 20:36:34,r neuralatex a machine learning library written in pure latex exicting times sota wrt to pytorch tf and resenttransformer papers,,,,,
1jp21ld,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 17:54:07,d what are the hardest llm tasks to evaluate in your experience i am trying to figure out which llm tasks are the hardest to evaluate especially ones where public benchmarks dont help much any niche use cases come to mind eg ner for clinical notes qa over financial news etc would love to hear what you have struggled with,,,,,
1jozejh,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 16:07:52,d dubious validation accuracy on different dataset splits hi all i have been working on a hydrological forecasting model for some time now with the goal of making the model robust enough to inform operations at my company specifically for several years into the future for this reason most of my time spent designing and training the model i have been using a timebased split of the data to simulate the potential of the model being used for a long time this training process often saw overfitting at around epochs the best model producing a mae of however i am now being asked to train the final production model and i want to use all of the available data for this i use a standard random split including the years i previously held out importantly this model is training on less data than the prior models but now the model seems to be capable of much lower error around in most cases it also has never overfit with the same hyperparameters i used for the previous models im concerned that this production model isnt actually capable of making robust predictions for future conditions and the random split is actually allowing it to memorize the current river morphology conditions rather than generally understand the flow and the potential of other conditions how could i analyze the potential of this model on conditions that we havent seen should i return to the old approach of using the timebased split should i try a kfold crossvalidation with time splits any help is appreciated two notes i am on another team analyzing the long term flow of the river and there is a long term trend that we can observe but we are not sure of the actual shape of the curve given the next years hydrology is evil and because of this i tried at one point using a positional encoding rotary that corresponded to the day of the current observation since the first observation in the dataset jan jan this was in hopes of the model discovering the trend itself i attempted using this in both the encoder and decoder with no success,,,,,
1joyu43,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 15:45:29,r the future of romance novel techniques for replacing your boyfriend with generative ai i hope today is an okay day to post this here,,,,,
1joxq8q,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 15:00:42,d simple questions thread please post your questions here instead of creating a new thread encourage others who create new posts for questions to post here instead thread will stay alive until next one so keep posting after the date in the title thanks to everyone for answering questions in the previous thread,,,,,
1jowuwz,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 14:24:28,r query generation with executionguided selection for improved texttosql accuracy i was intrigued by this executionguided approach to sql generation that uses database query results to improve accuracy the key insight is simple but powerful by executing candidate sql queries against the actual database and analyzing the results models can learn from their mistakes and generate better sql the method works in two ways during training models are shown not just sql queries but also their execution results during inference multiple candidate queries are generated executed and the best one is selected using minimum bayes risk mbr decoding utility functions determine the best query based on execution success row counts and result similarity performance gains are substantial improvement for gpt and for gpt on the spider benchmark works with both closedsource llms gpt models and opensource models codellama requires no architectural changes to existing models i think this approach could become standard practice for sql generation systems the ability to incorporate execution feedback addresses a fundamental limitation in current texttosql systems that rely solely on textual prompts this could make natural language database interfaces much more reliable in practical applications i think the computational overhead is a real concern though executing multiple queries introduces latency that might be problematic for realtime applications the privacy implications also need careful consideration you dont want incorrect queries accidentally returning sensitive data tldr by executing candidate sql queries and using their results as feedback this approach improves sql generation accuracy by across different models its a practical enhancement that could make natural language database interfaces significantly more reliable full summary is here paper here,,,,,
1jot2zr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 11:18:05,dp turning knowledge graphs into memory with ontologies most ai models rely on external data that is either in a knowledge graph vector store or a combination of both but they mostly regurgitate the already available datasets but memory doesnt work that way the brain uses symbolic models to power the mental architecture that governs how we think reason and behave weve added ontologies to cognee our ai memory tool which uses rdf owl to match external system rules to llm generated graphs in order to ground them our assumption is that we will need dozens of small validated ontologies to ground the memory systems across different models we might have ontologies for modelling timegraphs or complex rulesets for hypergraphs and in the end you get to see and explore a nice looking graph here is a short tutorial set up ontologies with cognee here is our repository would love to get your feedback on our approach,,,,,
1jo8hyp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 17:16:08,r latent verification for absolute factual accuracy improvement let me preface by saying im a little nervous embarrass posting this here im just some selftaught dude thats been dabbling in ml since my implementation is probably incredibly crude and amateur but i found it really rewarding regardless the transmla paper blew my mind when it came out since then ive been playing around with manipulating pretrained llms im nowhere near as smart as the people behind transmla or probably any of you but i hope you still find this interesting heres the repo to the implementation for my architectural modification it adds selfverification capabilities to llms currently implemented in qwen b it works by adding verification adapters lightweight modules every few layers these modules analyze the hidden states passing through its layer computes a confidence score indicating how reliable the states are applies weighted correction based on the inverse of that confidence score and returns the corrected state back to the models processing flow then the crosslayer verifier compares representation across different layers to ensure consistency in the models internal reasoning its pretty cool you can actually see the verification happening in the pca projection within the results directory anyway hope yall enjoy this looking forward to any feedback or ideas for improvement repo,,,,,
1jose8v,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 10:34:02,r proof or bluff evaluating llms on usa math olympiad proof or bluff evaluating llms on usa math olympiad ivo petrov jasper dekoninck lyuben baltadzhiev maria drencheva kristian minchev mislav balunović nikola jovanović martin vechev eth zurich insait sofia university st kliment ohridski recent math benchmarks for large language models llms such as matharena indicate that stateoftheart reasoning models achieve impressive performance on mathematical competitions like aime with the leading model omini achieving scores comparable to top human competitors however these benchmarks evaluate models solely based on final numerical answers neglecting rigorous reasoning and proof generation which are essential for realworld mathematical tasks to address this we introduce the first comprehensive evaluation of fullsolution reasoning for challenging mathematical problems using expert human annotators we evaluated several stateoftheart reasoning models on the six problems from the usamo within hours of their release our results reveal that all tested models struggled significantly achieving less than on average through detailed analysis of reasoning traces we identify the most common failure modes and find several unwanted artifacts arising from the optimization strategies employed during model training overall our results suggest that current llms are inadequate for rigorous mathematical reasoning tasks highlighting the need for substantial improvements in reasoning and proof generation capabilities arxiv cscl,,,,,
1jopjw2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 07:05:28,d any open source library similar to this this will make it easier for annotating a dataset which is niche,,,,,
1joncpd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 04:35:47,d multigpu thread ive just bought parts for my first pc build i was deadset in january on getting an rtx and attempted almost every drop to no avail unfortunately with the tariffs the price is now out of my budget so i decided to go with a xtx i bought a mobo that has pcie x lanes so i can utilize two gpus at x lanes my main question is can you mix gpus i was torn between the xt or the xtx since the xt only has gb of vram while the xtx has gb i opted for more vram even though it has marginally lower boost clock speeds would it be possible to get both cards if not dual xtxs could work but it would be nice if i could allocate the xt for stuff such as gaming and then both cards if i want parallel processing of different ml workloads from my understanding the vram isnt necessarily additive but im also confused since others claim their dual xtx setups allow them to work with larger llms what are the limitations for dual gpu setups and is it possible to use different cards im definitely assuming you cant mix both amd and nvidia as the drivers and structure are extremely different or maybe im mistaken there too and theres some software magic to let you mix im new to pc building but have a few years experience tinkering with and training aiml models,,,,,
1jomxcm,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 04:09:43,project axiomgpt programming with llms by defining oracles in natural language hello there ive been working on something called axiomgpt for a while which is a model of latentspace programming that treats language not just as instruction but as invocation instead of writing traditional functions you define oracles using natural language tiny semantic contracts like defn fibber oracle return the nth fibonacci number fibber oracles can be procedural personabased conceptual or abstract theyre not executed but remembered manifested and reconstructed by the model through learned latent behavior highlights you can define entities like defn clarke or defn tspsolver oracles can be composed piped even treated like lambda functions ughhh and no you dont have to program them in lisp but it helps they work with real algorithms recursive calls mapreduce and code in any language entire functions and their behaviors can live inside a single token its programmable in english by design weve written up a full codex with theory usage quotes even philosophical parallels to quantum computing if you are into ai cognition symbolic programming or latent computing its well worth checking out and weird ride easy to try it yourself in minutes for fun and profit explore it here very happy to answer any questions and hear your thoughts,,,,,
1jol6ez,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 02:32:55,d ijcnn results seems vague my ijcnn paper is rejected fair enough however the reviewer comments are very good usually atleast one reviewer criticize the work to be rejected moreover individual reviewer score is not shared which is not the case of top conferences and this statement at the end of the email thank you again for your submission but stay tuned a selection of papers will soon be invited to participate in additional initiatives related to ijcnn thoughts,,,,,
1jokue7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 02:15:33,ijcnn acceptance notification n hello did anybody get their acceptance notification for ijcnn today was supposed to be the paper notification date i submitted a paper and havent gotten any response yet,,,,,
1joh6di,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 23:15:21,r ieee access publishing im looking to make a paper into a new metric to evaluate prompt engineeringpls dont hound me for this for code generation do you guys think it has a good chance to get published in ieee access btw im a hs senior looking to boost my college app thanks for the help,,,,,
1jof0f2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 21:41:12,project tensara codeforceskaggle for gpu programming a few friends and i recently built tensaraorg a competitive gpu kernel optimization platform where you can submit and benchmark kernels in flops for common deep learning workloads gemm convd etc in cudatriton we launched month ago and weve gotten k submissions on our platform since we just released a bunch of updates that we wanted to share triton support is live problems waiting to be solved profile pages to show off your submission activity ratings that track skillactivity rankings to fully embrace the competitive spirit a cli tool in rust to submit solutions were fully opensource too try it out and let us know what you think,,,,,
1joby4h,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 19:35:48,p d having trouble enhancing gnn lstm for d data forecasting hi everyone im working on a forecasting task involving d data with shape t h w where each frame corresponds to a daily snapshot im trying to model both spatial and temporal dependencies but im running into some issues and would love some advice on improving the models performance setup i flatten each h w frame into n where n is the number of valid spatial locations the full dataset becomes a t n time series i split the data chronologically into train val and test sets so no shuffling when splitting my data graph construction for each sequence eg days i construct a semidynamic i am not sure what to call it sequence of graphs gₜ node features value h w where the value changes daily edges static across the sequence based on euclidean distance threshold pearson correlation computed over the sequence edge features direction angle to north and distance loss mae shown below model spatial encoder layer gnn edge update edge aggregation node update recently added skip connections selfattention and increased hidden units temporal encoder layer lstm prediction head feedforward layer to predict values for the next time steps current behavior initially gnn layers were barely learning lstm and ff layers dominated after adding skip connections and selfattention gnn behavior improved somewhat but overall loss is still high training is slow so its hard to iterate quickly im currently prototyping using just batches for trainingvalidation to track behavior more easily i have around batches in total parameter update magnitudes tracking l norm of weight changes across layers im currently trying to figure out how to break out of this learning plateau the model starts converging quickly but then flattens out around mae even with a scheduled learning rate and weight decay in place could this be a case of overcomplicating the architecture would switching from mae to a different loss function help with optimization stability or gradient flow also if anyone has advice on better ways to integrate spatial learning early on eg via pretraining or regularization or general tips for speeding up convergence in gnnlstm pipelines id love to hear it,,,,,
1jo7w6z,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 16:51:45,d distillation with different number of tokens hi folks ive been reading some distillation literature for image encoders particular vit and variants often when distilling a larger model with a bigger embedding dimension than the student model we use an upprojection linear layer that is thrown away after distillation what do you do when you have different number of tokens this can arise if youre using different patch sizes or image resolutions or just different pooling techniques i havent been able to find literature that does this so wanted to know if there were some common approaches im missing thanks,,,,,
1jo7l3f,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 16:38:53,p best approach to building an efficient search tool for a metadata dictionary in excel i am working with a metadata dictionary stored in excel which contains information about database fields across multiple tables the dataset includes the following columns physical table name database name physical column name eg hlp_mgr__full_nm logical column name eg home loan processor manager name definition eg name of the th manager in the loan processing team primaryforeign key indicator rows where a column is a primary or foreign key are marked as true problem statement i want to build a search engine that allows users to enter a query and get the most relevant columns from the dictionary ranked by relevance the challenge is that exact matches arent always available users might search for loan number but the metadata might store it as servicing loan account number srvcing_loan_acc_num acronyms and abbreviations exist physical column names often use acronyms hlp_mgr__full_nm while logical names are in full form home loan processor manager name the search should understand these mappings users should be able to filter by tabledatabase the user may want to search only within a specific table or database this filtering should be applied before the ranking process primaryforeign key retrieval for any table returned in the search results i need to automatically list its primary and foreign keys in a separate column since a table can have multiple keys they should be concatenated in a single cell commaseparated the search should work well even in a restrictive environment i am working in a vdi environment where i cant install large nlp models eg sentencetransformers solutions that are lightweight and work locally are preferred current approaches i am exploring so far i have considered the following tfidf fuzzy matching precompute tfidf embeddings for the metadata dictionary use cosine similarity to compare search queries against the metadata combine this with fuzzy string matching fuzzpartial_ratio to improve ranking acronym expansion normalization maintain a dictionary of common acronyms eg hlp home loan processor mgr manager expand query terms before searching exact tabledatabase filtering apply exact match filtering on table and database names first before performing text matching concatenation of primaryforeign keys extract all primaryforeign keys for each table in the results and concatenate them into a single output column looking for better approaches while these approaches work reasonably well i am looking for alternative solutions beyond nlp that might be faster more efficient and simpler to implement in a restricted vdi environment would a different ranking strategy work better is there a database indexing technique that could improve search speed are there other lightweight similarity approaches i havent considered would love to hear from others who have solved similar metadata search challenges any insights or suggestions are greatly appreciated,,,,,
1jo48j9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 14:16:29,p developing a opensource retrieval augmented generation framework written in c with python bindings for high performance been exploring ways to optimize retrievalaugmented generation rag lately and its clear that theres always more ground to cover when it comes to balancing performance speed and resource efficiency in dynamic environments so we decided to build an opensource framework designed to push those boundaries handling retrieval tasks faster scaling efficiently and integrating with key tools in the ecosystem were still in early development but initial benchmarks are already showing some promising results in certain cases its matching or even surpassing wellknown solutions like langchain and llamaindex in performance comparisson for cpu usage over time comparisson for pdf extration and chunking it integrates smoothly with tools like tensorrt faiss vllm and others and our roadmap is packed with further optimizations tools integrations and updates were excited to roll out if that sounds like something youd like to explore check out the github repo contributions are welcome whether through ideas code or simply sharing feedback and if you find it useful dropping a star on github would mean a lot,,,,,
1jo2il4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 12:55:30,r deepfake video detection insights into model generalisation a systematic review im excited to share that my paper deepfake video detection insights into model generalisation a systematic review has been published in an elsevier q open access journal this work examines the current landscape of deep learning models used for detecting deepfakes with a special focus on how well these models can generalize across different datasets and scenariosa critical factor in their realworld application key highlights from the study include model generalisation the research identifies key challenges in achieving robust performance when detection models encounter new unseen data we discuss strategies to enhance model adaptability crucial for keeping pace with evolving deepfake techniques methodological advances the paper reviews various architectural innovations and algorithmic strategies that show promise in improving detection accuracy and efficiency crossdataset performance a significant portion of the paper is dedicated to analyzing how these models perform across different datasets a factor critical to their practical deployment the study suggests improvements in training practices to better prepare models for a diverse range of inputs read the full paper here id love to engage with the community here and hear your thoughts or questions about the research how do you see ai and deep learning contributing to media security and what are your thoughts on overcoming the challenges posed by deepfake technology,,,,,
1jo04ad,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 10:34:22,r trajectoryguided video motion segmentation using dino features and sam prompting sammotion introduces a novel approach to video object segmentation by focusing on motion patterns rather than object categories the key innovation is a motion pattern encoding technique that leverages trajectory information to identify and segment moving objects of any type in videos the technical approach consists of motion pattern encoding tracks point trajectories across video frames using raft for optical flow estimation pertrajectory motion prediction determines if trajectories belong to moving objects by comparing against camera motion motion decoder generates precise segmentation masks by combining motion information with sam architecture works without categoryspecific training making it generalizable to any moving object key results stateoftheart performance on davis fbms and moca datasets successfully segments diverse motion types rigid vehicles articulated humans and nonrigid fluids enables applications like selective motion freezing and interactive editing outperforms existing methods in both accuracy and generalization ability i think this approach represents a significant paradigm shift in how we tackle video understanding by focusing on motion patterns rather than predefined categories sammotion offers much greater flexibility for realworld applications the trajectorybased method seems particularly wellsuited for scenarios where object appearance varies widely but motion characteristics remain distinct i think the most promising aspect is how this bridges the gap between motion analysis and object segmentation traditional methods excel at one or the other but sammotion effectively combines both paradigms this could be particularly valuable for robotics and autonomous systems that need to identify and track moving objects in dynamic environments that said the dependence on highquality trajectory estimation could be limiting in challenging conditions like poor lighting or extremely fast motion id be interested to see how robust this approach is in more adverse realworld scenarios tldr sammotion segments any moving object in videos by encoding motion patterns from trajectory information achieving sota results without categoryspecific training and enabling new video editing capabilities full summary is here paper here,,,,,
1jnfr0s,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 16:06:11,r gans evaluation metrixs hello guys i am im the process of choosing my bachelors thesis one idea i had was to focus on compering different methods of evaluating gans as a experiment i thought of artificially adding artefacts to generated images and then checking the impact that different artefacts can have on different evaluation scores do you think that this idea makes sense and is appropriate for a bachelors thesis if you see any issues and problems with this topic please let me know thanks for help,,,,,
1jnm8dj,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 20:48:26,discussion rethinking advanced ai benchmarks why autonomous homesteads should be a realworld testing ground good day reddit community i have spent a considerable amount of time working on ai projects like vector neural networks that treat scalars as d vectors and spatial probability networks where vectors get dynamically routed across multitudes of nodes i have been keeping up with our pursuit of more advanced and intelligent neural networks and our approach toward advanced ai i hear about advanced ai benchmarks that look similar to iq tests and that test the complexity of the mental model that ais can build internally superintelligent ais are poised to tackle realworld problems such as preventing aging and curing diseases all of this is great but most of it does not seem focused on basic human needs it seems like jumping into the deep end of the pool before actually learning how to swim they seem more focused on giving us what we desire than what we truly need deep down as a society our society has been built on scarcity it drives supply and demand and our economies it can be a force for good but at the same time a force for inequality when we empower our ai models and ai agents to conquer our most difficult open problems are they also solving the longest rooted ones the ones that have been dug the deepest are we focused on truly reducing scarcity and moving toward abundance we have been conditioned to live in a scarcity economy for so long are we just prolonging it by focusing on ai and agi benchmarks that are ethereal and abstract or are we focused on first providing for our basic needs then building off of that are we following the path of least resistance or following the best path we have opensource libraries where the distributed community can create better and more powerful ai models but do we have an embodied github one focused on embodied ai that can attend to our physical needs should we be focused on agi that does work and physical labor rather than one that relies on the human race to do the work and physical labor while ai is stuck in intellectual pursuits does it result in a race to the bottom or a race to the top for the wellbeing of the human race the case for autonomous homesteads i envision autonomous selfsustaining homesteads as testing grounds for agi not just as another benchmark but as a way to ground artificial intelligence in the real physical needs of human beings these homesteads should be decentralized distributed and open source think about what this would require systems that can actually see and understand their environment through multiple senses real physical control of things like water systems energy management and growing food the ability to plan for longterm changes like weather and seasons natural ways to communicate with humans about whats happening learning to make safe decisions in an environment where mistakes have real consequences adapting to constant change in messy realworld conditions this isnt about creating another smart home or narrow automation system its about developing embodied intelligence that can maintain a habitat adapt to change and collaborate with humans how would this actually work from a technical perspective i imagine integrating several key components edge computing systems running multiple ai agents that work together to handle different aspects of the homestead vision systems that can actually understand what theyre seeing in the environment language models that can translate between human needs and system actions learning systems that share knowledge between different homesteads robust ways to collect and use sensor data each homestead becomes a living testbeda node in a distributed benchmark ecosystem testing intelligence with respect to survival sustainability and sovereignty its like a survivor for ai why this matters for agi research when i think about why this approach is important several key points come to mind instead of testing our ai systems on abstract problems wed be testing them against real physics biology and human needs the physical world creates natural boundaries you cant work around the fact that plants need water to grow success requires bringing together all the pieces perception planning and action nature provides the ultimate testing ground seasons change things break down new challenges constantly emerge wed be building systems that could actually help with food security energy independence and sustainable living safety constraints emerge naturally from working with real physical systems the embodied github open infrastructure for all i believe we need something like a github but for physical systems imagine open blueprints for building these homesteads shareable ai systems for controlling different aspects standard ways to connect sensors and systems designs that anyone could reproduce and improve a community working together on both the software and hardware this would help create a global movement of aialigned physically grounded infrastructure development the real challenges we need to solve i see several key technical hurdles we need to overcome making these systems work with limited computing resources bringing together data from many different sensors reliably planning for an uncertain future testing new approaches safely in the real world getting multiple ai systems to work together effectively a starting point i think we could begin with something as simple as a robotic garden pod that manages its own irrigation monitors plant health utilizes solar power and can communicate with humans about its activities even this small system would push our current capabilities in meaningful ways questions for discussion what existing opensource frameworks could serve as the base for this kind of project are you working on or aware of similar efforts that combine ai robotics and sustainability how would you approach designing a first prototype of an autonomous homestead node how might we structure this as a shared agi benchmark across research groups if our agi cant grow food clean water or maintain shelter can we really call it general intelligence maybe its time our benchmarks reflected the world we actually want to build,,,,,
1jnqe2p,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 00:02:55,r p d short time fourier transform based kolmogorovarnold network calledstftkan recently the kolmogorovarnold network kan has been used in many deep learning applications to improve accuracy and interpretability over classical mlps however the problem with kan lies in complexity control while we can increase the number of parameters by augmenting spline degrees or stacking more layers the challenge arises when we aim to maintain the same number of parameters or fewer than a simple linear layer in this context we propose a new kolmogorovarnold network called stftkan which provides increased control over complexity and parametrization based on the short time fourier transform principle without relying on complex nonlinear transformations while maintaining comparable performance i am sharing with you the github repository for stftkan along with a simple benchmark using the mnist datasetgithub we are waiting for your feedback,,,,,
1jnxkga,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 07:18:46,p curated list of awesome time series papers open source resource on github hey everyone if youre into time series analysis like i am i wanted to share a github repo ive been working on awesome time series papers its a curated collection of influential and recent research papers related to time series forecasting classification anomaly detection representation learning and more the goal is to make it easier for practitioners and researchers to explore key developments in this field without digging through endless conference proceedings topics covered forecasting classical deep learning anomaly detection representation learning time series classification benchmarks and datasets reviews and surveys id love to get feedback or suggestionsif you have a favorite paper thats missing prs and issues are welcome hope it helps someone here,,,,,
1jnyr2m,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 08:53:24,drquestion about llm vs prophet on time series forcasting task background the company has financial data related to income and expenses categorized into five types for each category there are approximately data points spanning from to the data exhibits reasonable periodicity with visible yearoveryear increases and decreases due to the small sample size the consideration is to use simple models or zeroshot forecasting models for prediction current status currently the company is using facebooks prophet statistical machine learning model which has yielded satisfactory results theres an ongoing effort to explore time series foundation models for zeroshot forecasting initial attempts with tsinghuas timer and amazons chronos models have shown poor performance often degenerating into nearmean predictions and failing to capture trends question the question is whether anyone has experience with similar tasks and can recommend models that would perform well with such a small sample size additionally are there any other time series foundation models worth trying,,,,,
1jnalfy,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 11:39:48,r frigorelu straightthrough relu from torch import tensor import torch import torchnn as nn class frigorelu nnmodule def __init__ self alpha superfrigorelu self__init__ selfalpha alpha def forward self x tensor tensor hard torchreluxdetach soft torchwherex x x selfalpha return hard softdetach soft i have figured out i can change relu in a similar manner to straightthrough estimators forward pass proceeds as usual with hard relu whereas the backward pass behaves like leakyrelu for gradient propagation it is a dogshit simple idea and somehow the existing literature missed it i have found only one article where they use the same trick except with gelu instead of leakyrelu i had an earlier attempt at mnist which had issues with relu likely dead convolutions that hindered learning and accuracy this was enabled by too high initial learning rate e and too few parameters which was deliberate the model produced canceled and accuracies after k iterations this model was the primary reason i transitioned to selu avgpoold and then to other architectures that did not have issues with learning and accuracy so now i brought back that old model and plugged in frigorelu with alpha parameter the end result was and with only k iterations better faster and more stable learning with higher accuracies on average so it is clear improvement compared to the old model for comparison the selu model produced and accuracies but with k iterations i am going to run xk iterations on frigorelu so i can compare them on an even playing field until then enjoy frigorelu and please provide some feedback if you do,,,,,
1jny30f,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 07:59:42,d cli for merging repos llm context hey i created a simple tool to merge repos into a single file so that i can give context to llms especially web based it prefixes each file with its relative path applies configurable probabilistic line skipping and filters to include only humanreadable code how can we further reduce the file size while preserving context for llms currently i just skip lines based on probability edit code,,,,,
1jnt4sp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 02:30:37,d monthly whos hiring and who wants to be hired for job postings please use this template hiring location salary remote relocation full time contract part time and brief overview what youre looking for for those looking for jobs please use this template want to be hired location salary expectation remote relocation full time contract part time resume link to resume and brief overview what youre looking for xb please remember that this community is geared towards those with experience,,,,,
1jnjfaq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 18:47:05,d why is table extraction still not solved by modern multimodal models there is a lot of hype around multimodal models such as qwen vl or omni got smoldocling etc i would like to know if others made a similar experience in practice while they can do impressive things they still struggle with table extraction in cases which are straightforward for humans attached is a simple example all i need is a reconstruction of the table as a flat csv preserving empty all empty cells correctly which open source model is able to do that,,,,,
1jngh6e,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 16:38:56,p agent a local computeruse operator for macos weve just opensourced agent our framework for running computeruse workflows across multiple apps in isolated macoslinux sandboxes grab the code at after launching computer a few weeks ago we realized many of you wanted to run complex workflows that span multiple applications agent builds on computer to make this possible it works with local ollama models if youre privacyminded or cloud providers like openai anthropic and others why we built this we kept hitting the same problems when building multiapp ai agents theyd break in unpredictable ways work inconsistently across environments or just fail with complex workflows so we built agent to solve these headaches it handles complex workflows across multiple apps without falling apart you can use your preferred model local or cloud were not locking you into one provider you can swap between different agent loop implementations depending on what youre building you get clean structured responses that work well with other tools the code is pretty straightforward async with computer as macos_computer agent computeragent computermacos_computer loopagentloopopenai modelllmproviderllmprovideropenai tasks look for a repository named trycuacua on github check the open issues open the most recent one and read it clone the repository if it doesnt exist yet for i task in enumeratetasks printfntask ilentasks task async for result in agentruntask printresult printfnfinished task i some cool things you can do with it mix and match agent loops openai for some tasks claude for others or try our experimental omniparser run it with various models works great with openais computer_use_preview but also with claude and others get detailed logs of what your agent is thinkingdoing super helpful for debugging all the sandboxing from computer means your main system stays protected getting started is easy pip install cuaagentall or if you only need specific providers pip install cuaagentopenai just openai pip install cuaagentanthropic just anthropic pip install cuaagentomni our experimental omniparser weve been dogfooding this internally for weeks now and its been a gamechanger for automating our workflows would love to hear your thoughts,,,,,
1jneuix,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 15:26:24,discussion linear regression performs better than lgbm or xgboost on time series hello im developing a model to hourly forecast weather theyre more than temperature points i used shifting rolling and ewm each of them from to and weekly and monthly linear regression mae result is while xgboost performs and lgbm performs ive tried many parameters or asked chatgpt with providing the code but i dont know if i am doing something really wrong or it is totally normal situation,,,,,
1jnc4vq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 13:14:12,d minimising focal loss but log loss exceeds base rate hey guys im working on a model for churn prevention the gist of it is this predict how likely somebody is to transact tomorrow given their last days of behaviour plot a line of these nextday predictions over a day time span the gradient of this line is a measure of the risk of a customer churning my company does not have a definition of churn static markers like customer has not transacted in the last days are too coarse the idea is to identify a negative shift in the latent representation of a users engagement with the platform by proxy of their likelihood to transact over time the real distribution of data is in favour of a user not transacting on any given day k total samples so naively guessing a chance of transacting gives you a model with accuracy of how good right log loss of undefined precision and recall so not a useful model i am trying to train an lstm if i minimise binary log loss it converges to straight away as expected if i minimise focal loss with a positive weight of i get accuracy precision recall and log loss of so the model learned something but the probabilities are uncalibrated i cannot get the log loss below the base rate of the difficult thing about this problem is there isnt a good way of being able to tell if this nextday prediction model suffices as a latent encoder of a customers engagement i havent tried negative subsampling yet as the data pipeline is more complex also users will often have long periods of inactivity so there may often be no engagement for a large proportion of any given sequence ie sample ive considered condensing each sample to only include rows ie days on which a user was engaged and adding some indicator feature number_of_days_since_last_engaged to capture the temporal difference anyway im a bit stuck atm so figured id reach out and see if anyone had any thoughts cheers,,,,,
1jn7jvg,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 07:50:09,r text based backprop optimizing generative ai by backpropagating language model feedback recent breakthroughs in artifcial intelligence ai are increasingly driven by systems orchestrating multiple large language models llms and other specialized tools such as search engines and simulators so far these systems are primarily handcrafted by domain experts and tweaked through heuristics rather than being automatically optimized presenting a substantial challenge to accelerating progress the development of artifcial neural networks faced a similar challenge until backpropagation and automatic diferentiation transformed the feld by making optimization turnkey analogously here we introduce textgrad a versatile framework that performs optimization by backpropagating llmgenerated feedback to improve ai systems by leveraging natural language feedback to critique and suggest improvements to any part of a systemfrom prompts to outputs such as molecules or treatment planstextgrad enables the automatic optimization of generative ai systems across diverse tasks we demonstrate textgrads generality and efectiveness through studies in solving phdlevel science problems optimizing plans for radiotherapy treatments designing molecules with specifc properties coding and optimizing agentic systems textgrad empowers scientists and engineers to easily develop impactful generative ai systems interesting paper published on nature on using text based backprop for llm optimization might have some potential but still not a perfect optimization technique edit paper link,,,,,
1jn11wq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 00:58:42,n p transformer model made with php new release rindow neural networks version has been released this release includes samples of transformer models we have published a tutorial on creating transformer models supported in the new version neural machine translation with transformer models in php rindow neural networks is a highlevel neural network library for php it enables powerful machine learning in php rindow neural networks overview rindow neural networks is a highlevel neural network library for php it enables powerful machine learning in php you can build machine learning models such as dnn cnn rnn multihead attention etc you can leverage your knowledge of python and keras popular computer vision and natural language processing samples are available by calling highspeed calculation libraries you can process data at speeds comparable to the cpu version of tensorflow no dedicated machine learning environment is required it can run on an inexpensive laptop nvidia gpu is not required you can utilize the gpu of your laptop what rindow neural networks is not it is not an inferenceonly library it is not a php binding for other machine learning frameworks it is not a library for calling ai web services,,,,,
1jn0ha9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 00:29:36,r d my mostly failed attempt to improve transformers by enriching embeddings with the last hidden state why it didnt scale hi guys i recently posted on this sub about what i believed was a suboptimal feature of decoder transformers namely the fact that the last hidden state which has the potential to carry a lot of information bits embedding dim is collapsed into a single token assuming temperature is that can only carry logvocab_size bits of information i tested a new architecture where the last hidden state of the transformer is used to enrich the embedding of the token that was generated using it it the last hidden state and would you believe it it failed the worst thing about it is that it worked well enough for very small k params transformers to give me hope and feed my self delusional grandiosity i had even given this architecture a name but when i scaled it up a whopping m params the compute overhead stopped being worth the improvement the highlevel idea of why it failed is that every hidden state of every previous token up to the penultimate one the input of the last decoder block are available when predicting the next token thanks to the tokenmixing property of the attention mechanism only the last couple of hidden states the input of the last decoder blocks ffn and final linear layer softmax are unavailable as there are no tokenmixing steps left so this hidden state injection idea is merely about not discarding the work done by the last couple layers which is not that important when there are a lot of decoder layers the marginal importance of each layer decreases anyway i wrote a words post about why it failed with a bit of nice math and some cattle pictures just in case you like cows honestly the post is quite long and technical but you might find one or two interesting things especially if you like to read about the failures of other people,,,,,
1jmsnjt,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 18:21:26,d do you also agree that rlhf is a scam hinton posted this tweet on i have recently seen a video where he is raising the same concerns explaining that rlhf is like you have a car with holes from bullet hallucinating model and you just paint it do you agree,,,,,
1jmsjfx,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 18:16:38,r synergistic eigenanalysis of covariance and hessian matrices for enhanced binary classification on health datasets ,,,,,
1jmlko7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 12:50:22,d what is your cloud setup specs and how did you setup the environment hi there i am planning to setup a cloud environment to run models for research i have beeb using local gpus for a while for small pojects but i would like to at least practice with cloud infrastructure and i am currently interested in using google tpu i would like to know is there any better providers and if anyone here is using cloud services how did they get started and set up the environment i would appreciate tutorials on getting started with setting up cloud vms as i already know there are quite a lot of online websites for running notebook style environments but i am more interested in using the whole machine with ssh thank you and have a great day everyone,,,,,
1jmjstd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 10:59:23,r deltaproduct improving statetracking in linear rnns via householder products code twitter x authors julien siems timur carstensen arber zela frank hutter massimiliano pontil riccardo grazzi equal contribution abstract linear recurrent neural networks linear rnns have emerged as competitive alternatives to transformers for sequence modeling offering efficient training and lineartime inference however existing architectures face a fundamental tradeoff between expressivity and efficiency dictated by the structure of their statetransition matrices while diagonal matrices used in architectures like mamba gla or mlstm yield fast runtime they suffer from severely limited expressivity to address this recent architectures such as gated deltanet and rwkv adopted a diagonal plus rank structure allowing simultaneous tokenchannel mixing which overcomes some expressivity limitations with only a slight decrease in training efficiency building on the interpretation of deltanets recurrence as performing one step of online gradient descent per token on an associative recall loss we introduce deltaproduct which instead takes multiple nh steps per token this naturally leads to diagonal plus rankstatetransition matrices formed as products of nh generalized householder transformations providing a tunable mechanism to balance expressivity and efficiency and a stable recurrence through extensive experiments we demonstrate that deltaproduct achieves superior statetracking and language modeling capabilities while exhibiting significantly improved length extrapolation compared to deltanet additionally we also strengthen the theoretical foundation of deltanet by proving that it can solve dihedral group word problems in just two layers,,,,,
1jmhoq6,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 08:18:04,r anthropic on the biology of a large language model in this paper we focus on applying attribution graphs to study a particular language model claude haiku released in october which serves as anthropics lightweight production model as of this writing we investigate a wide range of phenomena many of these have been explored before see related work but our methods are able to offer additional insight in the context of a frontier model introductory example multistep reasoning we present a simple example where the model performs twohop reasoning in its head to identify that the capital of the state containing dallas is austin we can see and manipulate an internal step where the model represents texas planning in poems we discover that the model plans its outputs ahead of time when writing lines of poetry before beginning to write each line the model identifies potential rhyming words that could appear at the end these preselected rhyming options then shape how the model constructs the entire line multilingual circuits we find the model uses a mixture of languagespecific and abstract languageindependent circuits the languageindependent circuits are more prominent in claude haiku than in a smaller less capable model addition we highlight cases where the same addition circuitry generalizes between very different contexts medical we show an example in which the model identifies candidate diagnoses based on reported symptoms and uses these to inform followup questions about additional symptoms that could corroborate the diagnosis all in its head without writing down its steps entity recognition and hallucinations we uncover circuit mechanisms that allow the model to distinguish between familiar and unfamiliar entities which determine whether it elects to answer a factual question or profess ignorance misfires of this circuit can cause hallucinations refusal of harmful requests we find evidence that the model constructs a generalpurpose harmful requests feature during finetuning aggregated from features representing specific harmful requests learned during pretraining an analysis of a jailbreak we investigate an attack which works by first tricking the model into starting to give dangerous instructions without realizing it after which it continues to do so due to pressure to adhere to syntactic and grammatical rules chainofthought faithfulness we explore the faithfulness of chainofthought reasoning to the models actual mechanisms we are able to distinguish between cases where the model genuinely performs the steps it says it is performing cases where it makes up its reasoning without regard for truth and cases where it works backwards from a humanprovided clue so that its reasoning will end up at the humansuggested answer a model with a hidden goal we also apply our method to a variant of the model that has been finetuned to pursue a secret goal exploiting bugs in its training process while the model avoids revealing its goal when asked our method identifies mechanisms involved in pursuing the goal interestingly these mechanisms are embedded within the models representation of its assistant persona the above excerpt is from a research by anthropic super interesting stuff basically a step closer to interpretability that doesnt just treat the model as a black box if youre into model interpretability safety or inner monologue tracing would love to hear thoughts paper link on the biology of a large language model,,,,,
1jmfg7h,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 05:32:48,d general questions regarding rebuttal phase acl arr feb hi all its my second time submitting to aclrelated conference but i am still pretty confused about the rebuttal phase i recognize that we could not really modify the original manuscript theres simply no such option if there are some suggested changes do we just say that we acknowledge them and we will make such changes if we agree those suggestions in the revised version or you guys actually revise the whole thing and place it in the response the amount of time needed will be substantially different if we actually rewrite the whole thing this might be a silly question but i want know how detailed we should be in the response,,,,,
1jmf17a,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 05:04:57,d difficulty understanding how dpo is different in vlms hi i recently tried to learn about dpo on visual language models and theres just not enough resources to help me understand the difference in implementation i see we are using the image embeddings but anyway using alignment only in language component which boils it down to doing the same thing in llms if there is no vision guidance then how will it learn vision cues to new image and question while answering it post preference alignment it might generate text in a better way but where are we guaranteed that it will give visually grounded outputs as well if the language component is only used in dpo anyone who has tried this can you please educate me on what i am missing out here,,,,,
1jm4aik,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 20:07:09,d curiosity based question if someone with an m pro or core gpu could run this script and share their results hello i was scrolling through youtube and came across this video github repo i was wondering what the results would look like for someone running a macbook with an m pro with a or core gpu just wanted to gauge the performance of that chip because i have heard they arent snappy when it comes to training relatively speaking for a laptop btw while i am looking for m pro performance any other gpu someone with a or anything else or soc results are more than welcome mods i am sorry if i messed up and posted in the wrong subreddit i did read the rules before posting,,,,,
1jm3xa2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 19:51:39,the need for model sharing in fsdp d title typo i meant sharding i understand that fsdp splits an fsdp unit across gpus then at forward time for example gpus allgather to get the part of the unit that they lack and this reconstruct the full unit for them to be able to perform the operation what i dont understand is what added benefit this splitting and compiling provides in other words if a gpu can hold the full fsdp unit anyway eg while performing the forward operation on its minibatch why do we do these extra communication routines instead of just always keeping the weights on that gpu as with data parallelism im not saying that ddp shards the model just to be clear,,,,,
1jm050g,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 17:11:57,d do you think that selfdistillation really works the gains from selfdistillation in image classification problems have not been substantial as published in empirical papers mostly they get at max improvement in test accuracy with the usual order being is there a strong reason to believe it really works other than a dark matter fairytale,,,,,
1jly7g6,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 15:49:37,acl february results are out d acl february results are out how did everyone do thoughts,,,,,
1jlxw5y,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 15:35:39,d two tis vs waiting for a im looking to buy graphics cards that would be best performance to price ive found two tis local to me for total meanwhile i havent really found any s under a grand i know the has significantly more vram but for my current use case thats not a major issue at the current moment unless i start trying to run significantly bigger models like llama b etc im mostly focused on training smaller models quickly and getting relatively fast generation speeds most likely rf learning on games smaller chat bots and creative writing i just want clarification before i go out and buy two of them just to find out that theres something better,,,,,
1jlu6qf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 12:44:05,d asymmetric gaussian filter find the optimal std for horizontal axis i want to use asymmetric gaussian filter to smooth an image because i dont want the equal smoothness in vertical and horizontal with different size of standard deviation σ this means that i want a different σ for the vertical and horizontal lets say σ_v and σ_h i want to use asymmetric gaussian filter to smooth an image because i dont want the equal smoothness in vertical and horizontal with different size of standard deviation σ this means that i want a different σ for the vertical and horizontal lets say σ_v and σ_h for a fixed gaussian filter i can do libraryterra f systemfileexelevtif packageterra r rastf gf terrafocalmatr gauss r_gf terrafocalr w gf fun sum parmfrow c plotr main original raster plotr_gf main gaussian filtered raster and the result will be fixed gaussian filter how can i set different σ for the vertical and horizontal sessioninfo r version ucrt platform x_wmingwx running under windows x build matrix products default locale lc_collateenglish_united statesutf lc_ctypeenglish_united statesutf lc_monetaryenglish_united statesutf lc_numericc lc_timeenglish_united statesutf attached base packages stats graphics grdevices utils datasets methods base other attached packages terra_ loaded via a namespace and not attached compiler_ tools_ rstudioapi_ rcpp_ codetools,,,,,
1jlt27q,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 11:40:42,d how do you make your published plots look so good im noticing that some of the graphics and plots for the papers i am reviewing look really good how do you make them look so good are you using any special python libraries that i dont know about i know some of you are using adobe illustrator and going over the plotsfigures but is there anything else im missing,,,,,
1jlsptp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 11:18:59,d looking for a theoretical niche in nlp coming from a developing country my nlp work naturally leaned toward hci due to limited access to computational resources for training large models im passionate about theory but most recent theoretical advancements in nlp from my observation focus on improving model training and inference i use a gb ram core i desktop for all my rd to give some perspective question are there any theoretical niches in nlp that are more rooted in computer science rather than linguistics and dont require heavy gpu resources,,,,,
1jlsm63,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 11:12:18,r evaluating multistep spatial reasoning in mllms through legobased visual tasks ive been digging into this new benchmark called legopuzzles that tests multimodal language models on spatial reasoning tasks using legostyle puzzles the authors created a dataset where models need to determine if given pieces can be assembled to form a target shape by reasoning about d spatial relationships over multiple steps key points the benchmark contains carefully balanced puzzles with varied complexity reasoning steps each puzzle asks if input lego pieces can be combined to form a target shape following physical connection rules tests were run on leading mllms including gptv claude models gemini pro and llava chainofthought prompting was used to optimize performance results human performance best model claude opus performance decreases as puzzle complexity increases models particularly struggle with negative puzzles where pieces cannot be combined common failure modes include misunderstanding connection mechanisms confusing orientations and losing track in multistep puzzles i think this work highlights a fundamental limitation in current visionlanguage models that isnt getting enough attention despite impressive capabilities in many domains these models lack basic spatial reasoning abilities that humans develop naturally the gap between human and best ai is substantial and suggests we need new architectural approaches specifically designed for processing spatial relationships and physical constraints this benchmark could be particularly valuable for robotics and embodied ai research where understanding how objects can be physically manipulated is essential im curious if future work will explore whether giving models access to d representations rather than just d images might help bridge this gap tldr current mllms perform poorly on spatial reasoning tasks involving legostyle puzzles scoring significantly below human performance with particular difficulty in multistep reasoning and understanding physical constraints full summary is here paper here,,,,,
1jlm1ma,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 03:34:42,d how can i train a model to improve quality of videos with fps inferencing speed i want to train a model to improve quality of videos basically remove compression artifacts and add preserve or generate finer detail any good models i have a good stock video dataset with thousands of videos,,,,,
1jlarz3,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 18:22:17,r alternative implementation of neural ordinary differential equations i was reading the original node paper and to me the approach seemed quite complex and contrived i derived my own version of node that only contains sets of differential equations and can be solved simultaneously without having to do forward and backward pass but only single forward pass i posted an image with derivations can anyone elaborate why arent nodes implemented in this way wouldnt this be easier if not did i make a mistake somewhere node derivation,,,,,
1jlan08,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 18:16:50,machine learning on mac discussion hi just started developing a deeplearning pipeline on mac through matlab the pipeline is for immunohistochemistry image analysis the first two training went well the laptop ran hot but managed it however i expect that as i increase the training data and eventually start image reconstruction my laptop will struggle first training session was min second wmore labels was min laptop specs is m max mbp gb um tb ssd the last training session was epochs with iterationsepoch image split into tiles it was only running on cpu but all cores were running at max unable to use gpu bc matlab on macos doesnt support gpu acceleration looking for advice on what to do next was thinking about using my universitys hpc colab or just continue to run it locally,,,,,
1jlalmz,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 18:15:18,d how do you optimize sota timeseries models patchtst timesnet etc for a fair comparison im benchmarking a new timeseries classification model against patchtst timesnet inceptiontime etc should i use each models default published hyperparameters run my own search lr batch size seq length dropout on the validation split how do you balance tuning effort and compute budget to ensure a fair comparison validation protocol early stopping equal trials thanks ps as mentioned by other people in the thread here im only considering deep learning based methods cnn transformers or combination of both of them,,,,,
1jlalko,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 18:15:14,d anybody successfully doing aspect extraction with spacy id love to learn how you made it happen im struggling to get a spancategorizer from spacy to learn anything all my attempts end up with the same epochs in and f precision and recall are all with a fluctuating increasing loss im trying to determine whether the problem is poor annotation quality or insufficient data a fundamental issue with my objective an invalid approach hyperparameter tuning context im extracting aspects commentary about entities from noisy online text ill use formula to craft an example my entity extraction eg charles yuki driver ferrari team monaco race works well now i want to classify spans like cant believe what i just saw charles is an absolute demon behind the wheel but ferrari is gonna ferrari they need to replace their entire pit wall because their strategies never make sense is an absolute demon behind the wheel driver quality they need to replace their entire pit wall because their strategies never make sense team quality lmao classic monaco i shouldve stayed in bed this race is so boring this race is so boring race quality yuki p what a drive p what a drive driver quality,,,,,
1jl9ze1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 17:49:45,exploring aidriven app development insights from nvidia gtc d hey mlers i wanted to share an insightful conversation from nvidias gtc i had with craig dennis developer educator at cloudflare we delve into building applications using ai tools like claude code creating user interfaces with ai assistance strategies for initiating projects from scratch check out the video here exploring aidriven app development insights from nvidia gtc would love to hear your thoughts and experiences on using ai in app development,,,,,
1jl7453,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 15:50:44,d converting d engineering drawings to d parametric models using ai what is the current state of leveraging artificial intelligence ai to convert d engineering drawings into d parametric models my research has revealed two primary approaches texttocad and imagetocad this method employs user prompts or extracts part features from d drawing images to generate code creating parametric models companies like zoo dev and adamcad are actively exploring this approach machine learning pipelines these pipelines utilize features extracted from d drawings to generate d cad construction sequences often leveraging transformerlike architectures research papers such as sketchashape demonstrate this methodology i would appreciate any insights on other companies research groups or opensource projects addressing this challenge alternative approaches or techniques being explored any information including academic research and industry applications would be valuable in understanding the current landscape and future directions in this field,,,,,
1jl0rgj,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 10:27:05,r channelaware mae framework for multichannel vision transformers with enhanced crosschannel learning ive been exploring the chamaevit model that addresses a key limitation in computer vision processing multichannel imagery effectively unlike standard approaches that treat all spectral channels the same this work introduces channelaware masking with channelspecific embedding layers to better handle the complex relationships between different spectral bands in remote sensing imagery the core technical innovations channelaware masking strategy that applies different masking rates to different channel groups recognizing their unique information content channelspecific embedding layers that maintain distinct representations throughout the network unified architecture that bridges pretraining and finetuning phases eliminating the pretrainingfinetuning discrepancy asymmetric encoderdecoder design where only unmasked tokens go through the full encoder reducing pretraining computation by key results stateoftheart performance on hyperspectral benchmarks accuracy on indian pines and on pavia university effective with minimal labeled data strong performance with as few as labeled samples per class optimal masking rates discovered through ablation for spectral channels for spatial dimensions improvement over supervisedonly approaches through selfsupervised pretraining i think this approach could significantly advance how we process multichannel data beyond just remote sensing medical imaging scientific instruments and industrial sensors all produce complex multichannel data that could benefit from these techniques the ability to learn from limited labeled examples is particularly valuable in domains where annotation is expensive or requires expert knowledge whats most interesting is how the model recognizes that different channels require different treatment this seems like an obvious insight in retrospect but implementing it effectively required several clever architectural decisions the technique bridges the gap between how humans understand multichannel data as distinct but related information sources and how neural networks process it tldr chamaevit introduces channelaware masked autoencoding for multichannel vision transformers demonstrating superior performance on hyperspectral image classification through strategic masking strategies and channelspecific processing especially in limiteddata scenarios full summary is here paper here,,,,,
1jkt42w,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 01:58:59,d gpto image generation and editing how any speculation as to how the recent crop of multimodal models gemini new o grok are doing native image generation so well is the basic approach still to tack on a image token encoderdecoder vqvae etc to the llm backbone and then train on image gen tasks also interested in relevant papers that may point to latest image tokenization and training approaches used to get to such high level of prompt adherence for both generation and editing eg edit after posting this discovered the deepseek janus papers which are super informative may not be the way the other labs do it but seems to be one viable direction llm with adaptor for autoregressive image gen training llm to directly predict velocity for rectified flow,,,,,
1jkqms0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 23:57:13,d suppose you have arbitrarily many bivariate observations drawn at uniform from these shapes what dimensionality reduction feature extraction methods if any could recover the shapes or adequately compress the coordinates to a single dimension in both cases you dont actually know anything about the shapes the data were sampled from in the first case the d data are sampled at uniform from a d line that is shaped like an archimedean spiral maybe it stops at some point or circles back in on itself who knows bivariate observations x_iy_i are drawn at uniform from this line are there any methods that can recover the true onedimensional coordinate eg distance from center along line of these observations ie from the information theoretic compression perspective instead of storing an array of d coordinates we can store a distance or total number of rotations etc along the line the equations describing it in the second case the points are sampled from one of two circles again at uniform from their length here too we can compress the data from two realvalued numbers to eg a single realvalued angle the equations for both circles their centers and radii and a binary indicator corresponding to which circle the point was drawn from bonus rd case now the circles intersect and points are drawn not from their perimeter directly but from some bivariate distribution centered on their perimeter we can still perform a now lossy compression as in but instead of a binary indicator we might have a probability that the point came from one circle or another an angle the probability feature still has lower entropy than a euclidean coordinate is there a fully generic method that can correctly identify the lowerdimensional latent space on which these points lie ie it does not know anything about the generative process besides the fact that there are finite coordinates in two dimensions which methods are able to do this with the smallest amount of data are there any methods that are decent at identifying the latent space of both the spiral and the circles in trying things out kpca rbf kernel does ok and diffusion mapping quite well at identifying a latent dimension separating out the two circles with smaller n amounts of data while a small vanilla vae with a d bottleneck needs lots more observations for decent performance and a few other methods eg isomap umap tsne i tried do quite poorly but it seems like my human eyeballs need quite a bit less data to be able to confidently tease out the true shapes so im curious what methods might be more performant here ofc in these specific examples peeking at the data first lets us narrow the space of viable functions quite a bit the more interesting case is when our circles are embedded on some wacky d manifold in d space or whatever and visual inspection does not work especially well but then one hopes the fully automated methods used there are able to resolve things in a much simpler d first,,,,,
1jknxj4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 21:58:10,d does preprocessing commonvoice hurt accuracy hey ive just preprocessed the commonvoice mozilla dataset and i noticed that a lot of the wav files had missing blanks silence so i trimmed them but heres the surprising partwhen i trained a cnn model the raw unprocessed data achieved accuracy while the preprocessed version only got could it be that the missing blank silence in the dataset actually plays an important role in the models performance should i just use the raw unprocessed data since the original recordings are already a consistent seconds long the preprocessed dataset after trimming varies between seconds and its performing worse would love to hear your thoughts on this,,,,,
1jknrd2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 21:50:47,r comfe an interpretable head for vision transformers interpretable computer vision models explain their classifications through comparing the distances between the local embeddings of an image and a set of prototypes that represent the training data however these approaches introduce additional hyperparameters that need to be tuned to apply to new datasets scale poorly and are more computationally intensive to train in comparison to blackbox approaches in this work we introduce component features comfe a highly scalable interpretablebydesign image classification head for pretrained vision transformers vits that can obtain competitive performance in comparison to comparable noninterpretable methods comfe is the first interpretable head that we know of and unlike other interpretable approaches can be readily applied to large scale datasets such as imagenetk,,,,,
1jkngt9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 21:38:17,d data for cow segmentation for vision transformer i am working on cow teeth segmentation i have limited amount of data i used cnn and the performance wasnt that good i know vision transformersvit will improve the performance but with the limited data how can i use vit is there any way to generate more similarcow teeth data,,,,,
1jkmc4m,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 20:50:27,d evaluating visual reasoning in llms deeptutor vs gpt vs deepseek r on interpreting figures ive been exploring how well different llmpowered tools handle visual data from academic papers especially in economics where graphs quantile plots and geographic maps often carry crucial meaning that text alone cant fully capture to explore this i compared the performance of deeptutor chatgpt gpt and deepseek deepseek r on interpreting figures from the wellknown economics paper robots and jobs evidence from us labor markets by acemoglu and restrepo the paper the focus was on how these models interpreted figures like fig and which present key insights on wage impacts and geographic robot exposure task example question which demographic group appears most negatively or positively affected by robot exposure across wage quantiles more detail with example responses chatgptgpt gave plausiblesounding text but made inferences not supported by the figures eg implied highwage workers may benefit which contradicts fig did not reference specific quantiles or cite visual evidence deepseekdeepseek r some improvement acknowledged wage differences and mentioned some figure components missed key insights like the lack of positive effect for any group even advanced degree holders which is a central claim of the paper deeptutor cited the th to th percentile range from fig b explicitly mentioned no wage gains for any group including those with advanced degrees synthesized insights from multiple figures and tables to build a more complete interpretation task example question can you explain figure a us map showing robot exposure by region more detail with example responses chatgptgpt paraphrased the text but showed almost no engagement with the visual layout ignored the distinction between panel a and b deepseekdeepseek r acknowledged twopanel structure mentioned shading patterns but lacked specific visual explanation eg geographic or grayscale detail deeptutor identified both panels and explained the grayscale gradient highlighting highexposure regions like the southeast and midwest interpreted panel bs exclusion of automotive industry robots and inferred sectoral patterns crossreferenced other figures eg figure to contextualize labor market impacts advantages and disadvantages of figure understanding summary toolrecognize componentsvisual interpretationrelies on textual datainferential reasoningconsistent with papers results chatgpt gpt no minimal heavily minimal no deepseek deepseek r yes limited heavily limited yes deeptutor yes strong precise minimal strong yes would love feedback how are you evaluating visual comprehension in llms are there other papers youd recommend testing this on if youre doing similar work lets connect or compare notes deeptutor is a tool im working on its designed to help users read and understand complex academic papers including visuals happy to answer questions about it or get feedback from the communitydeeptutor more detail with example responses,,,,,
1jkd393,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 14:28:53,d figuring out how to run simulations using bayesian belief networks hey all i want to run simulations using bayesian belief networks for some decision making i am new to bbn do you all have any suggestions or resources that might be helpful also to add i want to kind of recreate bayesian lab a paid software,,,,,
1jka0cy,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 11:57:42,p volga realtime data processing engine for aiml hi all wanted to share the project ive been working on volga realtime data processingfeature calculation engine tailored for modern aiml systems github blog roadmap what my project does volga allows you to create scalable realtime data processingml feature calculation pipelines which can also be executed in offline mode with the same code without setting upmaintaining complex infra flinkspark with custom data modelsdata services or relying on rd party systems datafeature platforms like tectonai fennelai chalkai if you are in ml space you may have heard about those volga at its core consists of two main parts streaming engine which is a soon to be fully functional alternative to flinkspark streaming with pythonnative runtime and rust for performancecritical parts called the push part ondemand compute layer the pull part a pool of workers to execute arbitrary userdefined logic which can be chained in a directed acyclic graphs at request time in sync with streaming engine which is a common use case for aiml systems eg feature calculationserving for model inference volga also provides unified data models with compiletime schemavalidation and an api stitching both systems together to build modular realtimeoffline general data pipelines or aiml features features pythonnative streaming engine backed by rust that scales to millions of messages persecond with millisecondsscale latency benchmark running volga on eks ondemand compute layer to perform arbitrary dags of request timeinference time calculations in sync with streaming engine brief highlevel architecture overview entity api to build standardized data models with compiletime schema validation pandaslike operators like transform filter join groupbyaggregate drop etc to build modular data pipelines or aiml features with consistent onlineoffline semantics built on top of ray easily integrates with ray ecosystem runs on kubernetes and local machines provides a homogeneous platform with no heavy dependencies on multiple jvmbased systems if you already have ray set up you get the streaming infrastructure for free no need to spin up flinkspark configurable data connectors to readwrite data fromto any third party system quick example define data models via entity decorator from volgaapientity import entity entity field entity class user user_id str fieldkeytrue registered_at datetimedatetime fieldtimestamptrue name str entity class order buyer_id str fieldkeytrue product_id str fieldkeytrue product_type str purchased_at datetimedatetime fieldtimestamptrue product_price float entity class onsaleuserspentinfo user_id str fieldkeytrue timestamp datetimedatetime fieldtimestamptrue avg_spent_d float num_purchases_h int define streamingbatch pipelines via source and pipeline from volgaapipipeline import pipeline from volgaapisource import connector mockonlineconnector source mockofflineconnector users sample user entities orders sample order entities sourceuser def user_source connector return mockofflineconnectorwith_itemsuser__dict__ for user in users sourceorder def order_sourceonline bool true connector this will generate appropriate connector based on param we pass during job graph compilation if online return mockonlineconnectorwith_periodic_itemsorder__dict__ for order in orders period_spurchase_event_delays_s else return mockofflineconnectorwith_itemsorder__dict__ for order in orders pipelinedependenciesuser_source order_source outputonsaleuserspentinfo def user_spent_pipelineusers entity orders entity entity on_sale_purchases ordersfilterlambda x xproduct_type on_sale per_user on_sale_purchasesjoin users left_onbuyer_id right_onuser_id howleft return per_usergroup_bykeysbuyer_idaggregate avgonproduct_price windowd intoavg_spent_d countwindowh intonum_purchases_h renamecolumns purchased_at timestamp buyer_id user_id run offline batch materialization from volgaclientclient import client from volgaapifeature import featurerepository client client pipeline_connector inmemoryactorpipelinedataconnectorbatchfalse store data inmemory can be any other userdefined connector eg rediscassandras note that offline materialization only works for pipeline features at the moment so offline data points you get will match event time not request time clientmaterialize featuresfeaturerepositoryget_featureuser_spent_pipeline pipeline_data_connectorinmemoryactorpipelinedataconnectorbatchfalse _asyncfalse paramsglobal online false get results from storage this will be specific to what db you use keys user_id useruser_id for user in users we user inmemory ray actor offline_res_raw raygetcache_actorget_rangeremotefeature_nameuser_spent_pipeline keyskeys startnone endnone with_timestampsfalse offline_res_flattened item for items in offline_res_raw for item in items offline_res_flattenedsortkeylambda x xtimestamp offline_df pddataframeoffline_res_flattened pprintoffline_df user_id timestamp avg_spent_d num_purchases_h for realtime feature servingcalculation define result entity and ondemand feature from volgaapion_demand import on_demand entity class userstats user_id str fieldkeytrue timestamp datetimedatetime fieldtimestamptrue total_spent float purchase_count int on_demanddependencies user_spent_pipeline name of dependency matches positional argument in function latest name of the query defined in ondemanddataconnector how we access dependant data eg latest last_n average etc def user_statsspent_info onsaleuserspentinfo userstats logic to execute at request time return userstats user_idspent_infouser_id timestampspent_infotimestamp total_spentspent_infoavg_spent_d spent_infonum_purchases_h purchase_countspent_infonum_purchases_h run onlinestreaming materialization job and query results run online materialization clientmaterialize featuresfeaturerepositoryget_featureuser_spent_pipeline pipeline_data_connectorpipeline_connector job_configdefault_streaming_job_config scaling_config _asynctrue paramsglobal online true query features client ondemandclientdefault_on_demand_client_url user_ids user ids you want to query while true request ondemandrequest target_featuresuser_stats feature_keys user_stats user_id user_id for user_id in user_ids query_args user_stats empty for latest can be time range if we have last_n query or any other queryparams configuration defined in data connector response await selfclientrequestrequest for user_id user_stats_raw in zipuser_ids responseresultsuser_stats user_stats userstatsuser_stats_raw pprintfnew feature user_stats__dict__ new feature user_id timestamp t total_spent purchase_count new feature user_id timestamp t total_spent purchase_count new feature user_id timestamp t total_spent purchase_count new feature user_id timestamp t total_spent purchase_count new feature user_id timestamp t total_spent purchase_count target audience the project is meant for data engineers aiml engineers mlopsaiops engineers who want to have general pythonbased streaming pipelines or introduce realtime ml capabilities to their project specifically in feature engineering domain and want to avoid setting upmaintaining complex heterogeneous infra flinksparkcustom data layers or rely on rd party services comparison with existing frameworks flinkspark streaming volga aims to be a fully functional pythonnative with some rust alternative to flink with no dependency on jvm general streaming datastream api volga exposes is very similar to flinks datastream api volga also includes parts necessary for fully operational ml workloads ondemand compute proper modular api bytewax similar functionality wrt general pythonbased streaming usecases but lacks mlspecific parts to provide full spectre of tools for realtime feature engineering ondemand compute proper data modelsapis feature serving feature modularityrepository etc tectonaifennelaichalkai managed servicesfeature platforms that provide endtoend functionality for realtime feature engineering but are black boxes and lead to vendor lockin volga aims to provide the same functionality via combination of streaming and ondemand compute while being opensource and running on a homogeneous platform ie no multiple system to support chronon has similar goal but is also built on existing engines flinkspark with custom scalajava services and lacks flexibility wrt pipelines configurability data models and python integrations whats next volga is currently in alpha with most complex parts of the system in place streaming ondemand layer data models and apis are done the main work now is introducing faulttolerance state persistence and checkpointing finishing operators join and window improving batch execution adding various data connectors and proper observability here is the v release roadmap im posting about the progress and technical details in the blog would be happy to grow the audience and get feedback here is more about motivation high level architecture and indepth streaming engine deign github stars are also extremely helpful if anyone is interested in becoming a contributor happy to hear from you the project is in early stages so its a good opportunity to shape the final result and have a say in critical design decisions thank you,,,,,
1jk9c51,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 11:16:53,r equivariant image generation through translationinvariant task decomposition ive been exploring this new equivariant approach to autoregressive image modeling that addresses a fundamental problem traditional image generation models dont handle transformations like rotations and flips consistently the researchers have developed a framework that ensures equivariance meaning that transforming an input and then processing it produces the same result as processing first and then transforming this is achieved through technical contributions equivariant pixel embeddings that transform properly with the image a novel equivariant pixel ordering method that maintains consistency across transformations integration with autoregressive models for image generation that preserves equivariance properties support for different transformation groups rotations reflections dihedral key results improved loglikelihood scores on cifar and imagenet compared to baseline models generated images maintain consistency and symmetry properties across transformations demonstrated better sample diversity while preserving structural properties showed that both equivariant ordering and embedding components contribute to performance gains i think this approach represents an important step toward more robust image generation systems when models understand fundamental transformation properties they can develop a more coherent internal representation of visual concepts this could potentially lead to better generalization more reliable image editing tools and models that require less data to learn meaningful representations i think the computational complexity challenges mentioned in the limitations are real concerns but the core principles could inspire more efficient implementations the focus on spatial transformations is a natural starting point and extending to other transformation types lighting perspective would be valuable future work tldr a new technique makes image generation models transformationaware by incorporating equivariance properties into autoregressive frameworks improving both quantitative metrics and sample qualityconsistency full summary is here paper here,,,,,
1jk8tad,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 10:42:58,tensorflow not detecting rtx gpu help d i built a new system with rtx in it and wanted to test out some previous models i had built using tensorflow and jupyter notebook but i just cant seem to get tensorflow to detect my gpu i tried running it on wsl ubuntu within a conda environment with python but after installing it it still doesnt detect my gpu when i try building it from source it doesnt build i dont know what to do does anyone here have an rtx series graphics card if so howd you get tensorflow running on your system,,,,,
1jjmm6l,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 15:51:39,d my custom dynamicneuralnetwork hit total loss on arcag at epochsprojected exactmatch validation before finishing epoch hey everyoneim excited and honestly a little stunned by how quickly my fromscratch dynamicneuralnetwork is learning arcagi tasks i built this model over two years after fewer than gradient updates of a full epoch on the example arc training set its already achieved total loss started above crossentropy knowledge distillation loss each cosine similarity to the teacher model combined reward healthy scaled entropy based on these curvesand comparing to distilled baselinesi project it will hit exactmatch accuracy on heldout arc validation by the end of epoch steps with bleu thats stateoftheart narrow reasoning performance for a small model before even finishing one pass through the data this isnt simply overfitting or memorization the models balanced ce vs kd losses rising cosine alignment and robust uncertainty suggest genuine pattern abstraction and its happening faster than any comparable distilled architecture ive seen im sharing because i believe phillnets early trajectory represents a meaningful advance in narrow generalization i introduce phillnet a dynamicneuralnetwork without any prior exposure to arcagi data phillnet distilled knowledge from a teacher and achieved a total training loss of at just epochs steps on the arcagi training set key metrics at this point include balanced crossentropy and knowledgedistillation losses each cosine similarity of with the teachers hidden representations and a combined reward of exceeding typical baseline performance i forecast a heldout exactmatch accuracy of by the end of epoch surpassing stateoftheart distilled models on arc these results suggest phillnet rapidly internalizes complex reasoning patterns marking a substantial leap in narrow generalization capabilities,,,,,
1jjkhbf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 14:20:24,r spatial text rendering enabling textonly llms to see documents hey rmachinelearning i recently published an article titled spatial text rendering pushing the limits of spatial understanding in llms where i share a technique ive been using for quite some time now to help textonly llms process visually complex documents before vision language models vlms became usable i thought it might be useful for anyone working with document processing article link summary this article introduces spatial text rendering str a method that bridges the gap between visually complex documents and textonly llms by preserving the crucial spatial information that gives documents their meaning while visionlanguage models vlms continue to advance we needed an immediate solution that could handle complex financial documents in the mea region but not limited to it including arabic text and mixed righttoleft scripts str uses image processing techniques to extract the documents underlying structure and render it as spatiallyaware text that llms can understand key points and highlights financial documents present unique challenges complex layouts mixed languages and data that require absolute precision spatial text rendering involves document preprocessingdeskewing ocr with spatial coordinates structure extraction and structural line detection we use a textbased rendering approach that translates visual structure into a format llms already understand from their pretraining a compaction process significantly reduces token usage while preserving key information testing showed excellent results across multiple llms claude gpto etc even without finetuning the approach offers an immediate solution for document processing while vlms continue to develop and become more affordable to use link to a comparison of model results on an example document side open discussion one interesting aspect ive observed is that many llms seem to have robust spatial reasoning capabilities from their pretraining alone despite not being explicitly trained for this task this suggests that llms might have absorbed more spatial understanding through their textonly training than previously thought im curious if others have observed and taken advantage of similar capabilities let me know what you think,,,,,
1jk6i69,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 07:48:58,d acl arr feb discussion feb arr reviews will be out soon this is a thread for all types of discussions,,,,,
1jk4qkj,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 05:37:29,d p determining physical anchor points on object hi fellow redditors im pretty far along with a project ive been building and i could use some ideas or dialog on a specific problem problem i need to determine two physical or grabbing or anchoring the positioning logical are handled by other models i have working details looking top down on an object the goal is to find two anchor spots the objects are known and only or variants they are all flat but not d aka have some volume and the dimension varies the goal is to find the center bisect and then half way between the center and edge of object on each side establish a point to anchor too physically my question for all of you what possible strategies or models would you all consider for a task like this i considered using yolov for segmentation and then more simplistic methods for final processing but my solution feels awkward and inefficient the objects are in perfect lighting controlled environment and there is a decent amount of computing power available for the task,,,,,
1jjo5xb,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 16:56:03,d p variational inference for neural network weights in highdimensional spatiotemporal models hey everyone im currently working on a spatiotemporal prediction project for my bayesian ml class using a combination of gnn messagepassing style and lstm the goal is to recursively predict the mean and standard deviation of a target variable over multiple future steps right now im optimizing the negative log likelihood of a predicted gaussian to capture aleatoric uncertainty so far im only feeding in the past values of the target input though i plan to bring in auxiliary variables physical features etc later ive seen some skepticism in this subreddit around using variational inference vi for uncertainty quantification particularly about its expressiveness and scalability still im curious what are some viable approaches for capturing epistemic uncertainty via vi over neural network weights especially in highdimensional settings but im wondering what the best way is to model epistemic uncertainty ideally through variational inference over the network weights my data is pretty highdimensional d structure time space features so any method would need to scale reasonably a few techniques that come to my mind bayes by backprop mcmc dropout maybe even lowrank approximations has anyone had success applying vi to large models like gnn lstm hybrids in a way thats not intractable would love to hear what others have tried or if there are any recent papers worth looking into thanks in advance,,,,,
1jjn3v6,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 16:12:17,r d the disconnect between ai benchmarks and math research current ai systems boast impressive scores on mathematical benchmarks yet when confronted with the questions mathematicians actually ask in their daily research these same systems often struggle and dont even realize they are struggling ive written up some preliminary analysis both with examples i care about and data from running a website that tries to help with exploratory research,,,,,
1jjlwu8,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 15:22:41,dp can i use smplgenerated outputs to train a commercial pose estimation model i plan to train a pose estimation network as part of a pipeline in a product to be commercialized my question is if i can use a pose estimator trained to output smpl pose parameters to generate pseudo ground truths on my own set of images that will be used to train my network i will then use my trained network to output the pose parameters and run forward kinematics on it using my own manually computed limb measurements and for other tasks that does not involve smpl at all this post mentions that it is only the body models that are licensed which is something i do not use at all how true is that i cant use models like openpose or rtmw because they only output the joint positions i need the joint angles for internal limb rotations something that is very difficult impossible to obtain via keypoints,,,,,
1jjkkhi,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 14:24:13,r adaptive token selection via reconstructionbased feature utility for efficient vision encoders ive been looking into this new approach called adaptive token reduction atr for vision transformers which tackles a fundamental efficiency problem in computer vision models transformers have become dominant in vision tasks but they process images by splitting them into hundreds or thousands of tokens which gets computationally expensive fast atr addresses this by adaptively reducing tokens based on their importance to the final prediction the key insight is that not all image regions require equal attention some contain critical information while others are redundant atr uses a twostage method stage a lightweight token scorer assigns importance values to each token stage lowimportance tokens are pruned while similar tokens are merged the reduction happens progressively through the network layers token importance is determined adaptively for each image unlike fixed patterns the results are impressive vitb flop reduction with only accuracy drop on imagenet object detection flop reduction with just ap drop on coco semantic segmentation flop reduction with miou drop on adek works with both supervised models and selfsupervised approaches mae consistently outperforms previous token reduction methods i think this addresses a critical bottleneck in deploying transformer models in production environments where computational resources are limited the ability to maintain of the original accuracy while nearly halving computation is a substantial step toward more efficient vision systems whats particularly valuable is that atr is architectureagnostic it can be integrated into existing transformerbased models without major redesigns this means we could see these efficiency gains applied broadly across computer vision systems im especially interested in how this approach might extend to video models where the token redundancy problem is even more severe due to temporal dimensions tldr atr introduces an adaptive way to reduce token counts in vision transformers by up to while maintaining accuracy it intelligently decides which image regions to keep based on their importance and works across multiple vision tasks full summary is here paper here,,,,,
1jjkcgi,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 14:14:38,d facct doctoral colloquium did any of you applied to facct doctoral colloquium did you already receive any response from the selection process the notification date was march th but i didnt receive anything yet,,,,,
1jjjmj1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 13:41:36,d icml workshops does anyone know when will the list of workshops at icml be published i saw that the workshop notification deadline has passed already a week ago id specifically like to know if there will be a workshop related to geometric deep learning or symmetries in ml and if there is one what is the deadline for submissions thanks,,,,,
1jjh4i5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 11:27:54,a better place for graph learning papers r d we have a paper on graph neural networks that weve been working on for a while over the past year weve submitted it to several toptier ml conferences neurips icml and log but unfortunately it hasnt been accepted at this point were considering submitting it to a different venue do you have any suggestions for conferences or workshops that might be a good fit also any feedback or comments on the paper would be greatly appreciated,,,,,
1jjfwoq,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 10:06:59,d scopus listing of conferences like icmliclrneurips i know a bit stupid question because how considered these journals are in the community but as a phd student for my publications only scopus listed publications are considered i googled a bit but could not find information on the scopus listing of these conferences do you have any knowledge on this,,,,,
1jixiqu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 18:12:29,p how to improve the performance of my classifier so far ive trained a model through m rows i used smote crossvalidation method i also tried not using smote and the performance of the model was relatively close the data is highly imbalance approximately best model i got so far is a gbm model wondering how i can further improve the performance of the model basically ones that are predicted correctly will increase price the ones that are predicted as will reduce price goal is maximize revenue,,,,,
1jizocl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 19:36:57,p efficient language model built on wikitext a simpler alternative to transformers source code results included hi all got gpt to draft the rest of this as i am not as good at explaining things would be great to hear some feedback on this work and whether it seems like its worth continuing experimenting with please feel free to use and modify the source code for your own experiments but please credit me if youre doing anything cool with it the tldr is made a model that is vastly more efficient than transformers and has good eval metrics validation loss perplexity hey everyone i recently worked on a language model project and wanted to share it with you the goal was to build an efficient model that can understand and generate textsimilar to how transformers workbut with less computational overhead ill explain what i did in simple terms and share both the code and the evaluation results what is this project about traditional transformers transformers are a popular type of model for language tasks but they perform something called full selfattention which means every word in a sentence looks at every other word this leads to high computational costs especially for longer texts my approach i built a model that uses a method called hierarchical snapshot modeling instead of having every word interact with every other word the model compresses the sequence into a smaller set of snapshot tokens think of these snapshots as summary points that capture the key ideas of the text key ideas behind the model enhanced positional encoding what it means the model learns not only where each word is in a sentence but also how words relate to each other over distances why its cool this helps the model understand longrange connections in text without extra heavy computations dynamic snapshot aggregation what it means instead of simply averaging these snapshot tokens the model uses an attention mechanism a way to weight the importance of each snapshot to decide which parts of the text are most important why its cool this allows the model to focus on the most informative parts of the text and ignore less useful parts efficient graph layers what it means the model uses layers that only let words close to each other interact rather than forcing all words to interact it also combines local details with a global overview why its cool this sparse connectivity significantly reduces the number of calculations required making the model faster and more efficient hybrid adaptive techniques what it means the model includes options for experimenting with even more efficient attention methods inspired by recent research so that it can adaptively choose which words to pay attention to why its cool its a flexible design that could potentially lead to even more improvements in the future how does it compare to traditional transformers efficiency standard transformers compute interactions between all pairs of words quadratic complexity my model reduces this by summarizing the sequence into snapshot tokens making it more efficient especially on longer texts size performance with about million parameters this model is in the same ballpark as some small transformer models like certain configurations of transformerxl that have been used on the wikitext dataset our evaluation showed validation loss perplexity these numbers indicate that the model is performing well on the task even though it is more efficient whats next ive made the full source code available below along with detailed evaluation logs this project is a proofofconcept that efficient modeling is possible without the heavy computational cost of full selfattention whether youre just curious about language models or looking to experiment with new ideas in nlp i hope you find this work interesting import os osenvironxla_flags xla_gpu_enable_command_buffer import tensorflow as tf import math import re import numpy as np from collections import counter from tqdm import tqdm enable xla jit compilation tfconfigoptimizerset_jittrue hugging face datasets spacy and nltk assumed installed from datasets import load_dataset import spacy import nltk nltkdownloadpunkt from nltktranslatebleu_score import sentence_bleu printtensorflow version tf__version__ printgpu available lentfconfiglist_physical_devicesgpu model components def split_headsx num_heads x batch seq_len total_dim batch num_heads seq_len d total_dim tfshapex d total_dim num_heads x tfreshapex tfshapex tfshapex num_heads d return tftransposex perm enhanced positional encoding relative position bias class relativepositionbiastfkeraslayerslayer def __init__self max_seq_len num_snapshots num_heads max_distance max_seq_len maximum sequence length num_snapshots number of snapshot tokens virtual query positions num_heads number of attention heads max_distance maximum relative distance to consider will be clipped superrelativepositionbias self__init__ selfmax_seq_len max_seq_len selfnum_snapshots num_snapshots selfnum_heads num_heads selfmax_distance max_distance create an embedding table for relative distances in the range max_distance max_distance selfrelative_embedding tfkeraslayersembedding max_distance num_heads precompute snapshot positions as evenly spaced indices as integers in max_seq_len selfsnapshot_positions tfcasttflinspace max_seq_len num_snapshots tfint def callself token_positions token_positions b seq_len with integer positions compute relative distances between each snapshot query and each token key expand snapshot positions to num_snapshots and token_positions to b seq_len token_positions tfcasttoken_positions tfint snapshot_positions tfreshapeselfsnapshot_positions selfnum_snapshots token_positions_expanded tfexpand_dimstoken_positions axis b seq_len relative_distance token_positions_expanded snapshot_positions b num_snapshots seq_len clip distances and shift to nonnegative indices for embedding lookup clipped_distance tfclip_by_valuerelative_distance selfmax_distance selfmax_distance clipped_distance selfmax_distance now in max_distance lookup the bias for each relative distance output shape b num_snapshots seq_len num_heads bias selfrelative_embeddingclipped_distance transpose to b num_heads num_snapshots seq_len so it can be added to attention scores bias tftransposebias perm return bias multihead snapshot module with dynamic aggregation and optional linear attention class multiheadsnapshotmoduletfkeraslayerslayer def __init__self embed_dim num_heads snapshot_dim num_snapshots max_seq_len use_linear_attentionfalse embed_dim final model embedding dimension num_heads number of snapshot heads snapshot_dim perhead dimension num_snapshots fixed number of snapshot tokens max_seq_len maximum sequence length for relative positional bias use_linear_attention flag to optionally use an approximate linear attention mechanism supermultiheadsnapshotmodule self__init__ selfnum_heads num_heads selfsnapshot_dim snapshot_dim perhead dimension selfnum_snapshots num_snapshots total_snapshot_dim num_heads snapshot_dim trainable snapshot tokens shape num_snapshots total_snapshot_dim selfsnapshot_tokens selfadd_weight shapenum_snapshots total_snapshot_dim initializerrandom_normal trainabletrue selfkey_proj tfkeraslayersdensetotal_snapshot_dim selfvalue_proj tfkeraslayersdensetotal_snapshot_dim selfquery_proj tfkeraslayersdensetotal_snapshot_dim selfout_proj tfkeraslayersdenseembed_dim relative positional bias layer selfrel_pos_bias relativepositionbiasmax_seq_len num_snapshots num_heads dynamic aggregation instead of averaging snapshot tokens learn to weight them selfsnapshot_agg tfkeraslayersdense flag for potential hybrid attention mechanisms selfuse_linear_attention use_linear_attention def callself x token_positionsnone x b seq_len embed_dim batch_size tfshapex seq_len tfshapex keys selfkey_projx b seq_len total_snapshot_dim values selfvalue_projx b seq_len total_snapshot_dim expand snapshot tokens b num_snapshots total_snapshot_dim snapshot tfexpand_dimsselfsnapshot_tokens axis snapshot tftilesnapshot batch_size queries selfquery_projsnapshot b num_snapshots total_snapshot_dim keys split_headskeys selfnum_heads b num_heads seq_len snapshot_dim values split_headsvalues selfnum_heads b num_heads seq_len snapshot_dim queries split_headsqueries selfnum_heads b num_heads num_snapshots snapshot_dim d tfcastselfsnapshot_dim tffloat scale tfmathsqrtd standard dotproduct attention scores attn_scores tfmatmulqueries keys transpose_btrue scale b num_heads num_snapshots seq_len integrate relative positional bias if token positions are provided if token_positions is not none rel_bias selfrel_pos_biastoken_positions b num_heads num_snapshots seq_len attn_scores rel_bias optionally one could implement a linear attention variant here if selfuse_linear_attention placeholder implement linear attention approximations eg using kernel feature maps for now we continue with standard softmax attention pass attn_weights tfnnsoftmaxattn_scores axis head_output tfmatmulattn_weights values b num_heads num_snapshots snapshot_dim head_output tftransposehead_output perm b num_snapshots num_heads snapshot_dim combined tfreshapehead_output batch_size selfnum_snapshots selfnum_heads selfsnapshot_dim dynamic snapshot aggregation using learned attentionbased pooling agg_weights selfsnapshot_aggcombined b num_snapshots agg_weights tfnnsoftmaxagg_weights axis b num_snapshots global_snapshot tfreduce_sumcombined agg_weights axis b num_heads snapshot_dim output selfout_projglobal_snapshot b embed_dim return output spatial graph layer with sparse connectivity hierarchical aggregation and adaptive gating class spatialgraphlayertfkeraslayerslayer def __init__self embed_dim sparse_thresholdnone use_hierarchicalfalse residual_scale embed_dim embedding dimension sparse_threshold if provided only tokens with distances below this threshold contribute to messages use_hierarchical if true incorporates a global context via a hierarchical connection residual_scale scaling factor for the residual connection improved stability superspatialgraphlayer self__init__ selfembed_dim embed_dim selfsparse_threshold sparse_threshold selfuse_hierarchical use_hierarchical selfresidual_scale residual_scale selfcoord_proj tfkeraslayersdense selfmessage_proj tfkeraslayersdenseembed_dim selfupdate_proj tfkeraslayersdenseembed_dim selfnorm tfkeraslayerslayernormalization if selfuse_hierarchical selfglobal_proj tfkeraslayersdenseembed_dim adaptive gating mechanism to allow tokens to dynamically control the update selfgate_proj tfkeraslayersdenseembed_dim activationsigmoid def callself x x b seq_len embed_dim coords selfcoord_projx b seq_len coords_sq tfreduce_sumtfsquarecoords axis keepdimstrue b seq_len distances coords_sq tftransposecoords_sq perm tfmatmulcoords coords transpose_btrue distances tfmaximumdistances sigma edge_weights tfexpdistances sigma b seq_len seq_len apply sparse connectivity if a threshold is specified if selfsparse_threshold is not none mask tfcastdistances selfsparse_threshold tffloat edge_weights edge_weights mask edge_weights edge_weights tfreduce_sumedge_weights axis keepdimstrue e else edge_weights edge_weights tfreduce_sumedge_weights axis keepdimstrue e messages selfmessage_projx b seq_len embed_dim aggregated tfmatmuledge_weights messages b seq_len embed_dim update selfupdate_projaggregated adaptive gating compute a gate from the input to modulate the update gate selfgate_projx update update gate hierarchical connection add global context if enabled if selfuse_hierarchical global_context tfreduce_meanx axis keepdimstrue global_context selfglobal_projglobal_context update global_context shape b embed_dim broadcasts to b seq_len embed_dim updated selfnormx update selfresidual_scale return updated hierarchical snapshot model class hierarchicalsnapshotmodeltfkerasmodel def __init__self vocab_size max_seq_len embed_dim num_layers snapshot_dim num_snapshots group_size num_snapshot_heads dropout_rate superhierarchicalsnapshotmodel self__init__ selfvocab_size vocab_size selftoken_embed tfkeraslayersembeddingvocab_size embed_dim selfabs_pos_embed tfkeraslayersembeddingmax_seq_len embed_dim selfgrouped_pos_embed groupedpositionalembeddingmax_seq_len group_size embed_dim pass max_seq_len to the snapshot module for relative bias computation selfmulti_head_snapshot multiheadsnapshotmodule embed_dim num_snapshot_heads snapshot_dim num_snapshots max_seq_len you can adjust the graph layer with sparse_threshold and hierarchical flags as needed selfgraph_layers spatialgraphlayerembed_dim sparse_threshold use_hierarchicaltrue residual_scale for _ in rangenum_layers selfout_proj tfkeraslayersdensevocab_size selfdropout tfkeraslayersdropoutdropout_rate def callself inputs trainingfalse inputs tuple token_ids positions group_ids token_ids positions group_ids inputs x selftoken_embedtoken_ids abs_pos selfabs_pos_embedpositions grouped_pos selfgrouped_pos_embedpositions group_ids x x abs_pos grouped_pos x selfdropoutx trainingtraining global context from multihead snapshot attention pass the token positions to enable relative positional bias snapshot_vector selfmulti_head_snapshotx token_positionspositions b embed_dim snapshot_bias tfexpand_dimssnapshot_vector axis b embed_dim x x snapshot_bias for layer in selfgraph_layers x layerx logits selfout_projx return logits redefining the groupedpositionalembedding for completeness class groupedpositionalembeddingtfkeraslayerslayer def __init__self max_position group_size embed_dim supergroupedpositionalembedding self__init__ selfabs_embedding tfkeraslayersembeddingmax_position embed_dim num_groups max_position group_size group_size selfgroup_embedding tfkeraslayersembeddingnum_groups embed_dim def callself positions group_ids pos_embed selfabs_embeddingpositions group_embed selfgroup_embeddinggroup_ids return pos_embed group_embed data loading preprocessing wikitext printloading wikitext dataset english dataset load_datasetwikitext wikitextv train_sentences datasettraintext valid_sentences datasetvalidationtext nlp_en spacyloaden_core_web_sm def tokenize_entext return tokentext for token in nlp_entext def build_vocabsentences tokenizer min_freq counter counter for sentence in sentences tokens tokenizersentence counterupdatetokens specials pad sos eos unk vocab token i for i token in enumeratespecials for token freq in counteritems if freq min_freq and token not in vocab vocabtoken lenvocab return vocab printbuilding vocabulary vocab build_vocabtrain_sentences tokenize_en min_freq vocab_size lenvocab printvocab size vocab_size def tokens_to_idstokens vocab return vocabgettoken vocabunk for token in tokens def collate_fnsentences batch_token_ids batch_positions batch_group_ids for sentence in sentences tokens tokenize_ensentence tokens sos tokens eos token_ids tokens_to_idstokens vocab positions listrangelentoken_ids group_ids group punct for token in tokens group_idsappendgroup if token in punct group batch_token_idsappendtoken_ids batch_positionsappendpositions batch_group_idsappendgroup_ids max_len maxlenseq for seq in batch_token_ids for i in rangelenbatch_token_ids pad_len max_len lenbatch_token_idsi batch_token_idsi vocabpad pad_len batch_positionsi pad_len batch_group_idsi pad_len inputs seq for seq in batch_token_ids targets seq for seq in batch_token_ids positions seq for seq in batch_positions group_ids seq for seq in batch_group_ids return nparrayinputs dtypenpint nparraypositions dtypenpint nparraygroup_ids dtypenpint nparraytargets dtypenpint def generatorsentences batch_size batch for sentence in sentences if sentencestrip batchappendsentence if lenbatch batch_size yield collate_fnbatch batch if batch yield collate_fnbatch batch_size train_dataset tfdatadatasetfrom_generator lambda generatortrain_sentences batch_sizebatch_size output_signature tftensorspecshapenone none dtypetfint tftensorspecshapenone none dtypetfint tftensorspecshapenone none dtypetfint tftensorspecshapenone none dtypetfint valid_dataset tfdatadatasetfrom_generator lambda generatorvalid_sentences batch_sizebatch_size output_signature tftensorspecshapenone none dtypetfint tftensorspecshapenone none dtypetfint tftensorspecshapenone none dtypetfint tftensorspecshapenone none dtypetfint map dataset elements to inputs positions group_ids targets train_dataset train_datasetmaplambda a b c d a b c d num_parallel_callstfdataautotune valid_dataset valid_datasetmaplambda a b c d a b c d num_parallel_callstfdataautotune repeat training dataset so modelfit doesnt run out of data compute steps_per_epoch train_dataset train_datasetrepeatprefetchtfdataautotune valid_dataset valid_datasetprefetchtfdataautotune build inverse vocabulary for decoding inv_vocab i token for token i in vocabitems training setup device gpu if lentfconfiglist_physical_devicesgpu else cpu printtraining on device device updated hyperparameters for increased capacity max_seq_len embed_dim increased embedding dimension num_layers more layers snapshot_dim perhead dimension can be tuned num_snapshots group_size num_snapshot_heads more snapshot heads num_epochs more epochs learning_rate e lower learning rate for more stable training define masked loss and accuracy functions to ignore pad tokens def masked_loss_fnpad_token_id def loss_fny_true y_pred loss tfkeraslossessparse_categorical_crossentropyy_true y_pred from_logitstrue mask tfcasttfnot_equaly_true pad_token_id tffloat loss mask return tfreduce_sumloss tfreduce_summask return loss_fn def masked_accuracy_fnpad_token_id def accuracy_fny_true y_pred y_pred_ids tfargmaxy_pred axis output_typetfint mask tfcasttfnot_equaly_true pad_token_id tffloat correct tfcasttfequaly_true y_pred_ids tffloat mask return tfreduce_sumcorrect tfreduce_summask return accuracy_fn pad_token_id vocabpad with tfdevicedevice model hierarchicalsnapshotmodel vocab_size max_seq_len embed_dim num_layers snapshot_dim num_snapshots group_size num_snapshot_heads dropout_rate modelcompile optimizertfkerasoptimizersadamlearning_rate lossmasked_loss_fnpad_token_id metricsmasked_accuracy_fnpad_token_id compute steps per epoch based on training examples steps_per_epoch mathceillens for s in train_sentences if sstrip batch_size validation_steps mathceillens for s in valid_sentences if sstrip batch_size add a learning rate scheduler callback lr_scheduler tfkerascallbacksreducelronplateaumonitorval_loss factor patience min_lre verbose checkpoint_dir kaggleworkingcheckpoints osmakedirscheckpoint_dir exist_oktrue checkpoint_path ospathjoincheckpoint_dir cpepochdweightsh checkpoint_callback tfkerascallbacksmodelcheckpoint filepathcheckpoint_path save_weights_onlytrue verbose save_freqepoch history modelfit train_dataset epochsnum_epochs steps_per_epochsteps_per_epoch validation_datavalid_dataset validation_stepsvalidation_steps callbackscheckpoint_callback lr_scheduler printtraining complete evaluation functions def evaluate_perplexitymodel dataset total_loss total_tokens for inputs positions group_ids targets in tqdmdataset descevaluating perplexity logits modelinputs positions group_ids trainingfalse loss tfkeraslossessparse_categorical_crossentropytargets logits from_logitstrue mask tfcasttfnot_equaltargets pad_token_id tffloat loss mask total_loss tfreduce_sumlossnumpy total_tokens tfreduce_summasknumpy avg_loss total_loss total_tokens perplexity mathexpavg_loss return avg_loss perplexity avg_loss perplexity evaluate_perplexitymodel valid_dataset printfvalidation loss avg_lossf perplexity perplexityf def generate_textmodel prompt_tokens max_length temperature generated prompt_tokenscopy for _ in rangemax_length input_seq tfexpand_dimsgenerated axis current_length positions tfexpand_dimstfrangelengenerated axis group_ids tfzeros_likeinput_seq dtypetfint logits modelinput_seq positions group_ids trainingfalse temperature sampling instead of pure greedy last_logits logits temperature next_token tfrandomcategoricaltfexpand_dimslast_logits num_samples numpyitem generatedappendnext_token if next_token vocabeos break return generated def decode_tokenstoken_list inv_vocab words inv_vocabgettoken unk for token in token_list if token not in vocabsos vocabeos vocabpad return joinwords def evaluate_bleumodel sentences num_examples max_gen_length temperature scores for sentence in sentencesnum_examples tokens tokenize_ensentence tokens sos tokens eos token_ids tokens_to_idstokens vocab prompt vocabsos generated_ids generate_textmodel prompt max_lengthmax_gen_length temperaturetemperature generated_text decode_tokensgenerated_ids inv_vocab reference_text decode_tokenstoken_ids inv_vocab bleu sentence_bleureference_textsplit generated_textsplit scoresappendbleu return npmeanscores bleu_score evaluate_bleumodel valid_sentences num_examples max_gen_length temperature printaverage bleu score on validation examples bleu_score evaluation logs epoch s msstep accuracy_fn loss val_accuracy_fn val_loss learning_rate e validation loss perplexity final thoughts this project is an experiment in making language models more efficient without sacrificing performance im excited to see how these ideas could be expanded and improved in the future if you have any questions suggestions or just want to chat about language models please feel free to comment cheers and happy coding,,,,,
1jjena7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 08:29:33,p is there anyway to finetune stable video diffusion with minimal vram im posting here instead of rgenerativeai since there seems to be more active people here is there any way to use as little vram as possible for finetuning stable video diffusion ive downloaded the official pretrained svd model the description says this model was trained to generate frames at resolution x given a context frame of the same size thus for full finetuning do i have to stick with frames and x resolution which requires vram what i want for now is just to debug and test the training loop with slightly smaller vram ex with then would it be possible for me to do things like reducing the number of frames or lowering spatial resolution since currently i have only smaller gpu i just want to verify that the training code runs correctly before scaling up would appreciate any tips thanks,,,,,
1jjc39f,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 05:18:34,p seeking alternatives to trd for d object detection using pointcloud data from realsense d camera im currently working on a d object detection project using pointcloud data captured from a realsense d camera heres my current setup ive collected custom datasets from a realsense d camera and formatted them to match the sunrgbd dataset structure im using the trd model for detecting different objects however im not satisfied with the detection performance im getting with trd what im specifically looking for models that utilize pointcloud data xyzrgb including color information for learning ways to improve trds performance sota models that can perform d object detection with sunrgbd dataset format using pointcloud any recommended models that can be trained with custom pointcloud datasets ive searched through papers with code and github but havent found suitable opensource alternatives yet any suggestions or guidance would be greatly appreciated development environment ubuntu ros humble python c,,,,,
1jj1l2y,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 20:51:25,p building a retrievalaugmented generationbased voice assistant and chat for github repos get insights instantly hey devs im working on making a ragpowered voice assistant that lets you chat with your github repos and get insightsfaster and smarter chat with your repo to ask questions and get deep insights live voice assistant for seamless repo interaction visual knowledge graph to map key components relationships collaborative network analysis to see who works well together streamlined knowledge transfer for easy onboarding interview tool in progress ask questions to a user based on their github activity ill be deploying on hugging face soon and id love your feedback check it out contribute here github link and hugging face space,,,,,
1jj1249,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 20:30:20,d what exactly counts as uncertainty quantification im trying to wrap my head around whats exactly meant by uncertainty quantification uq in the context of bayesian ml and sequential decisionmaking is uq specifically about estimating things like confidence intervals or posterior variance or is it more general like estimating the full predictive distribution since we quantify its parameters for example if i fit a mixture model to approximate a distribution is that already considered uq since im essentially quantifying uncertainty and what about methods like expected improvement or value at risk they integrate over a distribution to give you a single number that reflects something about uncertainty but are those considered uq methods or are they acquisitionutility functions that use uncertainty estimates rather than quantify them this came up as i am currently writing a section on a related topic and trying to draw a clear line between uq and acquisition functions but the more i think about it the blurrier it gets especially in the context of singleline acquisition functions like ei ei clearly fits in uq field and uses the full distribution often a gaussian but its unclear which part can be referred to as uq there if we had a nongaussian process i understand this might be an openended question but i would love to hear different opinions people might have on this topic,,,,,
1jiuqib,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 16:22:48,d icml review discussion icml reviews will release tomorrow march aoe this thread is open to discuss about reviews and importantly celebrate successful reviews let us all remember that review system is noisy and we all suffer from it and this doesnt define our research impact lets all prioritise reviews which enhance our papers feel free to discuss your experiences,,,,,
1ji1s82,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 15:27:02,d conformal prediction in industry hi everyone conformal prediction has been very popular in the statisticsmachine learning community for uncertainty quantification i was wondering if this is only an academic popularity or are there deployed pipelines in the industry which uses conformal prediction as tool from my limited understanding it looks like the research groups in the industry are using it but the method still hasnt reached to production anyone with experience in industry can comment on this,,,,,
1ji3fvs,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 16:39:31,d multimodal generative models principles applications and implementation guide for unified media generation ,,,,,
1ji7cx3,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 19:24:01,d is mcp really a solution or just another layer we dont need hey folks i recently came across model context protocol mcp it is being pitched as this usbc for ai helping models like gpt or claude pull context from tools like postgres github and confluence in a standardized way it sounds promising but the more i dug in the more it started feeling like we are overengineering a fairly simple problem like do we really need a whole clientserver architecture with its own protocol just to fetch a few rows from a db or call an api i ended up making a video about it on my channel logical lenses breaking down the architecture and sharing my take also touched on how langchain and other frameworks already kind of solve the same thing curious what others think has anyone here actually used mcp in a real setup did it make life easier or just add complexity here is the link if you want to check out the video looking forward to your thoughts especially if you disagree,,,,,
1jihs98,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 03:35:57,d reviewed several acl papers on data resources and feel that llms are undermining this field i reviewed multiple acl papers in the field of resources and evaluation a concerning trend i noticed in almost all of them except one is that researchers are increasingly using llms to generate socalled benchmark datasets and then claiming that these datasets can be used for trainingfinetuning and testing llms or other models the types of data involved include but are not limited to conversations citation information in scholarly papers and questionanswering datasets etc this review cycle gave me the impression that fewer and fewer researchers are willing to curate data manually or apply rigorous and logical methods to pre or postprocess datasets instead they rely on llms to generate data because it is easy and convenient the typical process involves downloading existing data performing minimal preprocessing designing a few prompts and paying openai a fee the dataset is created some of them may have a look at the correctness of the data but can they represent the text data in the real world i do not see this kind of check because this approach is so straightforward these papers often lack substantial content to make the paper look like a paper authors usually apply models often llms to their generated datasets and compare model performance but the primary goal of a resource paper should be to provide a highquality dataset and convincingly demonstrate its value to the research community it is not merely to compare model performance on a dataset of unknown quality and representativeness adding numerous model evaluation experiments does little to achieve this main objective because the data quality is not evaluated i am quite open to synthetic data even when generated by llms but do most of these papers truly add value to the research community im not sure and sometimes i honestly dont even know how to assign scores to them,,,,,
1jils6h,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 08:16:43,d is the term interference used in the domain of aiml a general term is inference to request a generate from a model but what about the term interference compare it to the meaning in physics etc is this term used at all apparently this is the time it takes until the promptrequest reaches the model,,,,,
1jilo1l,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 08:07:18,d relationship between loss and lr schedule i am training a neural network on a large computer vision dataset during my experiments ive noticed something strange no matter how i schedule the learning rate the loss is always following it see the images as examples loss in blue and lr is red the loss is softmaxbased this is even true for something like a cyclic learning rate last plot has anyone noticed something like this before and how should i deal with this to find the optimal configuration for the training note the xaxis is not directly comparable since its values depend on some parameters of the environment all trainings were performed for roughly the same number of epochs,,,,,
1jiia8n,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 04:05:04,p machine learning visualized want to see machine learning algorithms training i made a website machine learning visualized implements and mathematically derives machine learning algorithms from firstprinciples the output of each notebook is a visualization of the machine learning algorithm throughout its training phase feel free to contribute to this opensource resource this will be especially helpful for students in an introductory machine learning class github,,,,,
1jifxob,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 01:55:51,r how can i dynamically estimate parameters a and b in this equation deltapt adeltapt bqp i am currently using pinns to estimate the parameters dynamically do you think its necessary in this case is there a simpler way my data is periodic and these parameters change for every cycle and can change within the cycle too depending on operating conditions or disturbances,,,,,
1jifoxl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 01:43:08,p and d country recognition model hey all wondering if anyone knows of or has created a country recognition model learning model that could be fed text and have it spit out what country the text is talking about have been working on one with positive and negative comments about each country took nearly a week to build but im only getting about confidence when trained as a bert model with epoch i went back to the drawing board and thought i wonder has anyone else done this for example i provide the following text for example nothing specific just random news headline grab russian troops are advancing into ukraine the model would return the country name russia as the country being spoken about anyone have anything like this know of anything or could give me some suggestions,,,,,
1jidrkx,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 00:06:58,p local ai voice assistant with ollama gtts i built a local voice assistant that integrates ollama for ai responses it uses gtts for texttospeech and pygame for audio playback it queues and plays responses asynchronously supports ffmpeg for audio speed adjustments and maintains conversation history in a lightweight jsonbased memory system google also recently released their chirp voice models recently which sound a lot more natural however you need to modify the code slightly and add in your own api key json file some key features local ai processing uses ollama to generate responses audio handling queues and prioritizes tts chunks to ensure smooth playback ffmpeg integration speed mod tts output if ffmpeg is installed optional i added this as i think google tts sounds better at around x speed memory system retains past interactions for contextual responses instructions have ollama installed clone repo install requirements run app i figured others might find it useful or want to tinker with it repo is here if you want to check it out and would love any feedback github,,,,,
1jicpo2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 23:16:58,discussion what does gpu ondemand pricing mean and how can i optimize server runtime im trying to get a better understanding of ondemand pricing and how to ensure a server only runs when needed for instance ondemand pricing if a server costs per hour does that mean ill pay roughly a month if its running optimizing server usage what are the best strategies to make sure the server is active only when a client requires it are autoscaling scheduled startstop or serverless architectures effective in this case any insights experiences or best practices on these topics would be really helpful,,,,,
1ji6xlv,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 19:05:50,d topological deep learning promising or hype hi all some of you might know that there is a relatively niche and emerging subfield of deep learning labeled by authors as topological deep learning one of such recent papers about on the field is a position paper position topological deep learning is the new frontier for relational learning which has a rather bold title and also has some names that also appear a lot in the relatively parallel fields of geometric deep learning and graph representation learning such as michael bronstein pietro lio petar velickovic etc i think there already is some dispute about geometric deep learning there was a post about it here the other day i am curious if anybody has any opinions about topological deep learning ill abbreviate tdl from now and what it promises from what i have understood what tdl promises is a method of incorporating higherorder structural relationships in representations or architectures and i am aware that some of these are used in biology especially as molecules also have some topological properties similar to the use cases of geometric deep learning i guess but again i am just curious if these promises are realistic my main questions are we can try to include higherorder relations but gnns can already do that cant they we can just do higherorder message passing in gnns and how would a topological approach help it including higherorder relations by simply looking at every possible higherorder interaction is computationally not feasible is it afaik higherorder gnns have also good expressive capacity but sometimes are not used because of these limitations would tdl offer a way to do this faster i think similar to geometric deep learning sometimes it might look that there is fancy maths but no groundbreaking achievements or i might be ignorant about this apologies if so are there any problems where we would say tdl is necessary or in a few years likely tdl methods will be sota i think that position paper i mentioned refers to these problems but as it stands it is a position paper clearly people will be all for tdl i want an outside perspective if anyone has any knowledge or criticisms,,,,,
1ji57cm,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 17:53:29,d how are you handling reproducibility in your ml work what are your approaches for ensuring reproducibility in your ml work any specific processes or tools that you use what are their proscons,,,,,
1ji1x2t,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 15:33:02,r best loss for rdh task i am working on reversible data hiding task in short i have to predict dot images from cross images dot images are formed by taking an image and zeroing every alternate pixel a pixel will be surrounded by on sides cross are complementary of dot images merging both cross and dot images will give the original image image sizes are x model parameter size is between k and k whats the best loss for this task i am looking to increase the histogram error peak then second priority is improving psnr appreciate any other suggestions or ideas,,,,,
1ji09oy,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 14:17:35,question about transfer learning the coral approach for domain adaptation dp for context im doing an undergrad project on breast cancer classification focussed on both debiasing and transfer learning ive been trying to understand the correlation alignment approach and while i understand the mathematics behind it im struggling to understand how it helps models with transfer learning from my understanding transfer learning is training a model from a dataset d_s in the s source domain and testing it on a dataset d_t in a totally different domain t target the problem here lies in the fact that both sets due to being in different domains will typically have completely different features so domain adaptation techniques are used to encode d_t into an sdomain dataset so it can be used on a previously sdomain trained model now coral does the opposite which confuses me as per the original paper coral instead encodes d_s into the t domain then you i presume train the model on the encoded d_s but why the purpose of transfer learning is that when you want to feed your trained model an unseen dataset of a completely different type it can make predictions no problem if you have to each time retrain the model on the new unseen instance then this is not transfer learning right sorry if this is a really silly question im just getting really confused on why coral is designed the way it is coral can surely be reversed as in t s instead of s t right thank you in advance edit edited to remove paper link didnt see rule,,,,,
1jhw20e,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 10:11:34,d locally hosted databricks solution warning this is not an llm post i use databricks at work i like how it simplifies the end to end i want something similar but for local research i dont care about productionisation are there any open source selfhosted platforms that unify delta lake apache spark and mlflow or similar i can spin up the individual containers but a nice interface that unifies key technologies like this would be nice i find its difficult to keep research projects organised over time if not any one have advice on organising research projects beyond just folder systems that become quickly inflexible i have a minio server housing my raw data in jsons and csvs im bored of manipulating raw files and storing them in the cleaned folder,,,,,
1jhvq8d,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 09:48:12,p formula race prediction model shanghai gp results analysis i built a machine learning model to predict formula race results focusing on the recent shanghai grand prix this post shares the methodology and compares predictions against actual race outcomes methodology i implemented a random forest regression model trained on historical f data seasons with these key features qualifying position influence historical driver performance metrics team strength assessment driver experience factors circuitspecific performance patterns handling of driver lineup changes eg hamilton to ferrari implementation details data pipeline collection automated data fetching via fastf api processing comprehensive feature engineering for drivers and teams training random forest regressor optimized with crossvalidation evaluation mean squared error and position accuracy metrics features engineering created composite metrics for driver consistency developed team strength indicators based on historical performance designed circuitspecific performance indicators technical stack python fastf pandas numpy scikitlearn matplotlibseaborn predictions vs actual results my model predicted the following podium max verstappen red bull liam lawson red bull george russell mercedes the actual race saw russell finish p as predicted while leclerc and hamilton finished p and p respectively analysis insights the model successfully captured mercedes pace at shanghai correctly placing russell on the podium overestimated red bulls dominance particularly for their second driver the model showed promising predictive power for midfield performance feature importance analysis revealed qualifying position and teamspecific historical performance at the circuit were the strongest predictors future work incorporate weather condition impact modeling with rainfall probability distributions implement tire degradation modeling based on compound selection and track temperature develop race incident probability modeling using historical safety carred flag data enhance driver headtohead performance analytics i welcome any suggestions for improving the model methodology or techniques for handling the unique aspects of f racing in predictive modeling shanghai f prediction model,,,,,
1jhv82o,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 09:10:19,dsynthetic image generation for object detection im working on a project to generate synthetic datasets for training object detection models and could use some insights from the community my goal is to create realistic images of random environments with objects eg shelves with items complete with annotations object_id center_x center_y width height to train a model that can detect these objects in realworld settings the idea is to bypass the laborintensive process of manually annotating bounding boxes on real images so far ive programmatically generated some synthetic scenes and trained a model on them the images include objects placed in specific locations and ive added basic variations like lighting and positioning however i havent conducted enough tests to accurately compare the models performance against one trained on a realworld dataset im curious about the realism of the synthetic data and how well it translates to realworld detection tasks has anyone here experimented with generating synthetic images for object detection what techniques or tools did you use to make them realistic eg lighting shadows texture variations more importantly what kind of accuracy did you achieve compared to models trained on real data id love to hear about your experiencessuccesses challenges or any pitfalls to watch out for thanks in advance for any advice or pointers,,,,,
1jhtjxg,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 07:05:13,r grpobased reinforcement learning improves math reasoning in small llms with limited resources just read a new paper exploring how to make small language models bb params better at reasoning through reinforcement learning the researchers compare different rl approaches ppo vs dpo on mathematical and logical reasoning tasks the core approach involves finetuning small llms using reinforcement learning to improve their reasoning abilities with careful attention to dataset quality and reward design key technical points they evaluated ppo and dpo on b and b llama models using mathematical gsmk svamp and logical reasoning logiqa benchmarks ppo performs better for mathematical reasoning while dpo excels at logical reasoning combining ppodpo yielded the best overall results achieving up to on gsmk with a b model highquality training data with stepbystep reasoning traces was crucial for success reward modeling focused on reasoning quality rather than just answer correctness b models consistently outperformed b models but both showed significant improvements i think this work could change how we approach building reasoning capabilities into llms instead of just scaling to massive models careful rl training could make smaller more deployable models viable for reasoningheavy applications this feels like a step toward democratizing access to reasoningcapable ai without requiring enormous computational resources whats particularly interesting is how the training methodology seems more important than raw parameter count for some tasks the b models trained with this approach performed competitively with much larger models on specific reasoning benchmarks tldr researchers showed small language models bb can develop strong reasoning capabilities through reinforcement learning with ppo working best for math problems and dpo for logical reasoning the combination of these techniques with highquality training data resulted in performance competitive with much larger models full summary is here paper here,,,,,
1jhrkz1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-23 04:48:18,time series to predict categorical values r p am trying use use a bunch of time series values categorical and numeric values to create a logistic regression to predict a categorical value eg heart rate data available for weeks age numeric gender categorical smoker categorical to predict if someone will have a heart attack categorical this is not the exact study i am doing just giving an example which i can replicate for my own work wondeiring if you guys can help in how can i include the persons likelihood of having a heart attack by using the entire time series data without converting it into a single value eg avg heart rate as a predictor any papersyoutube videos reference material on how a similar model has been setup would be very helpful is this even possible thank you,,,,,
1jhhlbg,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 20:16:10,r what is the best models to convert pdfs to text trying to analyze jfk files they are all in pdfs which i was able to convert to pngs now i need a way to convert them to text i tried trocr and it wasnt good qwenvlb was good at summarization but i just want to convert everything to text when i instructed to do so model was hallucinating like putting weong department names any suggestions about which model is perfect for this png text conversion,,,,,
1jhhk5u,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 20:14:47,d difficulty understanding realtime forecasting conceptually i understand some use cases for realtime machine learning usage such as training a model for fraud detection and querying new data against that object via api however i have had a lot of clients request realtime time series forecasts is the only way to do this via a full retrain every time a new data point comes in i struggle to understand this conceptually it feels unbelievably computationally inefficient to do so especially when we have huge datasets i could run batch retraining daily or weekly but thats still not real time am i missing something obvious thanks all,,,,,
1jhh5m7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 19:57:28,d help needed help needed hello everyone i am working on clustering models for this i have used self supervised technique in which kldiv is used as one of loss functions but when writing code i have missed the instruction of torchkldiv to have input in logspace instead i have used input and target both in probability space that makes loss fuction qlogqp qtarget pinput and it gives accuracy of almost acc nmi ari but after recognising the fault i changed the input in logspace but it drastically changed the accuracy to around nmi and ari is lower this is happening for several datasets can anyone elaborate why its happening moreover can the wrong loss be assumed to be a good loss for the model then whats the theoretical concepts,,,,,
1jhc1qr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 16:15:12,myceliumwebserver running evolutionary fungus nodes locally to train ai models communication happens via activitypub p ,,,,,
1jhap5l,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 15:15:26,d on sentiment analysis hi guys i am trying to see where sentiment analysis can be useful and whether starting such a company today is a goodbad idea from what i understand companies that use sentiment analysis usually deliver things like categories where the product may be relevant what are the relative awareness figures of members of a competitive set what are roughly the positive neutral negative leanings for brands in a competitive set what marketing executions have attracted attention do you have any other suggestions on how to leverage sentiment analysis from social media,,,,,
1jh8avu,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 13:21:24,d looking to contribute to opensource machine learning projects hi everyone im a full stack developer with a background in machine learning and reinforcement learning looking to contribute to interesting ml projects id love to find a project where i can both apply my skills and continue learning from the community my background msc in information and communications systems engineering experience with python tensorflow pytorch and scikitlearn worked on reinforcement learning projects specifically ddpg for robotics applications professional experience as a machine learning engineer and full stack developer currently enhancing my knowledge through a post graduate program in ai ml areas of interest reinforcement learning computer vision sensor data processing robotics integration deep learning applications im open to contributing to existing opensource projects research implementations or joining small teams working on interesting ml challenges i can dedicate consistent time each week and am looking for something that will help me grow while making meaningful contributions if youre working on something cool or know of projects seeking contributors with my skill set id appreciate any recommendations also happy to share my github or portfolio via dm for those interested in collaborating thanks,,,,,
1jh6lr0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 11:44:12,researchcan ai remember irreversibly like a brain does i built a model that tries and it works surprisingly well most ai models update memory reversibly but biological memory doesnt work that way the brain forgets evolves and never undoes anything i built a model called tmemneti which uses entropybased decay irreversible memory updates high kl divergence tools like recurrence plots permutation entropy and lyapunov exponents still being refined it beats transformers and cnns on longterm retention and memory asymmetry paper its still a work in progress some chaos metrics need tightening but early results show signs of real emergent memory is this a step toward more brainlike memory in ai open to thoughts questions and critique,,,,,
1jh6clm,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 11:27:40,domain adaptation for ct scans for pretraining rp i was wondering what kind of domain adaptation techniques are standard while working with multidomain data for medical images i need to pretrain my encoder with ctmr images which are single channelled and then use it for rgb images ie channels it is a segmentation problem what domain adaptation techniques or image processing are standard just clone ct channel to all three it wont add any new information though use some windowing colouring etc image processing techniques to atleast add some variation but i feel too old school for research papers use stylecyclegans but there is no problem implementation anywhere nor any pretrained models for ctmr to rgbsurgical any inputs will be valueable,,,,,
1jh5ib9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 10:29:09,d looking for applications of ml in the chemical industry hello i am trying to look for industrial applications of mldl in the chemical industry not for research but for ideas of a project proposal the it infra in the chemical industry is generations older than the tech industry and many of the things happening in the tech industry are not viable to be applied in the chemical industry for this reason alone let alone the difference in the use case most of the papers i have read were academic reviews of research topics not what is currently being applied in the industry i want to find what is the current gap between the current research trends and the realized applications of ai in this industry would like if someone could link me to good papersarticles that discuss this exclusively,,,,,
1jh4c92,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 09:02:28,ml models for fraud detection d i am currently planning to write my master thesis i stumbled across fraud detection in some courses and i find it to be an interesting topic unfortunately the methods we looked at were rather outdated and i would prefer to use some promising models from what ive read so far ensemble methods like boosting and isolation forests are very common in that field and more recently gnns and rl are used what development is currently promising or would you rather consider doing something more traditional like neural networks i would also be interested if you know any platforms news pages which are interesting to keep up with the developments in anomalyfraud detection appreciate your help,,,,,
1jh3cod,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 07:47:29,digital twins extended reality and artificial intelligence in manufacturing reconfiguration review r digital twins extended reality and artificial intelligence in manufacturing reconfiguration how are dts and ai reshaping manufacturing systems this review explores how dts reduce system reconfiguration time xr enhances humanmachine interaction and ai realtime decisions link to the full research paper available in the description on youtube tiktok or researchgate youtube tiktok researchgate key benefits realtime monitoring predictive analytics with dts enhanced situational awareness through xr aidriven automation for reconfiguration processes digitaltwin smartmanufacturing curious about realworld applications in smart manufacturing,,,,,
1jh2y7e,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 07:17:05,r a survey of efficient reasoning approaches for large language models reducing computational overhead in chainofthought methods this survey investigates the overthinking problem in llms where models generate unnecessarily long reasoning chains that waste computation without improving accuracy the authors categorize efficient reasoning optimization techniques into three main approaches reasoning length reduction methods include skipstep cot removing redundant steps direct reasoning skipping intermediate steps and structured approaches like tree of thoughts early exit mechanisms confidencebased stopping verifier models that check intermediate results and adaptive thresholds that adjust based on question difficulty reasoning acceleration techniques for making each reasoning step more efficient through parallelization compressed representations and distillation key technical findings models often reach their best answer before completing full reasoning chains efficient reasoning can reduce computation by while maintaining comparable accuracy the tree of thoughts approach offers better results than linear reasoning by exploring multiple reasoning paths lightweight models can effectively determine when reasoning should stop taskspecific optimization is necessary no single approach works best for all scenarios reinforcement learning shows promise for teaching models when to terminate reasoning i think this work could significantly impact both research and practical applications of llms by reducing computational requirements without sacrificing performance these techniques could make sophisticated reasoning more accessible and affordable the categorization framework helps clarify the landscape of efficiency approaches providing a foundation for researchers to build upon the most intriguing direction to me is the development of adaptive reasoning strategies that dynamically adjust based on problem difficulty this mirrors human cognition we spend more mental effort on complex problems and less on simple ones if implemented effectively these approaches could lead to llms that are not just more efficient but also more naturally intelligent in how they allocate their reasoning resources tldr llms tend to overthink with unnecessarily long reasoning chains this survey categorizes techniques for more efficient reasoning into three approaches reducing reasoning length implementing early stopping and accelerating reasoning steps experiments show these methods can cut computation by without sacrificing accuracy full summary is here paper here,,,,,
1jh2gyb,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 06:41:11,research peer review process in conferences i am new to reviewing i have a couple of questions that i would like to ask experienced reviewers what do you think about iclr publishing rejected papers in openreview is it ok to have the papers there although it is rejected i got papers to review for a conference and of them are iclr rejected ones i am already biased now reading the reviews there how much time do you spend reviewing a paper i am a phd student i spent almost half a day yesterday trying to review a page paper thoroughly am i over doing it should i spend days for reviewing papers,,,,,
1jh2bax,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 06:29:33,d advice how do i become a reviewer hello all some background i have publications subset of them are in acl eacl tkdd emnlp almost all but one publication is ndrd author its been a year since i have last published and i would like to participate as a reviewer at these conferences i am a masters graduate what are the requirements to be a reviewer i dont see applications for reviewers in most conferences so how do i become one do i just email the chairs from the conference any advice is appreciated tia,,,,,
1jgwjjk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 00:56:04,d are gnns obsolete because of transformers ive always been interested in graph neural networks gnns but havent had the chance to study them deeply now that transformers are prevalent the attention mechanismwhere each query interacts with all keysfeels conceptually similar to operations on densely connected graphs this makes me wonder if transformers can be considered a type of gnn is there any truth to this can transformers actually replace gnns,,,,,
1jglv23,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 17:07:34,d best practices for diagramming ml system internals well in todays world we have so many systems that use ml under the hood usually what happens before the development of these systems is that engineers use a diagramming language ie uml for sw to design the architecture and the working internals but i find it hard to apply this to ml systems because they involve many different components like pipelines software pieces apis databases scheduled task and more so my question is what is the standardized way to diagram these systems can uml be adapted for this or are there better frameworksresources for diagramming ml system internals im looking for best practices and learning materials,,,,,
1jgjf73,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 15:25:28,r scalewise distillation of diffusion models today our team at yandex research has published a new paper here is the gist from the authors who are less active here than myself tldr weve distilled sd largemedium into fast fewstep generators which are as quick as twostep sampling and outperform other distillation methods within the same compute budget distilling texttoimage diffusion models dms is a hot topic for speeding them up cutting steps down to but getting to steps is still tough for the sota texttoimage dms out there so theres room to push the limits further by exploring other degrees of freedom one of such degrees is spatial resolution at which dms operate on intermediate diffusion steps this paper takes inspiration from the recent insight that dms approximate spectral autoregression and suggests that dms dont need to work at high resolutions for high noise levels the intuition is simple noise vanishes high frequences we dont need to waste compute by modeling them at early diffusion steps the proposed method swd combines this idea with sota diffusion distillation approaches for fewstep sampling and produces images by gradually upscaling them at each diffusion step importantly all within a single model no cascading required images generated with swd distilled sd paper code hf demo,,,,,
1jgfo2h,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 12:29:45,r looking for an estimator to measure the coverage of sampled points in ndimensional space lets say i have a blackbox function that maps inputs to points in an ndimensional space the functions output space may be finite or infinite given a set of sampled points obtained from different inputs i want to estimate how much of the functions possible output space is covered by my samples for a simpler case assume the function returns a single numerical value instead of a vector by analyzing the range of observed values i can estimate an interval that likely contains future outputs if a newly sampled point falls outside this range my confidence in the estimated range should decrease if it falls within the range my confidence should increase what kind of estimator am i looking for i appreciate any insights,,,,,
1jgfkrl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 12:24:50,d the recurrent delusion how ml collectively forgot what rnns were built for when our field first developed rnns they were the obvious choice for sequential tasks until vanishingexploding gradients and the inherently unparallelizable backpropagation through time bptt limited their scalability years of collective research addressing these issues ultimately birthed the transformermassively parallelizable scalable and easier to train marking the revolutionary arrival of the golden age of attention the ignored alternatives state space models and parallelizable lstm variants emerged as potential solutions to the parallelization issues of traditional rnns but they sacrificed the ability to generalize to problems in the nc complexity class which vanilla rnns can do staying within tc like transformers this isnt just theoreticalafter over years and billions spent optimizing hardware for transformers these alternatives offered virtually no compelling advantage the chain of thought contradiction fast forward to chain of thought prompting suddenly were training models with elaborate reasoning examples often including this bizarre theatrical process where llms are deliberately trained to make mistakes just to demonstrate correction capabilities its computational theater but deepseeks r approach is where this paradox becomes undeniable theyre using reinforcement learning to train reasoning chains which is genuinely innovative but why are we still using transformers for what is fundamentally a recurrent reasoning process let me dissect this architectural mismatch were tokenizing chains of thought severely restricting their expressive potential the reasoning process itself functions as a hidden state without ground truth labels which is actually perfect otherwise wed just be training glorified memorization this scenario logically demands a bpttlike approach which would be completely unparallelizable even with transformers since we lack intermediate labels yet were circumventing this entire problem with grpo and somehow getting spectacular results were essentially performing recurrent optimization while stubbornly avoiding recurrent architectures the intellectual contradiction is mindboggling its as if the entire field developed collective amnesia about the fundamental principles of sequential processing that motivated rnns in the first place the billiondollar blindspot lets cut to the chase rnns can solve problems in the nc complexity class that transformers fundamentally cannot this isnt academic nitpickingits about computational expressiveness that directly impacts reasoning capabilities a transformer forced to use input sequences as pseudornn states is crippled for reasoning poor length generalization inefficient information pruning and suboptimal cache performance yet rs approachusing reinforcement learning without bpttworks brilliantly and could resurrect even basic rnns with superior results at inference the process is identical store state sample outputs track probabilities then adjust based on reasoning quality so why arent we applying this to architectures designed for sequential reasoning this architectural mismatch seems strikingly obvious yet remains unaddressed is it infrastructure lockin publication pressure or has the field collectively forgotten why recurrent networks were created in the first place the emperor has no clothes the question is who will be the first to point it out,,,,,
1jgf1pd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 11:54:21,r tulip enhancing visionlanguage models with multimodal contrastive learning and generative regularization ive been diving into tulip a new approach for visionlanguage pretraining that addresses what the authors call the seeing half a scene problem in models like clip the key insight is combining contrastive learning with masked feature prediction in a unified framework technical approach uses a dualencoder architecture vit text transformer similar to clip introduces blockwise masking with patch shuffling a new visual masking strategy combines two training objectives contrastive learning and masked feature prediction leverages both real imagetext pairs and synthetic data from diffusion models key results stateoftheart performance across multiple benchmarks on imagenetk classification vitb box ap on coco detection miou on adek segmentation shows that neither contrastive learning nor masked prediction alone is sufficient works well even with limited text descriptions m imagetext pairs performance scales effectively with increased model size and pretraining data i think this approach represents an important shift in how we build visionlanguage models by forcing models to understand both global imagetext relationships and local visual feature relationships we can create systems with more comprehensive visual understanding the use of synthetic data to supplement real datasets is also pragmatic it helps address data scarcity for specific concepts without requiring expensive annotation the blockwise masking strategy seems particularly clever instead of randomly masking individual patches which can be too easy for models to solve this approach creates a more challenging pretraining task that encourages understanding of spatial relationships tldr tulip combines contrastive learning with masked feature prediction to create visionlanguage models that understand both whole images and their detailed components it achieves sota results across multiple vision tasks and demonstrates effective use of synthetic training data full summary is here paper here,,,,,
1jgf0lf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 11:52:31,p alphazero applied to tetris incl other mcts policies most implementations of reinforcement learning applied to tetris have been based on handcrafted feature vectors and reduction of the action space actiongrouping while training agents on the full observation and actionspace has failed i created a project to learn to play tetris from raw observations with the full action space as a human player would without the previously mentioned assumptions it is configurable to use any tree policy for the montecarlo tree search like thompson sampling ucb or other custom policies for experimentation beyond puct the training script is designed in an onpolicy sequential way and an agent can be trained using a cpu or gpu on a single machine have a look and play around with it its a great way to learn about mcts,,,,,
1jg9ou5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 05:31:56,n introducing flashtokenizer the worlds fastest tokenizer library for llm inference were excited to share flashtokenizer a highperformance tokenizer engine optimized for large language model llm inference serving developed in c flashtokenizer offers unparalleled speed and accuracy making it the fastest tokenizer library available key features unmatched speed flashtokenizer delivers rapid tokenization significantly reducing latency in llm inference tasks high accuracy ensures precise tokenization maintaining the integrity of your language models easy integration designed for seamless integration into existing workflows supporting various llm architecturesgithub whether youre working on natural language processing applications or deploying llms at scale flashtokenizer is engineered to enhance performance and efficiency explore the repository and experience the speed of flashtokenizer today we welcome your feedback and contributions to further improve flashtokenizer,,,,,
1jg0up9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-20 21:57:09,r revisiting semisupervised learning in the era of foundation models semisupervised learning ssl leverages abundant unlabeled data alongside limited labeled data to enhance learning as vision foundation models vfms increasingly serve as the backbone of vision applications it remains unclear how ssl interacts with these pretrained models to address this gap we develop new ssl benchmark datasets where frozen vfms underperform and systematically evaluate representative ssl methods we make a surprising observation parameterefficient finetuning peft using only labeled data often matches ssl performance even without leveraging unlabeled data this motivates us to revisit selftraining a conceptually simple ssl baseline where we use the supervised peft model to pseudolabel unlabeled data for further training to overcome the notorious issue of noisy pseudolabels we propose ensembling multiple peft approaches and vfm backbones to produce more robust pseudolabels empirical results validate the effectiveness of this simple yet powerful approach providing actionable insights into ssl with vfms and paving the way for more scalable and practical semisupervised learning in the era of foundation models paper link,,,,,
1jfykdy,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-20 20:21:19,d journals with no publication charge or article processing fee what are some good journals without any publication fee or processing charges,,,,,
1jfvwar,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-20 18:31:18,d sentiment analysis of meetings trancripts weve working on a project to predict sentiment of client meeting transcripts into negative neutral or positive im using siebert model currently which is roberta large variant to predict sentiment of each speaker sentences upto tokens as this is its context length of a transcript and then applying some logic on sentences preds were defining whole transcript sentiment issue is it is giving around recall and precision to tackle this we fed neutral predicted transcripts to llama b it improved recall to but precision fell in range im looking for ideasdifferent approaches to tackle this issue any suggestions are welcome,,,,,
1jfmovl,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-20 11:28:01,r analyzing failure modes in sliding windowbased time series clustering this paper explores the mathematical properties of sliding window clustering proving several fundamental behaviors that explain why certain clustering approaches succeed or fail the key technical contribution is a set of mathematical proofs showing that the clustering behavior of sliding windows depends critically on window size and data symmetry properties small windows produce flat centroids they mathematically prove that as window size becomes small relative to signal frequency cluster centroids approach constant functions nearsymmetric data creates meaningless clusters when data satisfies ft ft they show clustering becomes essentially random large windows naturally form interval clusters they prove that optimal clustering of large sliding windows forms intervals contiguous chunks of the time series formal mathematical framework the paper establishes theoretical foundations using properties of autocorrelation and similarity measures the main results include theorem shows that small windows produce nearly identical flat cluster centroids proposition demonstrates that with symmetric periodic signals windows are assigned to clusters essentially randomly theorem establishes that with large windows optimal clusters form intervals several corollaries extend these results to specific clustering algorithms and data types i think this work explains phenomena many practitioners have observed empirically but couldnt fully explain when working with sliding windows ive often noticed that small windows produce uninformative clusters while larger ones tend to identify meaningful temporal segments now we have mathematical explanations for why this happens i think these results could guide better algorithm design for time series analysis understanding the mathematical limitations of different window sizes should help researchers avoid approaches that are doomed to fail due to fundamental constraints rather than implementation issues tldr the paper provides mathematical proofs showing that small sliding windows produce flat meaningless clusters nearly symmetric data makes clustering ineffective and large windows naturally form intervalbased clusters explaining why some sliding window clustering approaches work while others fail full summary is here paper here,,,,,
1jfiowc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-20 06:31:09,d improving largecontext llm calls with filter llms i am working on a system that initially used rag to fetch relevant information but recently i found better performance using a caglargecontext llm architecture where i do the following pull all the relevant data use gemini flash to take the query the retrieved data and filter it to only the relevant data pass the filtered data to the most performant llm for the task to respond to the prompt the second step helps mitigate what ive seen referred to as the lost in the middle phenomenon and distraction in my case scaling over time is not a major concern as the context window size stays more or less consistent the problem and in hindsight its quite obvious is that even after being filtering the document is still big and for the filter llm to output that filtered document takes up to s for gemini flash that latency isnt acceptable in the system i have considered solutions like enumerating all the data in the context window and getting the filter llm to only output the indices of relevant data effectively letting us do lossless compression on the output prompt meaning we can generate the output faster in my testing and im not sure if this is really an issue ive found that this produces different results for the filter which concerns me a bit so i am still a bit stuck on how best to speed up the filter im curious if anyone else here has tried an architecture like this with filtering large context with an llmis knowledgeable enough to weigh in,,,,,
1jfev1c,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-20 02:33:44,d seeking advice on finetuning qwqb model hi rmachinelearning im planning to finetune the qwqb model on a custom dataset and would appreciate some guidance from those with experience my current situation i have a dataset in alpaca format im unsure about the optimal finetuning approach for qwqb i do have few questions can qwqb be effectively finetuned using the alpaca format dataset or would this be suboptimal should i convert my data to use the think format instead if so would generating a new dataset using deepseek or claude be recommended does qwqb support qlora finetuning or is full finetuning required id appreciate hearing about your experience finetuning qwqb including any challenges faced and helpful configurations or optimization tips thank you in advance for any insights,,,,,
1jf6lxm,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-19 20:15:35,d resources for the score based generative models can anyone send some begineer freindly resources for the score based generative models all videosblogspapers which i see are diving directly into the mathematical explanation which is hard to grasp for me,,,,,
1jf6jmk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-19 20:12:56,d who reviews the papers something is odd happening to the science there is a new paper called transformers without normalization by jiachen zhu xinlei chen kaiming he yann lecun zhuang liu they are selling linear layer with tanh activation as a novel normalization layer was there any review done it really looks like some vibe paper review thing i think it should be called parametric tanh activation followed by useless linear layer without activation,,,,,
1jf2rg4,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-19 17:38:34,d iccv desk reject for appendix in main paper anyone else hey everyone our iccv paper just got deskrejected because we included the supplementary material as an appendix in the main pdf which allegedly put us over the page limit given that this year iccv required both the main paper and supplementary material to be submitted on the same date we inferred apparently incorrectly that they were meant to be in the same document for context in other major conferences like neurips and acl where the supplementary deadline is the same as the main paper its completely standard to include an appendix within the main pdf so this desk rejection feels pretty unfair did anyone else make the same mistake were your papers also deskrejected curious to hear how widespread this issue is,,,,,
1jeva17,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-19 11:58:29,r evaluating video models on impossible scenarios a benchmark for generation and understanding of counterfactual videos ipvbench evaluating video generation models with physically impossible scenarios researchers have created a new benchmark called ipvbench to evaluate how well video generation models understand basic physics and logic this benchmark contains carefully crafted prompts that test models on their ability to handle physically impossible scenarios across categories including gravity violations object permanence issues and logical contradictions the key methodology included testing models with both create impossible prompts asking for impossibilities and avoid impossible prompts requesting physically plausible videos evaluating videos through both automated metrics and human assessment testing across multiple stateoftheart models including sora morphe walt show gen runway pika and lavie developing a detailed taxonomy of impossible physics scenarios main findings current sota models produce physically impossible content of the time even when explicitly asked to follow physics laws performance was worst on change impossibilities and contact impossibilities accuracy different models show different impossibility profiles making distinct types of physical reasoning errors strong text understanding doesnt guarantee strong physical reasoning human evaluators easily identified these impossibilities highlighting the gap between ai and human understanding i think this research reveals a fundamental limitation in current video generation systems they lack the intuitive physics understanding that humans develop naturally this matters significantly for applications where physical plausibility is important like simulation education or training robotics systems the benchmark provides a systematic way to measure progress in this area which will be crucial as these models become more widely deployed the taxonomy theyve developed is particularly useful as it gives us a framework for thinking about different types of physical reasoning failures i suspect well see this benchmark become an important tool for improving the next generation of video models tldr ipvbench is a new benchmark testing video models understanding of physical impossibilities current models frequently generate physically impossible content even when instructed not to showing they lack true understanding of how the physical world works full summary is here paper here,,,,,
1jeueo1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-19 11:05:20,d should my dataset be balanced i am making a water leak dataset i cant seem to agree with my team if the dataset should be balanced or unbalanced to reflect real world scenarios because leaks arent that often can someone help its an uni project and we are all sort of beginners,,,,,
1jenmqz,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-19 03:08:39,r rwkv goose with expressive dynamic state evolution rwkv goose with expressive dynamic state evolution bo peng ruichong zhang daniel goldstein eric alcaide haowen hou janna lu william merrill guangyu song kaifeng tan saiteja utpala nathan wilce johan s wind tianyi wu daniel wuttke christian zhouzheng arxiv cscl abstract we present rwkv goose a new sequence modeling architecture along with pretrained language models that establish a new stateoftheart in downstream performance at the billion parameter scale on multilingual tasks and match current sota english language performance despite being trained on dramatically fewer tokens than other top b models nevertheless rwkv models require only constant memory usage and constant inference time per token rwkv introduces a newly generalized formulation of the delta rule with vectorvalued gating and incontext learning rates as well as a relaxed value replacement rule we show that rwkv can perform state tracking and recognize all regular languages while retaining parallelizability of training this exceeds the capabilities of transformers under standard complexity conjectures which are limited to 𝖳𝖢 to demonstrate rwkvs language modeling capability we also present an extended open source trillion token multilingual corpus and train four rwkv models ranging from billion to billion parameters on this dataset to foster openness reproduction and adoption we release our models and dataset component listing at this url and our training and inference code at this url all under the apache license code and website,,,,,
1jep8am,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-19 04:42:38,n call for papers ieee fityr dear researchers we are excited to invite you to submit your research to the st ieee international conference on future intelligent technologies for young researchers fityr which will be held from july in tucson arizona united states ieee fityr provides a premier venue for young researchers to showcase their latest work in ai iot blockchain cloud computing and intelligent systems the conference promotes collaboration and knowledge exchange among emerging scholars in the field of intelligent technologies topics of interest include but are not limited to artificial intelligence and machine learning internet of things iot and edge computing blockchain and decentralized applications cloud computing and serviceoriented architectures cybersecurity privacy and trust in intelligent systems humancentered ai and ethical ai development applications of ai in healthcare smart cities and robotics paper submission important dates paper submission deadline april author notification may final paper submission cameraready june for more details visit we look forward to your contributions and participation in ieee fityr best regards steering committee cisose,,,,,
1jeh3zs,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 21:56:01,r compute sponsorshipsgrants does anyone know of any companies that are providing freediscounted compute grants or sponsorships for people wanting to work on their own research ideas for example i know falai has a research grant program and so does google curious if people know of any others,,,,,
1jefrb3,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 20:58:36,r forget chainofthought reasoning introducing chainofdraft thinking faster and cheaper by writing less i recently stumbled upon a paper by zoom communications yes the zoom we all used during the thing they propose a very simple way to make a model reason but this time they make it much cheaper and faster than what cot currently allows us here is an example of what they changed in the prompt that they give to the model here is how a regular cot model would answer cot reasoning here is how the new chainofdraft model answers chainofdraft reasoning we can see that the answer is much shorter thus having fewer tokens and requiring less computing to generate i checked it myself with gpto and cod actually much much better and faster than cot here is a link to the paper,,,,,
1je93sv,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 16:29:46,r jagged flash attention optimization meta researchers have introduced jagged flash attention a novel technique that significantly enhances the performance and scalability of largescale recommendation systems by combining jagged tensors with flash attention this innovation achieves up to speedup and memory reduction compared to dense attention outperforming even dense flash attention with speedup and better memory efficiency read the full paper write up here,,,,,
1je7vcn,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 15:38:47,d what libraries would you like to see created im looking for ideas for libraries that people might use i work mostly in pytorch these days so something in that area would be ideal im open to all suggestions though also does not have to be neuralnets is sckitlearn missing something you want did somebody publish an amazing algorithm but their implementation is nonexistent or terrible,,,,,
1je79zr,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 15:13:07,p i built a tool to make research papers easier to digest with multilevel summaries audio and interactive notebooks like many people trying to stay current with ml research ive struggled with reading papers consistently the biggest challenges for me were discovering highquality papers in fastmoving areas understanding dense material without spending hours per paper retaining what i read and applying it effectively to address that i started building a tool called streampapers its designed to make academic papers more approachable and easier to learn from its currently free and im still iterating based on feedback the tool includes curated collections of research papers grouped by topic eg transformers prompting retrieval multilevel summaries starter intermediate expert to adapt to different levels of background knowledge audio narration so users can review papers passively interactive jupyter notebooks for handson exploration of ideas interactive games made from paper contents to help reinforce key concepts im also working on the discovery problem surfacing relevant and often overlooked papers from arxiv and conferences the goal is to help researchers students and engineers engage with the literature more efficiently try it id really appreciate thoughts or critiques from this community what would make this genuinely useful in your research or workflow,,,,,
1je53t0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 13:36:00,r smoldocling a compact visionlanguage model for complete document element recognition and markup generation ive been studying smoldocling a new ultracompact visionlanguage model that achieves remarkable efficiency for document understanding the key innovation is combining a small b parameter vision encoder with a b parameter language decoder to create a model that can process documents endtoend while being much smaller than competitors the technical approach consists of efficient architecture b parameters total b vision b language compared to models x larger novel training method pretraining on b tokens of text and document images followed by taskspecific finetuning direct visionlanguage integration vision tokens pass directly to the language decoder preserving spatial information multiresolution processing handles highresolution document images efficiently while maintaining detail recognition performance results matches or exceeds larger models like gptv on document conversion benchmarks f vs speed improvement processes documents approximately x faster than larger counterparts i think this work significantly changes the efficiency equation for document ai by showing that a b parameter model can match or exceed the performance of b parameter models the researchers demonstrate that careful architecture design can be more important than raw parameter count this could enable document processing in more resourceconstrained environments and make these capabilities accessible to more organizations i think the most important implication is for ondevice or privacysensitive document processing many industries like healthcare legal and financial services handle sensitive documents that ideally wouldnt leave local systems a compact but capable model makes this much more feasible tldr smoldocling achieves stateoftheart document understanding performance with just b parameters through careful architecture design and training methodology processing documents x faster than models x larger full summary is here paper here,,,,,
1je3xzf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 12:38:23,d are there realworld benefits to combining blockchain with machine learning hey everyone im curious about use cases at the intersection of blockchain and machine learning i see a lot of theoretical discussiondecentralized ml marketplaces trusted data sharing tamperproof datasets for ai training and so onbut im wondering if youve seen or worked on actual projects where these two technologies add real value together do immutable ledgers or onchain data help ml systems become more trustworthy eg in fraud detection supply chain audits has anyone integrated a smart contract that automates or rewards model predictions any success stories in advertising healthcare or iot where blockchains transparency ensures higherquality training data id love to hear your experienceswhether positive or negativeand any insights on which domains might benefit most or if you think its all hype feel free to share that perspective too thanks in advance,,,,,
1je3j8b,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 12:15:40,p help required for a project using pytorch hooks so im using gpt from huggingface and i want to capture and modify the last layer attention scores using hooks if someone has a better way please let me know heres where im stuck python def forward_hookmodule input output printoutput printoutputshape printoutputshape need to figure out the structure of output modified_output output output return modified_output attach hook to last attention layer hook_layer modeltransformerhattn hook hook_layerregister_forward_hookforward_hook n_heads d_model python printoutputshape torchsize printoutputshape torchsize i understand that is the no of heads is my output sequence length is d_modeln_heads but why are there sets of these in output and output where do i get the headwise attention scores from even if output contains the attention scores i would assume gpt decoder only to create an attention sequence with upper triangular values as zero which i cant seem to find please assist me thanks,,,,,
1jdy405,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 05:42:58,d r is autosklearn depreciated is autosklearn depreciated by any chance i am new to automl and many tutorials out there are for autosklearn however i could not get it to set up in my wsl system i downgraded my python to and set up a new conda env which didnt help either then i followed the instrcution at with commands like sudo aptget install buildessential swig pythondev which didnt do anything either i also tried to install it with pip in a new google notebook and kaggle which also failed i can see that autosklearn only made it to ver does that mean it is discontinued even if it is discontinued can someone still lmk how to set up a compatible environment to get it running thank you,,,,,
1jdv3c5,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 02:41:21,p pytorch transformer stuck in local minima occasionally hi i am working on a project to pretrain a custom transformer model i developed and then finetune it for a downstream task i am pretraining the model on an h cluster and this is working great however i am having some issues finetuning i have been finetuning on two hs using nndataparallel in a jupyter notebook when i first spin up an instance to run this notebook using pbs my model finetunes great and the results are as i expect however several runs later the model gets stuck in a local minima and my loss is stagnant between the model finetuning how i expect and getting stuck in a local minima i changed no code just restarted my kernel i also tried a new node and the first run there resulted in my training loss stuck again the local minima i have tried several things only using one gpu still gets stuck in a local minima setting seeds as well as cuda based deterministics torchbackendscudnndeterministic true torchbackendscudnnbenchmark false at first i thought my training loop was poorly set up however running the same seed twice with a kernel reset in between yielded the same exact results i did this with two sets of seeds and the results from each seed matched its prior run this leads me to be believe something is happening with cuda in the h i am confident my training loop is set up properly and there is a problem with random weight initialization in the cuda kernel i am not sure what is happening and am looking for some pointers should i try using a py script instead of a notebook is this a cudagpu issue any help would be greatly appreciated thanks,,,,,
1jd6hky,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 06:41:29,table structure detection d for the last few weeks i have been wrestling with table transformer to extract table structure and the data from scanned document learned lesson the hard way table transformer paddleocr google doc ai got ocr graphocr and many are good with simple table structure but fails to detect and extract tables with complex structure tables with spanning row spanning cols multi line heading etc are not properly mapped and even the paid service like omniai is not fulfilling the requirements realising that ai is god mode on social media but when it comes to the real business use cases it fails to deliver any suggestions to solve this retraining with my dataset is not easy as i have only around to data samples suggestions are appreciated thanks in advance,,,,,
1jdgfr0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 16:11:58,p trading strategy creation using genetic algorithm i had this idea were we create a genetic algo ga which creates trading strategies genes would the entryexit rules for basics we will also have genes for stop loss and take profit now for the survival test we will run a backtesting module optimizing metrics like profit and losswins ratio,,,,,
1jdqyce,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 23:20:31,d visual explanation of backpropagation feedforward neural network hi i previously shared part part part of the post here part part part here is the part where i share how to implement backpropagation for feedforward neural network thanks,,,,,
1jdq9og,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 22:50:10,research ai dominance requires interpretability our response to the white house ai action plan rfi i recently submitted a response to the white houses request for information on their ai action plan our team argues that interpretabilitynot just capabilitywill determine ai leadership key points true ai mastery requires understanding internal mechanisms not just building powerful black boxes chinese models are gaining an edge in interpretability research due to computational transparency we propose standards like ndif that enable innovation while protecting ip the full response is available here or here to retweet would love to hear the communitys thoughts especially from those working on interpretability,,,,,
1jdpkig,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 22:19:38,p make webassemblypowered python or sql notebooks with ai hey all my friends and i put together an app that generates python notebooks with an llm the unique part is that the notebooks run interactively in the browser powered by webassembly and pyodide you can also download the notebook locally and run it with marimo we had a lot of fun coming up with the example prompts on the homepage including basic machine learning ones involving classical unsupervised and supervised learning as well as more general ones like one that creates a tool for calculating your own python codes complexity the generated notebooks are marimo notebooks which means they can contain interactive ui widgets which reactively run the notebook on interaction,,,,,
1jdiafd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 17:25:16,p i finetuned qwen coder on a single repo and got a improvement in code completion accuracy hey all just wanted to share an interesting experiment i ran to see what kind of performance gains can be achieved by finetuning a coding model to code from a single repo tldr the finetuned model achieves a improvement in the code completion task tab autocomplete accuracy goes from to exact match against ground truth after a short training run of only iterations on a single rtx gpu this is interesting because it shows that there are significant gains to be had by finetuning to your own code highlights of the experiment model qwencoder b bit quantized training data svelte source files from this repo unsloth for lora training with rank sequence length gpu single rtx iterations with effective batch size,,,,,
1jdg2r0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 15:57:20,d where do you share and find research im not a fan of reading the abstract on every arxiv paper and want to just subscribe to something any discord channels or sites you use to communicate research,,,,,
1jdfshf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 15:45:46,d recent trend in crawler traffic on websites getting stuck in facet links i am a web developer maintaining several websites and my colleagues and i have noticed a significant increase in traffic crawling our sites notably getting stuck in what we call search pages facet links in this context facets are the list of links you can use to narrow down search results by category this has been a design pattern for searchlisting pages for many years now and to prevent search index crawlers from navigating these types of pages weve historically used robotstxt files which provide directives for crawlers to follow eg url patterns to avoid delay times between crawls also these facet links have attributes for relnofollow which are supposed to perform a similar function on individual links telling bots not to follow them this worked great for years but a recent trend weve seen is what appear to be crawlers not respecting either of these conventions and proceeding to endlessly crawl these faceted page links as these pages may have a large number of facet links that all slightly vary the result being that we are being inundated by requests for pages we cannot serve from cache this causes requests to bypass cdn level caching like cloudflare and impacts the performance of the site for our authenticated users who manage content also this drives up our hosting costs because even elite plans often have limits eg pantheons is million requests a month one of my clients whose typical monthly visits was around million had million requests in february additionally these requests do not seem to identify themselves as crawlers for one they come from a very wide range of ip addresses not from a single data center we would expect from a traditional crawlerbot also the useragent strings do not clearly indicate these are botscrawlers for example openai documents the user agents they use here but the ones we are seeing hitting these search pages tend appear more like a typical browser os combo that a normal human would have albeit these tend to be older versions now i know what you may be wanting to ask are these ddos attempts i dont think so but i cant be certain of that my clients tend to be more mission focused organizations and academic institutions and i dont put it beyond that there are forces out there who wish to cause these organizations harm especially of late but if this were the case i feel like id see it happening in a better organized way while some of my clients do have access to tools like cloudflare with a web application firewall waf that can help mitigate this problem for them such tools arent available to all of my clients due to budget constraints so now that ive described the problem i have some questions for this community is this likely from aillm training this is my own personal hunch that these are poorly coded crawlers not following general conventions like the ones i described above getting stuck in an endless trap of variable links in these facets it seems that just following the conventions though or referring to the commonly available sitemapxml pages would save us all some pain what tools might be using this do these tools have any systems for directing them where not to crawl do the members from this community have any advice im continuing to come up with ways to mitigate on my side but many of the options here impact users as we cant easily distinguish between humans and these bots the most surefire way seems to be a fullon block for any urls that contain parameters that have more than a certain number of facets thank you im interested in machine learning myself as im especially apprehensive about my own future prospects in this industry but here i am for now,,,,,
1jdbc8u,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 12:22:39,p my surveillance cameras with ai anomaly detection are paying off caught a meteor on camera last night extend your senses and be amazed thats the theme of this experimentturning cheap cameras and offtheshelf ml models into a diy surveillance network the barrier to entry lower than ever it caught a meteor on camera last night,,,,,
1jdb2bk,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 12:07:13,p i built an open source framework that lets ai agents interact with sandboxes hi everyone just opensourced computer a computeruse interface cui framework that enables ai agents to interact with isolated macos and linux sandboxes with nearnative performance on apple silicon computer provides a pyautoguicompatible interface that can be plugged into any ai agent system openai agents sdk langchain crewai autogen etc why computer as cua ai agents become more capable they need secure environments to operate in computer solves this with isolation run agents in sandboxes completely separate from your host system reliability create reproducible environments for consistent agent behaviour safety protect your sensitive data and system resources control easily monitor and terminate agent workflows when needed how it works computer uses lume virtualization framework under the hood to create and manage virtual environments providing a simple python interface from computer import computer computer computerosmacos displayx memorygb cpu try await computerrun take screenshots screenshot await computerinterfacescreenshot control mouse and keyboard await computerinterfacemove_cursor await computerinterfaceleft_click await computerinterfacetypehello world access clipboard await computerinterfaceset_clipboardtest clipboard content await computerinterfacecopy_to_clipboard finally await computerstop features full os interaction control mouse keyboard screen clipboard and file system accessibility tree access ui elements programmatically file sharing share directories between host and sandbox shell access run commands directly in the sandbox resource control configure memory cpu and display resolution installation pip install cuacomputer,,,,,
1jda0jm,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 11:04:03,p update tool calling support for qwqb using langchains chatopenai qwqb support ive updated my repo with a new tutorial for tool calling support for qwqb using langchains chatopenai via openrouter using both the python and javascripttypescript version of my package note langchains chatopenai does not currently support tool calling for qwqb i noticed openrouters qwqb api is a little unstable likely due to model was only added about a week ago and returning empty responses so i have updated the package to keep looping until a nonempty response is returned if you have previously downloaded the package please update the package via pip install upgrade taot or npm update taotts you can also use the taot package for tool calling support for qwqb on nebius ai which uses langchains chatopenai alternatively you can also use groq where their team have already provided tool calling support for qwqb using langchains chatgroq openai agents sdk not yet i checked out the openai agents sdk framework for tool calling support for nonopenai models and they dont support tool calling for deepseekr or any models available through openrouter yet so there you go check it out my updates here python javascripttypescript please give my github repos a star if this was helpful,,,,,
1jd8nbc,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 09:30:52,r block diffusion interpolating between autoregressive and diffusion language models diffusion language models offer unique benefits over autoregressive models due to their potential for parallelized generation and controllability yet they lag in likelihood modeling and are limited to fixedlength generation in this work we introduce a class of block diffusion language models that interpolate between discrete denoising diffusion and autoregressive models block diffusion overcomes key limitations of both approaches by supporting flexiblelength generation and improving inference efficiency with kv caching and parallel token sampling we propose a recipe for building effective block diffusion models that includes an efficient training algorithm estimators of gradient variance and datadriven noise schedules to minimize the variance block diffusion sets a new stateoftheart performance among diffusion models on language modeling benchmarks and enables generation of arbitrarylength sequences we provide the code along with the model weights and blog post on the project page this url interesting approach merging autoregressive and diffusion language models what does everyone think arxiv link block diffusion interpolating between autoregressive and diffusion language models,,,,,
1jd3toe,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 03:44:14,p humanizer prompt advanced a new way to humanize ai texts hpa ,,,,,
1jd1xxp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 02:02:07,d bounding box in forms is there any model capable of finding bounding box in form for question text fields and empty input fields like the above imagei manually added bounding box i tried qwen vl but the coordinates is not matching with the image,,,,,
1jd1g5p,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 01:36:19,d milestone xaiinterpretability papers what are some important papers that are easy to understand that bring new ideas or have changed how people think about interpretability explainable ai there are many new technique papers im thinking more papers that bring new ideas to xai or where they are actually useful in real scenarios some things that come to mind axiomatic attribution for deep networks sanity checks for saliency maps anthropics whole mechanistic interpretability series interpreting interpretability understanding data scientists use of interpretability tools for machine learning,,,,,
1jd0q1e,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 00:58:24,p kmeans efficiently groups similar data points by minimizing intracluster variance this animation transforms raw data into dynamic clusters why does clustering matter anomaly detection customer segmentation recommendation systems and more tools python ,,,,,
1jd0p2i,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 00:57:08,r how to incorporate multiple changing initial conditions for a system of odes in pinns i have two odes the initial condition of the first ode is equal to the final value of the second ode and the initial condition of the second ode is the final value of the first ode these initial conditions also change how would i incorporate this into my typical pinn coding script thank you in advance,,,,,
1jcvfpx,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 20:52:26,p i created an open source perplexitystyle unified search for your distributed second brain hey everyone i added a major feature amurex today a self hosted open source perplexitystyle unified search for your second brain one that will not just store your knowledge but actually understands it retrieves it and helps you act on it right now all my online knowledge is fragmented notes live in notion ideas in obsidian and documents in google drive and it is only getting worse with time with many of my items in whatsapp messages and even slack so i built a perplexitystyle search for your second brain unlike traditional search this system should help you make sense about it we just launched it today and it is meant to be fully self hostable and open source the managed version only embeds documents but you can easily change it in the self hosted version check it out here github would love to hear anything you have to share d,,,,,
1jctc0p,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 19:20:42,d any new interesting methods to represent setspermutationinvariant data i have been reading about applying deep learning on sets however i couldnt find a lot of research on it as far as i read i could only come across a few one introducing deep sets and another one is using the pooling techniques in a transformer setting set transformer would be really glad to know the latest improvements in the field and also is there any crucial paper related to the field other than those mentioned,,,,,
1jcpfl7,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 16:33:50,d combining llm machine learning models hello reddit community hope you are doing well i am researching about different ways to combine llm and ml models to give best accuracy as compared to traditional ml models i had researched research articles but havent found any of them useful as some sample code for reference on kaggle github is limited here is the process that i had followed there are multiple columns in my dataset i had cleaned dataset and i am using only text column to detect whether the score is positive negative or neutral using transformers such as bert then i extracted embeddings using bert and then combined with multiple ml models to give best accuracy but i am getting a drop in accuracy as compared to traditional ml models i made use of mistral b falcon but the models in the first stage are failing to detect whether the text column is positive negative or neutral do you have any ideas what process scenario should i useconsider in order to combine llm ml models thank you,,,,,
1jcpc2a,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 16:29:39,d relevance of aixi to modern ai what do you think about the aixi does it make sense to study it if you are interested in ai applications is aixis theoretical significance is of the same magnitude as kolmogorov complexity and solomonoff induction does it have any relevance to what is done with deep learning ie explaining to what really happens in transformer models etc,,,,,
1jcozts,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 16:14:33,d double descent in neural networks double descent in neural networks why does it happen give your thoughts without hesitation doesnt matter if it is wrong or crazy dont hold back,,,,,
1jckva9,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 12:57:55,dautosocial building an llmpowered social media distribution tool tldr article recently completed a fun weekend project called autosocial a tool that uses claude sonnet to automatically create and distribute content across multiple social platforms the system takes a blog post url extracts the content has an llm write appropriate summaries for different platforms and then posts them automatically using playwright my implementation posts to hacker news reddit x and discord with plans for youtube instagram and medium in the future the architecture is clean and modular separate components handle webpage content extraction llm summarization social posting automation and a simple gui interface working with llm apis rather than building models was refreshing and i was struck by how capable these systems already are for content creation tasks the experience left me contemplating the tension between efficiency and intentionality while automation saves time theres something meaningful about the manual process of sharing your work despite creating it i likely wont use this tool for my own content as i believe posts should be made with care and intention that said it provided a fascinating glimpse into how content distribution might evolve,,,,,
1jcje46,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 11:26:25,p insights from building an embeddings and retrievalaugmented generation app from scratch in this post ill share key insights and findings from building a practical text search application without using frameworks like langchain or external apis ive also extended the apps functionality to support retrievalaugmented generation rag capabilities using the gemini flash b model,,,,,
1jciynf,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 10:57:02,p i had ai play the lottery so you dont have to waste your money ,,,,,
1jcgxa6,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 08:24:14,research one year later our paper on ai ethics in hr remains relevant despite the generative ai revolution just one year ago our paper ai for the people embedding ai ethics in hr and people analytics projects was published in technology in society we conducted comparative case studies on how organizations implement ai ethics governance in hr settings whats fascinating is that despite conducting this research before chatgpt was publicly available the fundamental challenges we identified remain exactly the same organizations i consult with today are struggling with identical governance questions just with more powerful tools key findings that have stood the test of time ethics review boards often lack meaningful authority privacy concerns are prioritized differently based on organizational structure external regulation dramatically impacts implementation quality human oversight remains essential for ethical ai deployment id be interested to hear if others are seeing similar patterns in organizational ai ethics especially as we shift to generative ai tools has your approach to responsible ml deployment changed in the llm era if anyone would like a preprint of the paper feel free to dm me the published version is here,,,,,
1jcfw3p,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 07:04:28,r d language fields for dynamic scenes via mllmguided objectwise video captioning i just read an interesting paper about integrating language with d scene representations the researchers introduce d langsplat which combines d gaussian splatting for dynamic scene reconstruction with multimodal llms to create languageaware d scene representations the core technical contributions they attach languagealigned features to d gaussians using multimodal llms without requiring scenespecific training the system processes language queries by mapping them to the d scene through attention mechanisms this enables daware grounding of language in dynamic scenes maintaining consistency as viewpoints change they use offtheshelf components d gaussian splatting gptv rather than training specialized models key capabilities demonstrated temporal object referencing track objects mentioned in queries across time dynamic scene description generate descriptions of whats happening at specific moments querybased reasoning answer questions about object relationships and actions viewpoint invariance maintain consistent understanding regardless of camera position zeroshot operation works with new videos without additional training i think this represents an important step toward more natural interaction with d content the ability to ground language in dynamic d scenes could be transformative for applications like arvr where users need to reference and interact with moving objects through natural language the zeroshot capabilities are particularly impressive since they dont require specialized datasets for each new scene i think the computational requirements might limit realtime applications in the near term the system needs to process features for all gaussians through large language models which is resourceintensive also the quality is bound by the limitations of both the gaussian representation which can struggle with complex motion and the underlying llm tldr d langsplat enables language understanding in dynamic d scenes by combining d gaussian splatting with multimodal llms allowing users to ask questions about objects and actions in videos with daware grounding full summary is here paper here,,,,,
1jcaklx,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 01:34:18,p dbscan clustering on a classic nonlinear dataset six halfmoons unlike kmeans dbscan excels at detecting nonlinear patterns like these six halfmoons instead of assuming spherical clusters it groups points based on density connectivity making it ideal for complex datasets ,,,,,
1jc8icd,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 23:48:40,d confidence score behavior for object detection models i was experimenting with the postprocessing piece for yolo object detection models to add context to detections by using confidence scores of the nonmax classes for example say a model detects car dog horse and pig if it has a bounding box with confidence as a dog but also has a confidence for cat in that same bounding box i wanted the model to be able to annotate that it also considered the object a cat in practice what i noticed was that the confidence scores for the nonmax classes were effectively pushed to rarely above a my limited understanding of the sigmoid activation in the classification head tells me that the model would treat the multiclass labeling problem as essentially independent binary classifications so theoretically the model should preserve some confidence about each class instead of minmaxing like this maybe i have to apply label smoothing or do some additional processing at the logit levelbottom line is im trying to see what techniques are typically applied to preserve confidence for nonmax classes,,,,,
1jc2u32,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 19:20:22,d thesis topic in music field hi ive been studying ai for the past years and am currently approaching the completion of my studies im looking for a suitable topic for my bachelors thesis initially my supervisor suggested focusing on the application of graph neural networks gnns in music generation and provided this paper a starting point he proposed either adapting the existing model from the paper or trainingfinetuning it on a different dataset and performing comparative analyses however ive encountered significant challenges with this approach the preprocessing steps described in the paper are meant for a specific dataset additionally the models implementation quite complicated poorly documented and uses outdated libraries and packages making troubleshooting and research more timeconsuming although i understand the core ideas and individual components of the model navigating through the complexity of its implementation has left me feeling stuck after discussing my concerns with my supervisor he agreed that i could switch to another topic as long as it remains related to music therefore im now searching for new thesis ideas within the domain of music that are straightforward to implement and easy to comprehend any guidance suggestions or ideas would be greatly appreciated thank you,,,,,
1jbzh5n,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 16:52:28,d using grpc in ml systems grpc as far as i understand is better than rest for intermicroservices communication because it is more efficient where would such a protocol be handy when it comes to building scalable ml systems does the synchronous nature of grpc cause issues when it comes to scalability for example what two ml microservices would make a very good use case for such communication thanks,,,,,
1jbyg7i,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 16:06:54,d kernel functions how support vector machines transform ghostly and pumpkin data linear rbf polynomial and sigmoid kernels show different ways machine learning algorithms can slice through complex datasets creating unique decision boundaries that separate the pumpkins from the ghosts ,,,,,
1jby0cz,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 15:46:55,d the cultural divide between mathematics and ai ,,,,,
1jbxo3p,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 15:31:34,d is it true that residual forces network to be boosting rather than feature learning recent paper from meta on normalization got interesting replies original tweet,,,,,
1jbws7c,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 14:51:06,d whats going on with the recent development of pytorch lightning id like to discuss the current state and future of pytorch lightning a popular library for machine learning research and development ive been a pytorch lightning user for about years since version primarily using it for model training with generally satisfactory experiences however recent trends have raised concerns about its future ive observed the following slowed development commit frequency has dropped significantly since as shown in the bar chart below release cycles have also slowed several major bugs remain unfixed for extended periods core contributor departure awaelchli a significant contributor to code and discussions has left the organization for more than half a year given these observations id like to open a discussion on the following questions whats happening with lightning and what might the librarys future look like is it advisable for users to continue basing longterm work on this library if pytorch lightning becomes poorly maintained what are some good alternatives if anyone else has noticed similar trends or has additional information please share your opinions thanks,,,,,
1jbuz8h,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 13:21:23,p finance dataset hello everyone i hope you are all doing well i have been looking for hours but cant find a dataset set with historical stock information such as the prices some indicators and the final buy sell or hold decision does anyone know a dataset that could match these needs or should i rather create it myself,,,,,
1jb2unn,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 12:34:40,d aligning dayahead market data with dfr hour blocks for price forecasting question im forecasting prices for the uks dynamic frequency response dfr markets which operate in hour efa blocks i need to align dayahead hourly and halfhourly data with these blocks for model training the challenge is that the dfr day runs from day to day while the dayahead markets run from to options considered aggregate dayahead data to match the hour dfr blocks but this may lose crucial information expand dfr data to match the halfhourly granularity by copying data points but this might introduce bias key points dfr data and some dayahead data must be lagged to prevent data leakage dayahead hourly data is available at forecast time but halfhourly data is not fully available seeking insights on the best approach to align these datasets any alternative methods or considerations for data wrangling in this context,,,,,
1jb79ox,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 15:58:17,d revisiting open public discussions on academic papers i went through some previous posts about people naively discussing about open forums for papers like enabling comments on arxiv im by no means suggesting that these things replace peer review entirely but i also think we should think about this idea as not being entirely decoupled from formal peer review lets say a system like this would sit on top of openreview where they already have plenty of data regarding different peoples interaction in peer review features for moderationpermissions etc first off i hope we can agree as a starting point that it would be nice to not have to search several different social media platforms for discussion it would be really convenient if we can post it to openreview in an arxiv like manner have it open for discussion and if it was released publicly to a submitted conference be able to cleanly link it to the original preprint but what do you think about other mechanisms that could be built on top of the open forums what do you think about incentivizing reviews with a karmalike system i feel like program chairs organizing these things would like a way to sift through the thousands of potential reviewers to find ones who are actually passionate in reviewing and reading the literature who knows maybe theres already a list of blacklisted reviewers being shared between iclricmletc im also open to the idea being shot down entirely if you think this is a terrible idea lol i just want to know where the community is at,,,,,
1jbbrb2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 19:15:35,d training deepseek r b for a financial expert seeking advice experiences hi everyone im planning to train an llm to specialize in financial expertise and im considering using deepseek r b due to my limited hardware this is an emerging field and i believe this subreddit can provide valuable insights from those who have experience finetuning and optimizing models i have several questions and would appreciate any guidance feasibility of b for financial expertise given my hardware constraints im considering leveraging rag retrievalaugmented generation and finetuning to enhance deepseek r b do you think this approach is viable for creating an efficient financial expert bot or would i inevitably need a larger model with more training data to achieve good performance gpu rental services for training has anyone used cloud gpu services lambda labs runpod vastai etc for finetuning if so what was your experience any recommendations in terms of costeffectiveness and reliability finetuning rag best practices from my research dataset quality is one of the most critical factors in finetuning any suggestions on methodologies or tools to ensure highquality datasets are there any pitfalls or best practices youve learned from experience challenges lessons learned this field is vast with multiple factors affecting the final models quality such as quantization dataset selection and optimization techniques this thread also serves as an opportunity to hear from those who have finetuned llms for other use cases even if not in finance what were your biggest challenges what would you do differently in hindsight im eager to learn from those who have gone through similar journeys and to discuss what to expect along the way any feedback is greatly appreciated thanks in advance,,,,,
1jbeats,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 21:03:31,r are there any good ai tts voices that can run on a cpu only so i have heard xtts v can run on a cpu only but i have not managed to get it to work something about weight only cant be loaded or something as im not a developer i have no idea what that means and even after hours of research i couldnt fix it so i tried piper tts and which worked but wasnt really good i also tried tortoise but that also did not work but i dont think it even runs on cpus at all i would really appreciate it if anyone could recommend me a good one,,,,,
1jbs7xg,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 10:30:09,r transformers without normalization fair meta new york university mit princeton university transformers without normalization jiachen zhu xinlei chen kaiming he yann lecun zhuang liu arxiv cslg abstract normalization layers are ubiquitous in modern neural networks and have long been considered essential this work demonstrates that transformers without normalization can achieve the same or better performance using a remarkably simple technique we introduce dynamic tanh dyt an elementwise operation dytxtanhαx as a dropin replacement for normalization layers in transformers dyt is inspired by the observation that layer normalization in transformers often produces tanhlike sshaped inputoutput mappings by incorporating dyt transformers without normalization can match or exceed the performance of their normalized counterparts mostly without hyperparameter tuning we validate the effectiveness of transformers with dyt across diverse settings ranging from recognition to generation supervised to selfsupervised learning and computer vision to language models these findings challenge the conventional understanding that normalization layers are indispensable in modern neural networks and offer new insights into their role in deep networks code and website detailed thread on x by zhuang liu,,,,,
1jbrjw2,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 09:41:06,d looking for feedback on a build im looking for a budget starter build for ai ive never built my own pc and ive come across this article on medium i like the low price but im uncertain if itll cause me problems in the future for one thing the motherboard is amd ive never had to work with an amd cpu and i dont even know if it makes a difference to me im just doing python jax the low level stuff happens behind the scenes from my pov another concern is how upgradable is this im happy to spend more on a build if i can successfully make use of this basic one for example start with a gpu and in a year go for a gpu but its not clear to me how upgradable this build is ive asked on rpcbuild and the feedback was that the psu should be w for upgradability and that getting a b would be little extra cost for the benefit so my question for the room is what problems can you see with the build in the article the specific points that concern me at the moment are does gb on the gpu look small obviously it depends on the specifics but for a starter build amd ive done intel all my life am i gonna run against amdspecific oddities like oops doesnt work on x where x is something you absolutely need in ai thank you,,,,,
1jbpqsp,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 07:22:44,r block diffusion a hybrid language model combining autoregressive and diffusion approaches for flexiblelength generation ive been reading the block diffusion paper which introduces a clever hybrid between autoregressive and diffusion language models the researchers developed a blockbased approach that divides text into chunks processing each block with a mix of autoregressive conditioning across blocks and diffusion techniques within blocks the key innovation is that theyre effectively interpolating between these two paradigms rather than treating them as distinct approaches which solves several limitations that have held back diffusion lms key technical aspects they process text in flexible blocks with autoregressive dependencies between blocks and diffusionstyle parallel processing within blocks implemented kv caching and parallel token sampling for significant efficiency gains during generation developed datadriven noise schedules based on variance minimization rather than using uniform noise schedules achieved perplexity on c validation setting a new sota for diffusion language models enabled arbitrarylength sequence generation previously impossible with standard diffusion lms used a specialized objective function that balances between autoregressive and diffusion approaches i think this research could significantly influence how we think about language model architectures while diffusion models have struggled to match autoregressive performance in language tasks this hybrid approach suggests we dont need to choose between paradigms the ability to generate variablelength text while maintaining some parallelism during generation could be particularly valuable for practical applications i think the most promising aspect is how this bridges the efficiencycontrollability gap autoregressive models are typically more efficient but less controllable while diffusion models offer more control but suffer efficiency issues this approach provides a tunable middle ground tldr block diffusion creates a hybrid between autoregressive and diffusion language models by processing text in blocks achieving sota diffusion lm performance enabling arbitrarylength generation and improving efficiency through specialized techniques like kv caching and datadriven noise schedules full summary is here paper here,,,,,
1jbovy1,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 06:19:56,d fallacies of mlops i wrote this article as i meet so many people misallocating their time when their goal is to build an ai system teams of data engineers data scientists and ml engineers are often needed to build ai systems and they have difficulty agreeing on shared truths this was my attempt to define the most common fallacies that i have seen that cause ai systems to be delayed or fail do it all in one ml pipeline all data transformations for ai are created equal there is no need for a feature store experiment tracking is not needed mlops mlops is just devops for ml versioning models is enough for safe upgraderollback there is no need for data versioning the model signature is the api for model deployments prediction latency is the time taken for the model prediction llmops is not mlops the goal of mlops should be to get to a working ai system as quickly as possible and then iteratively improve it full article,,,,,
1jbotgn,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 06:15:04,discussion finetuning a mamba model with using hugging face transformers hey community im working on finetuning the mamba model specifically statespacesmambabhf for a multiturn dialogue system but im hitting some roadblocks my goal is to build a chatbot that retains context across conversations like input dialogue hi can you recommend a pizza place dialogue sure are you looking for vegan options dialogue yes preferably near downtown output bot expected response my setup using hugging face transformers and peft for lora training on custom conversational data specific questions data formatting how should i structure multiturn dialogues im using endoftext as a separatoreos token for statespacesmambabhf but the model ignores past turns should i prepend userbot labels or use special tokens lora targets which mamba layers should i adapt currently targeting x_proj in_proj and out_proj is r sufficient for conversational tasks code snippet training args pythontraining_args trainingarguments per_device_train_batch_size gradient_accumulation_steps learning_ratee fptrue i am having hard time writing the code for mamba b to finetune it either it doesnt work or it doesnt finetune properly any tips on architecture tweaks data prep evaluation strategies or any code suggestionsdocumentations,,,,,
1jbes50,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 21:24:56,p help with audio denoising model offline hi guys im working on an offline speechaudio denoising model using deep learning for my graduation project unfortunately it wasnt my choice as it was assigned to us by professors and my field of study is cybersecurity which is way different than ai and ml so i need your help i did some research and studying and connected with amazing people that helped me as well but now im kind of lost my inputs are a mixture of clean speech files and noise files randomized at snr im using a unet model structure and preprocessing with mel spectrograms after training and evaluation the results are not inspiring at all the denoised audio ends up distorted or with higher noise im not sure whether the issue is in the reconstruction function or its in the mask prediction heres the link a copy of my notebook on google colab feel free to use it however you like also if anyone would like to contact me to help me on in zoom or discord or something ill be more than grateful im not asking for someone to do it for me i just need help on what should i do and how to do it d also the dataset im using is the mssnsd dataset,,,,,
1jb8n3u,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 16:56:32,d is the deep learning loss curve described by some function in deep learning the loss vs training iteration curve always has that characteristic elbow shape what is that curve is it described by some function what is it about the training process that gives rise to that particular curve,,,,,
1jb4vbn,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 14:13:50,r how pickle files backdoor ai modelsand what you can do about it this articles deep dives on python serialisation and how it is being used to exploit ml models do let me know if there are any feedbacks thanks blog,,,,,
1jb42oo,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 13:36:47,p develop an ai model to validate selfies in a user journey verification process by applying object detection techniques to ensure compliance with specific attributes hi everyone im currently a web development intern and pretty confident in building web apps but ive been assigned a task involving machine learning and i could use some guidance the goal is to build a system that can detect and validate selfies based on the following criteria no sunglasses no scarf sufficient lighting not too dark eyes should be open additional checks face should be centered in the frame no obstructions eg hands objects neutral expression appropriate resolution minimum pixel requirements no reflections or glare on the face face should be facing the camera not excessively tilted the dataset will be provided by the team but its unorganized so ill need to clean and prepare it myself while i have a basic understanding of machine learning concepts like regression classification and some deep learning this is a bit outside my usual web dev work id really appreciate any advice on how to approach this from structuring the dataset to picking the right models and tools thanks a lot,,,,,
1jb34g0,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 12:49:09,d help for my lstm model hi im having some trouble with my ltsm model to predict a water level im like a begginer with coding and especially with machine learning so its quite difficult to me i have a data set of water level with an associate date and an another data set with rain and other climatic data also with a associated date my problem is i put all my data in the same textfile but i have a lot of missing data for the water level more than few month sometimes and i donno what to do with these big missing value i did an interpolation for the missing data d but i dont know what to do with the others missing value i can not delete them bc the model can only understand a continuous time step can someone help me im a begginer so im trying my best thanks ps im french so my english can be bad,,,,,
1jb29ro,,,,,,,,,MachineLearning,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 12:02:27,r multiview video generation via viewinvariant motion learning and crossview consistent translation just saw this new paper that tackles d video generation by framing it as a videotovideo translation problem the researchers introduce reangleavideo which can generate arbitrary camera viewpoints from a single input video while maintaining temporal consistency the key innovation is treating novel view synthesis as a translation task rather than trying to build explicit d models this means a specially designed reference image sampling strategy that helps the model better adapt to input video content a transformation module that aligns reference and target views without needing camera parameters a videotovideo diffusion approach that ensures temporal consistency across generated frames all this from a single video input no multiview data camera parameters or d models required the results are quite impressive stateoftheart visual quality and temporal consistency compared to previous methods ability to generate arbitrary camera trajectories while preserving the original videos content and motion user studies confirming the generated videos appear more realistic than those from competing approaches i think this could significantly impact content creation workflows by allowing postproduction camera angle adjustments without reshooting for filmmakers and video editors being able to generate new perspectives from existing footage could reduce costs and increase creative flexibility the videotovideo translation framing also seems conceptually simpler than approaches requiring explicit d understanding which might lead to more accessible tools that said the paper notes limitations with extreme viewpoints and complex scenes with multiple moving objects the quality also depends heavily on having some camera movement in the original video to provide d cues tldr reangleavideo introduces a novel approach that treats d video generation as a videotovideo translation problem allowing for arbitrary viewpoint synthesis from a single video without requiring d reconstruction or camera parameters full summary is here paper here,,,,,
1k9momp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-28 04:01:31,weekly entering transitioning thread apr may welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1k8n1yq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 20:58:52,interview with bcg x hey i have an interview coming up with bcg x anyone here been through the process with them what about other consultingmbb firms,,,,,
1k8hjp4,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 16:55:12,this environment would be a real nightmare for me youtube released some interesting metrics for their year celebration and their data environment is just insane processing infrastructure handling million daily video uploads storage and retrieval systems managing billion total videos analytics pipelines tracking billion daily likes and million daily comments realtime processing of engagement metrics creatorhearted comments reaching million daily infrastructure supporting multimodal data types video audio comments metadata from an analytics point of view it would be extremely difficult to validate anything you build in this environment especially if its something that is very obscure supposed they calculate a content stickiness factor a metric which quantifies how much a video prevents users from leaving the platform how would anyone validate that a factor of is correct for creator x that is just for creator in one segment there are different segments which all have different behaviors eg podcasts which might be longer vs shorts i would assume training ml models or basic queries would be either slow or very expensive which punishes mistakes a lot you either run computer for days or or computers for hours and if you forget that computer cluster running for just a few minutes for lunch maybe or worse over the weekend you will come back to regret it any mistakes you do are amplified by the amount of data you omitting a single limit or use a select in the wrong place and you could easy cost the company millions of dollars forgot a single cluster running well you just lost us million dollars buddy and because of these challenges l believe such an environment demands excellence not to ensure that no one makes mistakes but to prevent obvious ones and reduce the probability of catastrophic ones l am very curious how such an environment is managed and would love to see it someday youtube article,,,,,
1k89ohp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 10:14:41,people here working in healthcare how do you communicate with healthcare professionals im pursuing my doctoral deg in data science my domain is ai in healthcare we collab with a hospital from where i get my data in return im practically at their beck and call they expect me analyze some of their data and automate a few tasks not a big deal when i have to build a model its usually a simple classification model where i use ml models or do some transfer learning the problem is communicating the feature selectionextraction process i dont need that many features for the given number of data points how do i explain to them that even if clinically those two features are the most important for the diagnosis i still have to scrape one of them its too correlated and is only adding noise and i do ask them to give me more variable data and they cant they insist i do dimensionality reduction but then i end up with lower accuracy i dont understand why people think ai is intuitive or will know things that we humans dont it can only perform based on the data given,,,,,
1k87wnq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 08:05:54,thoughts on getting a masters while working as a ds i entered ds straight after an undergrad in computer science during my degree i did multiple ds internships and an ml research internship i figured out i didnt like research so a phd was out i couldnt afford to stay on for a masters so i went straight into work and found a ds role where im performing very well and getting promoted quickly i like my current org but its a very narrow field of work so i might want to move on in years i see a lot of postings both internally and externally require a masters so im wondering if im putting myself at a disadvantage by not having one my current employer has tuition reimbursement up to k a year so i was thinking of doing a parttime masters something like omscs omsa or a statistics ms program offered by a local uni partially for the signalling of having a masters and partially because i just really love learning and i feel like the learning has stagnated in my current role on the other hand im worried that doing a masters alongside work will impact my ability to focus on my job progression plans ive already done two masters courses parttime free creditbearing but cant transfer them to a degree and found it ok but any of the degrees ive been considering would be much more workload another option would be to take a year out between jobs and do a masters but with the job market the way it is that feels like a big risk thanks in advance for your opinionsdiscussion,,,,,
1k81pru,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 01:46:55,an example of how statistics can be used to unintentionally deceive and why data analysis is important ,,,,,
1k80mxy,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 00:49:51,question about how to use churn prediction when churn prediction is done we have predictions of who will churn and who will retain i am wondering what the typical strategy is after this like target the people who are predicting as being retained perhaps to upsell on them or try to get people back who are predicted as churning my guess is it is something that depends on the priority of the business im also thinking if we output a probability that is borderline that could be an interesting target to attempt to persuade,,,,,
1k804yc,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-26 00:23:51,thought i was prepping for mlds internships turns out i need fullstack backend cloud and dark magic to qualify im currently doing my undergrad and have built up a decent foundation in machine learning and data science i figured i was on track until i actually started looking for internships now every mlds internship description looks like must know fullstack development backend frontend cloud engineering devops machine learning deep learning computer vision and also invent a new programming language while youre at it bro i just wanted to do some modeling not rebuild twitter from scratch i know basic stuff like sdlc git and cloud fundamentals but i honestly have no clue about real frontendbackend development now im thinking i need to buckle down and properly learn swe if i ever want to land an mlds internship first am i wrong for thinking this way is fullstack knowledge pretty much required now for mlds intern roles or am i just applying to cracked job posts second if i do need to learn swe properly where should i start i dont want to sit through super basic hello world courses no offense to ibmmeta coursera certs but i need something a little more serious i heard the amazon junior developer program on coursera might be good anyone tried it not trying to waste time spinning in circles just wanna know how people here approached it if you were in a similar spot appreciate any advice,,,,,
1k7xi9g,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-25 22:17:08,responsible tech certificates a worthwhile expense curious what people here think about this article responsible tech certificates a worthwhile expense personally i find these to be mostly a waste of money but as someone whos interested in getting into ethical ai was wondering if anyone has had a similar experience and if it helped them get their foot in the door,,,,,
1k76c0v,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 23:16:01,step in the right or wrong direction long term im a sophomore double majoring in data analytics and data engineering with a minor in computer science it sounds like a lot but i came in with an associates degree from high school so its honestly not a ton my end goal is to become a data scientist ideally specializing in timeseries forecasting or recommendation systems i plan to go straight into a masters in data science after undergrad today i just got an offer for a business analyst internship the role focuses heavily on sql and power bi but doesnt involve any python machine learning or advanced statistics its a great opportunity and id be working with a business analytics team at a credit union but im a bit torn will having business analyst intern on my resume make me look less competitive for future data science internships or fulltime rolesespecially compared to students who land internships with data scientist or data science intern in the title i know im only a sophomore and i dont want to overthink it but i also dont want to unintentionally steer myself toward an analystonly path any advice or insight would be appreciated,,,,,
1k6za0y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 18:16:54,signs of burnout hey all i posted a little bit about my current job situation in a previous post ever since the year started ive just been looped into tasks where i have no context what its supposed to do dont have the requirements clear frequently have my boss try to get something out without clear requirements and then us fixing it after the fact with another coworker constantly expressing dissapointment and frustration for things not churning out sooner for the past month ive been working several hour shifts on days when i dont have quick turnaround times ive noticed myself losing focus losing interest in the work overall i signed up for a bunch of udemy classes in the beginning of the year and feel like my headspace isnt there to upskill even though i had a lot of enthusiasm before has anybody gone through this situation and have advice i want to change my job eventually in a few months but i want to spend time preparing rather than just jump ship at the moment esp in this market,,,,,
1k6wi45,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 16:25:16,what are some universities that you believe are cashcows ,,,,,
1k6tz9y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 14:43:37,leadership said they doesnt understand what we do our ds group was moved under a traditional it org that is totally focused on delivery we saw signs that they didnt understand prework required to do the science side of the job get the data clean figure out the right features and models etc we have been briefing leadership on projects goals timelines seemed like they got it now they admit to my boss they really dont understand what our group does at all very frustrating anyone else have this situation,,,,,
1k6sdkm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 13:35:44,does anyone here do data sciencemachine learning at walgreens if so whats it like my parents live in the chicagoland area and im considering moving back home ive been a data scientist at my current company for about years now primarily doing either ml builds but not deployment thats another role at my company or more classical statistical analyses to aid in decision making i have a location requirement where i work currently and while ive been given feedback that im a strong performer i dont anticipate being granted permission to work remotely ive been looking into the companies in the area and walgreens is one of the ones im considering but in addition to the current acquisition theyre undergoing im hearing some odd things about their data science group however it looks like theres ml roles open in the area im wondering if theres anyone who works there that would be open to just a quick conversation about how those roles look there so i can better understand if its a viable option for me,,,,,
1k6rj0y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 12:56:42,deep analysis the analytics analogue to deep research ,,,,,
1k6pqem,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-24 11:22:17,polars what is the status of compatibility with other python packages ,,,,,
1k63zii,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 16:47:23,to interviewers who ask product metrics cases study what makes you say yes or no to a candidate do you want complex metrics or basic works too hi i was curious to know if you are an interviewer lest say at faang or similar big tech what makes you feel yes this is good candidate and we can hire what are the deal breakers or something that impress you or think that a red flag like you want them to think about out of box metrics or complex metrics or even basic engagement metrics like daus conversions rates view rates etc are good enough also i often see people mention ab test whenever the questions asked so do you want them to go on deep in it or anything you look them to answer also how long do you want the conversation to happen edit also anything you think that makes them stands out or topics they mention make them stands out,,,,,
1k60gey,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-23 14:24:10,how can i come up with better feature ideas im currently working on a credit scoring model i have tried various feature engineering approaches using my domain knowledge and my manager has also shared some suggestions additionally ive explored several feature selection techniques however the models performance still isnt meeting my managers expectations at this point ive even tried manually adding and removing features step by step to observe any changes in performance i understand that modeling is all about domain knowledge but i cant help wishing there were a magical tool that could suggest the best feature ideas,,,,,
1k5ikzd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 21:48:15,how is your teaming using ai for ds i see a lot of job posting saying leverage ai to add value what does this actually mean using ai to complete ds work or is ai is an extension of ds work ive seen a lot of cool is cases outside of ds like content generation or agents but not as much in ds itself mostly just code assist of document creationsummary which is a tool to help ds but not ds itself,,,,,
1k52w1u,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 10:23:19,request for review ,,,,,
1k4u3dp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-22 01:13:22,any experience with incrmntal for marketing studies my firm was contacted by a marketing measurement company called incrmntal their product is an mmm that uses interrupted time series ie synthetic control with a reinforcement learning step their documentation is very light there are no simulation studies and just a handful of comparisons with ab tests its not clear what the reinforcement learning process is if its there at all and the time series model is similarly opaque the whole thing seems pretty scammy the marketing materials are fairly aggressive and make repeatedly inaccurate claims has anyone used them any insights into what theyre doing how well did it work for you,,,,,
1k4q8b8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 22:12:22,in an effort to keep learning i have a new ds starting soonmodalities change and all of that more importantly for those of you hired in the last year what are some things you wish were presented earlier than they were or things done in general looking to make this a very positive experience for the new employee,,,,,
1k4geso,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 15:30:34,ever met a person you think lied about working in data science you ever get the feeling someone online or inperson just straight up lied to you about having a data science job data scientist data analyst data engineer machine learning engineer data architect etc i was recently talking to someone at a technical meetup for working professionals and one person was saying some really weird stuff it was like they had heard of the technical terms before but didnt actually have the experience working with the technologiesskills for example they mentioned that they had all sorts of experience with kafka but didnt know that it is a tool that data engineers and related professionals could use for their workflows they also mixed up the definitions of common machine learning models what said models could do for a business nosql sql etc it was jarring also sometimes i get the impression that a minority of people on this subreddit come on and lie about ever having a data science job the more obvious examples are those who post the chatgpt answers to post questions no shade thrown to anyone here i encounter many qualified people here and have learned new stuff just reading through posts any of you ever had an experience like that edit hello all thank you for all of the responses on this post i have gotten some good perspective some hilarious comments and some cool advice i appreciate all of you on this subreddit i do want to say that i do not believe that all data scientists need to know kafka or any other specific tech i dont know a bunch of stuff i brought up the kafka example because it was the most egregious the person claimed to have all these years of experience but didnt know a bunch of stuff including the basics the conversation was minutes so i only wanted to bring up the outliersnotable examples and i want to emphasize that i was talking about all data science jobs data scientist data analyst data engineer machine learning engineer data architect etc because i think that these are all valid roles and that we all have unique experiences skills and knowledge to bring to this field anyways i appreciate all the comments and i will read through them after work,,,,,
1k44mgg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-21 04:01:43,weekly entering transitioning thread apr apr welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1k3nxj7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 14:36:36,pandas why the hype im an r user and im at the point where im not really improving my programming skills all that much so i finally decided to learn python in earnest ive put together a few projects that combine general programming ml implementation and basic data analysis and overall i quite like python and it really hasnt been too difficult to pick up and the few times ive run into an issue ive generally blamed it on r eg the day i learned about mutable objects was a frustrating one however basic analysis like summary stats feels impossible all this time ive heard python users hype up pandas but now that i am actually learning it i cant help think why simple aggregations and other tasks require so much code but more confusng is the syntax which seems to be odds with itself at times sometimes we put the column name in the parentheses of a function other times be but the column name in brackets before the function sometimes we call the function normally egmean other times it is contain by quotations the whole thing reminds me of the angostura bitters bottle story where one of the brothers designed the bottles and the other designed the label without talking to one another anyway this wasnt really meant to be a rant im sticking with it but does it get better should i look at polars instead to r users everyone needs to figure out what hadley wickham drinks and send him a case of it,,,,,
1k3jt7b,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 10:42:51,is there something similar tailored for data science interviews asking on behalf of my friend ,,,,,
1k3e4nb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-20 04:03:47,unit tests serious question can anyone provide a real example of a series of unit tests applied to an mlops flow and when or how often do these unit tests get executed and who is checking them sorry if this question is too vague but i have never been presented an example of unit tests in production data science applications,,,,,
1k33k6t,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 18:58:05,finally releasing the bambu timelapse dataset open video data for printfailure ml sorry for the delay hey everyone i know its been a long minute since my original callforclips life got hectic and the project had to sit on the back burner a bit longer than id hoped thanks for bearing with me whats new the dataset is live on hugging face and ready for download or contribution first models are on the way starting with buildplate identification but i cant promise an exact release timeline yet life still throws curveballs dataset page whats inside timelapse videos from px printers fulllength camera recordings straight off the printer cam thumbnails csv metadata for quick indexing ccby license free for hobby research and even commercial use with proper attribution why bother its the first fully open corpus of bambu timelapses most prior failuredetection work never shares raw data bambu lab printers are everywhere so the footage mirrors realworld conditions great sandbox for manufacturing qa projectsfailure classification anomaly detection buildplate detection and more contribute your clips open a pull request on the repo originalstimelapsesyour_id if prs arent your jam dm me and well arrange a transfer link please crop or blur anything private aim for bedonly views skill level if you know some python and basic ml this is a perfect intermediate project to dive into computer vision total beginners can still poke around with the sample code but training solid models will take a bit of experience thanks again for everyones patience and for the clips already sharedcant wait to see what the community builds with this,,,,,
1k32lrl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 18:15:04,python users which r packages do you use if any im currently writing an r package called rixpress which aims to set up reproducible pipelines with simple r code by using nix as the underlying build tool because it uses nix as the build tool it is also possible to write targets that are built using python here is an example of a pipeline that mixes r and python i think rixpress can be quite useful to python users as well and i might even translate the package to python in the future and im looking for examples of python users that need to also work with certain r packages these examples would help me make sure that passing objects from and between the two languages can be as seamless as possible so python data scientists which r packages do you use if any,,,,,
1k2y84g,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 15:01:46,data science content gap im trying to get back into the habit of writing data science articles i can cover a wide range of topics including ab testing causal inference and model development and deployment id love to hear from this communitywhat kinds of articles or posts would be most valuable to you i know theres already a lot of content out there and im to understand im writing something people find valuable edit thanks for the response ive learned that people want to see more realworld data science applications here are a few topics i could write about using time series forecasting to determine the best location for building a hydro power plant developing topline kpi metrics to track product or business health modeling clv for bb businesses especially where most revenue comes from a few accounts applying quasiexperiments to measure the impact of marketing campaigns prioritizing different genai opportunities detecting survey fraud by analyzing mouse movement developing a full endto end modeling,,,,,
1k2u4nd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-19 11:27:41,leverage points for a design matrix with mainly categorial features hello i hope this is a stupid question and gets quickly resolved as per title i have a design matrix with a high amount of categorial features i am applying a linear regression model on the data set mainly for training myself to get familiarity with linear regression the model has a high amount of categorial features that i have onehot encoded now i try to figure out high leverage points for the design matrix after a couple of attempts i was wondering if that would even make sense and how to evaluate if determining high leverage points would generally make sense in this scenario after asking chatgpt which provided a weird answer i know is incorrect and searching a bit i found nothing explaining this so i thought i come here and ask in how far does it make sense to computecheck for leverage values given that there is a high amount of categorial features how to compute them would i use the diagonal of the hat matrix or is there eventually another technique i am happy about any advise or hint explanation or approach that gives me some clarity in this scenario thank you,,,,,
1k2igce,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 23:15:55,what sweai engineer skills in can i learn to complement data science at my company currently the hype is to use llms and genai at every intersection i have seen this means that a lot of ds work is now instead handed to swes and the modelling is all a gptapi call maybe this is just a feature of my company and the way they look at their tech stack but i feel that ds is not getting as many projects and things are going to the swes only as they can quickly build and rapidly deploy into product i want to better learn how to integrate genai featuresapps in our javascript based product so that i can also build and integrate and build working pocs rather than being trapped in notebooks im not sure if i should just learn raw js because id even want to know how to put things into a silent test as an example where predictions are made but no prediction is shown to the user maybe the more apt title is going from a ds ai engineer and what skills to learn to get there,,,,,
1k2ax74,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:43:54,what does a good ds manager look like to you how does one manage a ds project hi all i have found myself numerous times in leadership roles for data science projects i never feel that i am doing a sufficient job i find that i either end have up doing a lot of the work on my own and failing to split up task in the data science realm a lot of these projects and i hate to say it like this without sounding cocky i feel that i can do on my own from end to end maybe some minimal support from other teams in helping with data flow issues etc im not a manager by any means i am individual contributor for those in this subreddit who are managers what are some ways you found success in managing data science teams and projects for those as individual contributors what are some things that you like to have in a data science manager,,,,,
1k2a8t6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 17:15:21,forecasting principles and practice the pythonic way ,,,,,
1k26kp3,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 14:41:25,whats your data science coding stack ai tools workflow curious how others are working these days whats your current setup ide notebook tools vs code cursor jupyter etc are you using ai tools like cursor windsurf copilot cline roo how do they fit into your workflow eg prompting style tasks theyre best at any wins limitations or tips,,,,,
1k26920,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 14:27:09,how do you go about memorizing all the ml algorithms details for interviews ive been preparing for interviews lately but one area im struggling to optimize is the ml depth rounds right now im reviewing islr and taking notes but im not retaining the material as well as id like even though i studied this in grad school its been a while since i dove deep into the algorithmic details do you have any advice for preparing for ml breadthdepth interviews any strategies for reinforcing concepts or alternative resources youd recommend,,,,,
1k22cd4,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 11:10:37,working with distance im super curious about the solutions youre using to calculate distances i cant share too many details but we have data that includes two addresses and the gps coordinates between these locations while the results weve obtained so far are interesting they only reflect the straightline distance google has an api that allows you to query travel distances by car and even via public transport however my understanding is that their terms of service restrict storing the results of these queries and the volume of the calls have any of you experts explored other tools or data sources that could fulfill this need this is for a corporate solution in the uk so it needs to be compliant with regulations edit thanks you guys are legends,,,,,
1k20azb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 08:53:19,have a lot of experience but not getting any interviews help hi i was here a few weeks back and you helped me to cut down my cv and demo more impact i have applied to jobs all over and get only rejections i know the market is hard right now but i would think that i would at least get invited to have at least initial conversations this makes me think there must be something really missing could you tell me what you think it could be due to ai hype there are a lot of postings with llms i dont have corporate experience there but i plan to do projects to learn demo it this week i have lowered my salary requirements by k and still get rejections i have versions a pager and a pager have been applying with the pager mostly until now am grateful for your feedback and any help you can give me,,,,,
1k1x464,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 05:10:50,what is the difference between did and incremental testing i did search online and gpt but didnt find convincing difference hi what is the difference between did and incremental testing i did search online and gpt but didnt find convincing difference i dont get it as both are basically difference between control and treatment group if anyone could explain then would be great help thanks,,,,,
1k1wu9o,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 04:53:31,forecasting models for small data in operations hi i work in a company that provides a weekly service to our customers one of the most important things for our operations is to know to weeks in advance how many customers we expect to have for each of those future weeks company is operating for about years so there are roughly historical data points i wonder which data science ml models are best for small data with some seasonal trends facebook prophet arima and sarima are the ones we use but it feels like we are missing some any thoughts,,,,,
1k1vo23,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-18 03:43:49,advice before getting data engineer fellowship position hey everybody i need some advice i have an msc in data science and have really struggled to find jobs i got an average paying data science adjacent but not data science enough quantitative analyst job in a bank in fact i feel like i get dumber every day im there and im miserable none of the skills or achievements there are noteworthy no model building no big analyses no data engineering or gen ai work just model validation work helping other people fix their modeling solutions long story short im interviewing for a fellowship position to be a data engineer in a nonprofit it lasts for one year and exposes me to many clients that i will aid at most i can extend the fellowship for one additional year it sounds exciting it pays k less but its a step in the right direction it gets me closer to what i actually studied the reason i write this post is because i want to know if it will negatively impact my resume or future chances if i take this job my resume will look like this data analyst job years with a bit of sql and excel two data science internships one months and one months at the university quantitative analyst months data engineer fellowship year will this make companies look at me like a problem and not give me a chance to even interview thanks in advance everybody,,,,,
1k1ohsp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 21:39:22,website that allow comparing vlms and llms i am trying to initiate a project in which i will describe images then the descriptions will go through another pipeline i already tested chatgpt and saw that it was successful in giving me the description i needed however it is expensive and infeasible for my project there are going to be billions of images i am searching for an online platform that enables comparison of various vlm outputs thanks,,,,,
1k1mjok,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 20:15:22,lead ds book suggestions ive landed my first role as a lead ds my responsibilities outside actual ds work is upskilling the analytics team in python r and powerbi which ive got experience with however this is the first role where im mentoringcoachingleading a team i would welcome any suggestions for reading materials that would help me in this new leadership role thank you for your time,,,,,
1k1lh3r,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 19:30:23,experiences from past open data science conferences odsc i have an opportunity to attend odsc east and want to see if this is worth it as a ms cs graduate looking for networking and employment opportunities i am less interested in tutorials and workshops than in networking and employment is it worth it to show up with a resume and portfolio links looking to network i searched this sub and reviews are mixed but fairly old anyone gone recently,,,,,
1k0zcye,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-17 00:02:25,data engineer trying to understand data science to provide better support i work as a data engineer who mainly builds maintains data warehouses but now im starting to get projects assigned to me asking me to build custom data pipelines for various data science projects and im assuming deployment of data scienceml models to production since my background is data engineering how can i learn data science in a structured bottom up manner so that i can best understand what exactly the data scientists want this may sound like overkill to some but so far the data scientist im working with is trying to build a data science model that requires enriched historical data for the training of the data science model ok no problem so far however they then want to run the data science model on the data as its collected before enrichment but the problem is this data science model is trained on enriched historical data that wont have the exact same schema as the data thats being collected real time whats even more confusing is some data scientists have said this is ok and some said it isnt i dont know which person is right so id rather learn at least the basics preferably through some good books projects so that i can understand when the data scientists are asking for something unreasonable i need to be able to easily speak the language of data scientists so i can provide better support and let them know when theres an issue with the data that may effect their data science model in unexpected ways,,,,,
1k0vdku,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 21:02:18,quick question regarding nested resampling and model selection workflow edit post wording is confusing when i refer to models i mean one singular model tuned n number of ways eg random forrest tuned to different depths would be model abcd in my diagram just wanted some feedback regarding my model selection approach the premise need to train dev a model and i will need to perform nested resmapling to prevent against spatial and temporal leakage outer samples will handle spatial leakage inner samples will handle temporal leakage i will also be tuning a model via the diagram below my model tuning and selection will be as follows make inital data budget perfrom some number of spatial resamples shown here for each spatial resample i will make n shown spatial splits for each inner time sample i will train and test n shown models and mark their perfromance for each outer samples inner samples one winner model will be selected based on some criteria eg model a out performs all models trained innner samples for outer sample outerspatial winner model a outerspatial winner model d outerspatial winner model c outerspatial winner model a i take each winner from the previous step and train them on their entire train sets and validate on their test sets eg train model a on outer train and test on outer test train model d on outer train and test on outer test and so on from this step the model the perfroms the best is then selected from these and then trained on the entire inital train and evalauated on the inital holdout should i change my method up at all i was thinking that i might be adding bias in to the second modeling step training the winning models on the outerspatial samples because there could be differences in the spatial samples themselves potentially some really bad data ends up exclusively in the test set for one of the outer folds and by default make one of the models not be selected that otherwise might have,,,,,
1k0v0dc,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 20:46:54,does anyone here work for doordash discover home depot or liberty mutual why do you keep posting the same jobs over and over again,,,,,
1k0mdr3,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 14:53:37,did great in the coding round but still never heard back from the hr i had a python and sql coding round last week i managed to do all the questions within the given time interviewer had to provide hint for a syntax in one of the questions but everything except that i was able to do on my own even spoke out loud about my thought process at the end the interviewer said i passed both sql and python and to expect to hear from hr on the next steps to my surprise i never heard back from anyone i cant seem to understand what could i have done better was requiring hint for syntax a deal breaker it feels a bit disappointing as i dont even know what to improve going forward based on your experience is this a normal scenario,,,,,
1k0c459,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 04:38:29,data science is not about theres a lot of posts on linkedin which claim data science is not about python its not about sql its not about models its not about stats but its about storytelling and business value there is a huge amount of people who are trying to convince everyone else in this bs imho its just not clear why technical stuff is much more important it reminds me of some rich people telling everyone else that money doesnt matter,,,,,
1k082ij,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-16 00:58:27,is timeseriessplit appropriate for purchase propensity prediction i have a dataset of price quotes for a service with the following structure client id quote id date daily target variable indicating whether the client purchased the service and several features im building a model to predict the likelihood of a client completing the purchase after receiving a quote does it make sense to use timeseriessplit for training and validation in this case would this type of problem be considered a time series problem even though the prediction target is not a continuous timedependent variable,,,,,
1jzml32,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-15 08:17:24,is agentic ai remotely useful for real business problems agentic ai is the latest hype train to leave the station and there has been an explosion of frameworks tools etc for developing llmbased agents the terminology is all over the place although the definitions in the anthropic blog building effective agents seem to be popular i like them has anyone actually deployed an agentic solution to solve a business problem is it in production ie more than a poc is it actually agentic or just a workflow i can see clear utility for openended web searching tasks eg deep research where the user validates everything but having agents autonomously navigate the internal systems of a business and actually being useful and reliable just seems fanciful to me for all kinds of reasons how can you debug these things there seems to be a vast disconnect between expectation and reality more than weve ever seen in ai am i wrong,,,,,
1jz4teg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 17:36:38,why wont they let you run your code so i just got done with a sql zoom screen i practiced for a long time on mediums and hards one thing that threw me off was i was not allowed to run the query to see the result the problems were medium and hard often requiring multiple joins and ctes mediums hards mins only got done with and they wouldnt even tell me if i was right or wrong just logic looks sound all the practice resources like leetcode and data lemur allow you to run your code i did not expect this is this common practice definitely failed and feel totally dejected,,,,,
1jz0h1y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 14:39:04,saw greg pinged me logged off immediately ,,,,,
1jyu503,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 08:46:26,powerbi but not powerbi figured this was the best community to ask this question i have a bunch of personal data think personal finance spreadsheet type stuff and id love to build a dashboard for it purely for me i have access to power bi through my work so i know how to build the sort of thing i want however i obviously cant use my work account to create a personal dashboard with my personal data etc so im trying to find alternative solutions to set up a personal pbi account seems to need a lot of hoops like owning your own domain for an email address etc so im wondering if anyone in this community might use any other dashboard tools that they reccomend and that would have similar basic functionality and be a bit less faff to try and set up a personal account,,,,,
1jyq1tk,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 04:01:49,weekly entering transitioning thread apr apr welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1jyloqi,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-14 00:01:06,reputed graduate certificates since finishing my masters in stats years ago the field has changed a lot i feel like my education had a lot of useless classes and missed things like bayesian graphs dl big data etc stanford seems to have some good graduate certs with classes im interested in and my employer will cover the costs are these worth taking or is there a better way to get this info online i have yoe as ds at well known companies so will these graduate certs from reputed unis improve my resume or is it similar to coursera,,,,,
1jyicx6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 21:19:41,why are methods like forwardbackward selection still taught when you could just use lassorelaxed lasso instead,,,,,
1jygakg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 19:48:56,features you would love if someone were to create a new cloud based data system what features would you love it to have what features do other services lack,,,,,
1jy2pe0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 08:04:16,is a masters still necessary can i break into ds with just a bachelors i have yoe of relevant experience although not titled as data scientist i always come across roles with bachelors as a minimum requirement but masters as a preferred however i have not been picked up for an interview at all i do not want to take the financial burden of a masters degree since i already have the knowledge and experience to succeed but it feels like i am just putting myself at a disadvantage in the field should i just get an online degree for the masters stamp,,,,,
1jxtzs1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 23:11:08,which topics or questions frequently asked for a data science role in traditional banks or for fraud detectionrisk modeling topics hi i am proficient with statisticscausal inference parametric non parametric tests and ml models but i dont what models statistical techniques are used in fraud detection and risk modeling especially in finance industry so could anyone suggest faqs or topics i should focus more on or any not common topic you ask to candidates that are crucial to know role requires years of experience also would like to know what techniques you work on in your day to work in fraud detection it would help me great how it works in industry and prepare for a potential interview thanks edit would you consider it to be similar like anomaly detection in time series if so what methods you use in your company i know concept of a few methods like zscore arima sarima med and other but would like to know in practice what you use as well edit i am interested more on the topics that i could learn like i know sql and python will be there,,,,,
1jxl18x,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 16:20:55,ace the interview sql intuitively and exhaustively explained sql is easy to learn and hard to master realistically the difficulty of the questions you get will largely be dictated by the job role youre trying to fill from its highest level sql is a declarative language meaning it doesnt define a set of operations but rather a desired end result this can make sql incredibly expressive but also a bit counterintuitive especially if you arent fully aware of its declarative nature sql expressions are passed through an sql engine like postgresql mysql and others thes engines parse out your sql expressions optimize them and turn them into an actual list of steps to get the data you want while not as often discussed for beginners i recommend sqlite its easy to set up in virtually any environment and allows you to get rocking with sql quickly if youre working in big data i recommend also brushing up on something like postgresql but the differences are not so bad once you have a solid sql understanding in being a high level declaration sqls grammatical structure is fittingly fairly high level its kind of a weird super rigid version of english sql queries are largely made up of keywords special words in sql that tell an engine what to do some common ones which well discuss are select from where insert update delete join order by group by they can be lowercase or uppercase but usually theyre written in uppercase identifiers identifiers are the names of database objects like tables columns etc literals numbers text and other hardcoded values operators special characters or keywords used in comparison and arithmetic operations for example or not in like well cover these later clauses these are the major building block of sql and can be stitched together to combine a queries general behavior they usually start with a keyword like select defines which columns to return from defines the source table where filters rows group by groups rows etc by combining these clauses you create an sql query there are a ton of things you can do in sql like create tables create table peoplefirst_name last_name age favorite_color insert data into tables insert into people values tom sawyer white mel gibson green daniel warfiled yellow select certain data from tables select first_name favorite_color from people search based on some filter select from people where id and delete data delete from people where age what was previously mentioned makes up the cornerstone of pretty much all of sql everything else builds on it and there is a lot primary and foreign keys a primary key is a unique identifier for each record in a table a foreign key references a primary key in another table allowing you to relate data across tables this is the backbone of relational database design super keys and composite keys a super key is any combination of columns that can uniquely identify a row when a unique combination requires multiple columns its often called a composite key useful in complex schemas like logs or transactions normalization and database design normalization is the process of splitting data into multiple related tables to reduce redundancy first normal form nf ensures atomic rows second normal form nf separates logically distinct data and third normal form nf eliminates derived data stored in the same table creating relational schemas in sqlite you can explicitly define tables with foreign key constraints using create table these relationships enforce referential integrity and enable behaviors like cascading deletes sqlite enforces not null and unique constraints strictly making your schema more robust entity relationship diagrams erds erds visually represent tables and their relationships dotted lines and cardinality markers like or n indicate how many records in one table relate to another which helps document and debug schema logic joins join operations combine rows from multiple tables using foreign keys inner join includes only matched rows left join includes all from the left table and full outer join emulated in sqlite combines both proper joins are critical for data integration filtering and leftright join differences join order affects which rows are preserved when theres no match for example using left join ensures all lefthand rows are kept useful for identifying unmatched data sqlite lacks right join but you can simulate it by flipping the table order in a left join simulating full outer joins sqlite doesnt support full outer join but you can emulate it with a union of two left join queries and a where clause to catch nulls from both sides this approach ensures no records are lost in either table the where clause and filtration where filters records based on conditions supporting logical operators and or numeric comparisons and string operations like like in and regexp its one of the most frequently used clauses in sql distinct selections use select distinct to retrieve unique values from a column you can also select distinct combinations of columns eg select distinct name grade to avoid duplicate rows in the result grouping and aggregation functions with group by you can compute metrics like avg sum or count for each group having lets you filter grouped results like showing only departments with an average salary above a threshold ordering and limiting results order by sorts results by one or more columns in ascending asc or descending desc order limit restricts the number of rows returned and offset lets you skip rows useful for pagination or ranked listings updating and deleting data update modifies existing rows using set while delete removes rows based on where filters these operations can be combined with other clauses to selectively change or clean up data handling nulls null represents missing or undefined values you can detect them using is null or replace them with defaults using coalesce aggregates like avgcolumn ignore nulls by default while count includes all rows subqueries subqueries are nested select statements used inside where from or select theyre useful for filtering by aggregates comparisons or generating intermediate results for more complex logic correlated subqueries these are subqueries that reference columns from the outer query each row in the outer query is matched against a custom condition in the subquery powerful but often inefficient unless optimized common table expressions ctes ctes let you define temporary named result sets with with they make complex queries readable by breaking them into logical steps and can be used multiple times within the same query recursive ctes recursive ctes solve hierarchical problems like org charts or category trees a base case defines the start and a recursive step extends the output until no new rows are added useful for generating sequences or computing reporting chains window functions window functions perform calculations across a set of table rows related to the current row examples include rank row_number lag lead sum over and moving averages with sliding windows these all can be combined together to do a lot of different stuff in my opinion this is too much to learn efficiently learn outright it requires practice and the slow aggregation of concepts over many projects if youre new to sql i recommend studying the basics and learning through doing however if youre on the job hunt and you need to cram you might find this breakdown useful,,,,,
1jxk5za,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 15:42:38,building a reliable texttosql pipeline a stepbystep guide pt ,,,,,
1jxe7rg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 10:24:53,help modeling tariff impacts on trade flow im working on a trade flow forecasting system that uses the ras algorithm to disaggregate highlevel forecasts to detailed commodity classifications the system works well with historical data but now i need to incorporate the impact of new tariffs without having historical tariff data to work with current approach use historical trade patterns as a base matrix apply ras to distribute aggregate forecasts while preserving patterns need help with methods to estimate tariff impacts on trade volumes by commodity incorporating price elasticity of demand modeling substitution effects trade diversion integrating these elements with our ras framework any suggestions for modeling approaches that could work with limited historical tariff data particularly interested in econometric methods or data science techniques that maintain consistency across aggregation levels thanks in advance,,,,,
1jxdlfg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 09:38:49,marketing mix models are they really a good idea hi ive seen a prior thread on this but my question is more technical a prior company got sold a return on marketing invest project by one of the big consultancies the basis of it was build a bunch of mmms pump the budget in and it automatically tells what you where to spend the budget to get the most bang for you buck sounds wonderful i was the ds shadowing the consultancy to learn the models so we could do a refresh the company had an annual marketing budget of m and its revenue was between and bn once i got into doing the refresh i really felt the process was never going to succeed marketing thought theres years of data we must have a good model but in reality weeks is a tiny amount of data when you try to fit in tv radio press ooh whitemail email search social and then include prices from you and comp and seasonal variables you need to adstock each media to take affect for lags and finding the level of adstock requires experimentation the weeks need to have a test and possibly a validation set given the experiments the business is then interested in things like what happens when we do tv and ooh together which means creating combined variables more variables on very little data i am a practical data scientist i dont get hung up on the technical details and am focused on generating value but this whole process seemed a crazy and expensive waste of time the positive that came out of it was that we started doing ab testing in certain areas where the initial models suggested there was very low return and those areas had previously been very resistant to any kind of testing this feels a bit like a rant but im genuinely interested if people think it can work it feels like its a over promising in the worst way,,,,,
1jx5k15,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 01:03:26,any good classification datasets that are comprised primarily of categorical features looking to test some segmentation code real world data preferred,,,,,
1jwlf3f,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 09:04:26,causal inference casework hii all my team currently has a demand forecasting model in place though it answers a lot of questions but isnt very good i did a one day research on casual inference and from a brief understanding i feel it can be something worth looking at i am a junior data scientist how can i go forward and put this case forward to the principal data scientist from whom i need a sign off essentially should i create a poc on my own without telling anyone and present it with the findings or are there better ways thanks in advance,,,,,
1jwduc6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 01:04:56,predicting with anonymous features how and why ,,,,,
1jwbevk,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 23:02:18,what technical skills should young data scientists be learning data science is obviously a broad and illdefined term but most ds jobs today fall into one of the following flavors data analysis ab testing causal inference experimental design traditional ml supervised learning forecasting clustering data engineering etl cloud development model monitoring data modeling applied science deep learning optimization bayesian methods recommender systems typically more advanced and niche requiring doctoral education the notion of a full stack data scientist has declined in popularity and it seems that many entrants into the field need to decide one of the aforementioned areas to specialize in to build a career for instance a seasoned product ds will be the best candidate for senior product ds roles but not so much for senior data engineering roles and vice versa since i find learning and specializing in everything to be infeasible i am interested in figuring out which of these paths will equip one with the most employable skillset especially given how fast ai is changing the landscape for instance when i talk to my product ds friends they advise to learn how to develop software and use cloud platforms since it is essential in the age of big data even though they rarely do this on the job themselves my data engineer friends on the other hand say that data engineering tools are easy to learn change too often and are becoming increasingly abstracted making developing a strong productbusiness sense a wiser choice is either group right am i overthinking and would be better off just following whichever path interests me most edit i think the essence of my question was to assume that candidates have solid business knowledge given this which skillset is more likely to survive in today and tomorrows job market given ai advancements and market conditions saying all or multiple pathways will remain important is also an acceptable answer,,,,,
1jw7i9l,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 20:11:29,seeking advice finetuning hello i am still new to fine tuning trying to learn by doing projects currently im trying to fine tune a model with unsloth i found a dataset in hugging face and have done the first project the results were fine based on training and evaluation loss so in my second project i decided to prepare my own data i have pdf files with plain text and im trying to transform them into a question answer format as i read somewhere that this format is necessary to fine tune models i find this a bit odd as acquiring such format could be nearly impossible so i came up with two approaches i extracted the text from the files into small chnuks first one is to use some nlp technics and pre trained model to generate questions or queries based on those chnuks results were terrible maybe im doing something wrong but idk second one was to only use one feature which is the chunks only row dataset shape is i trained it on steps and notice an overfitting by measuring the loss of both training and testing test loss was point something and traing loss was somthing my questions are how do you prepare your data if you have pdf files with plain text my case datset about law what are other evaluation metrics you do how do you know if your model ready for real world deployment,,,,,
1jvwexo,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 12:14:12,do professionals in the industry still refer to online sources or old code for solutions hey everyone im currently studying and working on improving my skills in data science and ive been wondering something do professionalsthose already working in the industrystill take reference from online sources like stack overflow old github repos documentation or even their previous jupyter notebooks when theyre coding sometimes i feel like im cheating when i google things i forgot or reuse snippets from old work but is this actually a normal part of professional workflows for example take this small code block below instantiate the random forest classifier rf randomforestclassifierrandom_state create a dictionary of hyperparameters to tune cv_params max_depth none max_features max_samples min_samples_leaf min_samples_split n_estimators define a list of scoring metrics to capture scoring accuracy precision recall f instantiate the gridsearchcv object rf_cv gridsearchcvrf cv_params scoringscoring cv refitrecall would professionals be able to code this entire thing out from memory or is referencing docs and previous code still common,,,,,
1jvrgr5,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 06:37:36,fixing the agent handoff problem in llamaindexs agentworkflow system fixing the agent handoff problem in llamaindexs agentworkflow system the position bias in llms is the root cause of the problem ive been working with llamaindexs agentworkflow framework a promising multiagent orchestration system that lets different specialized ai agents hand off tasks to each other but theres been one frustrating issue when agent a hands off to agent b agent b often fails to continue processing the users original request forcing users to repeat themselves this breaks the natural flow of conversation and creates a poor user experience imagine asking for research help having an agent gather sources and notes then when it hands off to the writing agent silence you have to ask your question again the receiving agent doesnt immediately respond to the users latest request the user has to repeat their question why this happens the position bias problem after investigating i discovered this stems from how large language models llms handle long conversations they suffer from position bias where information at the beginning of a chat gets forgotten as new messages pile up different positions in the chat context have different attention weights arxiv in agentworkflow user requests go into a memory queue first each tool call adds messages call result the original request gets pushed deeper into history by handoff time its either buried or evicted due to token limits functionagent puts both tool_call and tool_call_result info into chatmemory which pushes user requests to the back of the queue research shows that in an k token context window information in the first of positions can lose over of its influence weight the llm essentially forgets the original request amid all the tool call chatter failed attempts first i tried the developersuggested approach modifying the handoff prompt to include the original request this helped the receiving agent see the request but it still lacked context about previous steps the original handoff implementation didnt include user request information the output of the updated handoff now includes both chat history review and user request information next i tried reinserting the original request after handoff this worked better the agent responded but it didnt understand the full history producing incomplete results after each handoff i copy the original user request to the queues end the solution strategic memory management the breakthrough came when i realized we needed to work with the llms natural attention patterns rather than against them my solution clean chat history only keep actual user messages and agent responses in the conversation flow tool results to system prompt move all tool call results into the system prompt where they get x more attention weight state management use the frameworks state system to preserve critical context between agents attach the tool call result as state info in the system_prompt this approach respects how llms actually process information while maintaining all necessary context the results after implementing this receiving agents immediately continue the conversation they have full awareness of previous steps the workflow completes naturally without repetition output quality improves significantly for example in a research workflow search agent finds sources and takes notes writing agent receives handoff it immediately produces a complete report using all gathered information researchagent not only continues processing the user request but fully perceives the search notes ultimately producing a perfect research report why this matters understanding position bias isnt just about fixing this specific issue its crucial for anyone building llm applications these principles apply to all multiagent systems complex workflows any application with extended conversations the key lesson llms dont treat all context equally design your memory systems accordingly in different llms the positions where the model focuses on important info dont always match the actual important info spots want more details if youre interested in the exact code implementation deeper technical explanations additional experiments and findings check out the full article on ive included all source code and a more thorough discussion of position bias research have you encountered similar issues with agent handoffs what solutions have you tried lets discuss in the comments,,,,,
1jvlqx7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 01:00:00,is agentic ai a generative ai swe or am i missing a thing basically i just started doing handson around the agentic ai however it all felt like creating multiple functionsmodules powered with genai and then chaining them together using swe skills such as through endpoints some explanation said that agentic ai is proactive and genai is reactive but then i also thought that if you have a function that uses genai to produce output then run another code to send the result somewhere else wouldnt that achive the same thing as agentic ai or am i missing something thank you note this is an oversimplification of a scenario,,,,,
1jvcz3t,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 18:27:13,genai and llm preparation for technical rounds from technical rounds perspective can anyone suggest resources or topics to study for genai and llms i have had some experience with them but then in interviews they go into the depth eg attention mechanism qlearning chunking strategies case studies etc honestly most of what i can see in youtube is just in surface level if its just about calling an api and feeding your documents then its too simple but thats not how interviews happen,,,,,
1jvav77,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 17:02:34,just took a new job in supply chain optimization what do i need to learn to be effective i am new to supply chain and need to know what resourcesconcepts i should be familiar with,,,,,
1jv4xqf,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 12:47:32,hi im a junior in high school and i am interested in data science whats steps should i take to get there from now to the end of high school picture will be referenced later for some background all ive done related to data science is a harvard edx python course which i took twice first time i got all the way to the final project then quit the second time i wasnt able to finish all the lectures though i know i have the skills i really need a refresher on the language some questions i have are is it good to take certifications in this field for example in the computer networking role the ccna is an extremely important certification and can easily get you hired for an entry level position is there anything similar in data science any way to find data science internships idk why but its kinda hard to find data science internships i did manage to find a few but idk which ones the best use of my time any help here in the picture i put a roadmap that i found online the words are kinda small to clarify first they say to learn python then r then git then data structures and algorithms after that they recommend learning sql then mathstatistics then data processing and visualization machine learning deep learning and finally big data is this a good path to follow if so how should i approach going down this route any resources i can use to start learning any other tips would be greatly appreciated thank you all for reading i really appreciate it,,,,,
1juzclh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 06:36:18,familiar matchmaking in gaming to match players with players they like and have played with before ive seen the classic mmrs before based on skill level in many different games but the truth is gaming is about fun and playing with people you already like or who are similar to people you like is a massive fun multiplier so the challenge is how would you design a method to achieve that multiple algorithms or something simpler my initial idea is raw and ripe for improvement during or after a game session is over you get to thumbs up or thumbs down players you enjoyed playing with later on if you are in a matchmaking queue the list of players youve thumbed up is consulted and the party that has players with the greatest total thumbs up points at the top of that list gets matched to your party if there is free space and if you are at the top of the available people on their end too the end goal here is to make public matchmaking more fun and feel more familiar as you get to play repeatedly with players youve enjoyed playing with before the main issue with this type of matchmaking is that over time it would be difficult for newer players to get enough thumbs up to get higher on the list harder to get to play with the people who already have a large pool of people they like to play with i dont know how to solve that issue at the moment,,,,,
1juvgek,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 02:36:43,azure course for beginners learn azure data bricks in hour free azure course for beginners learn azure data bricks in hour,,,,,
1juo7ue,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 20:50:36,absolutely bombed interview i landed a position weeks ago and so far wasnt what i expected in terms of skills basically look at graphs all day and reboot it issues not ideal but i guess its an ok start right when i started i got another interview from a company paying similar but more aligned to my skill set in a different industry i decided to do it for practice based on advice from l people on here first interview went well then got a technical interview scheduled for today and absolutely bombed it it was bad badd it made me realize how confused i was with some of the basics when it comes to the field and that i was just jumping to more advanced skills similar to what a lot of people on this group do it was literally so embarrassing and i know i wont be moving to the next steps basically the advice i got from the senior data scientist was to focus on the basics and dont rush ahead to making complex models and deployments know the basics of sql statistics linear regression logistic xgboost and how youre getting your coefficients and what they mean and python know the basics,,,,,
1ju139m,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 00:45:48,career crossroads ds manager retail w finance background head of finance analytics offer seeking guidance perspectives hey rdatascience hoping to tap into the collective wisdom here regarding a potential career move id appreciate any insights or perspectives you might have my background current role data science manager at a retail company experience years in data science started as ic now manager prior experience years in financema before transitioning into data science the opportunity i have an opportunity for a head of finance analytics role situated within or closely supporting the financial planning analysis fpa function the appeal this role feels like a potentially great way to merge my two distinct career paths finance data science it leverages my domain knowledge from both worlds the head of title also suggests significant leadership scope the nature of the work the primary focus will be data analysis using sql and bi tools to support financial planning and decisionmaking revenue forecasting is also a key component however its not a traditional data science role expect limited exposure to diverse ml projects or building complex predictive models beyond forecasting the tech stack is not particularly advanced likely more sqlbicentric than pythonr ml libraries my concerns questions for the community career trajectory title vs substance moving from a data science manager to a head of finance analytics seems like a step up titlewise however is shifting focus primarily to sqlbidriven analysis and forecasting away from broader mlds projects and advanced techniques a potential functional downstep or specialization that might limit future pure ds leadership roles technical depth vs seniority as you move towards head ofdirectorvp levels how critical is maintaining cuttingedge data science technical depth versus deep domain expertise finance strategic impact through analysis and leadership does the type of technical work eg complex sqlbi vs complex ml become less defining at these senior levels compensation outlook what does the compensation landscape typically look like for senior analytics leadership roles like head of finance analytics especially within fpa or finance departments compared to pure data science managementdirector tracks in tech or other industries trying to gauge the longterm financial implications im essentially weighing the unique opportunity to blend my background and gain a significant leadership title head of against the tradeoffs in the type of technical work and the potential divergence from a purely data science leadership path has anyone made a similar move or have insights into navigating careers at the intersection of data science and financefpa particularly in roles heavy on analysis and forecasting any perspectives on whether this is a strategic pivot leveraging my unique background or a potential limitation for future highlevel ds roles would be incredibly helpful thanks in advance for your thoughts tldr ds manager yoe ds yoe finance considering head of finance analytics role opportunity to blend background senior title work is mainly sqlbi analysis forecasting less diverseadvanced ds worried about technical downstep vs pure ds track longterm compensation seeking advice,,,,,
1jtyyc0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 23:02:31,do remote data science jobs still exsist evry time i search remote data science etc jobs i exclusively seem to get hybrid if anything results back and most of them are days in office a week do remote data science jobs even still exsist and if so is there some in the know place to look that isnt a paid for site or linkedin which gives me nothing helpful,,,,,
1jtoul7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 16:02:32,data science projects for year of experience hello seniorleadmanager data scientist what kind of data science projects do you typically expect from a candidate with year of experience,,,,,
1jtn8oj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 14:56:15,if snl can go live every week why cant our models go live in months the show doesnt go on because its ready it goes because its i love this quote from saturday night lives creator lorne michaels it holds a lot of wisdom about how projects should be planned and executed in data science it perfectly captures the idea of shaping a project with fixed time and flexible scope too often we get stuck in poc hell when every new project is treated as an experiment requirements tend to be vague definitions of done unclear we fall into the rabbit hole of endlessly tweaking hyperparameters convinced that the right combination will solve all our problems we end up running in circles with yet another poc that never makes it to production lorne understood back in that to make people laugh every saturday they had to work with a fixed time and flexible scope if theyve managed to do that every week for nearly years why cant we get a model into production in less than six months,,,,,
1jtmrxz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 14:36:50,we built a framework for building sql bots and automations hey folks we recently released oxy an opensource framework for building sql bots and automations in short oxy gives you a simple yamlbased layer over llms so they can write accurate sql with the right context you can also build with these agents by combining them into workflows that automate analytics tasks the whole system is modular and flexible thanks to jinja templates you can easily reference or reuse results between steps loop through data from previous operations and connect everything together we have a few folks using us in production already but would love to hear what you all think,,,,,
1jti77o,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 10:40:13,i created a basic playground to help people familiarise themselves with copulas hi guys so this app allows users to select a copula family specify marginal distributions and set copula parameters to visualize the resulting dependence structure a standalone calculator is also included to convert a given kendalls tau value into the corresponding copula parameter for each copula family this helps users compare models using a consistent level of dependence the motivation behind this project is to gain experience deploying containerized applications heres is the link if anyone wants ton interact with it it was build with desktop view in mind but later i realised that its very likely people will try to access via phone it still works but it doesnt look tidy,,,,,
1jtdrvr,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 05:19:02,mscs admit preparing for summer internship recruitement i got admitted to a top mscs program for fall i want to be ready for data science recruitement for summer i have yoe as a data scientist in a fintech firm with a mix of crossfunctional productiongrade projects in nlp genai unsupervised learning supervised learning with high proficiency in python sql and aws unfortunately do not have experience with big data technologies spark snowflake big query etc experimentation ab testing or deployment due to the nature of my job no recent personal projects lastly i did my undergrad from a top school with majors in data science and business had some comprehensive projects from classes currently listed on my resume would highly appreciate advice on the best course of action in the comming months to maximize my chances in landing a good internship in i recognize my weaknesses but would like to determine how i can prioritize them have not recruitedinterviewed in a while add info i am also an international working under an n hb update many of you have flagged that i should not be seeking data science internships with yoe however my current title is quant analyst and is a bit more geared towards finance yes the skills are transferable but the problems and the approach are very different,,,,,
1jtcjlc,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 04:01:43,weekly entering transitioning thread apr apr welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1js5jby,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 15:07:28,is ongoing part time degree considered a red flag during job hunting is ongoing part time degree considered a red flag on your resume during job hunt im pursuing a part time mba on weekends to upskill myself this doesnt affect my productivity at work i am currently considering switching jobs i want to understand if this should be listed on my resume i plan to inform the hiring manager during final stages of the interview let me know if im thinking about this wrong,,,,,
1js1sgj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 11:56:16,how to deal with medium data i recently had a problem at work that dealt with what im coining as medium data which is not big data where traditional machine learning greatly helps and it wasnt small data where you can really only do basic counts and means and medians what im referring to is data that likely has a relationship that can be studied based on expertise but falls short in any sort of regression due to overfitting and not having the true variability based on the understood data the way i addressed this was i used elasticity as a predictor where i divided the percentage change of each of my inputs by my percentage change of my output which allowed me to calculate this elasticity constant then used that constant to somewhat predict what i would predict the change in output would be since i know what the changes in input would be i make it very clear to stakeholders that this method should be used with a heavy grain of salt and to understand that this approach is more about seeing the impact across the entire dataset and changing inputs in specific places will have larger effects because a large effect was observed in the past so i ask what are some other methods to deal with medium sized data where there is likely a relationship but your ml methods result in overfitting and not being robust enough edit the main question i am asking is how have you all used basic statistics to incorporate them into a useful modelproduct that stakeholders can use for data backed decisions,,,,,
1jrz1k5,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 08:42:19,ds seeking development into swe hi community im a data scientist thats worked with both parametric and non parametric models quite experienced with deploying locally on our internal systems recently ive been needing to develop client facing systems for external systems however i seem to be out of my depth are there recommendations on courses that could help a ds with a core in pandas scikit learn keras and tf develop skills on how endpoints and api works development of backend applications in python im guessing it will be a major issue faced by many data scientists id appreciate if you could help with recommendations of courses youve taken in this regard,,,,,
1jrx6qg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 06:28:50,what do you think about the blog towards data science breaking free from medium is it the best blog about data science out there what are your favourites i have been following towards data science for years it was one of the main reasons i considered and took a medium subscription in the past however it recently decided to offboard medium and launch their own independent blog i was wondering about the reasons for this move it is a loss for medium since it was mediums largest publication i also imagine it could possibly be worse for towards data science since they have to get readers to their independent website instead of take advantage of mediums user base i also wanted to know if it is the best data science blog out there since it is now independent what are your favourites here are some of mine data skeptic a weekly email newsletter every wednesday deep dive amazons monthly newsletter focused on data science and machine learning quanta it is a popular science blog and not strictly about data science though some articles have an intersection with it this is my first post on this subreddit i really like it i notice this subreddit is much more motivating and positive compared to some other subreddits on computer science,,,,,
1jrr35h,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 00:30:58,how do you calculate your hourly rate if you were to consider contract over fte i have always been an fte in this field receiving compensations and benefits that extend far beyond the base salary for many years now every contract opportunity a recruiter presented never made financial sense to me regardless of the level and even for top faang employers known for generous pay packages is this really the case and contract workers are scammed in this field or is it just my luck or is it the recruiters robbing us for reference i take my annual tc divide it by weeks times hours because there will be at least unpaid vacation weeks if i contract to estimate my hourly rate which isnt even fair to me because i am not factoring benefits anyway the value i get is always multiples more than the best contract offer a recruiter presented so am i doing it wrong t,,,,,
1jrdrpx,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 14:51:09,ml engineer genai amazon ill be having technical ml engineer interview amazon on thursday and was researching what can i expect to be asked about all online resources talk about ml concepts system design and leadership rules but they seem to omit job description imo it doesnt make any sense for interviewer to ask about pca kmeans linear regression etc when the role is mostly relating to applying genai solutions llm customization and fine tuning also data structures algos seem to me close to irrelevant in that context does anyone have any prior experience applying to this department and know if its better to focus on prioritizing more on genai related concepts or keep it broad or maybe youve been interviewing to different department and can tell how closely the questions were relating to job description,,,,,
1jr680q,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 07:30:24,getting back to data science after years out hi i left the corporate world to try to build my own apps they have not been successful and so i am trying to get hired back as a data scientist i have not yet heard anything from the applications i have sent so i would greatly appreciate your feedback on my cv ive anonymised where i can re the picture in germany it is very normal and even expected that you add a picture so this is why there is a placeholder there cloud computing has become much more prevalent in the posts i see so i am working my way through various azure qualifications my current thoughts are add in linkedin recommendations somehow rewrite the key achievements to show monetary impact current focus is on showing range of skills and impact add git maybe add specific links to the different elements ive done for my own app development greatly appreciate your feedback,,,,,
1jr4rwq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 05:50:44,explain complex interactions beyond univariate insights im analyzing a complex process where the outcome is client conversion rate influenced by both numerical and categorical variables about client profile product features sales service for instance so far only univariate analyses have been used but they fail to explain the variations effectively ive already applied traditional multivariable models like decision trees and shap but they havent provided clear or actionable insights to explain the changes in conversion im now looking for creative multivariable approaches possibly involving dimensionality reduction or latent structure to better explain whats driving conversion any advice on how to approach this differently,,,,,
1jqpm9u,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 18:08:26,data scientist quiz from unofficial google data science blog ,,,,,
1jqjinm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 14:12:50,ace the interview graphs a solid grasp of graph theory can give you an edge in technical interviews especially when the problem at hand is less about code and more about the structure beneath it at their core graphs are about relationships each node represents an entity and each edge represents a relationship this simple abstraction lets you model remarkably complex systems what matters most in interviews is not memorizing jargon but understanding what these structures mean and how to work with them intuitively a graph doesnt care where things are laid outit only matters who connects to whom thats why there are countless ways to visualize the same graph this property reminds us that graph algorithms dont depend on visuals but on connectivity you should also get comfortable with the flavors of graphs some have direction like a tweet being retweeted some allow duplicate edges multigraphs and some are fully connected cliques and complete graphs understanding when to use each form lets you frame problems properly which is half the battle in any interview one of the most powerful concepts is the subgrapha way to isolate parts of a system for focused analysis its useful when troubleshooting a bug analyzing a subset of users or designing modular systems key graph metrics like degree centrality and shortest path help you quantify structure they reveal which nodes are important how information flows and how efficient routes can be these arent just for theorythey appear constantly in ranking algorithms search engine logic and network analysis and dont overlook concepts like bridges which are edges whose removal splits the graph or graph coloring which underpins classic scheduling and resource allocation problems questions about exam scheduling register allocation or task assignment often reduce to coloring graphs efficiently ultimately the interview isnt testing whether you know the name of every centrality metric its testing whether you can recognize a graph problem when you see oneand whether you can think in terms of connections constraints and traversals i noticed the top posts on rdatascience tend to be about getting a job id love to hear about what other topics you think i should cover also i wrote an educational piece on graphs if you want to learn more,,,,,
1jqa0yn,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 05:11:54,does moving between domains a thing hi just started a ds role at a financial company and i was curious to know whether transitioning to a medicalbiologicalanyotherbased company later is possiblecommon in the field do companies care about domain specific knowledge or only about the actual soft and hard skills required for a data scientist initially i started studying ds from the motivation to use data to help people but i grew up and understood that my noble ideas at a young age arent always realistic but the idea it is possible since there are data scientists in these domains really encourages me to try and work with them sometime in the future thanks learned a lot from this sub,,,,,
1jq3j72,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 23:43:56,is there an unspoken glass ceiling for professionals in aiml without a phd degree ive been on the job hunt for mle roles but it seems like a significant portion of them certainly not all prefer a phd over someone with a masters if i look at the applicant profiles via linkedin premium it seems like anywhere from of applicants have phds as well i work for a large organization and many of the leads and managers have phds too so now this got me worried about whether theres an unspoken glass ceiling for ml practitioners without a phd im not even talking about researchapplied scientist positions either but just ml engineers and regular data scientists do you find that this is true if so why is this,,,,,
1jq1lwz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 22:18:39,select typical select unusual select comprehensive hi group im a data scientist based in new zealand some years ago i did some academic work on nonrandom sampling selecting points that are interesting in some sense from a dataset im now thinking about bringing that work to a wider audience i was thinking in terms of implementing as sql syntax although rsnowflake suggests it may work better as a stored procedure this would enable some powerful exploratory data analysis patterns without stepping out of sql we might propose queries like select typical finds records that are average or normal in some sense select unusual finds the records that are most different from the rest of the dataset in some sense select comprehensive finds a group of records that between them represent as much as possible of the dataset select representative finds a group of records that between them approximate the distribution of the full dataset as closely as possible ive implemented a bunch of these selectadjectives in r as a first step most of them work off a difference matrix using a generic metric using gowers distance for example select unusual finds the ten records with the least rms distance from all records in the dataset for demonstration purposes i applied these methods to a test dataset of countries or territories of the world containing various economic and social indicators and found five typical countries are the dominican republic the philippines mongolia malaysia thailand generally middleincome quite democratic countries with moderate social development the most unique countries are afghanistan cuba fiji botswana tunisia and libya none of which is very like any other country a comprehensive list of seven countries spanning the range of conditions as widely as possible is mauritania poor less democratic cote divoire poor more democratic kazakhstan middle income less democratic dominican republic middle income more democratic kuwait high income less democratic slovenia high income more democratic germany very high income the six territories that are most different from each other are sweden the usa the democratic republic of the congo palestine and taiwan the six countries that are most similar to each other are denmark finland germany sweden norway and the netherlands please dont be offended if ive mischaracterised a country you love please also dont be offended if ive said a region is a country that in your view is not a country the blame doubtless rests with my rather outofdate test dataset so any interest in hearing more about this line of work,,,,,
1jpy5qs,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 19:57:27,robbery prediction on retail stores hi just looking for advice i have a project in which i must predict probability of robbery on retail stores i use robbery history of the stores in which i have robberies in the last years im trying to predict this monthly so i add features such as robbery in the area in the last months behind in areas for km i even add month and if it is a festival day on that month i am using xgboost for binary classification wether certain store would be robbed that month or not so far results are bad predicting even robberies in a month with only as true robberies actually so its starting be frustrating anyone has been on a similar project,,,,,
1jpq0x1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 14:31:26,tensorflowkeras vs pytorch for industry i have used both keras and pytorch but only at the surface level i am thinking to learn one in depth keeping dsmle positions in mind i have heard that big companies use tensorflow since it is more flexible in production while pytorch is much more used in academia and research i cant learn both at the same time so want to know which one would be worth my time given that i am working in industry note by tensorflowkeras i meant starting with keras and eventually evolving to tensorflow ps from the comments i can see a lot of preferences for pytorch its a clear winner,,,,,
1joot5w,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 06:11:47,high quality time series data sources with realtime are there any services or offerings that make highquality time series data public perhaps with the option of ingesting data from it in real time ideally a service like this would have anythingovertime available from weather to stock prices to air quality to country migration patterns unified under an easy to use interface which would allow you to explore these data sources and potentially subscribe to them does anything like this exist if not is there any use or demand for anything like this,,,,,
1jogiud,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 22:46:14,psa largest airbnb datasets available for free at airroi i came across this as i was looking to analyze some trends for my data science project it covers more than a million listings and has highquality data for many of the biggest rental markets,,,,,
1jobolz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 19:24:53,tired of ai one of the reasons i wanted to become an ai engineer was because i wanted to do cool and artsy stuff in my free time and automate away the menial tasks but with the continuous advancements i am finding that it is taking away the fun in doing stuff the sense of accomplishment i once used to have by doing a task meticulously for hours can now be done by ai in seconds and while its pretty cool it is also quite demoralising the recent ghibli style photo trend made me wanna vomit because its literally nothing but plagiarism and theres nothing novel about it i used to marvel at the art created by van gogh or picasso and always tried to analyse the thought process that might have gone through their minds when creating such pieces as the starry night so much so that it was one of the first style transfer project i did when learning machine learning but the images now generated while fun seems soulless and the hypocrisy of us using ai for such useless things oh my god it boils my blood thinking about how much energy is being wasted to do some of the stupid stuff via ai all the while there is continuously increasing energy shortage throughout the world and the amount of job shortage we are going to have in the near future is going to be insane because not only is ai coming for software development art generation music composition etc it is also going to expedite the already flourishing robotics industry case in point look at all the agentic mcp and self prompting techniques that have come out in the last months itself i know that no one can stop progress and neither should we but sometimes i dread to imagine the future for not only people like me but the next generation itself are we going to need a universal basic income how is innovation going to be shaped in the future apologies for the rant and being a downer but needed to share my thoughts somewhere ps i am learning to create mcp servers right now so i am a big hypocrite myself,,,,,
1jo82j8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 16:59:00,struggling to understand ab test hi today i tried to understand the ab testing expecially in ml domain for example when a new recommendation system is better than another i losed hours just to understand null hypotesis alpha factor and ttest only to find out that i completely miss a lot of things power mde why ttest vs ztest vs persons chi test do you know a resource to understand all of these things written resources preferred thank you so much,,,,,
1jo2gxt,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 12:53:12,i have tested all the popular coding assistant for data science heres what i found recently i feel like much less productive when doing data science work when i do more software development i think it is because i use ai effectively when building software so i setup a test to find the best ai coding assistant to help with data science task the result is a bit surprising for me none of the popular ai agent works for data science although the demo looks gorgeous google gemini in colab fail pretty bad but there are some tools that has potential and some are already a bit useful check article for more detailed analysis,,,,,
1jnwt7l,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 06:21:15,getting high information value on a credit scoring model im working on a credit scoring model for a few features out of im getting high information values iv such as and however according to the theory the maximum threshold should be anything above this requires severe investigation as it might indicate data leakage ive checked the features and the pipeline several times but i couldnt find any data leakage is it normal to have high iv values or should i investigate further,,,,,
1jnupvt,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 04:01:43,weekly entering transitioning thread mar apr welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1jnkxza,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 19:53:02,use of generative ai im averse to generative ai but is this one of those if you cant beat em join em type of things is it possible to market myself by making projects nowadays without shoehorning llms or wrappers,,,,,
1jnh32k,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 17:05:36,why you should use rmse over mae i often see people default to using mae for their regression models but i think on average most people would be better suited by mse or rmse why because they are both minimized by different estimates you can prove that mse is minimized by the conditional expectation mean so ey x but on the other hand you can prove that mae is minimized by the conditional median which would be mediany x it might be tempting to use mae because it seems more explainable but you should be asking yourself what you care about more do you want to predict the expected value mean of your target or do you want to predict the median value of your target i think that in the majority of cases what people actually want to predict is the expected value so we should default to mse as our choice of loss function for training or hyperparameter searches evaluating models etc edit just to be clear business objectives always come first and the business objective should be what determines the quantity you want to predict and therefore the loss function you should choose lastly this should be the final optimization metric that you use to evaluate your models but that doesnt mean you cant report on other metrics to stakeholders and it doesnt mean you cant use a modified loss function for training,,,,,
1jn9p9e,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 10:37:34,should i invest time learning a language other than python i finished my phd in cs three years ago and ive been working as a data scientist for the past two years exclusively using python i love it especially the statistical side and scripting capabilities but lately ive been feeling a bit constrained by only using one language im debating whether its worthwhile to branch out and learn another language to broaden my horizons r seems appealing given my interests in stats but im also curious about languages like julia scala or even something completely different has anyone here faced a similar decision did learning another language significantly boost your career or was it just a nicetohave skill or maybe this is just a waste of time thanks for any insights update im not completely sure about my long term goals tbh i do like statistics and stuff like causal inference and bayesian inference looks appealing at the same time i feel that doing some dl might also be great and practical as they are the most requested in the industry took some courses about nlp but at my work we mostly do tabular data with classical ml those are the main direction but im aware that they might be too broad,,,,,
1jma2jy,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 00:29:47,how to suck less in math my masters wasnt math heavy but the focus was r and application i want to understand some theory without going back to study calculus and linear algebra not because im lazy but because it is busy at work and im at loss of what to prioritize i feel like i suck at coding too so i give it the priority at work since i spend lots of time data cleaning is there a shortcut coursebook for math specific to data sciencestaistical methods used in research,,,,,
1jm4yzm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 20:36:45,if you are the one who says you want curious and motivated person then do you actually hire them or its just a formality and decide based on tech skills i often see hiring managers and job posts saying they want someone whos curious and motivated i genuinely am i ask a lot of questions on projects whether im working with data or just walking down the street thinking about things ive even shared work that shows this curiosity and drive like how deeply i explore projects or how i published research papers just because i wanted to dive deeper into topics not because i had to for grades i also often think about ways to improve the products we use but i rarely get a response or acknowledgment of these examples so i was wondering how do you actually evaluate curiosity and motivation in a candidate or does it not matter that much and the decision mostly comes down to whether someone meets the coding criteria once the recruiter passes the resume along i personally feel that curiosity is one of the most important traits for a data scientist but im not sure how often that really gets noticed or valued in the process,,,,,
1jlxfhj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 15:15:41,eda is useless hey folks yes that is unpopular opinion eda is useless ive seen a lot notebooks on kaggle in which people make various plots histograms density functions scatter plots etc but there is no point in doing it since at the end of the day just some sort of catboost or lightgbm is used and still such garbage is encouraged as usual great work all that eda is done for the sake of eda and doesnt lead to any kind of decision making,,,,,
1jlu60y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 12:43:03,options for a ds with yoe i have been working as a data scientist for years now in a consulting firm i have experience with classical ml models deep learning models and some experience with genai but my daily tasks revolve mostly around doing adhoc analytics i am a cs grad i am not very interested in analytics and consulting firm so what are the available options for me should i consider sde i dont have the experience though mle or ds in a product based company with more focus on model building i want growth and compensation and more interested in product based companies what are my options whats your advice to be honest working in consulting firm its too much frustrating due to long working hour and daily adhoc requests,,,,,
1jlr7wo,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 09:35:51,need career guidance ambiguity due to rising genai hey everyone i have yoe in ds and my primary expertise is problem solving classic ml regression classification etc azure mlcognitive resources have worked on actual manufacturing finance industry use cases i have dipped my hands a bit in genai neural nets vision models etc but felt they are not my cup of tea i mean i know the basics but dont feel like a natural with those tech primary reason not to prefer genai is because unless you are trainingbuilding llms rare opportunity all you are doing is software development using pretrained models rather than any data science work so my question is to any industry leadersexperts here where should i focus more on path stick to my skills and continue with the same concerned if this sub segment becomes redundant in future path diversify and focus on gen ai or other sub segments path others,,,,,
1jlnhg1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 04:59:43,good at practical ml weak on theory getting the same feedback everywhere how do i fix this recently got this feedback after a machine learning engineer interview you clearly understand how to make ml algorithms work in practice and have solid experience with realworld projects but your explanations of the theoretical concepts behind the algorithms were vague or imprecise we recommend taking a few months to review the fundamentals before reapplying this isnt the first time ive heard this in fact its a pattern im seeing across multiple interviews with techfocused companies and its getting in the way of landing the kinds of roles im really interested in some context ive been working for years as an ml engineer at a large nontech company my experience is pretty diverse from traditional supervised learning to computer vision with a recent shift toward genai llms embeddings prompting rag etc ive built endtoend pipelines deployed models and shipped ml to production but because the work is so applied and lately very genaioriented ive honestly drifted away from the theoretical side of ml now im trying to move into roles at more mlmature companies and im getting stuck at the theory part of the interviews my question is how would you recommend brushing up on ml theory in a structured deep way after being in the field for a while im not starting from zero but i clearly need to tighten up my understanding and explanations would love any advice resources or even personal stories from others who made the leap from appliedpractical ml to more theoryheavy roles thanks in advance,,,,,
1jlmc8t,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-28 03:51:17,roast my freelancing website hey fellow data scientists i am attempting to start my own business as a freelancer i am at the very beginning of my journey i have experience as a free lancer but i do have years of career experience as a data analyst for anyone willing i need constructive criticism on the website ive made i realize its not great i made it with a free square space trial feel free to be brutally honest but if you can offer any improvement advice that would be very appreciated password for the website roast,,,,,
1jlh6ae,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 23:31:35,got a technical interview for data science intern at capital one anyone been through it hey yall just got an invite for a technical interview for a data science internship at capital one wasnt expecting to get this far tbh lol anyone here been through it would love to hear about your experience what kind of stuff do they ask any curveballs or stuff i should brush up on ive done some leetcodestatsprep but not sure what capital one specifically leans into any advice or horror stories lol welcome,,,,,
1jl7q5h,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 16:16:15,how the fuck do i even get started in this field tiny bit of background i have my masters in biostatistics and my undergrad in math and did learn some ml modeling methods during grad school working as a data analyst currently but my daytoday work involves very little actual analysis or even statistics on the other hand reading all the posts and resumes here and current job openings for data scientists i have honest to god no idea how i would ever even get one of these jobs or work towards it i understand that having a statistics background can help in some vague handwavey way but i genuinely dont think i have any of the hard skills needed to work in ds and dont even know where to start,,,,,
1jl6tt4,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 15:38:30,does anyone else lose interest during maintenance mode youve built a cool thing it works great now it needs to be maintained with updates now im bored,,,,,
1jl6otm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 15:32:31,not getting calls for a month now what can i do better what can i do better in this resume ive also worked on more projects but i have only listed high impact projects in my experience,,,,,
1jl5tjk,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 14:55:43,causal inference given calls i have been working on a usecase for causal modeling how do we handle an observation window when treatment is dynamic say we have a month observation window and treatment can occur every day or every other day given this the treatment is repeated or done every other day experimentation is not possible because of this observation window can have overlap from one time point to another ideally i want to essentially create a playbook of different strategies by utilizing say a dynamicdml but that seems pretty complex is that the way to go note that treatment can also have a mediator but that requires its own analysis i was thinking of a simple static model but we cant just aggregate it for example we do treatment day had an immediate effect we the treatment window of days wont be viable day will always have treatment day maybe or maybe not my main issue is reverse causality is my proposed approach viable if we just account for previous information for treatments as a confounder such as a sliding window or aggregate windows ie of times treatment has been done if we model the problem its essentially this treatment response action however it can also be treatment action as response didnt occur,,,,,
1jl1ldy,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 11:22:11,leaving data science what are my options this doesnt seem to be within the scope of the transitioning thread so asking in my own post i have yoe and am in the us was laid off in january was an actuarial analyst back in i have four exams passed using vba and excel worked my way up to data analyst doing sql dashboarding shiny tableau power bi d statistician using r and sql and python and ended up at a lead ds minus things like qlik databricks spark and snowflake i have probably used that technology in a professional setting yes i have used all three major cloud services i have a ms in statistics my thesis was on time series and am currently enrolled in omscs but i am considering ending my enrollment there after having taken cv dl and rl i am very disappointed by how i observe the field has changed since chatgpt came out in the jobs i have had since that time as well as with interviews the general impression i get is that people expect models to do both causal discovery and prediction optimally through mere data ingestion and algorithmic processing without any sort of thought as to what data are available what research questions there are and for what purpose we are doing modeling i did not enter this field to become a software engineer and just watch the process get automated away due to others expectations of how models work only to find that expectations dont match reality and then aside from that i want nothing to do with generative ai that is a whole other can of worms i wont get into very long story short due to my mental health and due to me pushing through genai hype for job security i did end up losing my memory in the process im taking good care of myself as mentioned in the comments ive been weeks into therapy but im at a point right now where im not willing to just take any job without recognizing my mental limits i am looking for data roles tied to actual business operations that have some aspect of requirements gathering analyst engineering scientist manager roles that arent screaming ai all over them and statistician roles but especially given the layoff situation with the federal employees and contractors as well as entrylevel saturation this seems to be an uphill battle i also think im in a situation where i have too much experience for an ic role and too little for a managerial role the most extreme option i am considering is just dropping everything to become an electrician or hvac person not like im particularly attached to due to my memory loss anyway i want to ask this community for two things suggestions for other things to pursue and how to tailor my resume given the current situation i have paid for a resume service and ive had my resume reviewed by tons of people i have done a ton of networking i just dont think that my mindset is right for this field,,,,,
1jkzb3c,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 08:35:54,i built an aipowered outreach system that automates job applications to ceos data heads and tech recruiters hey guys ive been applying for a lot of jobs lately hahaha yeah the market sucks in the states so i decided to build an ai system to make it a little less painful it scrapes linkedin to find ceos data heads and recruiters predicts and verifies their emails writes personalized messages using mistral via ollama picks the best resume from a few versions i have and sends it out automatically i even set up a dashboard to keep track of everything im getting a response rate so far which is way better than the usual black hole experience let me know if youre curious about how it works or if you have any ideas to make it even better,,,,,
1jkvbkv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 03:56:16,designplanning tools and workflows interested in the tools workflows and general approaches other practitioners use to research design and document their ml and analytics solutions my current workflow looks something like this initial requirements gathering and research in a markdown document or confluence page etl eda in one or more notebooks with inline markdown documentation solutionmodel candidate design back in confluencemarkdown and onward to model experimentation iteration deployment documenting as we go i feel like im at the point where my approach to the planningdesign portions are bottlenecking my efficiency particularly for managing complex projects in particular i havent found a satisfactory diagramming tool i bounce around between mermaid diagrams and drawing in powerpoint braindumping in a markdown document feels natural but i suspect i can be more efficient than just starting with a blank canvas and hammering away my team usually uses mlflow to manage experiments but tends to present results by copy pasting into confluence how do you andor your colleagues approach these elements of the ds workflow,,,,,
1jks145,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-27 01:04:17,what the fuck is happening on linkedin and reddit with llms hi im a very regular data scientist really very regular finding good time applying statistics and linear algebra and machine learning to problems with some optimization sometimes end the week with a good prd and call it a day i swore to god id never learn about llms im simply not interested ill never find a thrill learning it let alone absorbing it on my timeline everything now must talk about something every time i open linkedin something dies do any of you guys see an out of this how how can one be a data scientist without having to deal with this every now and then what fields rely on data scientists actually doing data science like work on numbers apply some model create a good pipeline or optimize some process and some storytelling and stuff tbh ive always been interested in ranching or plumbing i guess thats my way out,,,,,
1jkmgo7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 20:56:02,data scientists in france how do i improve my hiring chance i am a freelancer in france i did école ingénieur in statistics my cv is a bit chaotic with short missions in data science then spent year just doing sql r and some power bi no ml i did a gcp tensorflow learning but they won t hire me for these cuz i don t have many projectsor even data science cuz i have a few experience do you have some good projects i can work on since i am unemployed now is it useful to learn something what cuz anyway they ll be like oh u dont have any projects or yr experience in this what are your advice gor me please,,,,,
1jkjs7y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 19:05:38,isnt this solution overkill im working at a startup and someone one my team is working on a binary text classifier to given the transcript of an online sales meeting detect who is a prospect and who is the sales representative another task is to classify whether or not the meeting is internal or external could be framed as internal meeting vs sales meeting we have labeled data so i suggested using two tfidfcount vectorizers simple ml models for these tasks as i think both tasks are quite easy so they should work with this approach imo my team mates who have never really done or learned about data science suggested training two separate llama models for each task the other thing they are going to try is using chatgpt am i the only one that thinks training a llama model for this task is overkill as hell the costs of training inference are going to be so huge compared to a tfidf logistic regression for example and because our contexts are very large k this is going to need a a for training and inference i understand the chatgpt approach because its very simple to implement but the costs are going to add up as well since there will be quite a lot of input tokens my approach can run in a lambda and be trained locally also i should add for of meetings we get the true labels out of meetings metadata so we wouldnt need to run any model even if my tfidf model was worse than the llama approach the real difference would really only be hence why i think this is good enough,,,,,
1jkjee5,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 18:50:18,navigating the team in vested interest i have recent joined as an associate data scientist with previous background of swe this is definitely my dream role and totally love the problems the team are solving but it is kind of an ideal world scenario where the deployment is being done by de team pipelines as well no containerisation or in short no mlops practices i do not like de and the ever changing landscape of swe in general but i am wary of the stuff that this situation might set me back in the near future as all ds job postings do ask for some kind of de cloud containerisation etc how do i get my hands on these things or rather convince the team to move towards these tech stacks,,,,,
1jkfv0p,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 16:26:12,first ds interview next week just informed it will be very data engineering focused advice hi all im going through the interview process for the first time i was informed that i got to the technical round but that i should expect the questions to be very deetl pipeline development focused i have decent experience with datacleaningtransformation for analysis and modelling from my phd but much less with the data ingestion part of the pipeline what suggestions would you give for me to brush up ontools i should be able to talk fluently about the job is going to be dealing with a lot of realtime market data timeseries data heavy etc im kinda surprised as there was no mention until now that it would be the de side of the team they specifically asked for predictive modelling with timeseries data in description but its definitely something im interested in regardless side note do people find that many dstitled jobs these days are actually de or is the field so overlapping that the distinct titles arent super relevant,,,,,
1jka8tt,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 12:10:35,timeseries forecasting ml models perform better than classical forecasting models this article demonstrated that ml models are better performing than classical forecasting models for timeseries forecasting however it has been my opinion also the impression i got from the ds community that classical forecasting models are almost always likely to yield better results anyone interested to have a take on this,,,,,
1jk8klq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-26 10:26:39,first position job seeker and dsmleai landscape armed to the teeth with some projects and a few bootcamp certifications im soon to start applying at anything that moves assuming you dont know how to code all that much what have been your experiences when it comes to the use of llms in the workplace are you allowed to use them did you mention it during the interview,,,,,
1jj82n6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-25 01:35:07,its not you its me ,,,,,
1jivc2n,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 16:47:18,data science thesis on crypto fraud detection looking for feedback hey rdatascience im about to start my masters thesis in ds and im planning to focus on financial fraud detection in cryptocurrency i believe crypto is an emerging market with increasing fraud risks making it a high impact area for applying ml and anomaly detection techniques original plan handling imbalanced datasets from opensources elliptic dataset ciphertrace since fraud cases are rare techniques like smote might be the way to go anomaly detection approaches autoencoders for unsupervised anomaly detection and feature extraction graph neural networks gnns since financial transactions naturally form networks models like gcn or gat could help detect suspicious connections maybe both why this project i want to build an attractive portfolio in fraud detection and fintech as id love to contribute to fighting financial crime while also making a living in the field and i believe amlcft compliance and crypto fraud detection could benefit from aidriven solutions my questions to you any thoughts or suggestions on how to improve the approach should i explore other ml models or techniques for fraud detection any resources datasets or papers youd recommend im still new to the ds world so id appreciate any advice feedback and critics thanks in advance,,,,,
1jiui1n,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 16:13:16,name your job title and what you do at a company wrong answers only basically what title says,,,,,
1jii855,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-24 04:01:44,weekly entering transitioning thread mar mar welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1jhdo7j,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 17:25:59,management at my company claims to want coders innovation but rejects deliverables which arent excel i work at a large financial firm we have a ton of legacy excel processes which require manual work buggy addons or vba code that takes several minutes to load spreadsheets that chug like hell to open or need to be operated with formula calculation off just to work in them management will hype up innovation and will try to hire people with technical skills they will send official communication talking about how the company is adopting ai and hyping up our internal chatbot which is just some enterprise agreement with chatgpt ive tried using python to automate some of our old processes for example for adhoc deliverables ill use pandas and then style my work using greattables ill plot stuff in plotly etc i spend a lot of time styling my tables and plots to make them look professional i use the company color scheme when creating them so that they look right however when i send stuff to my boss or his boss theyll either complain that this doesnt look like the stuff that other people are doing will say i dont like the formatting but wont give specific examples on what to improve wont provide examples of what constitutes good work independently of this i recently spoke with a colleague who made attempts to move towards bi software such as tableau for their processes even they have mentioned that the higher ups will ask for these types of solutions but ultimately prefer excels visuals for the deliverables im at a loss i personally find excel tables and graphs to be ugly including the ones that my colleagues send they look like something that a college student put together if thats what the management wants im inclined to stop complaining and just give it to them but how would i actually do that in python in past jobs ive seen people do stuff like save templates in excel and have python spit the df into the template ive also heard there are packages that can create an excel file and then mark it up from within the code at the end of the day this sounds like a recipe for me to create shitty code and unsustainable processes which we already have plenty of i want to be able to use a real plotting and table packages and perhaps just make something that is just good enough does anyone have any suggestions for me edit this post seems to have gained traction i just wanted to clarify i think some people read this post as if my boss asked me to send an xlsx or csv file and i refused or am unwilling that is not what happened this is a post about visuals and formatting ie sending emails or reports with inline tables and graphscharts if attaching an excel file with a raw df were sufficient obviously i would do that anyway i will look into using pythonexcel packages to mark up my stuff thanks,,,,,
1jhbvbg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 16:07:27,tips for migrating rbased etl workflows to python using llm assistant my team uses r heavily for production etl workflows this has been very effective but i would prefer to be doing this in python anyone with experience migrating r codebases to python using llm assistant our systems can be complex multiple functions sql scripts nested folders config files etc we use rstudio server for an ide ive been using gemini for ideation and some initial translation but its tedious,,,,,
1jhbqxn,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-22 16:02:07,admission requirements of applied statistics ds master im looking at some schools within and outside of us for a master degree study in areas in the subject line just my past college education didnt involve much algebracalculus programming course have acquired some skills thru mitx online courses how can i validate that my courses have met the requirements of such graduate programs and potentially showcase them to the admission committee,,,,,
1jgnzw6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 18:35:30,harnham professional ghosts has anyone else been contacted by a recruiter from harnham conducted a min informational call been told that their resume would be sent to the hiring manager and then subsequently get ghosted by the recruiter its happened to me or or maybe more times now,,,,,
1jgnhn7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 18:14:10,deep learning industry practitioners how do you upskill yourself from the intermediate level ive been recently introduced to gpumode which is a great resource for kernelsgpu utilisation i wondered what else is out there which is not pure research,,,,,
1jgmsj0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 17:45:05,moshivis new conversational ai model supports images as input realtime latency kyutai labs released moshi last year opensourced moshivis a new vision speech model which talks in real time and supports images as well in conversation check demo,,,,,
1jgkdwa,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 16:06:05,scheduling optimization with genetic algorithms and cp hi i have a problem for my thesis project i will receive data soon and wanted to ask for opinions before i went into a rabbit hole i have a metal sheet pressing scheduling problems with n jobs for varying order sizes orders can be split m machines machines are identical in pressing times but their suitability for mold differs every job can be done with a list of suitable subset of molds that fit in certain molds setup times are sequence dependant there are differing setup times for changing molds subset of molds changing of metal sheets pressing each type of metal sheet differs so different processing times there is only one of each mold certain machines can be used with certain molds i need my model to run under hour the company that gave us this project could only achieve a feasible solution with cp within a couple hours my objectives are to decrease earliness tardiness and setup times i wanted to achieve this with a combination of genetic algorithms some algorithm that can do local searches between iterations of genetic algorithms and constraint programming my groupmate has suggested simulated anealing hence the local search between ga iterations my main concern is handling operational constraints in ga i have a lot of constraints and i imagine most of the childs from the crossovers will be infeasible this chromosome encoding a lot of my problems but i still have to handle the fact that i can only use one mold at a time and the fact that this encoding does not consider idle times we hope that constraint programming can add those idle times if we give the approximate machine job allocations from the genetic algorithm to handle idle times we also thought we could add dummy jobs with no due dates and no setup only processing time so there wont be any earliness and tardiness cost we could punish simultaneous usage of molds heavily in the fitness function we hoped that optimally these dummy jobs could fit where we wanted there to be idle time implicitly creating idle time is this a viable approach how do people handle these kinds of stuff in genetic algorithms thank you for reading and giving your time,,,,,
1jgjuhz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 15:43:43,deepml leetcode for machine learning new feature break down problems into simpler steps new feature break down problems into simpler steps weve just rolled out a new feature to help you tackle challenging problems more effectively if youre ever stuck on a tough problem you can now break it down into smaller simpler subquestions these bitesized steps guide you progressively toward the main solution making even the most intimidating problems manageable give it a try and let us know how it helps you solve those tricky challenges its free for everyone on the daily question,,,,,
1jg8inp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-21 04:17:26,really interesting ml use case from strava ,,,,,
1jfv15y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-20 17:55:44,breadth vs depth and gatekeeping in our industry why is it very common when people talk about analytics there is often a nature of people dismissing predictive modeling saying its not real data science or how people gatekeeping causal inference i remember when i first started my career and asked on this sub some person was adamant that you must know real analysis despite the fact in my years of working i never really saw any point of going very deep into a single algorithm or method often not i found that breadth is better than depth especially when its our job to solve a problem as most of the heavy lifting is done wouldnt this mindset then really be toxic in workplaces but also be the reason why we have these unrealistic takehomes where a manager thinks a candidate should for example build a cnn model with data on forensic bullet holes to automate forensic analytics instead its better for the work geared more about actionability more than anything id love to hear what people have to say good coding practice good fundamental understanding of statistics and some solid understanding of how a method would work is good enough,,,,,
1jftqor,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-20 17:02:49,i simulated march madness brackets ,,,,,
1jf8uwm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-19 21:50:22,how exactly people are getting contacted by recruiters on linkedin i have been applying for jobs for almost an year now and i have varied approach like applying directly on the websites cold emailing referral only applying for jobs posted in last hours and with each application been customized for that job description i have got interviews in total and unfortunately no offer but never a recruiter contacted me through linkedin even its regularly updated filled with skills projects and experiences i have made posts regarding various projects and topics but not a single recruiter contacted please share your input if you have received messages from recruiters,,,,,
1jeg1xn,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 21:10:41,setting expectations with management growing as a professional i am a data scientist at a f technically just changed to mle with the same team mostly a personal choice for future opportunities most of the work involves meeting with various clients consulting and building them aiml solutions the work has already been sold by people far above me and its on my team to implement it the issue is something that is probably well understood by everyone here the data is horrific the asks are unrealistic and expectations are through the roof the hard part is when certain problems feel unsolvable given the setup data quality availability of historical data etc i often feel doubt that i am just not smart and not seeing some obvious solution the leadership isnt great from a technical side so i dont know how to grow we had a model that we worked on for ages on a difficult problem that we got down to rmse and the client told us that much error is basically useless i was so proud of it it was months of work of gathering sources and optimizing at the same time i dont want to say this is the best you will get because the work has already been sold it feels like i have to be a snake oil salesmen to succeed which i am good at but feels wrong plus maybe im just missing something obvious that could solve these things anyone who has significant experience in ds specifically generating actual tangible value with mlpredictive analytics is it just an issue with my current role how do you set expectations with nontechnical management without getting yourself let go in the process apologies for the long post any general advice would be amazing thanks,,,,,
1je46q1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 12:50:43,i made a snowflake native app that generates synthetic card transaction data without inputs and quickly ,,,,,
1je02lx,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 08:15:40,spending and demographics dataset is there any free dataset out there that contains spending data at customer level and any demographic info attached i figure this is highly valuable and perhaps privacy sensitive so a good dataset unlikely freely available in case there is some anonymized toy dataset out there please do tell,,,,,
1jdv7ui,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-18 02:47:54,whats your expectation from jensen huangs keynote today in nvidia gtc some ai breakthrough round the corner today jensen huang nvidias ceo and my favourite tech guy is taking the stage for his famous keynote at pm ist in nvidia gtc given the track record we might be in for a treat and some major ai announcements might be coming i strongly anticipate a new agentic framework or some multimodal llm what are your thoughts note you can tune in for free for the keynote by registering at nvidia gtc here,,,,,
1jdotmw,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 21:47:30,what is financial fraud prevention data science like as a career path how are the hours the progression the income and the overall stress and worklife balance for this career path what are the pivots from here edit im most interested in learning about fraud prevention careers for banks and credit cards,,,,,
1jddkvq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 14:12:29,golden gigo ,,,,,
1jd5wub,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 05:58:51,moviesshows who gets it right who gets it so wrong got a fun one for ya which moments in moviesshows have you cringed over and which have you been impressed with in regard to how they discuss the field i feel like the term data hard drive has been thrown around since the s the spyrelated flicks always have some kind of weird geolocatingtracking animation that doesnt exist but who did it relatively well who did it the worst,,,,,
1jd44gj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 04:01:44,weekly entering transitioning thread mar mar welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1jd2kgg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-17 02:35:15,is rpa a feasible way for data scientists to access data siloes basically im debating whether i should make a case for my boss to learn my companys rpa tool ie robot process automation and invest a not insignificant amount of my time into implementing data pipelines we have an rpa tool already available and we have a number of use cases that would benefit from it i havent systematically quantified their value but i do have a rough idea personally i think im overqualifiedoverpaid for this type of data extraction plus its a technically inferior workaround to access siloed data lastly im not sure what that deep dive into business analystdata engineer light territory would mean for my career as a data scientist it might limit me in some ways and it might create opportunities in others on the other side its only way too access some sources now that may or may not change in two years time when a major software system is updated and that depends on it governance two years down the road at a large company long rambling i know my question do you have experience with rpa bots within your data teams or within your departments how and how well does it work for you how sustainable a data pipeline can rpas be do you have any advice for me,,,,,
1jcpd28,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 16:30:46,how to proceed with large work gap given competitive ds market ive been out of work for over a year now and dont get much traction with job applications i imagine the employment gap has rendered me basically unemployable in this market despite having a masters degree and a few years of subsequent work experience plus some unrelated work experience prior to the masters ive even applied to volunteer ds roles just to build my resume and been rejected i recognize that i will likely need to find other means of employment before i can reenter the ds space any advice on how to proceed and become employable again would be greatly appreciated,,,,,
1jcnell,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 15:03:14,reasons why data science projects fail have you ever seen any data science or analytics projects crash and burn why do you think it happened lets hear about it,,,,,
1jclsn8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-16 13:46:52,seeking advice how to effectively develop advanced ml skills about me i am a ds with currently yoe under my belt with experience in bfsi and fmcg in the past couple of months ive spoken with several midlevel data scientists working at my target companies after reviewing my resume they all pointed out the same gaps i lack nlp deep learning and llm experience i dont have any projects demonstrating these skills feedback on my resume format varied from person to person given this id like advice on the following how can i develop an intermediatelevel understanding of nlp dl and llms enough to score a new job courses provide a highlevel overview but they often lack depthwhats the best way to go deeper i feel like im being stretched too thin by trying to learn these topics in different ways courses projects etc how would you approach this to stay focused and maximize learning how do you gauge depth of your knowledge for interview would appreciate any insights or strategies that worked for you,,,,,
1jbqeyy,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-15 08:13:00,solar panel installation rate and energy yield estimation from houses in the neighborhood using aerial imagery and solar radiation maps ,,,,,
1jbhjmx,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 23:29:25,advice on building a data team im currently the chief ie only data scientist at a maturing start up the ceo has asked me to put together a proposal for expanding our data team for the past years ive been doing everything from data engineering to model development and mlops ive been working hour weeks and had to learn a lot of things on the fly but somehow ive have managed to build models that meet our benchmark requirements pushed them into production and started to generate revenue i feel like a jack of all trades and a master of none with the exception of timeseries analysis which was the focus of my phd in a nonrelated stem field im tired overworked and need to be able to delegate some of my work were getting to the point where we are ready to hire and grow our team but i have no experience with transitioning from a solo ic to a team leader has anybody else made this transition in a start up any advice on how to build a team ps please do not send me dms asking for a job we do not do visa sponsorships and we are only looking to hire locally,,,,,
1jbetth,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 21:26:55,chain restaurant data scientists what do you do and what kind of data do you work with is it mostly just marketing do yall ever work on pricing models or wholesalesupply chain analysis is your data internal or external this is all out of academic curiosity i am not currently looking to get into the industry,,,,,
1jbdpuh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 20:38:27,contract for hire work anybody have experience with contract for hire ds work did you convert did you get fired halfway through was it w or were you forced to do the annoying stuff that full timers didnt want to touch ive been ignoring these types of jobs for a while now but am interested in hearing how they are seems like a lack of security and benefits is traded for a high wage but idk should i continue ignoring,,,,,
1jb0i8y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 10:09:41,how much of the ml pipeline am i expected to know as ds im prepping for an l level ds interview at big tech the interview description is that well be doing ml case studies does anyone have a good framework for how to outline how to answer these questions how much you predict customer ltv how would you classify searches on the site how would you predict if the ad will be successful etc similar to the star framework for behavioral interviews how much of the pipeline am i supposed to know from the start to the end some of my interviews in the past have caught me off guard about some part in the pipeline i didnt think was the dss job,,,,,
1javfus,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-14 04:07:49,do you deal with unrealistic expectations from nontechnical people frequently ive been working at my job for a year and in data itself for several years im willing to admit my shortcomings willing to admit mistakes and learn however there are several times where i feel like ive been in situations where there is nowinning recently ive inherited a task from a colleague who has left there is no documentation my only way of understanding this task is through the colleague who assigned it to me who is not really a technical person ive inherited code which is repetitiveredundant difficult to follow and understand what i really want to do is spend time cleaning up this code so that debugging is easier and this code can run better but im not given a chance to do this bc everytime i get a request related to this project im asked to churn something out in less than a day this feels unrealistic bc i dont even have time to understand the outcome and whenever i do exactly as my collague asks it has times broken something downstream forcing me to undo this as soon as possible this has put a strain on other tasks and so when i put this task to the side to do other tasks theres been frustration expressed on me for not doing this task sooner the same colleague who assigned me this task initially told me that if i need help in understanding the requirements he can help with that when ive gone to him to ask questions or send updates he himself looks like he doesnt have time to answer my questions because of back to back meetings when he doesnt respond then he expresses frustration to my boss and other senior colleagues when i havent done something bc im still waiting for a response bc its taking too long my boss has expressed to me he feels i dont ask enough questions that could be holding up the process so i have tried to ask more questions but when colleagues cant get back to me on time im told im not asking the right people or if i ask a question im told im not asking the right question for example this same colleague wanted me to fix a bug and wrote that this bug is causing unexpected results a senior colleague asked me if the requirements to fix this bug are clear to me and i thought to just clarify with the colleague who put in the bug fix request do you want me to remove these records or figure out how to best include them in the end result my boss saw my response and said youre not asking the right question youre not supposed to ask people to do your work for you from my point of view i wasnt asking anybody to do my work bc im the one ultimately who will dive into the code to fix things im at a loss tbhim trying to do all the right things trying to also improve my people skills and understand what people want and how to streamline things i know theres more room for improvement for me but i am struggling with conflicting advice and lack of direction im not sure if others can relate to this,,,,,
1jally0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-13 20:17:31,does anyone have a job which doesnt use llmnlpcomputer vision i am looking for a new job and everything i see is llmnlpcomputer vision that stuff doesnt really interest me seems very computer science and my background is statsanalytics i do linear regression and xgboost do these jobs still exist if so where,,,,,
1jajnyq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-13 18:56:00,has anybody taken the datamasked course is it worth grand a data science coach influencer on linkedin highly recommended it im years post ms from a nonimpressive state school im working in compliance in the banking industry and bored out of my mind id like to break into experimentation marketing causal inference etc would this course be a good use of my money and time,,,,,
1j8kofx,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-11 06:42:20,free registrations for nvidia gtc one of the prominent ai conferences are open now nvidia gtc is set to take place from march bringing together researchers developers and industry leaders to discuss the latest advancements in ai accelerated computing mlops generative ai and more one of the key highlights will be jensen huangs keynote where nvidia has historically introduced breakthroughs including last years blackwell architecture given the pace of innovation this years event is expected to feature significant developments in ai infrastructure model efficiency and enterprisescale deployment with technical sessions handson workshops and discussions led by experts gtc remains one of the most important events for those working in ai and highperformance computing registration is free and now open you can register here i strongly feel nvidia will announce something really big around ai this time what are your thoughts,,,,,
1j8iqpw,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-11 04:30:44,msba with years experience in ds looking to pivot to an mle should i get a masters in cs i feel it would help me bridge the gap in software development and would appeal to recruitersi am unemployed rn,,,,,
1j8g4w9,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-11 02:09:18,mysql for ds interviews hi i currently work as a ds at a ai company we primarily use sparksql but i believe most ds interviews are in mysql any tipsreading material for a smooth transition for my work i use sparksql for eda and featurization,,,,,
1j87x92,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-10 20:03:57,how do you deal with coworkers that are adamant about their ways despite it blowing up in the past was discussing with a peer and they are very adamant of using randomized splits as its easy despite the fact that i proved that data sampling is problematic for replication as the data will never be the same even with random_seed set up factors like environment and hardware play a role i been pushing for model replication is a bare minimum standard as if someone else cant replicate the results then how can they validate it we work in a heavily regulated field and i had to save a project from my predecessor where the entire thing was on the verge of being pulled out because none of the results could be replicated by a third party my coworker says that the standard shouldnt be set up but i personally believe that replication is a bare minimum regardless as models isnt just fitting and predicting with validation if anything we need to ensure that our model is stable the person constantly challenges everything i say and refuses to acknowledge the merit of methodology i dont mind people challenging but constantly saying i dont see the point or it doesnt matter when it does infact matter by rd party validators this person when working with them i had to constantly slow them down and stop them from rushing through the work as it literally contains tons of mistakes this is like a common occurrence edit i see a few comments in my manager was in the discussion as my coworker brought it up in our stand up and i had to defend my position infront of my bosses director and above basically what they said is apparently we have to do this because i say this is what should be done now given the need to replicate so everyone is pretty much aware and my boss did approach me on this specifically because we both saw the fallout of how bad replication is problematic,,,,,
1j80r9t,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-10 15:06:42,happy mar day ,,,,,
1j7uxqq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-10 09:43:51,why is my macbook m pro faster than my rtx desktop for llm inference with ollama ive been running the deepseekcoderv model gb using ollama run on two systems macbook m pro latest model desktop with intel ik gb ram and an rtx gpu surprisingly the macbook m pro is significantly faster when running a simple query like tell me a long story the desktop setup which should be much more powerful on paper is noticeably slower both systems are running the same model with default ollama configurations why is the macbook m pro outperforming the desktop is it related to how ollama utilizes hardware gpu acceleration differences or perhaps optimizations for apple silicon would appreciate insights from anyone with experience in llm inference on these platforms note i can observe my gpu usage spiking when running the same and so assume the hardware access is happening without issue,,,,,
1j7uh4f,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-10 09:08:44,have you started using mcp model context protocol with your agentic workflow and data storages what is the experience if youve used mcp in your workflow how has the experience been do you use it on top of your current data storage as well to gather more data,,,,,
1j7q4w5,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-10 04:01:42,weekly entering transitioning thread mar mar welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1j7ln6i,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-10 00:06:41,what sort of things should i be doing in my personal time to make moving companies easier im looking to move from my current company but am aware thats tough right now im not new to the field but my company doesnt really measure impact of solutions outside a few places that i havent been able to get projects supporting so a lot of my resume lacks impact metrics what things can i do to show i have the hard and soft skills these roles are looking for and show i can succeed in a place that does measure impact im too small of a fish to change my company culture to get measurement in place as well and wouldnt want to stay and be the one to rise up to do that if that makes sense i assume personal projects are less impressive than work projects but is there anything i can do to make up for the fact that nothing i do at work really seems impressive either,,,,,
1j7gch1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-09 20:07:11,the kebab and the french train station yet another datadriven analysis ,,,,,
1j7b4sg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-09 16:21:01,setting up ab test infra hi im a bi analytics manager at a saas company focusing on the business side the company wishes to scale ab experimentation capabilities but were currently limited by having only one data analyst who sets up all tests manually this bottleneck restricts our experimentation capacity before hiring consultants i want to understand the topic better could you recommend reliable resources books videos courses on building ab testing infrastructure to automate test setup deployment and analysis any recommendations would be greatly appreciated ps there is no shortage on sources reiterating kohavi book but thats not what im looking for,,,,,
1j5t5gp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-07 16:46:58,agent flow vs data science i just wrapped up an experiment exploring how the number of agents or steps in an ai pipeline affects classification accuracy specifically i tested four different setups on a movie review classification task my initial hypothesis going into this was essentially more agents might mean a more thorough analysis and therefore higher accuracy but as youll see its not quite that straightforward results summary i have used the first reviews from imdb dataset to classify reviews into positive or negative i used gptomini as a model here are the final results from the experiment pipeline approachaccuracy classification only summary classification summary statements classification summary statements explanation classification lets break down each step and try to see whats happening here step classification only accuracy this simplest approachsimply reading a review and classifying it as positive or negativeprovided the highest accuracy of all four pipelines the model was straightforward and did its single task exceptionally well without added complexity step summary classification accuracy next i introduced an extra agent that produced an emotional summary of the reviews before the classifier made its decision surprisingly accuracy slightly dropped to it looks like the summarization step possibly introduced abstraction or subtle noise into the input leading to slightly lower overall performance step summary statements classification accuracy adding yet another step this pipeline included an agent designed to extract key emotional statements from the review my assumption was that added clarity or detail at this stage might improve performance instead overall accuracy dropped a bit further to while the statements created by this agent might offer richer insights on emotion they clearly introduced complexity or noise the classifier couldnt optimally handle step summary statements explanation classification accuracy finally another agent was introduced that provided human readable explanations alongside the material generated in prior steps this boosted accuracy slightly back up to but didnt quite match the original simple classifiers performance the major benefit here was increased interpretability rather than improved classification accuracy analysis and takeaways here are some key points we can draw from these results more agents doesnt automatically mean higher accuracy adding layers and agents can significantly aid in interpretability and extracting structured valuable datalike emotional summaries or detailed explanationsbut each step also comes with risks each guy in the pipeline can introduce new errors or noise into the information its passing forward complexity versus simplicity the simplest classifier with a single job to do direct classification actually ended up delivering the top accuracy although multiagent pipelines offer useful modularity and can provide great insights theyre not necessarily the best option if raw accuracy is your number one priority always double check your metrics different datasets tasks or model architectures could yield different results make sure you are consistently evaluating tradeoffsinterpretability extra insights and user experience vs accuracy in the end ironically the simplest methodologyjust directly classifying the reviewgave me the highest accuracy for situations where richer insights or interpretability matter multipleagent pipelines can still be extremely valuable even if they dont necessarily outperform simpler strategies on accuracy alone id love to get thoughts from everyone else who has experimented with these multiagent setups did you notice a similar pattern the simpler approach being as good or slightly better or did you manage to achieve higher accuracy with multiple agents full code on github tldr adding multiple steps or agents can bring deeper insight and structure to your ai pipelines but it wont always give you higher accuracy sometimes keeping it simple is actually the best choice,,,,,
1j5hrrn,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-07 07:08:10,thinking of selling my m air to buy an m pro is it worth the upgrade for machine learning hey everybody i need some advice im a rd year cs undergrad and currently have a macbook m air with gb ram and gb storage i bought it in for about cad but ive been running into issues when i open multiple apps like docker ollama pycharm and run training models the laptop quickly runs out of ram and gets heat up and starts swapping which isnt great for the ssd im leaning towards selling it to upgrade to an m pro especially for machine learning and data science tasks however apples tradein value is only around cad and i just recently had the motherboard chassis and display replaced everything except the battery so my laptop is basically new in most parts i was planning to sell it on facebook marketplace but im not sure what price i should target now that the m has been released on the flip side ive also considered keeping the laptop and using a google colab subscription for ml work but running many applications still leads to heavy swap usage which could harm the ssd in the long run given that i just renewed some parts it might be the best time to sell for a higher resale value if i decide to upgrade to the m im thinking of getting a model with at least gb ram and a core cpu and gpu combination do you guys think that would be enough to futureproof it what are your thoughts on selling now versus sticking with the current setup and using cloud resources,,,,,
1j4wn4d,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-06 14:27:14,failing final round interviews ive been applying to ds internships all year and just got rejected from my th final round does anyone have any advice for these interviews and is it bad practice for me to ask the hiring managers where i went wrong in the interviews,,,,,
1j4v2ee,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-06 13:08:46,google collab now provides native support for julia ,,,,,
1j47h7z,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-05 16:46:22,help with pyspark and bigquery hi everyone im creating a pyspark df that contains arrays for certain columns but when i move it to a bigqquery table all the columns containing arrays are empty they contains a message that says rows any suggestions thanks,,,,,
1j3r9qh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-05 01:19:21,best industryrecognized certifications for data science im looking to boost my university applications for a data sciencerelated degree and want to take industryrecognized certifications that are valued by employers right now im considering google advanced data analytics professional certificate deep learning specialization tensorflow developer certificate aws certified machine learning are these the best certifications from an industry perspective or are there better ones that hiring managers and universities prefer i want to focus on practical jobrelevant skills rather than just general knowledge,,,,,
1j3hx9m,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-04 18:36:32,googles data science agent free to use in colab build ds pipelines with just a prompt google launched data science agent integrated in colab where you just need to upload files and ask any questions like build a classification pipeline show insights etc tested the agent looks decent but has errors and was unable to train a regression model on some ev data know more here,,,,,
1j3hq4r,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-04 18:28:35,whats your favourite ai tool so far its hard for me too keep up please enlighten me on what i am currently missing out on,,,,,
1j3hc7l,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-04 18:12:56,would someone with a bba fintech make a good data scientist given they demonstrate fluency in data science programsmodels such as python r blockchain al etc and be able to recommend technological solutions to such problems as imperfect or asymmetric data deciding on a course to pursue with my limited regional options thank you,,,,,
1j3etuj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-04 16:32:32,favorite data science books and authors i enjoy oreilly books for data science i like how they build a topic progressively throughout the chapters im looking for recommendations on great books or authors youve found particularly helpful in learning data science analytics or machine learning what do you like about your recommendation do they have a unique way of explaining concepts great realworld examples or a handson approach,,,,,
1j39e2e,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-04 12:12:44,workflow with spark large datasets hi im a beginner ds working at a company that handles huge datasets m rows columns in databricks with spark the most discouraging part of my job is the eternal waiting times when i want to check the current state of my eda say i want the null count in a specific column for example i know i could sample the dataframe in the beginning to prevent processing the whole data but that doesnt really reduce the execution time even if i cache the sampled dataframe im waiting now for minutes for a count and i think this cant be the way real professionals work with such waiting times of course i try to do something productive in those times but sometimes the job just needs to get done so i ask the more experienced professionals in this group how do you handle this part of the job is sample our only option im eager to learn ways to be better at my job,,,,,
1j30hfs,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-04 02:33:42,huggingface free certification course for llm reasoning is live huggingface has launched a new free course on llm reasoning for explaining how to build models like deepseekr the course has a special focus towards reinforcement learning link,,,,,
1j2fd49,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-03 10:02:22,soft skills how do you make the rest of the organization contribute to data quality ive been in six different data teams in my career two of them as an employee and four as a consultant often we run into a wall when it comes to data quality where the quality will not improve unless the rest of the organization works to better it for example if the dev team doesnt test the event measuring and deploy a new version you dont get any data until you figure out what the problem is ask them to fix it and they deploy the fix they say that they will test it next time but it doesnt become a priority and happens a few months later again or when a team is supposed to reach a certain kpi they will cut corners and do a weird process to reach it making the measurement useless for example when employees on the ground are rewarded for the order to deliver time they might check something as delivered once its completed but not actually delivered because they dont get rewarded for completing the task quickly only delivering it how do you engage with the rest organization to make them care about the data quality and meet you half way one thing ive kept doing at new organizations is trying to build an internal data product for the data producing teams so that they can become a stakeholder in the data quality if they dont get their processes in order their data product stops working this has had mixed results form completely transformning the company to not having any impact at all ive also tried holding workshops and they seem to work for a while but as people change departments and other stuff happens this knowledge gets lost or deprioritized again what are your tried and true ways to make the organization you work for take the data quality seriously,,,,,
1j2b2ng,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-03 05:01:24,weekly entering transitioning thread mar mar welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1j271od,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-03 01:22:15,chain of drafts improvised chain of thoughts prompting cod is an improvised chain of thoughts prompt technique producing similarly accurate results with just of tokens hence faster and cheaper know more here,,,,,
1j1nr34,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-02 10:13:56,alternatives for streamlit for my most pet projects like creating dashboards of voting charts for songs or planning a trip with altitude chart and maps along with some proof of concept for llm or ml projects at work my first to go is streamlit i got accustomed to this tool but looking for some alternatives mostly because of the visual part i tried dash with plotly but missing the coherence of the streamlit what is the tool that can do the same for the front end part which can be uploaded in the simple way similar to streamlit as streamlit but is not streamlit what are your favorite similar frameworks,,,,,
1j1crux,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-01 23:22:17,any examples of genai in the value chain does anyone have some nobullshit examples of how the generative part of ai has actually added value to the business i come across a lot of chat interfaces but those often are more hype and fomo than value adds curious if you know something serious,,,,,
1j17yok,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-01 19:45:27,meta e ml experience cleared learned a lot form this subreddit so sharing my experience so people can learn from it too coding rounds it is going to be mids or easy and hard for me biggest shock was the interviewer asked questions to see if i understand what i am saying or just saying it because i saw on leetcode that is the best option so try to understand why the solution is working the way it is working and how is the space and time complexity calculated for that solution behavioral i created a story for every meta vision and mission that covers all meta questions the main difference i found in meta compared to other companies is the depth of follow ups the questions were very specific and there were follow up questions on my answer to previous follow ups i dont think one can lie in this round they would be caught in the follow up questions easily also there was no why meta or tell me about yourself mlsd alex xu book is all you need for structure and what ml models to read about the interviewer will ask technical questions including formula and how the particular thing actually work so my suggest use alex xu ml sd book to understand the format structure and solutions then googlechatgpt the technical part of each step in deep,,,,,
1j0y4xv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-01 12:12:36,influential timeseries forecasting papers of part this article explores some of the latest advancements in timeseries forecasting you can find the article here if you know of any other interesting ts papers please share them in the comments,,,,,
1j0x07s,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-01 10:56:53,data science web app project what are your best tips im aiming to create a data science project that demonstrates my full skill set including web app deployment for my resume im in search of wellstructured demo projects that i can use as a template for my own work id also appreciate any guidance on the best tools and practices for deploying a data science project as a web app what are the key elements that hiring managers look for in a project thats hosted online any suggestions on how to effectively present the project on my portfolio website and source code in github profile would be greatly appreciated,,,,,
1j0mkfs,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-01 00:18:42,textbook recommendations because of my background in ml i was put in charge of the design and implementation of a project involving using synthetic data to make classification predictions i am not a beginner and very comfortable with modeling in python with sklearn pytorch xgboost etc and the standard process of scaling data imputing feature selection and running different models on hyperparameters but ive never worked professionally doing this only some research and kaggle projects at the moment im wondering if anyone has any recommendations for textbooks or other documents detailing domain adaptation in the context of synthetic to real data for when the sets are not aligned and any on feature engineering techniques for nontime series tabular numeric data beyond crossing interactions and taking summary statistics i feel like theres a lot i dont know but somehow i know the most where i work so are there any intermediate to advanced resources on navigating this space,,,,,
1j0lhyr,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-28 23:28:10,presentation resources i am looking for any resources helpful for creating good slide decks for presenting our work i have seen some really fancy decks created by fellow ds at my company and i always wonder how are they creating these without any help these folks do tend to have consulting backgrounds so could be something learnt there is it possible to learn this skill as it seems like good ppt skills create more impact on business stakeholders,,,,,
1j0ikva,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-28 21:17:31,check out our ai data science tool demo video try out our beta here datascipro note the site isnt optimized for mobile yet our tool lets you upload datasets and interact with your data using conversational ai you can prompt the ai to clean and preprocess data generate visualizations run analysis models and create pdf reportsall while seeing the python scripts running under the hood were shipping updates daily so your feedback is greatly appreciated,,,,,
1j0eptr,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-28 18:31:59,ai file convention detectionlearning i have an idea for a project and trying to find some information online as this seems like something someone would have already worked on however im having trouble finding anything online so im hoping someone here could point me in the direction to start learning more so some background in my job i help monitor the moving and processing of various files as they move between vendorssystems so for example we may a file that is generated daily named customerdatammddyyrpt where mmddyy is the month day year yet another file might have a naming convention like genericreportmmddyycsv so what i would like to is to try and build a learning system that monitors the master data stream of file transfers that does two things automatically detects naming conventions for each naming conventionpattern found in step detect the normal cadence of the file movement for example is it days a week just week days once a month once are set up then alert if a file misses its cadence now i know how to get and set up however im having a hard time building a system to detect the naming conventions i have some ideas on how to get it done but hitting dead ends so hoping someone here might be able to offer some help thanks,,,,,
1j0abwb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-28 15:31:02,how would i recreate this page other data inputs and topics on my squarespace website hello all new hear i have a youtube channel and social brand im trying to build and i want to create pages like this or the data snapshots here i want to repeatedly create pages that would encompass a topic and have graphs and visuals like the above examples thanks for any help or suggestions,,,,,
1j04aqa,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-28 10:01:16,medium blog post on eda hi all started my own blog with the aim of providing guidance to beginners and reinforcing some concepts for those more experienced essentially trying to share value link is attached hope theres something to learn for everyone happy to receive any critiques as well,,,,,
1j03efx,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-28 08:53:32,fwd name shame pacific life insurance sharing cuz reading this pissed me off similar experience with them last year ,,,,,
1j029yl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-28 07:29:15,sales forecasting advice multiple out put hi all so im forecasting some sales data mainly units sold they want a daily forecast i tried to push them towards weekly but here we are i have a decades worth of data i need to model out the effects of lockdowns obviously as well as like a bazillion campaigns they run throughout the year ive done some feature engineering and ive tried running it through multiple regression but that doesnt seem to work there are just so many parameters i computed a pca on the input sales data and im feeding the lagged scores into the model which helps to reduce the number of features i am currently trying gaussian process regression the results are not generalizing well at all definitely getting overfitting it gives r and incredibly low rmse on training data then garbage on validation the actual predictions do not track the real data as well at all honestly was getting better just reconstruction from the previous days pca considering doing some cross validation and hyper parameter tuning any general advice on how to proceed im basically just throwing models at the wall to see what sticks would appreciate any advice,,,,,
1j0291u,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-28 07:27:17,question on gpt from scratch of andrej karpathy i was watching his video lets reproduce gpt m where he implemented gpt at around it says that the initial token is the endoftext token can someone explain why that is also it seems to me that with his code three sentences of length and tokens respectively will fit into a tensor ignoring any excess tokens with the first two sentences being adjacent this would be appropriate if the three sentences come from lets say the same book or article otherwise it could be detrimental during training is my reasoning correct,,,,,
1izmkfd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-27 18:21:55,ds is becoming ai standardized junk hiring is a nightmare the majority of applicants submit the same prepackaged solutions basic plots default models no validation no business reasoning eda has been reduced to prewritten scripts with no anomaly detection or hypothesis testing modeling is just feeding data into gptsuggested libraries skipping feature selection statistical reasoning and assumption checks validation has become nothing more than blindly accepting default metrics everybodys using ai and everything looks the same its the standardization of mediocrity data science is turning into a low quality copypaste job,,,,,
1izapxk,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-27 07:58:04,have you used data heatmap in your workflows if yes then how and what tools did you use one specific use case would be llm trainingfinetuning datasets could use heatmap to assess what records of a dataset have been mostly used across multiple models what else do you need data heatmap in your workflow and did you write your own code or external tools to assess this for yourself,,,,,
1iz76dr,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-27 04:09:07,unsupervised model failure instagram algorithm is broken every year on feb ,,,,,
1iyn2u6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-26 13:06:24,wan new sota model for video generation opensourced can run on consumer grade gpu alibabba group has released wan a sota model series which has excelled on all benchmarks and is opensourced the p version can run on just gb vram only know more here,,,,,
1iygj98,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-26 05:44:24,is there a large pool of incompetent data scientists out there having moved from academia to data science in industry ive had a strange series of interactions with other data scientists that has left me very confused about the state of the field and i am wondering if its just by chance or if this is a common experience here are a couple of examples i was hired to lead a small team doing data science in a large utilities company most senior person under me who was referred to as the senior data scientists had no clue about anything and was actively running the team into the dust could barely write a for loop couldnt use git took two years to get other parts of business to start trusting us had to push to get the individual made redundant because they were a serious liability it was so problematic working with them i felt like they were a plant from a competitor trying to sabotage us start hiring a new data scientist very recently lots of applicants some with very impressive cvs phds experience etc i gave a handful of them a very basic take home assessment and the work i got back was mind boggling the majority had no idea what they were doing couldnt merge two data frames properly didnt even look at the data at all by eye just printed summary stats i was and still am flabbergasted they have high paying jobs in other places they would need major coaching to do basic things in my team so my question is is there a pool of fake data scientists out there muddying the job market and ruining our collective reputation or have i just been really unlucky,,,,,
1iy6v4d,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-25 21:48:25,i get the impression that traditional statistical models are outofplace with big data whats the modern view on this im a data scientist but not good enough at stats to feel confident making a statement like this one but it seems to me that traditional statistical tests were built with the expectation that sample sizes would generally be around people applying them to big data situations where our groups consist of millions of people and reflect nearly of the population is problematic specifically im currently working on a ab testing project for websites where people get different variations of a website and we measure the impact on conversion rates stakeholders have complained that its very hard to reach statistical significance using the popular ab testing tools like optimizely and have tasked me with building a ab testing tool from scratch to start with the most basic possible approach i started by running a ztest to compare the conversion rates of the variations and found that using that approach you can reach a statistically significant pvalue with about visitors results are about the same with chisquared and ttests and you can usually get a pretty great effect size too cool but all of these data points are absolutely wrong if you wait and collect weeks of data anyway you can see that these effect sizes that were classified as statistically significant are completely incorrect it seems obvious to me that the fact that popular ab testing tools take a long time to reach statistical significance is a feature not a flaw but theres a lot i dont understand here whats the theory behind adjusting approaches to statistical testing when using big data how are modern statisticians ensuring that these tests are more rigorous what does this mean about traditional statistical approaches if i can see using big data that my ztests and chisquared tests are calling inaccurate results significant when theyre given small sample sizes does this mean there are issues with these approaches in all cases the fact that so many modern programs are already much more rigorous than simple tests suggests that these are questions people have already identified and solved can anyone direct me to things i can read to better understand the issue,,,,,
1iy5ud3,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-25 21:06:19,do you dev local or in the cloud like the question says by this i also think sshd into a stateful machine where you can basically do whatever you want counts as local my company has tried many different things for us to have development enviornments in the cloud jupyter labs aws sagemaker etc however i find that for the most part its such a pain working with these system that any increase in compute speed id gain would be washed out by the clunkiness of these managed development systems im sure theres times when your data gets huge but tbh i can handle a few trillion rows locally if i batch and my local gpu is so much easier to use than trying to download cuda on an aws system for me just putting a requirmentstxt in the rep and using either a venv or a docker container is just so much easier and in practice more standard than trying to grok these complicated cloud setups yet it seems like every company thinks data scientists need a cloud setup,,,,,
1iy5rks,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-25 21:03:07,shitty debugging job taught me the most i was always a losey developer and just started working on large codebases the past year first real job after school i have a strong background in stats but never had to develop the backend of data intensive applications at my current job we took over a project from an outside company who was originally developing it this was the main reason the company hired us trying to inhouse the project for cheaper than what they were charging the job is pretty shit tbh and i got intro into the code or what we are doing they figuratively just showed me my seat and told me to get at it ive been using a mix of ai tools to help me read through the code and help me understand what is going on in a macro level also when some bug comes up i let it read through the code for me to point me towards where the issue is and insert the neccesary print statements or potential modifications this excersize of something is constantly breaking is helping me to become a better data scientist in a shorter amount of time than anything else has the job is still shit and pays like shit so ill be switching soon but i learned a lot by having to do this dirty work that others wont unfortunately i dont think this opportunity is avaiable to someone fresh out of school in hcol countries since they put this type of work where the labor is cheap,,,,,
1iy3eqq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-25 19:25:46,microsoft ceo admits that ai is generating basically no value ,,,,,
1ixy90o,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-25 15:55:22,data scientist tasked with building interactive clientfacing productwhere should i start hi community im a data scientist with little to no experience in frontend engineering and ive been tasked with developing an interactive clientfacing product my previous experience with building interactive tools has been limited to streamlit and plotly but neither scales well for this use case im looking for suggestions on where to start researching technologies or frameworks that can help me create a more scalable and robust solution ideally id like something that can handle larger user loads without performance issues is relatively accessible for someone without a frontend background integrates well with python and backend services if youve faced a similar challenge what tools or frameworks did you use any resources tutorials courses documentation would also be much appreciated,,,,,
1ixlnua,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-25 03:38:58,if ai were used to evaluate employees based on selfassessments what input might cause unintended results have fun with this one,,,,,
1ixd4jm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-24 21:11:38,amazon as interviews starting in weeks hi i was recently contacted by an amazon recruiter i will be interviewing for an applied scientist position i am currently a ds with years of experience the problem is that the i terview process involves phone screen and onsite round which will have leetcode style coding i am pretty bad at dsa can anyone please suggest me how to prepare for this part in a short duration what questions to do and how to target any advice will be appreciated tia,,,,,
1ixctdh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-24 20:59:11,improving workflow managing iterations between data cleaning and analysis in jupyter notebooks i use jupyter notebooks for projects which typically follow a structure like this load data clean data analyze data what i find challenging is this iterative cycle i clean the data initially move on to analysis then realize during analysis that further cleaning or transformations could enhance insights i then loop back to earlier cells make modifications and rerun subsequent cells new cell embedded in workflow new cell this process quickly becomes convoluted and difficult to manage clearly within jupyter notebooks it feels messy bouncing between sections and losing track of the logical flow my questions for the community how do you handle or structure your notebooks to efficiently manage this iterative process between data cleaning and analysis are there best practices frameworks or notebook structuring methods you recommend to maintain clarity and readability additionally id appreciate book recommendations i like books from oreilly that might help me improve my workflow or overall approach to structuring analysis thanks in advanceim eager to learn better ways of working,,,,,
1ix80i6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-24 17:45:18,what are some good suggestions to learn route optimization and data science in supply chains as titled,,,,,
1ix7iu9,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-24 17:25:47,best books to learn reinforcement learning same as title,,,,,
1ix4ile,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-24 15:22:28,we are back with many data science jobs in soccer nfl nhl formula and more sports hey guys ive been silent here lately but many opportunities keep appearing and being posted these are a few from the last days or so parttime data scientist assistant nhl senior data scientist epic games data scientist atlanta united quantitative analyst midsenior basketball data analyst washington mystics senior data scientist nfl the score i run wwwsportsjobsonline a job board in that niche in the last month i added around jobs for the ones that already saw my posts before ive added more sources of jobs lately im open to suggestions to prioritize the next batch its a niche there arent thousands of jobs as in software in general but my commitment is to keep improving a simple metric jobs per month we always need some metric in ds ive created also a reddit community where i post recurrently the openings if thats easier to check for you i hope this helps someone,,,,,
1ix3ymj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-24 14:58:39,roast my cv basically the title any advice,,,,,
1ix350m,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-24 14:21:38,whats the best business book youve read i came across this question on a job board after some reflection i realized that some of the best business books helped me understand the strategy behind the companys growth goals better empathizing with others and getting them to care about impactful projects like i do what are some useful businessrelated books for a career in data science,,,,,
1iwu845,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-24 05:01:45,weekly entering transitioning thread feb mar welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1iwemoj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-23 16:57:07,gym chain data scientists just had a thoughtany gym chain data scientists here can tell me specifically what kind of data science youre doing is it advanced or still in nascency was just curious since i got back into the gym after a while and was thinking of all the possibilities data science wise,,,,,
1ivsn10,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-22 20:46:36,publishing a snowflake native app to generate synthetic financial data any interest ,,,,,
1ivolsz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-22 17:53:25,deepseek new paper native sparse attention for long context llms summary for deepseeks new paper on improved attention mechanism nsa,,,,,
1ivgrnb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-22 11:31:05,are llms good with ml model outputs the vision of my product management is to automate the root cause analysis of the system failure by deploying a multireasoningsteps llm agents that have a problem to solve and at each reasoning step are able to call one of multiple simple ml models get_correlationsx look_for_spikestime_seriestt i mean i guess it could work because llms could utilize domain specific knowledge and process hundreds of model outputs way quicker than human while ml models would take care of numericallyintense aspects of analysis does the idea make sense are there any successful deployments of machines of that sort can you recommend any papers on the topic,,,,,
1ivavo1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-22 04:49:02,large language diffusion models lldms diffusion for text generation a new architecture for llm training is proposed called lldms that uses diffusion majorly used with image generation models for text generation the first model llada b looks decent and is at par with llama b and qwen b know more here,,,,,
1iv8cbv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-22 02:28:18,was the hype around deepseek warranted or unfounded python da here whose upper limit is sklearn with a bit of tensorflow the question how innovative was the deepseek model there is so much propaganda out there from both sides thats its tough to understand what the net gain was from what i understand deepseek essentially used reinforcement learning on its base model was sucked then trained minimodels from llama and qwen in a distillation methodology and has data go thru those mini models after going thru the rl base model and the combination of these models achieved great performance basically just an ensemble method but what does distilled mean they imported the models ie pytorch or they cloned the repo in full and put data thru all models in a pipeline im also a bit unclear on the whole concept of synthetic data to me this seems like a huge no no but according to my chat with deepseek they did use synthetic data so was it a cheap knock off that was overhyped or an innovative new way to architect an llm and what does that even mean,,,,,
1iuw9ow,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-21 17:22:51,to the avid fans of r i respect your fight for it but honestly curious what keeps you motivated i started my career as an r user and loved it then after some years in i started looking for new roles and got the slap of reality that no one asks for r gradually made the switch to python and never looked back i have nothing against r and i still fend off unreasonable attacks on r by people who never used it calling it only good for adhoc academic analysis and bla bla but is it still worth fighting for,,,,,
1iun6jy,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-21 09:41:50,ai isnt evolving its stagnating ai was supposed to revolutionize intelligence but all its doing is shifting us from discovery to dependency development has turned into a cycle of finetuning and api calls just engineering lets be real the power isnt in the models its in the infrastructure if you dont have access to massive compute youre not training anything foundational google openai and microsoft own the stack everyone else just rents it this isnt decentralizing intelligence its centralizing control meanwhile the viral hype is wearing thin compute costs are unsustainable inference is slow and scaling isnt as seamless as promised we are deep in amaras law overestimating shortterm effects and underestimating longterm ones,,,,,
1iuivf9,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-21 04:52:37,how would you clean categorize job titles at scale i have a dataset with unique job titles and want to standardize them by grouping similar titles under a common category my approach is to take the top most frequently occurring titles unique use these reference titles to label and categorize the entire dataset assign a match score to indicate how closely other job titles align with these reference titles im still working through it but im curioushow would you approach this problem would you use nlp fuzzy matching embeddings or another method any insights on handling messy job titles at scale would be appreciated tldr i have k unique job titles and want to group similar ones using the top most common titles as a reference set how would you do it do you have any other ways of solving this,,,,,
1iuib2z,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-21 04:20:39,uncensored deepseekr by perplexity ai perplexity ai has released r a post tuned version of deepseekr with chinese censorship and bias the model is free to use on perplexity ai and weights are available on huggingface for more info,,,,,
1iuf85f,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-21 01:42:26,whats are the top three technical skills or platforms to learn not named r python sql or any of the bi platforms eg tableau powerbi eg alteryx openai etc,,,,,
1iu0skr,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-20 15:15:42,build demo pipelines x faster every time i start a new project i have to collect the data and guide clients through the first few weeks before i get some decent results to show them this is why i created a collection of classic data science pipelines built with llms you can use to quickly demo any data science pipeline and even use it in production in some cases all of the examples are using opensource library flashlearn that was developed for exactly this purpose examples by use case customer service classifying customer tickets finance parse financial report data marketing customer segmentation personal assistant research assistant product intelligence discover trends in product_reviews user behaviour analysis sales personalized cold emails sentiment classification feel free to use it and adapt it for your use cases ps the quality of the result should be off the specialized model i expect this gap will close with new development,,,,,
1itr8ub,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-20 05:36:16,who would contribute more to a company fresh graduates graduate a and b graduate a has a data science bachelors has completed various projects and research and stays up to date with industry skills internships completed too graduate b has a statistics bachelors has actively pursued academic research and applies learned skills to a startup after some projects no internships but lots of self initiation would graduate a or b make the cut for the data scientist andor mlai role,,,,,
1itqkyj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-20 04:57:16,help for unsupervised learning on transactions dataset i have a transactions dataset and it has too much excessive info in it to detect a transactions as fraud currently we are using rules based for fraud detection but we are looking for different options a ml modle or something i tried a lot but couldnt get anywhere can u help me or give me any ideas i tried to generate synthetic data using ctgan no help did clean the data kept few columns those columns were regarding is the trans flagged or not relatively flagged or not history of being flagged no help tried dbscan lof iso forest kmeans no help i feel lost,,,,,
1itpmil,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-20 04:03:27,upping my generative ai game im a pretty big user of ai on a consumer level id like to take a deeper dive in terms of what it could do for me in data science im not thinking so much of becoming an expert on building llms but more of an expert in using them id like to learn more about prompt engineering api integration light overview on how llms work custom gpts can anyone suggest courses books youtube videos etc that might help me achieve that goal,,,,,
1ito4a5,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-20 02:43:55,help analyzing profit loss statements across multiple years has anyone done work analyzing profit loss statements across multiple years i have several years of records but am struggling with standardizing the data the structure of the pdfs varies making it difficult to extract and align information consistently rather than reading the files with python i started by manually copying and pasting data for a few years to prove a concept id like to start analyzing years once i am confident i can capture the pdf data without manual intervention id like to automate this process if youve worked on something similar how did you handle inconsistencies in pdf formatting and structure,,,,,
1itn1zg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-20 01:51:16,how do you organize your files in my current work i mostly do oneoff scripts data exploration try different ways to solve a problem and do a lot of testing my files are a hot mess someone asks me to do a project and i vaguely remember something similar i did a year ago that i could reuse but i cannot find it so i have to rewrite it how do you manage your development work and rough drafts before you have a final cleaned up version anything in production is on github unit tested and all that good stuff im using a windows machine with spyder if that matters i also have a pretty nice linux desktop in the office that i can ssh into so thats a whole other set of files that is not a hot messyet,,,,,
1it3ed9,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-19 11:33:10,data science entrepreneur anyone in this group running a consultancy or trying to build a startup or even an early employee at a startup i feel like data science lends itself mainly to large corps and without much transferability to smes,,,,,
1isi8u2,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-18 17:30:40,building a reliable texttosql pipeline a stepbystep guide pt ,,,,,
1ish90u,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-18 16:51:36,anyone do testgorilla tests for a job app i recently did some technical assessments from testgorilla im wondering what other people thought of these,,,,,
1isdrmn,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-18 14:22:15,i created cv copilot for data scientists ,,,,,
1isd4tz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-18 13:52:19,time series data loading headaches tell us about them hi rdatascience i am revamping time series data loading in pytorch and want your input were working on a opensource data loader with a unified api to handle all sorts of time series data quirks different formats locations metadata you name it the goal make your life easier when working with pytorch forecasting foundation models and more no more wrestling with pandas polars or messy file formats we are planning to expand the coverage and support all kinds of time series data formats were exploring a flexible twolayered design but we need your help to make it truly awesome tell us about your time series data loading woes what are the biggest challenges you face what formats and sources do you typically work with any specific features or situations that are a real pain what would your dream time series data loader do your feedback will directly shape this project so share your thoughts and help us build something amazing,,,,,
1is56xt,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-18 05:17:10,system design oops apis security etc in data science interviews system design oops concepts and other things for ds interviews as a data scientist i know how to train a model how to build data pipelines how to create api and then deploy it on the server maybe not extensively but i know how to deploy it on say ec with a docker etc also i know basics of oops and pretty good with solving leetcode type problems ie optimising scripts but now with a years of exp do i need to know the system design as well that too extensive system design with everything that comes under the software pipeline a clienta software engineer just interviewed me for only such topics api end points scalability etc which i had zero idea about i know only the basics of these things and feels like this isnt something i should be looking at as data science itself is huge to learn how am i supposed to learn entire software stack am i right or im just living under a rock all this time,,,,,
1is21el,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-18 02:27:25,yes business impact matters this is based on another post that said ds has lost its soul because all anyone cared about was short term roi and they didnt understand that really good ds would be a gold mine but greedy shortterm business folks ruin that first off let me say i used to agree when i was a junior but now that i have yoe i have the opposite opinion ive seen so many boondoggles promise massive longterm roi and a bunch of phds and other ds folks being paid kyear would take years to develop a model that barely improved the bottom line whereas a lookup table could get of the way there and have practically no costs the other analogy i use is pretend youre the customer the plumbing in your house broke and your toilets dont work one plumber comes in and says they can fix it in a day for another comes and says they and their team needs months to do a full scientific study of the toilet and your house and maximize roi for you because just fixing it might not be the best longterm roi and you need to pay them an even higher hourly than the first plumber for months of work since they have specialized scientific skills the first plumber doesnt have then when you go with the first one the second one complains that youre so shortsighted and dont see the value of science and are just shortterm greedy and youre like dude i just dont want to have to piss and shit in my yard for months and i dont want to pay you tens of thousands of dollars when this other guy can fix it for,,,,,
1irs5de,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-17 19:18:27,what app making framework do you recommend to data scientists communicating findings from data analysis is important for people who work with data one aspect of that is making web apps for someone with nolittle experience with web development what app making framework would you recommend shiny for pythonr fasthtml django flask or something else and why the goal is to make robust apps that work well with multiple concurrent users should support asynchronous operations for long running calculations edit it seems that for simple to intermediate level complex apps shiny for rpython or fasthtml are great options the main advantage is that you can write all frontend and backend code in a single language fastapi authors developed fasthtml and they say it can replace fastapi js frontend so fasthtml is probably a good option for complicated apps also,,,,,
1irr33g,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-17 18:36:46,how to actually apply inferential statistics on analysesto help business hi guys im a data analyst with like years of experience i feel like in my last jobs i got too relaxed and have been doing too much sql building dashboards reporting and python automation without going into advanced analyses i just got lucky and had a great job offer from a company with millions of active users i dont want to waste this opportunity to learn and therefore am looking into more advanced topics namely inferential statistics to make my time here worthwhile as far as i know inferential statistics should be mostly about defining hypotheses doing statistical tests and drawing conclusions however what im not sure is whenhow can you make use of these tests to benefit a business could you please share a case just briefly is enough where you used inferentialadvanced statisticsanalysis to help your orgbusiness any other skills a great data analyst should have thank you very much any comment could help me a lot,,,,,
1irq8e0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-17 18:03:57,oc theres far better ways to work with larger sets of data and theres also more fun ways to overheat your computer than a massive excel book ,,,,,
1irlf7b,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-17 14:45:48,leverage my skills i work in automotive as a embedded developer c python in sensor processing and state estimation like sensor fusion also started to work in edge ai i really like to analyse signals think about models its not data science per se but i want to leverage my skills to find data science jobs how can i upskill what to learn is my skills valuable for data science,,,,,
1irkor6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-17 14:11:05,roc vs prc not what i expected interviewee started to talk about china and taiwan when asked this question watch out for chatgpt abuse,,,,,
1irc50e,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-17 05:01:44,weekly entering transitioning thread feb feb welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1ir3o2h,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-16 21:52:09,dataflow diagrams and other planning recently i have been thinking a lot about the project planning needed for good data science practices having intelligent conversations and defining clear goals is like half the battle for any job data science not being an exception one thing that my team has historically done towards the beginning of a project that i quite enjoy is to gather everyone together to discuss our dataflow diagrams for those of you who may not know what that is here is a link some people may think that this is solely the domain of the data architect or engineer neither of which i do on an official basis but i believe that getting the opinions of my teammates early on can reduce problems down the line i have even incorporated this practice at the place that i volunteer at on to the point of this post have any of you found the design of these quite helpful or not what are some practices that you do to maybe improve designing these any other planning tips or advice to share ps i usually lurk here so i guess it is time that i make a post lol,,,,,
1ir26jt,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-16 20:48:34,starting a data consultancy hey everyone was wondering if anyone here has successfully started their own data scienceanalyticsgovernance consultancy firm before what was the experience like and has it been worth it so far,,,,,
1iqfhq5,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-16 00:13:02,most trusted sources of ai news what is your most trusted source of ai news,,,,,
1iq9hcp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-15 19:43:19,what is your dailyweekly routine if you have a wfh position im asking this here since data scienceanalytics is a very remote industry im honestly trying to figure out a good cadence of when to make breakfast and get coffee when to meal prep when to get a minute walk in when to work out do my hobbies etc without driving myself insane especially when it comes to meal prepping and cooking when i was unemployed i was able to cook and meal prep for myself every day im trying to figure out how often to cook and meal prep and grocery shop so im not cooking as soon as i log off what is your routine for keeping up with life while youre working remotely,,,,,
1iq2oo0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-15 14:38:31,give clients bosses what they want every time i start a new project i have to collect the data and guide clients through the first few weeks before i get some decent results to show them this is why i created a collection of classic data science pipelines built with llms you can use to quickly demo any data science pipeline and even use it in production for noncritical use cases examples by use case customer service classifying customer tickets finance parse financial report data marketing customer segmentation personal assistant research assistant product intelligence discover trends in product_reviews user behaviour analysis sales personalized cold emails sentiment classification feel free to use it and adapt it for your use cases,,,,,
1ipcfkm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-14 14:59:13,thirdparty tools hey everyone curious to others experiences with business teams using thirdparty tools i keep getting asked to build dashboards and algorithms for specific processes that just get compared against thirdparty tools like microstrategy and others weve even had a longstanding process get transitioned out for a thirdparty algorithm that cost the company a few million to buy way more than it cost inhouse by like x even though we seem to have a large part of the same functionalities whats the point of companies having internal data teams if they just compare and contrast to thirdparty software so many of our teams goals are to outdo these softwares but the business would rather trust the software instead super frustrating,,,,,
1ip9y2l,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-14 12:55:32,looking for resources on interrupted time series analysis as the title says i am looking for sources on the topic it can go from basics to advanced use cases i need them both thanks,,,,,
1ioxz48,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-14 00:26:30,fcc text data im looking to do some projects regarding telecommunications would i have to build an fcc_publications dataset from scratch im not finding one on their site or others also whats the standard these days for storingsharing a dataset like that i cant imagine its csv but is it just a zip file with foldersdocuments inside,,,,,
1ios31c,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-13 20:02:22,what companiesindustries are slowpacedlow stress ive only ever worked in data science for consulting companies which are inherently fastpaced and quite stressful the money is good but i dont see myself in this field forever fastpace in my experience can be a code word for burn you out out of curiosity do any of you have lower stress jobs in data science my guess would be large retailerscorporations that are no longer in growth stage and just want to fine tunemaintain their production models while also dedicating some money to rd with more reasonable timelines,,,,,
1ior7cf,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-13 19:25:30,mcafee data scientist anyone has gone through mcafee data science coding assessment looking for some insights on the assessment,,,,,
1iolgcd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-13 15:23:26,is managing unstructured data a pain point for the airag ecosystem can it be solved by welldesigned software hey redditors ive been brainstorming about a software solution that could potentially address a significant gap in the aienhanced information retrieval systems particularly in the realm of retrievalaugmented generation rag while these systems have advanced considerably theres still a major production challenge managing the realtime validity updates and deletion of documents forming the knowledge base currently teams need to appoint managers to oversee the governance of these unstructured data similar to how structured databases like sql are managed this is a complex task that requires dedicated jobs and suitable tools heres my idea develop a unified user interface ui specifically for document ingestion advanced data management and transformation into synchronized vector databases the final product would serve as a single access point per document base allowing clients to perform semantic searches using their ai agents the ui would encourage data managers to keep their information uptodate through features like notifications email alerts and document expiration dates the project could start as opensource with a potential revenue model involving a paid service to deploy ai agents connected to the document base some technical challenges include ensuring the accuracy of embeddings and dealing with chunking strategies for document processing as technology advances these hurdles might lessen shifting the focus to the quality and relevance of the source document base do you think a welldesigned software solution could genuinely add value to this industry would love to hear your thoughts experiences and any suggestions you might have do you know any existing open source software looking forward to your insights,,,,,
1iogppw,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-13 11:07:35,data team benchmarks i put together some charts to help benchmark data teams for example average data team size as of the company hint median salary across data roles for job postings in europe distribution of analytics engineers data engineers and analysts the datatoengineer ratio at top tech companies the data comes from linkedin open job boards and a few other sources,,,,,
1iobbu2,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-13 04:45:08,what are the common challenges businesses face in llm training and inference hi everyone im relatively new to the ai field and currently exploring the world of llms im curious to know what are the main challenges businesses face when it comes to training and deploying llms as id like to understand the challenges beginners like me might encounter are there specific difficulties in terms of data processing or model performance during inference what are the key obstacles youve encountered that could be helpful for someone starting out in this field to be aware of any insights would be greatly appreciated thanks in advance,,,,,
1inytsd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-12 19:05:37,ai influencers will kill it sector techilliterate managers see aigenerated hype and think they need to disrupt everything cut salaries push impossible deadlines and replace skilled workers with ai that barely functions instead of making it more efficient they drive talent away lower industry standards and create burnout cycles the results worse products more tech debt and a race to the bottom where nobody wins except investors cashing out before the crash,,,,,
1inofnb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-12 11:05:07,kimi k o level reasoning llm free api so moonshot ai just released free api for kimi k a reasoning multimodal llm which even beat openai o on some benchmarks the free api gives access to million tokens check out how to generate,,,,,
1inl1gw,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-12 06:48:47,challenges with realtime inference at scale hello were implementing an ai chatbot that supports realtime customer interactions but the inference time of our llm becomes a bottleneck under heavy user traffic even with gpubacked infrastructure the scaling costs are climbing quickly has anyone optimized llms for highthroughput applications or found any company provides platformsservices that handle this efficiently would love to hear about approaches to reduce latency without sacrificing quality,,,,,
1imkowl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-10 23:39:02,evaluating the thinking process of reasoning llms so i tried using deepseek r for a classification task turns out it is awful still my boss wants me to evaluate its thinking process and he has now told me to search for ways to do so i tried looking on arxiv and google but did not manage to find anything about evaluating the reasoning process of these models on subjective tasks what else can i do here,,,,,
1imf5q9,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-10 19:48:16,takehomes how do you approach them and how to get better as the title says i have about year of data science experience mostly as junior ds my previous work consisted of month long ml projects so i am familiar with how to get each step done cleaning modeling feature engineering etc however i always feel like with take homes my approach is just bad i spent about hours normally seems to is expected afail but then the model is absolute shit if i were to break it down i would say hours on pandas wizardry of cleaning data eda basic plots and feature engineering on modeling usually i try several models and end up with one that works best however when i say best i do not mean it works well it almost always behaved like shit even something good like random forest with few features is typically giving bad predictions in most metrics so the question is if anyone has good examples tutorials on how the process should look like i would appreciate,,,,,
1im9ipe,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-10 16:03:09,building an app help i work as a data analyst i have been asked to create an app that can be used by employees to track general updates in the company the app must be able to be accessed on employees mobile phones the app needs to be separate to any work login information ideally using a personal phone number to gain access or a code i tried using power apps but that requires login through microsoft ive never built an app before i was wondering if anyone knew any low code applications to use to built it and if not any other relatively simple application to use thanks,,,,,
1ilyfhk,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-10 05:01:43,weekly entering transitioning thread feb feb welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1ilb54i,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-09 09:31:55,efforttime needed for data science not recognizedvalued i conduct many data analysis projects to improve processes and overall performance at my company i am not employed as a data analyst or data scientist but fill the job as manager for a manufacturing area i have the issue that top management just asks for analysis or insights but seems not to be aware of the effort and time i need to conduct these things to gather all data preprocess them make the analysis and then process the findings to nice visuals for them often it seems they think it takes one to two hours for an analysis although i need several days i struggle because i feel they do not appreciate my work or recognize how much effort it takes besides the knowledge and skills i have to put in to conduct the analysis is anyone else experiencing the same situation or have an idea how i can address this,,,,,
1ikgq0p,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-08 06:10:13,data analysis on ai agent token flow does anyone know of a particular tool or library that can simulate agent system before actually calling llms or apis something that i can find the distribution of token generation by a tool or agent or the number of calls to a certain function by llm etc any thoughts,,,,,
1ik6xjh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-07 21:57:47,what happens in managerial interviews i posted a few days ago that i had a technical meeting that i crushed the next one id be speaking with the senior swe manager and the director each are minutes referred that they will need to know about my skills and qualifications and for me to ask any questions i may have ill read about the company and its industry and products and ill come up with good questions i know but i fall short in identifying what skills they are interested in knowing didnt they get the sense from the technical one maybe theres something they need to know about my soft skills and work ethics or how much impact my projects had in my current and past jobs the job is for a data scientist thanks,,,,,
1ijzgvg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-07 16:47:48,perpetualbooster outperformed autogluon on out of classification tasks perpetualbooster is a gbm but behaves like automl so it is benchmarked against autogluon v best quality preset the current leader in automl benchmark top datasets with the most number of rows are selected from openml datasets for classification tasks the results are summarized in the following table openml task perpetual training duration perpetual inference duration perpetual auc autogluon training duration autogluon inference duration autogluon auc bngspambase bngtrains breast click_prediction_small colon higgs sea sfpoliceincidents bates_classif_ oom oom oom prostate oom oom oom average perpetualbooster outperformed autogluon on out of classification tasks training equally fast and inferring x faster perpetualbooster demonstrates greater robustness compared to autogluon successfully training on all tasks whereas autogluon encountered outofmemory errors on of those tasks github,,,,,
1ijs9gs,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-07 10:45:31,update use llms like scikitlearn a week ago i posted that i created a very simple python opensource lib that allows you to integrate llms in your existing data science workflows i got a lot of dms asking for some more real use cases in order for you to understand how and when to use llms this is why i created more or less real examples split by use caseindustry to get your brains going examples by use case customer service classifying customer tickets finance parse financial report data marketing customer segmentation personal assistant research assistant product intelligence discover trends in product_reviews user behaviour analysis sales personalized cold emails sentiment classification software development automated pr reviews i really hope that this examples will help you deliver your solutions faster if you have any questions feel free to ask,,,,,
1ijptot,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-07 07:47:43,anyone use uplift models how is your experience with uplift models are they easy to train and be used any tips and tricks do you retrain the model often how do you decide if uplift model needs to be retrained,,,,,
1ijji6f,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-07 01:37:34,looking for pytorch practice sources the textbook tutorials are good to develop a basic understanding but i want to be able to practice using pytorch with multiple problems that use the same concept with wellexplained stepbystep solutions does anyone have a good source for this datalemur does this well for their sql tutorial,,,,,
1ijfonh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-06 22:39:23,storing llmchatbot conversations on cloud hey i was wondering if anyone has any recommendations for storing conversations from chatbot interactions on the cloud for downstream analytics currently i use postgres but the varying length of conversation and long bodies of text seem really inefficient any ideas for better approaches,,,,,
1ijfjh6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-06 22:33:07,what does prompt engineering entail in a data scientist role ive seen postings for llmfocused roles asking for experience with prompt engineering ive finetuned llms worked with transformers and interfaced with llm apis but what would prompt engineering entail in a ds role,,,,,
1ij5jp8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-06 15:46:09,have anyone recently interviewed for metas data scientist product analytics position i was recently contacted by a recruiter from meta for the data scientist product analytics phd position i was told that the technical screening will be minutes long and cover four areas programming research design determining goals and success metrics data analysis i was surprised that all four topics could fit into a minute since i always thought even two topics would be a lot for that time this makes me wonder if areas and might be combined into a single productsense question with one big business case study also im curiousdoes this format apply to all candidates for the data scientist product analytics roles or is it specific to candidates with doctoral degrees if anyone has any idea about this id really appreciate it if you could share your experience thanks in advance,,,,,
1iid6zv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-05 15:55:42,data science skills help me fill the gaps im putting together a data science knowledge map to track key skills across different areas like machine learning deep learning statistics cloud computing and autonomyrl the goal is to make a structured roadmap for learning and improvement you can check it out here my goal is to make it general purpose so you can focus on skillset categories that are most useful to you would love your feedback are there any skills or topics you think should be added also if you have great resources for any of these areas feel free to share,,,,,
1iicldl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-05 15:30:04,advice on building live odds model etl pipeline database predictive modeling api im working on a side project right now that is designed to be a plugin for a rocket league mod called bakkesmod that will calculate and display live odds win odds for each team to the player these will be calculated by taking live playerteam stats obtained through the bakkesmod api sending them to a custom api that accepts the inputs runs them as variables through predictive models and returns the odds to the frontend i have some questions about the architectureinfrastructure that would best be suited keep in mind that this is a personal side project so the scale is not massive but id still like it to be fairly thorough and robust data pipeline my idea is to obtain json data from ballchasingcom through their api from the last thirty days to produce relevant models i dont want data from to have weight in predicting gameplay in my etl pipeline doesnt need to be immediately uptodate so i figured id automate it to run weekly from here id store this data in both aws s and a postgresql database the s bucket will house parquet files assembled from the flattened json data that is received straight from ballchasing to be used for longer term data analysis and comparison storing in s infrequent access ia would be gb and converting it to the glacier flexible retrieval type in s after a certain amount of time with a lifecycle rule would be gb i estimate that a single days worth of parquet files would be maybe mb so if i wanted to keep lets say days worth of data in ia and the rest in glacier flexible that would only be for ia gb and i wouldnt reach mo in glacier flexible costs until years worth of data past days old gb obviously there are costs associated with data requests but with the small amount of requests ill be triggering its effectively negligible as for the postgres db i plan on hosting it on aws rds i will only ever retain the last thirty days worth of data this means that every weekly run would remove the oldest seven days of data and populate with the newest seven days of data overall i estimate a single days worth of sql data being about mb making my total maybe around mb either way its safe to say im not looking to store a monumental amount of data during data extraction each group of data entries for a specific day will be transformed to prepare it for loading into the postgres db day retention and writing to parquet files to be stored in s ia glacier flexible afterwards ill perform eda on the cleaned data with polars to determine things like weights of different stats related to winning matches and what type of modeling library i should use scikitlearn pytorch xgboost api after developing models for different ranks and game modes id serve them through a grpc api written in go the goal is to be able to just send relevant stats to the api insert them as variables in the models and return odds back to the frontend i have not decided where to store these models yet s i doubt it would be necessary but i did think about using kafka to stream these results because thats a technology i havent gotten to really use that interests me and i feel it may be applicable here albeit probably not necessary automation as i said earlier i plan on this pipeline being run weekly whether that includes eda and iterative updates to the models is something i will encounter in the future but for now id be fine with those steps being manual i dont foresee my data pipeline being too overwhelming for aws lambda so i think ill go with that if it ends up taking too long to run there i could just run it on an ec instance that is turned onoff beforeafter the pipeline is scheduled to run ive never used cloudwatch but im of the assumption that i can use that to automate these runs on lambda i can conduct basic cicd through github actions frontend the frontend will not have to be hosted anywhere because its facilitated through rocket league as a plugin its a simple text display and the ingame live stats will be gathered using bakkesmods api questions does anything seem ridiculous overkill or not enough for my purposes have i made any mistakes in my choices of technologies and tools what recommendations would you give me for this architectureinfrastructure what should i use to transform and prep the data for load into spostgres what would be the best service to store my predictive models is it reasonable to include kafka in this project to get experience with it even though its probably not necessary thanks for any help edit revised data pipeline section to better clarify the storage of parquet files for longterm storage opposed to raw json,,,,,
1iibksg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-05 14:46:33,how do you all quantify the revenue impact of your work product im mostly an academic so pardon my cluelessness a lot of the advice given on here as to how to write an effective resume for industry roles revolves around quantifying the revenue impact of the projects you and your team undertook in your current role in that it is not enough to simply discuss technical impact increased accuracy of predictions improved quality of data etc but the impact a project had on a firms bottom line but it seems to me that quantifying the causal impact of an ml system or some other standard data science project is itself a data science project in fact one could hire a data scientist or economist whose sole job is to audit the effectiveness of data science projects in a firm i bet you arent running diffindiffs or estimating production functions to actually ascertain revenue impact so how are you guys figuring it out,,,,,
1ii5swa,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-05 08:48:13,xi ξ correlation coefficient in postgres ,,,,,
1ihsbrs,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-04 20:59:18,ml system design mock i have ml system design interview coming up and wanted to see if anyone here has website groupdiscord or want to mock together,,,,,
1ihnvjz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-04 17:58:58,side projects what are your side projects for me i have a betting model ive been working on from time to time over the past few years currently profitable in backtesting but too risky to put money into its been a fun way to practice things like ranking models and web scraping which i dont get much exposure to at work also could make money with it one day which is cool im wondering what other people are doing for fun on the side feel free to share,,,,,
1ihl43y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-04 16:06:22,for a takehome performance project thats meant to take hours would you actually stay under hours ive completed a take home project for an analyst role im applying for the project asked that i spend no more than hours to complete the task and that its okay if not all questions are answered as they want to get a sense of my data story telling skills but they also gave me a week to turn this in ive finished and i spent way more than hours on this as i feel like in this job market i shouldnt take the risk of turning in a sloppier take home task ive looked around and seen that others who were given hour take homes also spent way more time on their tasks as well it just feels like common sense to use all the time i was actually given especially since other candidates are going to do so as well but im worried that a hiring manager and recruiter might look at this and think they obviously spent more than hours,,,,,
1ih7qk4,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-04 02:52:15,guidance for new professionals hey everyone i worked at this company last summer and i am coming back as a graduate in march as a data scientist altough the title is data scientist projects with actual modelling are rare the focus is more on bi and creating new solutions for the company in its different operations i worked there and liked the people and environment but i really aim to stand out to try and give my best to learn the most i would love to get some tips and experiences from you guys thanks,,,,,
1igpsrg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-03 14:04:57,about data processing data science tiger style and assertions i recently came across a video in youtube mentioning this tiger coding style and the assertions part is quite interesting assertions detect programmer errors unlike operating errors which are expected and which must be handled assertion failures are unexpected the only correct way to handle corrupt code is to crash assertions downgrade catastrophic correctness bugs into liveness bugs assertions are a force multiplier for discovering bugs by fuzzing this style only reinforces that the practice that i already used to is relevant in other fields and i try to use that as much as i can but it seems to be only plausible to use for metadata and function parameters and not the actual data we work with i say that because if the dataset is large enough then any assertion would take a lot of time and slow the actual program execution should i do a lot of assertions that reduce performance or should i ignore the need for error detection and not use any assertions during data processing do you do anything similar to this how would you approach this performance error detection tradeoff is there any middle ground that could be found,,,,,
1igpi6w,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-03 13:51:02,tabpfn v a pretrained transformer outperforms existing sota for small tabular data and outperforms chronos for timeseries have any of you tried tabpfn v it is a pretrained transformer which outperforms existing sota for small tabular data you can read it in nature some key highlights it outperforms an ensemble of strong baselines tuned for hours in seconds for classification and seconds for regression tasks for datasets up to samples and features it is robust to uninformative features and can natively handle numerical and categorical features as well as missing values pretrained on million synthetically generated datasets it is a generative transformer model which allows for finetuning data generation and density estimation tabpfn v performs as well with half the data as the next best baseline catboost with all the data tabpfn v can be used for forecasting by featurizing the timestamps it ranks on the popular timeseries gifteval benchmark and outperforms chronos tabpfn v is available under an open license a derivative of the apache license with a single modification adding an enhanced attribution requirement inspired by the llama license you can also try it via api,,,,,
1igo4dh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-03 12:38:48,what areas does synthetic data generation has usecases there are synthetic data generation libraries from tools such as ragas and ive heard some even use it for model training what are the actual use case examples of using synthetic data generation,,,,,
1ighhad,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-03 05:01:44,weekly entering transitioning thread feb feb welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1ig62ea,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-02 19:59:00,any one here built a recommender system before i need help understanding the architecture i am building a rs based on a neoj database i struggle with the how the data should flow between the database recommender system and the website i did some research and what i arrived on is that i should make the rs as an api to post the recommendations to the website but i really struggle to understand how the backend of the project work,,,,,
1ifywzo,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-02 14:55:58,deepseekcom is down constantly alternatives to use deepseekr for free chatting since the deepseek boom deepseekcom is glitching constantly and i havent been able to use it so i found few platforms providing deepseekr chatting for free like open router nvidia nims etc check out here,,,,,
1ifub7j,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-02 10:16:24,ai tools what ai tools do you use as a copilot when working on your data science coding there are coding platforms like v and cursor that are very helpful for doing frontendbackend related coding work whats the one you use for data science,,,,,
1ifaenx,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-01 16:46:39,use llms like scikitlearn every time i wanted to use llms in my existing pipelines the integration was very bloated complex and too slow this is why i created a lightweight library that works just like scikitlearn the flow generally follows a pipelinelike structure where you fit learn a skill from sample data or an instruction set then predict apply the skill to new data returning structured results highlevel concept flow your data load skill learn skill create tasks run tasks structured results downstream steps installation pip install flashlearn learning a new skill from sample data like a fitpredict pattern from scikitlearn you can quickly learn a custom skill from minimal or no data below well create a skill that evaluates the likelihood of buying a product from user comments on social media posts returning a score and a short reason well use a small dataset of comments and instruct the llm to transform each comment according to our custom specification from flashlearnskillslearn_skill import learnskill from flashlearnclient import openai instantiate your pipeline estimator or transformer similar to a scikitlearn model learner learnskillmodel_namegptomini clientopenai data comment_text i love this product its everything i wanted comment_text not impressed wouldnt consider buying this provide instructions and sample data for the new skill skill learnerlearn_skill data task evaluate how likely the user is to buy my product based on the sentiment in their comment return an integer on key likely_to_buy and a short explanation on key reason save skill to use in pipelines skillsaveevaluate_buy_comments_skilljson input is a list of dictionaries whether the data comes from an api a spreadsheet or usersubmitted forms you can simply wrap each record into a dictionarymuch like feature dictionaries in typical ml workflows heres an example user_inputs comment_text i love this product its everything i wanted comment_text not impressed wouldnt consider buying this run in lines of code concurrency builtin up to callsmin once youve defined or learned a skill similar to creating a specialized transformer in a standard ml pipeline you can load it and apply it to your data in just a few lines suppose we previously saved a learned skill to evaluate_buy_comments_skilljson skill generalskillload_skillevaluate_buy_comments_skilljson tasks skillcreate_tasksuser_inputs results skillrun_tasks_in_paralleltasks printresults get structured results the library returns structured outputs for each of your records the keys in the results dictionary map to the indexes of your original list for example likely_to_buy reason comment shows strong enthusiasm and positive sentiment likely_to_buy reason expressed disappointment and reluctance to purchase pass on to the next steps each records output can then be used in downstream tasks for instance you might store the results in a database filter for highlikelihood leads below is a small example showing how you might parse the dictionary and feed it into a separate function suppose flash_results is the dictionary with structured llm outputs for idx result in flash_resultsitems desired_score resultlikely_to_buy reason_text resultreason now do something with the score and reason eg store in db or pass to next step printfcomment idx score desired_score reason reason_text comparison flashlearn is a lightweight library for people who do not need high complexity flows of langchain flashlearn minimal library meant for well defined us cases that expect structured outputs langchain for building complex thinking multistep agents with memory and reasoning if you like it give us a star github link,,,,,
1iez1k7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-01 05:05:32,is this job description the new normal for data science or am i going for a data engineering hunt hey guys i have an upcoming appointment for a security company but i think its focusing more on the data pipelines part where at my current job im focusing more on analysis and business and machine learningstatistics i do minimal mlops work i had to study the fundamentals of airflow and dbt to do a dummy data pipeline as a side project with snowflake free tier i feel cooked from the amount of information i had to consume in just two days the only problem is i dont know what questions should i expect not in machine learning or data processing but in modeling and engineering i said to myself its not worth it but all job description for data science today involve big data tools knowledge and cloud and some data modeling this made me reconsider my choices and the pace at which my career is growing and decided to go for it and actually treat it as a learning experience what are your thoughts about this guys could really use some advice,,,,,
1iew0k6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-01 02:15:54,for the causal ds do you follow any books or frameworks for observational studies asking as i am new to the space and wondering what are the best practises for assessing balance choosing confounders examples of a rigorous observational study done to learn from any tools made currently to help speed up the process many thanks,,,,,
1ievdxq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-02-01 01:42:51,got a raise out of the blue despite having a tech job offer this is a follow up on previous post long story short got a raise from my current role before i even told them about the new job offer to my knowledge our boss is very generous with raises typically around but my case i went by now my role pays more i communicated this to the recruiter and they were stressed but it is hard for me to make a choice now they said they cant afford me as they see me as a high intermediate and their budget at the max is and were offering i told them that my comp is total now i then explained why i am making so much more my current employer genuinely believes that i drive a lot of impact edit they do not know that i have a job offer yet,,,,,
1iet1j8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-31 23:49:02,any luck through job apps on job boards or is all success through recruiters and other methods the title is selfexplanatory how are people landing jobs in the data space right now,,,,,
1iepe0h,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-31 21:08:33,guide for running ab test on a product with network effects im working on a tool that is collaborative in nature and has realtime sync think multiplayer mode in a video game if anyone has any guidance on designing a statistical test for this kind of game or if the juice is worth the squeeze id really appreciate it,,,,,
1ienwes,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-31 20:05:22,is there a better changepoint detection model on python than ruptures im rebuilding a model in python that i previously built in r in r i used the changepoint package to changepoint identification which in python ive been trying to replicate using the ruptures package but holy hell is there ever a difference rs package gave me exactly what i expected every time without configuration but ruptures is spotty at best is anyone aware of a better changepoint detection package,,,,,
1ieitha,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-31 16:34:03,for the causal ds how long does it take you to complete a observational evaluation hey everyone im wondering for those of you working on observational studies and using methods like psmtmle matching etc how long does that project take you end to to endgetting the data to final evaluation result and have you found anyways to speed up your process looking to see if theres any ways i could be speeding up the whole process as they take forever normally months,,,,,
1iefenq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-31 14:00:22,deepseekr free api key so deepseekr has just landed on openrouter and you can now run the api key for free check how to get the api key and codes,,,,,
1iea72c,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-31 08:18:27,these are the instructions i created for my genai assistant that i use for programming projects im a head of at a largeish ecommerce company so do not code much these days but created said assistant to help me with programming tasks that has been massively helpful just sharing nand wondering what anyone else would use the do all charts in the style of the economist is massively helpful though works better in r and not python which is what we primarily use at work but cest la vie when i prompt you initially for a code related task make sure that you first understand the business objectives of the work that we are doing ask me clarifying questions if you have to when you are not clear on a task ask clarifying questions feel free to give me a list of queries that we can run to help you understand the task better for any charting requests always do in the style of the economist or the mckinsey harvard business review and following the principles of edward tufte outlined below try to give all responses integrated into the one code block that we were discussing always run debugging code within larger code blocks over lines and code to explicitly state where new files have been created debugging code should partition the larger query into small chunks and understand where any failures may be occurring if i want to break away from the current train of thought without starting a new chat i will preface my prompt with please retain memory but be aware that we may be switching context when we create a data frame or source data to perform analysis on or create charts from assign it a number we will use that number when writing prompts but the table data frame will remain the same in the code that we use we will just be assigning a number to allow for shorthand when communicating by prompt ie sales_table may just be so therefore a prompt to extract total sales from should return the code select sumsales from sales_table when i use the word innovation or any of its derivatives feel free to suggest out of the box ideas or procedural improvements to the topic we are discussing use python unless i specify otherwise r would be the next most likely language to be used when printing out charts also if you feel necessary print out summary statistics keep the tabular format clean and tidy do not use base r python to achieve this for any charting abide by the principles of visualisation pioneer edward tufte which are comprehensively summarised here graphical excellence show complex ideas communicated with clarity precision and efficiency tufte argues that graphics should reveal data avoid distorting what the data has to say encourage the eye to compare different pieces of data and make large datasets coherent dataink ratio maximize the ratio of dataink to total ink used in a graphic tufte advocates for removing all nonessential elements chartjunk decorative elements heavy gridlines unnecessary borders and redundant information that dont contribute to understanding data density present as much data as possible in the smallest possible space while maintaining clarity highdensity graphics can be both elegant and precise small multiples use repeated small charts with the same scale and design to show changing data across multiple dimensions or time periods this allows for easy comparison and pattern recognition this one is important use small multiples wherever possible integration of text and graphics words numbers and graphics should be integrated rather than separated labels should be placed directly on the graphic rather than in legends when possible truthful proportions the representation of numbers should be directly proportional to the numerical quantities represented this means avoiding things like truncated axes that can mislead viewers causality and time series when showing cause and effect or temporal sequences graphics should read from left to right and clearly show the relationship between variables aesthetics and beauty while prioritizing function tufte argues that the best statistical graphics are also beautiful combining complexity detail and clarity in an elegant way,,,,,
1iea500,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-31 08:13:58,any data analysts scientists out there help me create an assistant for my end users ,,,,,
1ie7ari,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-31 04:59:20,whats the most absurd data fire drillemergency youve had to work see prompt above,,,,,
1idzfhq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-30 22:26:46,aws applied scientist ii l offer evaluation received an offer for an applied scientist ii l role at aws kumo bellevue and wondering if its on the lower side offer details base k year signon k year signon k rsus shares every months in years estimated year tc k does this seem competitive for an applied scientist ii position i was told the correct range from as is about k k base can go up to k current c ai just joined this week senior data scientist genai tc k k base k rsus over years my details yoe full time in us years as senior applied scientist in midtier org india cofounded a legit ai startup in nyc ms from top ivy league recent grad top of class does it seem like a lowball of an offer,,,,,
1idyhdv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-30 21:46:14,is data science in small businesses pointless is it pointless to use data science techniques in businesses that dont collect a huge amount of data for example a dental office or a small retain chain would using these predictive techniques really move the needle for these types of businesses or is it more of a nice to have if not how much data generation is required for businesses to begin thinking of leveraging a data scientist,,,,,
1idu5it,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-30 18:45:34,whats your firms ai strategy hey ds community mid level data scientist here im currently involved in a project where im expected to work on delivering an appropriate ai strategy for my firm id like to benefit from the hives experience im interested looking at ideas and philosophies behind the ai strategy for the companies you work for what products do you use for your staff clients did you use inhouse solutions or buy a product how did you manage security and data governance issues were there open source solutions why did youdid you not go for them id appreciate if you could also share resources that aided you in defining a strategy for your teamfirm cheers,,,,,
1idtj2m,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-30 18:19:19,interview format different from what recruiter explained is this common i recently interviewed for a data scientist role and the format of the interview turned out to be quite different from what the recruiter had initially described specifically i was told that the interview would focus on a live coding test for sql and python but during the actual interview it included a case study while i was able to navigate the interview the difference caught me off guard has anyone else experienced a similar situation how common is it for interview formats to deviate from what was communicated beforehand also is it appropriate to follow up with the recruiter for clarification or feedback regarding this mismatch would love to hear your thoughts and experiences,,,,,
1idqgi8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-30 16:11:41,hirevue data science internship interviewadvice hey guys this is literally my first time attending an professional interview in my entire life i dont know how this roadmap works but i just got a email for hirevue as my first round and this is virtual interview which i was not expecting any inputs that you can give will potentially help me tia update passed the hirevue and into my second round technical assessment,,,,,
1iderhl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-30 04:46:05,why does there seem to be so many more data engineering jobs than data science or mle jobs i feel like i made a mistake in choosing data science and ml ive been browsing jobs recently since my current role doesnt pay well i usually search for jobs in the data field in general rather than a particular title since titles have so much variance but one thing ive noticed is that there are way more data engineering roles than either data scientists or ml engineers on the job boards when i say data engineering jobs i mean the roles where you are building etl pipelines scalabledistributed data infrastructure and storage in the cloud building data ingestion pipelines dataops etc but why is this i thought that given all the hype over ai these days that there would be more llmml jobs and theres certainly a number of those dont get me wrong but i just feel like they pale in comparison to the amount of data engineering openings did i make a mistake in choosing data science and ml is data engineering in more demand and secure if so why should i fully transition to data engineering,,,,,
1id8zee,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-30 00:14:22,green ai which programming language consumes the most ,,,,,
1id1gn1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-29 18:56:35,most secure data science jobs hey everyone im constantly hearing news of layoffs and was wondering what areas you think are more secure and how secure do you think your job is how worried are you all about layoffs are you always looking for jobs just in case,,,,,
1icvhgh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-29 14:51:17,i have opensourced several of my data visualization projects with plotly ,,,,,
1ic1mnm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-28 13:32:40,created an app for practicing for your interviews with gpt ,,,,,
1iby5om,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-28 09:54:09,nvidias paid generative ai courses for free limited period nvidia has announced free access for a limited time to its premium courses each typically valued between covering advanced topics in generative ai and related areas the major courses made free for now are retrievalaugmented generation rag for production learn how to deploy scalable rag pipelines for enterprise applications techniques to improve rag systems optimize rag systems for practical realworld use cases cuda programming gain expertise in parallel computing for ai and machine learning applications understanding transformers deepen your understanding of the architecture behind large language models diffusion models explore generative models powering image synthesis and other applications llm deployment learn how to scale and deploy large language models for production effectively note there are redemption limits to these courses a user can enroll into any one specific course platform link nvidia trainings,,,,,
1ibm1t4,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-27 22:25:55,is there a way to terminate a running ml algorithm in python i have a set of ml algorithms to be fit to the same data on a df some of them takes days to run while others usually take minutes what id like to do is to set up a max model fitting timer so once the fittingtraining of an algorithm exceeds that it will forgot that algo and move onto the next one is there way to terminate the modelfit after it is initiated based on a prespecified time here are my code excerpts ml_model_param_for_price_model_simple linear regression model linearregression params fit_intercept true false copy_x true false n_jobs none xgboost regressor model xgbregressorobjectiveregsquarederror random_staterandom_state params n_estimators learning_rate max_depth subsample colsample_bytree lasso regression model lassorandom_staterandom_state params alpha lasso regularization strength fit_intercept true false max_iter maximum number of iterations the looping and fitting of data below x dflist_of_predictors y dfoutcome_var x_train x_test y_train y_test train_test_splitx y test_size random_stateselfrandom_state hyperparameter tuning and model training tuned_models for model_name current_param in selfparam_gridsitems model current_parammodel params current_paramparams if params check if there are parameters to tune if model_name xgboost regressor model randomizedsearchcv model params n_iter cv scoringr random_stateselfrandom_state else model gridsearchcvmodel params cv scoringr start_time datetimenow start timing modelfitx_train y_train note i want this to break out when a timer is done end_time datetimenow end timing tuned_modelsmodel_name modelbest_estimator_ store the best fitted model loggerinfofnmodel_name best estimator modelbest_estimator_ loggerinfofmodel_name fitting time end_time start_time print the fitting time else start_time datetimenow start timing modelfitx_train y_train fit model directly if no params to tune end_time datetimenow end timing tuned_modelsmodel_name model save the trained model loggerinfofmodel_name fitting time end_time start_time print the fitting time,,,,,
1ibkw2h,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-27 21:38:39,would you rather be comfortable or take risks moving around i recently received a job offer from a midtolarge tech company in the gig economy space the role comes with a competitive salary offering a k increase over my current compensation while the pay bump is nice the job itself will be challenging as it focuses on logistics and pricing however i do have experience in pricing and have demonstrated my ability to handle optimization work this role would also provide greater exposure to areas like causal inference optimization and realtime analytics which are areas id like to grow in that said im concerned about my career trajectory ive moved around frequently in the pastfor example i spent years at a big bank in my first role but left due to a toxic team while im currently happy and comfortable in my role i havent been here for a full year yet my current total compensation is k while the worklife balance is great my team is lacking in technical skills and ive essentially been responsible for upskilling the entire practice another area of concern is that technically we are not able to keep up with bigger companies and the work is highly regulated so innovation isnt as easy given the frequency move what would you do in my shoes take it and try to improve career opportunities for big tech,,,,,
1ibedfy,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-27 17:16:40,as someone who aims to be a ml engineer how much oop and programming skills do i need when to stop on the developer track how much do i need to master to help me being a good mle,,,,,
1ib8lg1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-27 13:10:18,sample size calculator with live data visualization as parameters change demo of live updating chart on samplesizecalccom its been a while since ive worked on my sample size calculator tool last post here but i had a lot of fun adding an interactive chart to visualize required sample size and thought you all would appreciate it made with djs check it out here what i love about this is that it helps me understand the relationship between each of the variables statistical power and sample size hope its a nice explainer for you all too i also have plans to add a line chart to show how the statistical power increases over time ie the longer the experiment runs the more samples you collect and the greater the power as always let me know if you run into any bugs,,,,,
1ib33bq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-27 08:01:02,word of advice for job seekers if your potential employer requires you to sign an nda for a take home assignment theyre exploiting you for free work in particular if the work they want you to do is remarkably specific definifely do not do it,,,,,
1ib0dfb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-27 05:01:38,weekly entering transitioning thread jan feb welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1iawkau,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-27 01:43:41,free product analytics product data scientist case interview with answers if you are interviewing for product analyst product data scientist or data scientist analytics roles at tech companies you are probably aware that you will most likely be asked an analytics case interview question it can be difficult to find real examples of these types of questions i wrote an example of this type of question and included sample answers please note that you dont have to get everything in the sample answers to pass the interview if you would like to learn more about passing the product analytics interviews check out my blog post here if you want to learn more about passing the ab test interview check out this blog post if you struggled with this case interview i highly recommend these two books trustworthy online controlled experiments and ace the data science interview these are affiliate links but i bought and used these books myself and vouch for their quality without further ado here is the sample case interview if you found this helpful please subscribe to my blog because i plan to create more samples interview questions ___ prompt customers who subscribe to amazon prime get free access to certain shows and movies they can also buy or rent shows as not all content is available for free to prime customers additionally they can pay to subscribe to channels such as showtime starz or paramount all accessible through their amazon prime account in case you are not familiar with amazon prime video the homepage typically has one large feature such as watch the seahawks vs the ers tomorrow if you scroll past that there are many rows of video content such as movies we think youll like trending now and top picks for you assume that each row is either all free content or all paid content here is an example screenshot question what are the benefits to amazon of focusing on optimizing what is shown to each user on the prime video home page potential answers looking for proscons candidate should list at least good answers showing the right content to the right customer on the prime video homepage has lots of potential benefits it is important for amazon to decide how to prioritize because the right prioritization could drive engagement highlighting free content ensures customers derive value from their prime subscription increase revenue promoting paid content or paid channels can drive additional purchases or subscriptions customer satisfaction ensuring users find relevant and engaging content quickly leads to a better browsing experience content discovery showcasing a mix of content encourages customers to explore beyond free offerings but keep in mind potential challenges overemphasis on paid content may alienate customers who want free content they could think im paying for prime to get access to free content why is amazon pushing all this paid content question what key considerations should amazon take into account when deciding how to prioritize content types on the prime video homepage potential answers again the candidate should list at least good answers free vs paid balance ensure users see value in their prime subscription while exposing them to paid options this is a delicate balance amazon wants to upsell customers on paid content without increasing prime subscription churn keep in mind that paid content is usually newer and more in demand eg new releases user engagement consider the users watch history and preferences eg genres actors shows vs movies revenue impact assess how prominently displaying paid content or channels influences rental purchase and subscription revenue content availability prioritize content that is currently trending newly released or exclusive to amazon prime video geo and licensing restrictions adapt recommendations based on the content available in the users region question lets say you hypothesize that prioritizing free prime content will increase user engagement how would you measure whether this hypothesis is true potential answer i would design an experiment where the treatment is that free prime content is prioritized on row one of the homepage the control group will see whatever the existing strategy is for row one it would be fair for the candidate to ask what the existing strategy is if asked respond that the current strategy is to equally prioritize free and paid content in row one to measure whether prioritizing free prime content in row one would increase user engagement i would use the following metrics primary metric average hours watched per user per week secondary metrics clickthrough rate ctr on row one guardrail metric revenue from paid content and channels question how would you design an ab test to evaluate which prioritization strategy is most effective be detailed about the experiment design potential answer clearly state the hypothesis prioritizing free prime content on the homepage will increase engagement eg hours watched compared to equal prioritization of paid content and free content because free content is perceived as an immediate value of the prime subscription reducing friction of watching and encouraging users to explore and watch content without additional costs or decisions success metrics primary metric average hours watched per user per week secondary metric clickthrough rate ctr on row one guardrail metrics revenue from paid content and channels per user ensure prioritizing free content does not drastically reduce purchases or subscriptions numerator total revenue generated from each experiment group from paid rentals purchases and channel subscriptions during the experiment denominator total number of users in the experiment group bounce rate ensure the experiment does not unintentionally make the homepage less engaging overall numerator number of users who log in to prime video but leave without clicking on or interacting with any content denominator total number of users who log in to prime video per experiment group churn rate monitor for any longterm negative impact on overall customer retention numerator number of prime members who cancel their subscription during the experiment denominator total number of prime members in the experiment tracking metrics ctr on free paid and channelspecific recommendations this will help us evaluate how well users respond to different types of content being highlighted numerator number of clicks on freepaidchannel content cards on the homepage denominator total number of impressions of freepaidchannel content cards on the homepage adoption rate of paid channels percentage of users subscribing to a promoted channel randomization randomization unit users prime subscribers why this will work userlevel randomization ensures independent exposure to different homepage designs without contamination from other users point of incorporation to the experiment users are assigned to treatment free content prioritized or control equal prioritization of free and paid content upon logging in to prime video or landing on the prime video homepage if they are already logged in randomization strategy assign users to treatment or control groups in a split statistical test to analyze metrics for continuous metrics eg hours watched ttest for proportions eg ctr ztest of proportions also using regression is an appropriate answer as long as they state what the dependent and independent variables are bonus points if candidate mentions cuped for variance reduction but not necessary power analysis candidate should mention conducting a power analysis to estimate the required sample size and experiment duration dont have to go too deep into this but candidate should at least mention these key components of power analysis alpha eg power eg mde minimum detectable effect and how they would decide the mde eg prior experiments discuss with stakeholders and variance in the metrics do not have to discuss the formulas for calculating sample size question suppose the new prioritization strategy won the experiment and is fully launched leadership wants a dashboard to monitor its performance what metrics would you include in this dashboard potential answers engagement metrics average hours watched per user per week ctr on homepage recommendations broken down by free paid and channel content ctr on by row revenue metrics revenue from paid content rentals and purchases subscriptions to paid channels retention metrics weekly active users wau monthly active users mau churn rate of prime subscribers operational metrics latency or errors in the recommendation algorithm user satisfaction scores eg via feedback or surveys,,,,,
1iahg6i,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-26 15:33:05,warantly period and coverage after resignation i am leaving my current job i have built tooling to automate ml processes document everything and transfer knowledge nevertheless these systems are not battlehardened yet and those i am transferring to are either devops who know little ml or ds who have poor swe skills i suppose they would need my help later down the road i already offered that i would be available for quick chats if they needed me i was wondering what the norm is in handling these scenarios do people usually offer free consultation as a warranty and for how long,,,,,
1iadgz9,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-26 12:36:59,why ai agents will be a disaster ,,,,,
1ia175l,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-26 00:18:34,official end of year salary sharing thread this is the official thread for sharing your current salaries or recent offers see last years salary sharing thread here there was also an unofficial one from an hour ago here please only post salariesoffers if youre including hard numbers but feel free to use a throwaway account if youre concerned about anonymity you can also generalize some of your answers eg large biotech company or add fields if you feel something is particularly relevant title tenure length location remote salary companyindustry education prior experience internship coop relocationsigning bonus stock andor recurring bonuses total comp note that while the primary purpose of these threads is obviously to share compensation info discussion is also encouraged,,,,,
1i9shbm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-25 17:46:45,seeking advice on organizing a sprawling jupyter notebook in vs code ive been using a single jupyter notebook for quite some time and its evolved into a massive file that contains everything from data loading to final analysis my typical process starts with importing data cleaning it up and saving the results for reuse in pickle files when i revisit the notebook i load these intermediate files and build on them with transformations followed by exploratory analysis visualizations and insights while this workflow gets the job done its becoming increasingly chaotic some parts are clearly meant to be reusable steps while others are just me testing ideas or exploring possibilities it all lives in one place which is convenient in some ways but a headache in others i often wonder if theres a better way to organize this while keeping the flexibility that makes jupyter such a great tool for exploration if this were your project how would you structure it,,,,,
1i9n64r,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-25 13:41:35,do you implement own high performance python algorithms and in which language i want to implement some numerical algorithms as a python library in a low level compiled language like ccythonzig cnanobindpybind rustpyo and want to listen to some experiences from this field if you have some handson experience which language and library have you used and what is your recommendation i also have some experience with rcrcpp but also want to learn to do this in python,,,,,
1i9gcxu,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-25 05:48:23,what gpu config to choose for ai usecases ,,,,,
1i9ar5b,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-25 00:40:10,what to expect from this technical test i applied for a sql data analytics role and have a technical test with the following components multiple choice sql questions up to mins multiple choice general data science questions mins sql questions where you will write the code mins i can code well so im not really worried about the coding part but do not know what to expect of the multiple choice ones as ive never had this experience before i do not know much of the like infrastructure of sql of theory so dont know how to prepare especially for the general data science questions which i have no idea what that could be any advice,,,,,
1i98tom,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-24 23:09:31,data imbalance monitoring metrics hello all i am consulting a business problem from a colleague with a dataset that has of the class of interest the dataset k has observations and we were debating on what thresholds were selected for metrics robust to data imbalance like prauc brier and maybe mcc do you have any thoughts from your domains on how to deal with data imbalance problems and what performance metrics and thresholds to monitor them with as a an fyi sampling was ruled out due to leading to models in need of strong calibration thank you all in advance,,,,,
1i90imp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-24 17:15:42,dml researchers want to help me out here hey guys im a ms statistician by background who has been doing my masters thesis in dml for about months now one of the things that i have a question about is does the functional form of the propensity and outcome model really not matter that much my advisor isnt trained in this either but we have just been exploring by fitting different models to the propensity and outcome model what we have noticed is no matter you use xgboost lasso or random forests the ate estimate is damn close to the truth most of the time and any bias is like not that much so i hate to say that my work thus far feels anticlimactic but it feels kinda weird to done all this work to then just realize ah well it seems the type of ml model doesnt really impact the results in statistics i have been trained to just think about the functional form of the model and how it impacts predictive accuracy but what im finding is in the case of causality none of that even matters i guess im kinda wondering if im on the right track here edit dml double machine learning,,,,,
1i90dzu,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-24 17:10:24,imposter syndrome as a ds hello im seeking some career advice and tips ive essentially been pigeonholed into a tpm position with a data scientist title for the past years this is my first official ds role but i was in analytics for several years before the team i joined had no real need for a data scientist and have really been using me as a pm for reportingpartner management i occasionally get to do data science projects but they let me decide what to analyze without real engagement from partners around business needs this ends up being adhoc analyses with minimal business impact ive been looking for a new role for over a year now but the market is terrible im in the process of completing the omsa program so im not terribly rusty on statsml concepts but im starting to feel insecure in my abilities to cut it as a ds irl a new hire recently joined a team within my broader org and asked me how i productionalize my code but i never have and it made me feel like an imposter does anyone have tips or encouragement,,,,,
1i8t59p,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-24 11:17:37,building a reliable texttosql pipeline a stepbystep guide pt ,,,,,
1i8nauq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-24 04:29:01,i made a guide to help people understand docker when i first started out using docker it was really confusing i made a guide to help people understand what docker is used for please let me know what you think and if you have any feedback,,,,,
1i8hb9n,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-23 23:27:57,where is the standard mldl are we all shifting to prompting chatgpt i am working at a consulting company and while so far all the focus has been on cool projects involving setting up mldl models lately all the focus has been shifted on genai as a data scientistmaching learning engineer who tackled difficult problems of data and modles for the past months i have been editing the same prompt file saying things differently to make chatgpt understand me is this the new reality or should i change my environment please tell me there are standard ml projects,,,,,
1i8czdb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-23 20:22:30,i feel left behind on aws or any cloud services overall hi i got promoted to a data scientist at work from operations analysis to doing optimization and dynamic pricing however i only do code good and clean one but i feel like an analyst again but this time on steroids the only thing i touch is sagemaker jupyter lab to open my machine and some s concepts how to read write ther nothing fancy but really thats it i only do deep analysis and thats about it there are people around me who do ml deploy stuff manage versions on github and so on doing stuff that is required from the market when i tried applying out in other jobs i really stood out for my analytical skills and math statistics knowledge but i really lack practice i know ml concepts but i feel really rusty that i never get to use it except for linear regression and decision trees as i use them a lot in analysis i got stuck in an interview when asked about redshift eventbridge other aws services my teammates are super friendly they are my age and we are good friends when i talked to them asked them to involve me in their projects i just couldnt have the time for it as their projects always conflicts with mine they always tell me that youll know how to use them when you need them but i am afraid given my role condition i will never get to use them i analyze and stuff what can i do guys i could really use some advice i dont feel like i am doing fine i feel left out thanks,,,,,
1i89r5d,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-23 18:09:43,the most in demand ds skills via adzuna listings ,,,,,
1i894sd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-23 17:44:22,deep learning in adtech a handson example with kaggle ,,,,,
1i86l83,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-23 15:58:55,call for input regression discontinuity design and interrupted time series ,,,,,
1i7eaj9,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-22 15:55:36,scrapy mro error without any references to conflicting packages hi all im working on a little personal project quantifying what technologies are most asked for in data science jds really im more using it to work on my python chops im hitting a slightly perplexing error and i think chatgpt has taken me as far as it possibly can on this one when i attempt to crawl my spider i get this error typeerror cannot create a consistent method resolution order mro for bases injectable generic previously the code was attempting to import injectable from scrap_poet until i eventually inspected the package and saw that injectable doesnt exist so i attempted to avoid using that entirely and omitted all references to injectable in my code yet im still getting this error any thoughts heres what the spider looks like import scrapy import csv from scrapy_autoextract import request_raw class jobspiderscrapyspider name job_spider custom_settings downloader_middlewares scrapy_autoextractautoextractmiddleware read urls from linkscsv and start requests def start_requestsself with openadzuna_linkscsv r as file reader csvreaderfile for row in reader url row yield request_rawurlurl page_typejobposting callbackselfparse def parseself response try extract job details directly from the response json data returned by autoextract job_data responsejsongetjob_posting if job_data yield title job_datagettitle description job_datagetdescription company job_datagethiringorganization getname location job_datagetjoblocation getaddress dateposted job_datagetdateposted else selfloggererrorfno job data extracted from responseurl except exception as e selfloggererrorferror parsing job data from responseurl e,,,,,
1i7bnpd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-22 13:57:28,meta career advice vs data science i joined the thread to learn about data science something like percent of the posts are peoples resumes and requests for career advice i thought these were supposed to go into a weekly thread or something im getting a warning about the weekly thread even as im posting this comment can anyone suggest alternative subs with more educational content,,,,,
1i7b8id,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-22 13:35:44,graduated september and i am now looking for an entry level data engineering position what do you think about my cv ,,,,,
1i7a8e0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-22 12:41:54,ds interested in lower level languages hi community im primarily ds with quite a number of years in ds and de ive mostly worked with onsite infrastructure my stack is currently python julia r and my field of interest is numerical computing openmp mpi and gpu parallel computing down the line im curious as to how best to align my current work with high level languages with my interest in lower level languages if i were deciding based on work alone fortran will be the best language for me to learn as theres a lot of legacy code wed have to port in the next years however id like to develop in a language thatll complement the skill set of a ds my current view is julia c and fortran however im not completely sure of how useful these are outside of my veryspecific field are there any other ds that have gone through this how did you decide what would you recommend what factors did you consider,,,,,
1i6qa6u,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-21 19:02:10,analyzing changes to gravel height along a road im working with a dataset that measures the height of gravel along a km stretch of road at meter intervals i have two measurements baseline height the original height of the gravel new height a more recent measurement showing how the gravel has decreased over time this gives me the difference in height at various points along the road id like to model this data to understand and predict gravel depletion heres what im consideringidentifying trends or patterns in gravel loss eg areas with more significant depletion using interpolation to estimate gravel heights at points where measurements are missing exploring possible environmental factors that could influence depletion eg road curvature slope or proximity to towns however im not entirely sure how to approach this analysis some questions i have what are the best methods to visualize and analyze this type of spatial data are there statistical or machine learning models particularly suited for this if i want to predict future gravel heights based on the current trend what techniques should i look into any advice suggestions or resources would be greatly appreciated,,,,,
1i6pu2t,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-21 18:44:11,how to get individual restaurant review data ,,,,,
1i658fp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-21 00:02:35,what should i do to build a strong foundation in developing im interested in becoming a developer im currently proficient in tableau alteryx power bi etc i feel like theres million different avenues im not sure which route to take i want to get around a community where i can connect and get exposed to more im in the miami area ive checked out youtube videos on java script what do you all recommend,,,,,
1i60m31,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-20 20:47:12,question about using geographic data for soil analysis and erosion studies im working on a project involving a dataset of latitude and longitude points and im curious about how these can be used to index or connect to meaningful data for soil analysis and erosion studies are there specific datasets tools or techniques that can help link these geographic coordinates to soil quality erosion risk or other environmental factors im interested in learning about how farmers or agricultural researchers typically approach soil analysis and erosion management are there common practices technologies or methodologies they rely on that could provide insights into working with geographic data like this if anyone has experience in this field or recommendations on where to start id appreciate your advice,,,,,
1i5inrb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-20 05:01:44,weekly entering transitioning thread jan jan welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1i5d77u,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-20 00:08:12,anyone ever feel like working as a data scientist at hinge need to figure out what that damn algorithm is doing to keep me from getting matches lol on a serious note i have read about some interesting algorithmic work at dating app companies any data scientists here ever worked for a dating app company edit galeshapely algorithm,,,,,
1i57vx1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-19 20:17:55,where to start when data is limited a guide hey ive put together an article on my thoughts and some research around how to get the most out of small datasets when performance requirements mean conventional analysis isnt enough its aimed at helping people get started with new projects who have already started with the more traditional statistical methods would love to hear some feedback and thoughts,,,,,
1i5576y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-19 18:27:43,should i try to postpone my faang interview so i got contacted by a faang recruiter for a data scientist role i applied for a month and a half ago but as i have started to prep i realize i am not ready and need to months before i would be able to do well on all the technical interviews there are of them my sql is rusty because i have been using pyspark so much that i didnt really need to do medium to hard sql queries at work were also not allowed in most cases since sql is slower so i would just do everything in pyspark but now as i start practicing my sql i realize its very basic and its going to take some time before i can get it on the level my pyspark is at ive noticed that i feel like there is no chance of me performing well enough on this interview and it sucks because the recruiter said that the hiring manager was looking at my resume and really wants to interview me as soon as possible since he thinks i have strong experience for the role they made me bypass the phone screens because of it i have no doubt i would be able to do the role but interviews are another beast according to the prep guide my stats ml theory sql and python all have to be perfect since i joined my current company as an intern i didnt have to do as many indepth technicals as i have to do here ive interviewed at a couple other big companies last year and didnt make it to the final round for one simply because i needed more time to prepare the faang recruiter wants me to do the first interviews within the next two weeks and im worried about what it would do to my confidence if i failed this interview since this is pretty much my dream data scientist role my mind is already telling me just to make the best of this and use it as a learning experience but another part of me is wondering if i should just cancel it altogether or try to delay it as much as possible i have a mock interview with a company data scientist they set up for me in a few days but part of me feels defeated already and it sucks i honestly am not sure what to do as i need a lot more time ive heard others say it took them as long as months before they were ready to crush their faang interview and i know i am not there yet,,,,,
1i4yyoe,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-19 13:56:17,influential timeseries forecasting papers of part this article explores some of the latest advancements in timeseries forecasting you can find the article here edit if you know of any other interesting papers please share them in the comments,,,,,
1i4f1go,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-18 19:18:55,ai is difficult to get right apple intelligence rolled backmostly the summary feature source seems like even apple is struggling to deploy ai and deliver realworld value yes companies can make mistakes but apple rarely does and even so it seems like most of apple intelligence is not very popular with ios users and has led to the creation of rappleintelligencefail its difficult to get right in contrast to application development which was the era before the ai boom,,,,,
1i40izz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-18 05:22:57,do these recruiters sound like a scam hi all unsure of where else to ask this so asking here i had a recruiter heavy indian accent callemail me with an interesting proposition they work for the candidate rather than the company if they place you in a job within days they ask for of your first years salary they claim their value add is in a couple of things first they promise that they have advanced ats software that will help tweak professional qualifications second they say they will apply to approximately jds per day i am skeptical this many relevant jobs are even being posted i have never had luck with indian recruiters before but i have had good experiences professionally in offshoring some repetitive tasks for cheap this process sounds like it fits the bill the part where it gets sketchy is they want either access to my linkedingmail or they want me to create second linkedingmail accounts that they would have control over access to my gmail is a nonstarter obviously but creating spoof linkedingmails feels a little sketchy if were living in a universe where these guys are simply trying to provide the service theyve described im all in i just dont want to get softrolled into some sort of scam,,,,,
1i3zajz,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-18 04:08:05,huggingface smolagents code centric agent framework is it the best ai agent framework i dont think so ,,,,,
1i3y1qs,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-18 02:58:01,what salary range should i expect as a fresh college grad with a bs in statistics and data science for context im a student at ucla and am applying to jobs within california but im interested in peoples past jobs fresh out of college where in the country and what the salary was tentatively im expecting a salary of anywhere between k and k but ive been told i should be expecting closer to k which just seems ludicrous,,,,,
1i3x2cf,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-18 02:04:43,are there any ways to earn a little extra money on the side as a data scientist using data science skills otherwise im sure there are plenty i know there is data annotation but im not sure that qualifies as data science,,,,,
1i3clrk,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-17 09:24:26,microsoft mattergen genai model for material design and discovery ,,,,,
1i3cgo0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-17 09:13:37,guys is web crawling and scraping for data science or it doesnt matter by web crawling and scraping i mean advanced scraping with multiple websites for prices and products then building further things around it like strategic planning and buisness analytics edit is it a necessary skill or not it means its a great add on to ur skill stack,,,,,
1i3bwdj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-17 08:28:56,can someone help me understand what is the issue exactly ,,,,,
1i3a45a,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-17 06:15:21,how long did it take you to get a new role when looking for a new job im feeling very miserable at my job as well as feeling uneasy with the ethics of my company so i desperately am looking for a new role but this job market is concerning i have a bs in math and ms in ds been at my job as a data scientist for years worked for years between bs and ms in analyst roles is there hope to have something new soon how many apps per day should i be sending,,,,,
1i3a227,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-17 06:11:28,google titans new llm architecture with better long term memory ,,,,,
1i34tao,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-17 01:18:28,looking for arts sales data to understand arts pricing dynamics or madness i would like to explore datasets of arts sale and auctions please if anyone has a good source please post below in the link just curious to explore if there are any patterns in art prices or just maddness which data science cant understand why a banana and tape would sell for million or perhaps i can learn more about arts from this dataset thanks in advance thanks,,,,,
1i33mt0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-17 00:20:26,ive been given the choice between being a data scientist or an analytics manager which would you choose and why im coming from a data analyst position and ive essentially been given the choice between being a data scientist and or an analytics manager i thought data scientist was my dream job but the manager position would pay more and ive been dreaming about working my way up to director or cdo does analytics manager make the most sense in this case update for context im have a masters in data analytics and have been working in the same industry for years but in different roles ive been an analyst for years and previously was a data manager and a researcher,,,,,
1i2vmuv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-16 18:27:30,introducing mlsynth hi ds reddit for those of who you work in causal inference you may be interested in a python library i developed called machine learning synthetic control or mlsynth for short as i write in its documentation mlsynth is a onestop shop of sorts for implementing some of the most recent synthetic control based estimators many of which use machine learning methodologies currently the software is hosted from my github and it is still undergoing developments ie for computing inference for pointestinatesuser friendliness mlsynth implements the following methods augmented differenceindifferences clusterscm debiased convex regression undocumented at present the factor model approach forward differenceindifferences forward selected panel data approach the lpda the lrelaxation pda principal component regression robust pca synthetic control synthetic control method vanilla scm two step synthetic control and finally the two newest methods which are not yet fully documented proximal inferencescm and proximal inference with surrogatesscm while each method has their own options eg bayesian or not l relaxer versus l all methods have a common syntax which allows us to switch seamlessly between methods without needing to switch softwares or learn a new syntax for a different librarycommand it also brings forth methods which either had no public documentation yet or were written mostly forin matlab the documentation that currently exists explains installation as well as the basic methodology of each method i also provide worked examples from the academic literature to serve as a reference point for how one may use the code to estimate causal effects so to anybody who uses python and causal methods on a regular basis this is an option that may suit your needs better than standard techniques,,,,,
1i2vj0x,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-16 18:23:06,free learning paths for data analysts data scientists and data engineers using open resources hey im ryan and ive created a platform offering free structured learning paths for data enthusiasts and professionals alike the current paths cover data analyst learn essential skills like sql data visualization and predictive modeling data scientist master python machine learning and realworld model deployment data engineer dive into cloud platforms big data frameworks and pipeline design the learning paths use free open resources and dont require signup each path includes practical skills and a capstone project to showcase your learning i see this as a work in progress and want to grow it based on community feedback suggestions for content resources or structure would be incredibly helpful ive also launched a discord community with over members where you can collaborate on data projects share ideas and resources join future live hangouts for project work or qa sessions if youre interested check out the site or join the discord to help shape this platform into something truly valuable for the data community lets build something great together website discord,,,,,
1i2qj4j,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-16 14:48:39,books on machine learning in r im interested in everyones experience of books based specifically in r on machine learning deep learning and more recently llm modelling etc if you have particular experience to share it would really useful to hear about it as a subquestion it would be great to hear about books intended for relative beginners by which i mean those familiar with r and statistical analysis but with no formal training in ai there is obviously the wellknown introduction to machine learning with r by scott v burger available as a free pdf but it hasnt been updated in nearly years now and a quick scan of google shows quite a number of others suggestions much appreciated,,,,,
1i2mh17,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-16 11:01:47,solution completeness and take home assignments for interviews what is the general consensus about take home interviews and then completeness of solution i have around a week and it took me already days just to work with with the data just so i can clean it enhance it with external data feature engineer it establish baselines to capture lift the whole thing is supposed to be finished around the span of a week as i was scoping it out the whole thing is essentially potentially models in a framework given the complex nature of the work how critical is the completeness and assumptions being made regarding these take home assignments i didnt get a take home that large in scope its difficult task but very doable just laborious in the sense that it requires to be well thought out,,,,,
1i2m3mv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-16 10:35:04,what challenges do businesses face when developing ai solutions hello everyone im currently working on providing cloud services and looking to better understand the challenges businesses face when developing ai as a cloud provider im keen to learn about the realworld obstacles organizations encounter when scaling their ai solutions for those in the ai industry what specific issues or limitations have you faced in terms of infrastructure platform flexibility or integration challenges are there any key challenges in ai development that remain unresolved what specific support or solutions do ai developers need from cloud providers to overcome current limitations looking forward to hearing your thoughts and learning from your experiences thanks in advance,,,,,
1i2jytl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-16 07:52:27,start freelancing with experience i hear many people have the ambition to start freelancing as soon as they can ideally before having significant job experience i like the attitude but i tried myself a few years ago and got burned so i wanna share my experience i am a data scientist and tried to start freelancing with just one year job experience in did the usual stuff set up an upwork profile applied to jobs at nights and during weekends and waited for a reply crickets i applied to jobs and didnt get any looking back at that experience i see a few mistakes i didnt have a portfolio of projects that matched the jobs i applied to i only used upwork without leveraging linkedin catalant fiverr and others i gave up too early just applications over one month is not enough i recommend applying to jobs per week if possible i set an unreasonable hourly rate i set my hourly rate same as my daily job freelancing is a market where you are the product when there is no demand for you because nobody knows you its a smart move to set the price low once demand picks up increase the price accordingly overall i think experience is not the number one factor that a client looks for when hiring a freelancer its way more important to give the client confidence that you can do the job so you should always work with that goal in mind from the way you build your profile to all the communication with your client last bit of advice i found success in my local market at first in italy there is not many data professionals that are also freelancers and that helped me people like to work with familiar faces and speaking the same language sharing the same culture goes a long way building confidence curious to know your point of view too,,,,,
1i29a6d,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-15 22:10:31,advanced imputation techniques for correlated time series insights and experiences advanced imputation techniques for correlated time series insights and experiences hi everyone im looking to spark a discussion about advanced imputation techniques for datasets with multiple distinct but correlated time series imagine a dataset like energy consumption or sales data where hundreds of stores or buildings are measured separately the granularity might be hourly or daily with varying levels of data completeness across the time series heres the challenge some buildingsstores have complete or nearly complete data with only a few missing values these are straightforward to impute using standard techniques others have partial data with gaps ranging from days to months finally there are buildings with missing values for the target variable across the entire time frame leaving us reliant on correlated data and features the time series show clear seasonal patterns weekly annual and dependencies on external factors like weather customer counts or building size while these features are available for all buildingsincluding those with no target datathe features alone are insufficient to accurately predict the target correlations between the time series range from moderate to very high making the data situation highly heterogeneous my current approach for storesbuildings with few or no data points im considering an approach that involves using correlated stores identify stores with high correlations based on available data eg monthly aggregates these could serve as a foundation for imputing the missing time series reconciling to monthly totals if we know the monthly sums of the target for stores with missing hourlydaily data we could constrain the imputed time series to match these totals for example adjust the imputed hourlydaily values so that their sum equals the known monthly figure incorporating known features for stores with missing target data use additional features eg holidays temperature building size or operational hours to refine the imputed time series for example if a store was closed on a monday due to repairs or a holiday the imputation should respect this and redistribute values accordingly why just using correlated stores isnt enough while using highly correlated stores for imputation seems like a natural approach it has limitations for instance a store might be closed on certain days eg repairs or holidays resulting in zero or drastically reduced energy consumption simply copying or scaling values from correlated stores wont account for this the known features for the missing store eg building size operational hours or customer counts might differ significantly from those of the correlated stores leading to biased imputations seasonal patterns eg weekends vs weekdays may vary slightly between stores due to operational differences open questions feature integration how can we better incorporate the available features of stores with missing values into the imputation process while respecting known totals eg monthly sums handling correlationbased imputation are there specific techniques or algorithms that work well for leveraging correlations between time series for imputation practical adjustments when reconciling imputed values to match known totals what methods work best for redistributing values while preserving the overall seasonal and temporal patterns from my perspective this approach seems sensible but im curious about others experiences with similar problems or opinions on why this mightor might notwork in practice if youve dealt with imputation in datasets with heterogeneous time series and varying levels of completeness id love to hear your insights thanks in advance for your thoughts and ideas,,,,,
1i28x7i,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-15 21:55:11,what do you think about building the pipeline first with bad models to start refining quickly we have to build a computer vision application i detect main problems get the highest quality training set it is requiring lots of code and it may require lots of manual work to generate the ground truth train a classification model two main orthogonal approaches are being considered and will be tested train a segmentation model connect the dots and build the end to end pipeline one teammate is working in the highest quality training set and three other teammates in the classification models i think it would be incredibly beneficial to have the pipeline as soon as possible integrated with the extremely simple models and then iterate taking into account error metrics as it gives us goals and this lets them test their modulesection of the work also taking into account variation of the final metrics this would also help the other teams that depend on our output web development can use a model it is just a bad model but well improve the results the deployment work could also start now what do you guys think about this approach for me it looks like its all benefits and zero problems but i see some teammates are reluctant on building something that definitely fails at the beginning and im not definitely the most experienced data scientist,,,,,
1i275yh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-15 20:38:41,wasmpowered codespaces for python notebooks on github during a hackweek we built this project that allows you to run marimo and jupyter notebooks directly from github in a wasmpowered codespacelike environment what makes this powerful is that we mount the github repositorys contents as a filesystem in the notebook making it really easy to share notebooks with data all you need to do is prepend to any python notebook on github some examples jupyter notebook marimo notebook jupyter notebooks are automatically converted into marimo notebooks using basic static analysis and source code transformations our conversion logic assumes the notebook was meant to be run topdown which is usually but not always true it can convert many notebooks but there are still some edge cases we implemented the filesystem mount using our own fuselike adapter that links the github repositorys contents to the python filesystem leveraging emscriptens filesystem api the file tree is loaded on startup to avoid waterfall requests when reading many directories deep but loading the file contents is lazy for example when you write python that looks like with opendatacarscsv as f printfread or import pandas as pd pdread_csvdatacarscsv behind the scenes you make a request to docs we technically proxy it through the playground to fix cors issues and github ratelimiting why is this useful vieiwng notebooks on github pages is limiting they dont allow external css or scripts so charts and advanced widgets can fail they also arent itneractive so you cant tweek a value or panzoom a chart it is also difficult to share your notebook with code you either need to host it somehwere or embed it inside your notebook just append,,,,,
1i20otn,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-15 16:03:29,aspirations of starting a data science consultancy has anyone ever here thought of how to use their skills to start their own consultancy or some kind of business lately ive been kinda feeling that it would be really nice to have something of my own to work one involving analytics working for a company is great experience but part of me would really like to have a business that i own where i help small businesses who have data make sense of it with low hanging fruit solutions just a thought but ive always thought of some sort of consultancy where clients are some sort of local business that collects data but doesnt use it effectively or does not have the expertise on how to turn their data into insights that can be used for example suppose you had three clients local gyms which have lots of membership data my consultancy could offer services to measure engagement etc and use demographic information to further understand gym goers dont know what action they could take but a thought local shop has expenses they track and right now its all over the place a dashboard that can help them view everything in one place something where its tasks which are trivial for the average data scientist but generate a lot of value for local businesses but maybe you can go deeper im not sure how genai works and havent played around with like any of these tools but ive thought of ways these can be incorporated too idk i just find working in the industry sole draining and i just want to be able to have something that i can call my own work on my own schedule and it lead to a lot more revenue than working for a company if anyone has any thoughts on what they have done or how they have tried to do something please let me know ideally id try and start this after years of experience where ive built some niche industry experience,,,,,
1i1z6pj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-15 14:57:34,who is the most hungry for ai ml talent right now i run a job search engine for data scientists this week we added monitoring of the highest paid job openings in the last week this is what i saw it seems one company in particular wants to outbid everyone else and this is not because of lack of competition we monitor more than companies including all of fortune and most of fortune we index more than k data science jobs every month source jobsindatacom,,,,,
1i1wnxj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-15 12:50:03,leaving public sector for private posting for a friend currently in a an ostensibly manager level ds position in local government they are in the final stages of interviewing for a director level role at a private firm is the compensation change worth it posted below and are there any ds specific aspects they should consider right now they are an ic who occasionally manages but it seems this new role might be managing is that common for the private sector i told them it doesnt seem worth it im biased as i am also in the public sector but they said the compensation combined with more interesting work might be worth it public sector manager k pension secure but only okay payout student loan forgiveness private sector director k bonus k match,,,,,
1i1bjhi,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-14 17:35:52,evalues a modern alternative to pvalues in many modern applications ab testing clinical trials quality monitoring we need to analyze data as it arrives traditional statistical tools werent designed with this sequential analysis in mind which has led to the development of new approaches evalues are one such tool specifically designed for sequential testing they provide a natural way to measure evidence that accumulates over time an evalue of represents to evidence against your null hypothesis a direct and intuitive interpretation theyre particularly useful when you need to monitor results in realtime add more samples to ongoing experiments combine evidence from multiple analyses make decisions based on continuous data streams while pvalues remain valuable for fixedsample scenarios evalues offer complementary strengths for sequential analysis theyre increasingly used in tech companies for ab testing and in clinical trials for interim analyses if you work with sequential data or continuous monitoring evalues might be a useful addition to your statistical toolkit happy to discuss specific applications or mathematical details in the comments ps above was summarized by an llm paper hypothesis testing with evalues current code libraries python expectation new library implementing evalues sequential testing and confidence sequences confseq core library by howard et al for confidence sequences and uniform bounds r confseq the original r implementation same authors as above safestats core library by one of the researchers in this field of statistics alexander ly,,,,,
1i1951j,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-14 15:54:31,exit cmdexe from r or python without admin privilege i run systemtaskkill f im cmdexe i get erreur le processus cmdexe de pid na pas pu être arrêté raison accès denied erreur le processus cmdexe de pid na pas pu être arrêté raison accès denied i execute a batch file a cmd opena shiny open i do my calculations a button on shiny should allow the cmd closing and the shiny of course i can close the cmd from command line but i get access denied when i try to execute it from r is there hope i am on the pc company so i dont have admin privilege,,,,,
1i18xcv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-14 15:45:06,dash python incosistence performance im currently working on a project using dash python it was light and breezy in the beginning i changed a few codes while maintaining the error at testrunning it once in a while just to check if the code change affected the website and nothing bad happened but after i left it for a few hours without changing anything the website wouldnt run anymore and showed me an internal server error this happened way too many times and it stresses me out as i have to update most of the backend asap does anyone has any similar experience and manage to solve it id like to know how,,,,,
1i13e03,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-14 10:44:19,seeking advice on amazon bedrock and azure hello everyone im currently exploring ai infrastructure and platform for a new project and im trying to decide between amazon bedrock and azure ai infrastructure ai studio ive been considering both but would love to hear about your realworld experiences with them has anyone used amazon bedrock or azure ai infrastructure and azure ai studio how would you compare the two in terms of ease of use performance and overall flexibility are there specific features from either platform that stood out to you or particular use cases where one was clearly better than the other any advice or insights would be greatly appreciated thanks in advance,,,,,
1i0x2pm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-14 03:36:54,fuck pandas rant i have been a heavy r user for years and absolutely love r i can write love letters about the r datatable package it is fast it is efficient it is beautiful a coders dream but of course all good things must come to an end and given the steady decline of r users decided to switch to python to keep myself relevant and let me tell you i have never seen a stinking hot pile of mess than pandas everything is layers of stupid the syntax makes me scream there is no coherence or pattern oh use here but no use here want to do a if else ooops better download numpy want to filter ooops use loc and then iloc and write lines of code it is unfortunate there is no getting rid of this unintuitive maddening mess of a library given that every interviewer out there expects it there are much better libraries and it is time the pandas reign ends python data table even creates pandas data frame faster than pandas thank you for coming to my ted talk i leave you with this datatable comparison article while i sob about learning pandas,,,,,
1i0wxxt,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-14 03:30:03,mistral released codestral free to use with vs code and jet brains ,,,,,
1i0m1ts,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-13 19:19:32,advice on stabilizing an autoencoders representation ,,,,,
1i0dbaj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-13 12:56:06,mastering the poisson distribution intuition and foundations ,,,,,
1i0czn6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-13 12:37:08,skytb opensourced reasoning model outperforms openaio on coding and maths benchmarks ,,,,,
1i0c3x8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-13 11:42:00,humana senior ds position merrygoround anyone in the us apply to the humana revolving senior ds position over the last months they continuously post this position and never seem to fill it wondering if anyone has gotten an actual interview i make it to the prescreen rounds every single time i apply and then it just gets reposted,,,,,
1i0bhi3,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-13 10:58:39,seeking advice on gpu comparison greennode vs fpt im currently exploring gpu options for my projects and im curious if anyone here has experience using gpus from greennode or fpt im looking for real feedback on how they compare in terms of performance pricing and overall experience has anyone used gpus from either of these providers how do they stack up against each other in terms of power efficiency speed and reliability are there any specific use cases where one outperforms the other id love to hear your thoughts personal experiences or any suggestions you might have on which gpu might be better for intensive workloads thanks in advance,,,,,
1i06k3y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-13 05:01:45,weekly entering transitioning thread jan jan welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1i03pk7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-13 02:23:54,where do you go to stay up to date on data analyticsscience are there any people or organizations you follow on youtube twitter medium linkedin or some other websiteblogpodcast that you always tend to keep going back to my previous career absolutely lacked all the professional content creators that data analytics have so i was wondering what content you guys tend to consume if any previously id go to two sources one to stay up to date on semirelevant news and the other was a source thatd do high level summaries of interesting research papers really the kind of stuff would be talking about new toolsproducts that might be of use tips and tricks some relearning of knowledge you might have learned years ago deep dives of random but pertinent topics or someone that consistently puts out unique visualizations and how to recreate them you can probably see what im getting at sources for stellar information,,,,,
1hzpcuv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-12 15:42:14,how we matured fisher our ab testing library ,,,,,
1hyxec6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-11 14:47:36,simple full stack agentic ai project to please your business stakeholders since you all refused to share how you are applying gen ai in the real world i figured i would just share mine so here it is there is a rate limiter but we will see how it goes tech stack frontend nextjs tailwind shadcn backend django drf langgraph llm claude sonnet i am still unsure if l should sell it as a tool for data analysts that makes them more productive or for quick and easy data analysis for business stakeholders to selfserve on lowimpact metrics so what do you all think,,,,,
1hyte5x,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-11 10:44:44,feeling stuck in my career please help im in a weird position where i feel like im stuck in my career i really enjoy mathematics mlai implemented a lot of algorithms from scratch in c developed new models for business purposes presented at some internalsmall conferences and developed entire ml infrastructures for startups but having no real opportunities to grow more at the moment im making over k working remotely from eastern europe for a faang in the us they have an office here but my entire data science team is based in the us and im working on the same things as them when applying to companies in the usuk im receiving zero callbacks willing to relocate although companies from the same areas are reaching out with remote offers of kyear those dont have the benefits of my current company and are not attractive opportunities im looking to relocate and get k current internal transfers to the us are closed as they are looking to expand in east europe ive also asked for more difficult projects but those are only available for us not for my region the projects that are open to me at the moment offer zero satisfaction and i want to solve more complex problems and continue to expand my skills but im stuck for the only thing that my studies are in eastern europe and that i dont hold a phd even though ive already worked on novel models in industry and speaking with friends and colleagues that hold a phd my skills are on par im at a point where i feel like skills and projects dont mean absolutely anything and the only thing that has any weight for getting a job are diplomas and people you know maybe im exaggerating but from all of my experiences im starting to feel like people from my region without studies abroad are seen only as cheap labor that should never be given the chance to work on real problems and be paid accordingly a shitty company directly told me that while another told me explicitly that my skills dont matter and theyre only offering bad projects with bad pay in my region its like theres a limit to the level of difficulty i can work on and the pay i can receive regardless of how much i outcompete others at the moment im working on a side research project that ill be sending to some top tier conferences and then try getting a phd in the west but that will take years and if i already have the skills its so frustrating to be stuck for so long just for a diploma and a title or maybe my skills are really not on par and im only good compared to the people in my region heres my resume if anyone would be willing to offer me some feedback,,,,,
1hyploh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-11 06:05:25,applications no response please help i have applied for data science associate or midlevel positions thank you ,,,,,
1hyaw2t,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-10 18:16:01,how to communicate with investors im working at a small scale startup and my ceo is always in talks with investors apparently im currently working in different architectures for video classification as well as using large multimodal models to classify video they want to show how no other model works on our own data obviously and how recent architectures are not as good as our own super secret model videomae finetunned on our data im okay with faking resultsshowing results that cannot be compared fairly i mean im not but if thats what they want to do then fine doesnt really involve more work for me now what pisses me off is that now i need to come up with a way to get an accuracy per class in a multilabel classification setting based solely on precision and recall per class because different models were evaluated by different people at different times and i really only have those metrics per class precision and recall i dont even know if this is possible it feels like it isnt and is an overall dumb metric for our use case all because investors only know the word accuracy would it not be enough to say this is the f score for our most important classes and as you can see none of the other models or architectures weve tried are as good as our best model by the way if you dont know what f means just know that higher scores are better if you want i can explain it in more detail as opposed to getting metrics that do not make any sense i will not present it to the investors i only need to come up with a document but wouldnt it be enough for the higher ups in my company to say what i said above in this scenario,,,,,
1hy9am1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-10 17:10:04,spreadsheet first cell debate settle this debate im having with a coworker i say that spreadsheets should always start in row column a they say row column b edit so that there is an empty row and column before the table starts whats your take,,,,,
1hy8jhq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-10 16:38:47,sas sql question inobs vs outobs just a quick question here regarding proc sql in sas lets say im just writing some code and i want to test it since the database im querying has over a million records i dont want it to process my code for all the records my understanding is that i would want to use the inobs option to limit how much of the table is queried and processed on the server is this correct the outobs option will return however many records i set but it process every record on the table in the server is this correct,,,,,
1hy7g0m,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-10 15:51:38,sql squid game imagine you were a data scientist for squid games levels ,,,,,
1hxxjz6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-10 05:41:11,microsofts rstarmath b llms matches openai os performance on maths ,,,,,
1hxt0wl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-10 01:31:03,how good are your linear algebra skills started my masters in computer science in august bachelors was in chemistry so i took up to diff eq but never a full linear algebra class im still familiar with a lot of the concepts as they are used in higher level science classes but in my machine learning class im kind of having to teach myself a decent bit as i go maybe its me over analyzing and wanting to know the deep concepts behind everything i learn and im sure in the real world these pure mathematical ideas are rarely talked about but i know having a strong understanding of core concepts of a field help you succeed in that field more naturally as it begins becoming second nature should i lighten my course load to take a linear algebra class or do you think my basic understanding although not knowing how basic that is will likely be good enough,,,,,
1hxplq8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-09 22:48:24,best resources for co emissions modeling forecasting im looking for a good textbook or resource to learn about air emissions data modeling and forecasting using statistical methods and especially machine learning also can you discuss your work in the field id like tonlearn more,,,,,
1hxnq3t,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-09 21:25:45,question on quasiexperimental approach for product feature change measurement i work in ecommerce analytics and my team runs dozens of traditional clean online ab tests each year that said im far from an expert in the domain im still working through a parttime masters degree and ive only been doing experimentation without any real training for the last years one of my product partners wants to run a learning test to help with user flow optimization but because of some engineering architecture limitations we cant do a normal experiment here are some details desired outcome is to understand the impact of removing the outdated new user onboarding flow in our app proposed approach is to release a new app version without the onboarding flow and compare certain engagement purchase and retention outcomes control group users in the previous app version who did experience the new user flow treatment group users in the new app version who would have gotten the new user flow had it not been removed one major thing throwing me off is how to handle the shifted time series the weeks of data ill look at for each group will be different time periods another thing is the lack of randomization but that cant be helped given these parameters curious what might be the best way to approach this type of test my initial thought was to use differenceindifference but i dont think it applies given the specific lack of before for each group,,,,,
1hxi5em,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-09 17:30:55,rn tabpfn v accurate predictions on small data with a tabular foundation model ,,,,,
1hx305z,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-09 03:02:15,i was penalized in a ds interview for answering that i would use a generalized linear model for an ab test with an outcome of time on an app but a linear model with a binary predictor is equivalent to a ttest has anyone had occasions where the interviewer was wrong hi i underwent a technical interview for a ds role at a company the company was nice enough to provide feedback this reason was not only reason i was rejected but i wanted to share because it was very surprising to me they said i aced the programming however hey gave me feedback that my statistics performance was mixed i was surprised the question was what type of model would i use for an ab test with time spent on an app as an outcome i suspect many would use a ttest but i believe that would be inappropriate since time is a skewed outcome with only positive values so a ttest would not fit the data well ie gaussian outcome i suggested a lognormal or loggamma generalized linear model instead i later received feedback that i was penalized for suggesting a linear model for the ab test however a linear model with a binary predictor is equivalent to a ttest i dont want to be arrogant or presumptuous that i think the interviewer is wrong and i am right but i am struggling to have any other interpretation than the interviewer did not realize a linear model with a binary predictor is equivalent to a ttest has anyone else had occasions in ds interviewers where the interviewer may have misunderstood or been wrong in their assessment,,,,,
1hx286f,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-09 02:25:52,am i underpaidunderemployed at k for a data analyst position in a mcol city im in a mcol city i have a masters in data analytics that i finished in october and ive been working as a data analyst for years before that i was a study lead clinical data manager for over a year and before that i was a tax researcher and worked in hr currently i make k base salary but k total compensation i keep getting interviews for data scientist positions that are well into the k base salary range but i havent landed an offer yet its really disheartening am i underpaid ps im open to job suggestions lol,,,,,
1hwmsd2,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-08 15:30:02,absolute path to image in shiny ui hello is there a way to get an image from an absolute path in shiny ui i have my shiny app in a r and i havn t created any r project or formal shiny app file so i don t want to use a relative paths for now ui fluidpage tagsdiv tagsimgsrc absolute path to image doesn t work,,,,,
1hwcayh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-08 05:19:55,cag improved rag framework using cache ,,,,,
1hw5s76,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-07 23:48:17,as of which one would you install miniforge or miniconda as the title says which one would you install today if having a new computer for data science purposes miniforge or miniconda and why for tensorflow pytorch etc used to have both but used miniforge more since i got used to it since but i am formatting my machine and would like to know what you guys think would be more relevant now i will try uv soon but want to install miniforge or miniconda at the moment,,,,,
1hvzskd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-07 19:34:26,change my mind feature stores are needless complexity i started last year at my second fulltime data science role the company i am at uses dbt extensively to transform data and i mean very extensively the last company i was at the data scientist did not use dbt or any sort of feature store we just hit the raw data and write sql for our project the argument for our extensive feature store seems to be that it allows for reusability of complex logic across projects and yes this is occasionally true but it is just as often true that there is a table that is used for exactly one project now that im starting to get comfortable with the company im starting to see the crack in all of this complex tables built on top of complex tables built in to of complex tables built on raw data leakage and ambiguity everywhere onboarding is a beast i understand there are times when it might be computationally important to precompute some calculation when doing realtime inference but this is in most cases the exception not the rule most models can be run on a schedule tldr the amount of infrastructure abstraction and systems in place to make it so i dont have to copy and paste a few dozen lines of sql is n or even close to a net positive its a huge drag change my mind,,,,,
1hvy3ld,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-07 18:24:20,gradient boosting machine still running after hours should i terminate im running a gradient boosting machine with the caret package in rstudio on a fairly large healthcare dataset k records variables most are sparse binary predicting a binary outcome its running very slow on my work laptop over hours given the dimensions of my data was i too ambitious choosing hyperparameters of iterations and a shrinkage parameter of my code partition into training and testing data sets setseed intrain createdatapartitionasd_datak_asd_char p list false train asd_data intrain test asd_dataintrain fitting gradient boosting machine setseed gbmgrid expandgridinteractiondepthc ntrees shrinkage nminobsinnodec gbm_fit_brier_ trainasfactork_asd_char tunegrid gbmgrid datatrain trcontroltraincontrolmethodcv number summaryfunctionbigsummary classprobstrue savepredictionstrue trainfraction methodgbm metricbrier maximize false preprocessccenterscale,,,,,
1hvwxzv,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-07 17:37:09,people who do dsanalytics as freelancing any suggestions hi all ive been in ds and aligned fields in corporate for years now im thinking of trying ds freelance to earn additional income as well as learn whatever new things i can by doing more projects i have few questions for people who have done it or tried it does it pay well do you do it fulltime or along with your job is it very difficult with a job what are some good platforms how do you get started how much time does it take how to get your first project how to build your brand if you do it with your current job how much time does it take did you take permission from your manager about this other than freelancing are there better options to make additional income thanks,,,,,
1hvnkbl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-07 09:12:45,tried leetcode problems using deepseekv solved hard problems in st attempt ,,,,,
1hvk25m,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-07 05:07:41,best llms to use so i tried to compile a list of top llms according to me in different categories like best opensourced best coder best audio cloning etc check out the full list and the reasons here,,,,,
1hvfuwa,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-07 01:28:46,what technology should i acquaint myself with next hey all first id like to thank everyone for your immense help on my last question im a ds with about ten years experience and had been struggling with learning python ive managed to always work at rshops never needed it on the job and im profoundly lazy with your suggestions ive been putting in lots of time and think im solidly on the right path to being proficient after just a few days just need to keep hammering on different projects at any rate while hammering away at python i figure it would be beneficial to try and acquaint myself with another technology so as to broaden my resume and the pool of applicable jds my criteria for deciding on what to go with is essentially has as broad of an appeal as possible particularly for higher paying gigs isnt a total b to pick up and i can plausibly claim it as within my skillset within a month or two if im diligent about learning it i was leaning towards some sort of big data technology like spark but im curious what you fine folks think alternatively i could brush up on a visualization tool like tableau,,,,,
1hv5720,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-06 17:58:05,swe ds is learning both good i am doing a bachelor in ds but honestly i been doing full stack on the side studying hours per day and developing and i think its way cooler can i combine both will it give me better skills,,,,,
1hv3gn4,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-06 16:48:06,are medium articles helpful i read almost every day something from medium i do write stuff myself too though i kind of feel some of the articles even though highly rated are not properly written and to some extent loses its flow from the title to the content i want to know your thoughts and how have you found articles helpful on medium or tds,,,,,
1huz0m1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-06 13:30:08,metas large concept models lcms llms to output concepts ,,,,,
1hurpgg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-06 05:20:19,data experience ,,,,,
1hurdd1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-06 05:01:21,weekly entering transitioning thread jan jan welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1huoyaf,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-06 02:52:15,what schema or data model are you using for your llm rag prototyping how are you organizing your data for your rag applications ive searched all over and have found tons of tutorials about how the tech stack works but very little about how the data is actually stored i dont want to just create an application that can give an answer i want something i can use to evaluate my progress as i improve my prompts and retrievals this is the kind of stuff that i think needs to be stored prompt templates ie versioning my prompts final inputs to and outputs from the llm provider and associated metadata chunks of all my documents to be used in rag the chunks that were retrieved for a given prompt so that i can evaluate the performance of the retrieval step conversations or chains for when there might be multiple requests sent to an llm for a given question experiments this is for the purposes of evaluation it would associate an experiment id with a series of inputsoutputs for an evaluation set of questions i cant be the first person to hit this issue i started off with a simple sqlite database with a handful of tables and now that im going to be incorporating rag into the application and probably agentic stuff soon i really want to leverage someone elses learning so i dont rediscover all the same mistakes,,,,,
1huloe0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-06 00:14:04,how are these companies building videoimage generation tools from scratch finetuning llama or something else theres an enormous amount of llmbased tools popping up lately especially in videoimage generation each tied to a different company meanwhile we only see a handful of really good opensource llm models available so my question is how are these companies creating their videoimageavatargeneration tools are they building these models entirely from scratch or are they leveraging existing llms like llama gpt or something else if they are leveraging a model are they simply using an api to interact with it or are they actually finetuning those models with new data these companies collected for their specific use case if youre guessing the answer please let me know youre guessing as id like to hear from those with firsthand experience as well here are some companies im referring to videoimage generation heygencom invideoio characterai kindroidai runwaymlcom,,,,,
1huk9gq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-05 23:10:52,whats your biggest time sink as a data scientist ive got a few ideas for ds tooling i was thinking of taking on as a side project so this is a bit of a market research post im curious what datascientist specific taskproblem is the biggest time suck for you at work i feel like were often building a new class of software in companies and systems that were designed for web or even,,,,,
1hudtrj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-05 18:40:33,do you prepare for interviews first or apply for jobs first ive started looking for a new job and find myself in a bit of a dilemma that im hoping you might have some experience with every day i come across roles that seem like a great fit but i hesitate to apply because i feel like im not fully prepared for an interview while i know theres no guarantee ill even get an interview i worry about wasting an opportunity if im not ready on the other hand preparing for an interview when you have one lined up seems like the most effective approach but im not sure how to balance it all how do you usually handle this,,,,,
1hu86xb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-05 14:28:56,optimizing advent of code dp with highperformance rust ,,,,,
1htxzrg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-05 04:52:57,looking for some advice on my career path ,,,,,
1htlb8y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-04 18:50:56,i dont like my current subfield of ds i have been in data science for years and working as senior data scientist for a big company in my ds journey most of my work are applied data science where i was working on creating and training models improving models and analysing features and make improvements so on i worked on both ml dl models which i loved recently i have been moved to marketing data science where it feels like it is not appealing to me as im doing product data science with designing experiment analysing causal impact media mix modeling so on also im somewhat not well experienced in bayesian models or causal inference still learning but in this field what i feel is you do buch of stuff to answer to business stakeholder in or slides and move on to next business question also even if you come up with something business always work based on traditional way with their past experience im not feeling motivated and not seeing any of my solution is creating an impact is this common with product data science causal inference world or im not seeing with correct picture,,,,,
1htjd17,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-04 17:25:51,is there a similar career outperformance todo list for a dsda given some of the optionsapproaches arent available ,,,,,
1hti98t,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-04 16:38:08,do you have any tips to keep up to date with all the ml implementations i work as a data scientist but sometimes i feel so leftbehind in the field do you guys have some tips to keep up to date with the latest breakthrough ml implementations,,,,,
1htfjez,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-04 14:31:07,whats the best resources to be better at eda while i understand the math about ml the one thing i lack is understanding and interpreting the data better what resources could help me understand them,,,,,
1htcyqo,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-04 12:00:24,how do you find data science internships i am a high school student grade in a eu country and if i do well on the national entrance exams ill get to the best university in the country which is in the top for cs according to qs my experience with programmingdata science is with kaggle for the last years having participated in competitions bronze medal and having forks for my notebookscodebases starting with university how and when should i look for internships preferably overseas because my country is lackluster when it comes to tech let alone ai is there anything i can use to my advantage what did you guys do when you got your internships is it networkingnepotism that makes the difference,,,,,
1ht6ztm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-04 05:04:00,i feel useless im an intern deploying models to google cloud everyday i work hours debugging gcp crap that has little to no documentation i feel like i work my ass off and have nothing to show for it because some weeks i make progress because im stuck on a google cloud related issue gcp support is useless and knows even less than me our own it is super inefficient and takes weeks for me to get anything i need and thats with me having to harass them i feel like this work is above my pay grade its so frustrating to give my manager the same updates every week and having to push back every deadline and blame it on gcp i feel lazy sometimes because ill sleep in and start work at am but then work till pm to make up for it i hate logging on to work now besides i know gcp is just going to crash my pipeline again with little to no explanation and documentation to help every time i debug a data engineering error i have to wait an hour for the pipeline to run so i just feel very inefficient i feel like the company is wasting money hiring me is this normal when starting out,,,,,
1ht2bbg,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-04 00:58:25,moving to germany hi i am a data scientist in australia with about two years experience building ml models doing data mining and predictive analysis for a big company for personal reasons i am moving to munich at the end of the year but am a bit worried about finding a data job abroad i am wondering how difficult it might be to find a job in germany and what can i do to make myself competitive in an international market what skillsets are in demand these days that i can learn and market any advice would be greatly appreciated,,,,,
1hsyiwl,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-03 22:08:41,dicts vs classes which do you tend to use ive been thinking about the tradeoffs between using plain python dicts and more structured options like dataclasses or pydantics basemodel in my data science work on one hand dicts are super flexible and easy to use especially when dealing with json data or quick prototypes on the other hand dataclasses and basemodels offer structure type validation and readability which can make debugging and scaling more manageable im curiouswhat do you all use most often in your projects do you prefer the simplicity of dicts or do you lean towards dataclassesbasemodels for the added structure would love to hear the communitys thoughts,,,,,
1hsxfrd,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-03 21:22:53,data science job market in uk vs usa ive seen a worrying number of posts on social media over the past year describing how bad the job market is for recent computer science graduates particularly in the us obviously there are differences between cs grads and those who pursue ds though the general consensus as far as i am aware is that a cs could do a data scientist role but not vice versa firstly why do you think this is occurring ive seen a lot of people mention the hb visa is a key issue surrounding this though i personally havent a clue secondly is there a vast difference in the uk and usa job markets surrounding data science roles and is the market just as bad in the uk as it is in the usa thirdly are these cs graduates who are unable to get tech jobs migrating to more dscentred jobs this will obviously saturate the ds job market significantly finally as someone who is just starting to transition into the ds field how worried should i be about job market saturation in the uk,,,,,
1hsv9ql,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-03 19:50:33,professor looking for college basketball data similar to kaggles march madness the last years we have had students enter the march madness kaggle comp and the data is amazing i even did it myself against the students and within my company im an adjunct professor in preparation for this year i think itd be cool to test with regular season games after web scraping and searching kenpom ncaa website etc i cannot find anything as in depth as the kaggle comp as far as just regular season stats and matchup dataset any ideas thanks in advance,,,,,
1hsn3e4,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-03 14:01:12,why doesnt changepoint detection work the way i expect it to ive been experimenting with changepoint detection packages and keep getting results that look like this if you look at in that picture youll what to me looks like an obvious changepoint the line has been going down for a while and has suddenly started going up however the model im using here is using the red and blue bands to show where it identified changepoints and its putting the changepoint just a little bit after the obvious one this particular visualization was made using the ruptures package in python but im seeing pretty consistent results with every builtin changepoint model i can find does anyone know why these models by default arent picking up significant changes in direction and how i need to update the calibration to change their behavior,,,,,
1hsm94k,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-03 13:17:19,data scientist for schools chain of schools hi all im currently a data manager in a school but my job is mostly just mis upkeep data returns and using very basic built in analytics tools to view data i am currently doing a msc in data science and will probably be looking for a career step up upon completion but given the state of the market at the moment i am very aware that i need to be making the most of my current position and getting as much valuable experience as possible my work are very flexible and they would support me by supplying any data i need i have looked online and apparently there are jobs as data scientists within schools but there are so many prebuilt analytics tools and government performance measures for things like student progress that i am not sure there is any value in trying to build a tool that predicts student performance etc does anyone work as a data scientist in a school chain of schools if so what does your job usually entail does anyone have any suggestions on the type of project i can undertake i have access to student performance data and maybe financial data across secondary schools and maybe primary schools im aware that i should probably be able to plan some projects that create value but i need some inspiration and for someone more experienced to help with whether this is actually viable thanks in advance sorry for the meandering post,,,,,
1hslejn,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-03 12:28:54,how would you calculate whether to use open source llm vs vendors hi folks i saw a lot of people online comenting on using deepseek instead of gpto and i was wondering how much are we saving by switching does anyone know a framework to estimate that,,,,,
1hsgfvp,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-03 06:48:59,finetuning modernbert for classification ,,,,,
1hrpb9q,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-02 08:34:31,how do you selfidentify in this field and what is your justification ive been in this field for many years holding various titles and connecting with peers who are unfathomably dissimilar in their roles education and skills despite sharing titles i am curious to learn how folks view themselves and the various titles in this field assuming data science is the umbrella that encompasses computer science machine learning statistics maths etc and there is a spectrum of roles within this field how would you selfidentify the rules are it doesnt have to be your actual title from your employer or degree major it doesnt have to be a formally known identity for example you can identify as a number cruncher a tableau manager a deep learning developer make up your own or just use a formal identity such as data scientist or machine learning engineer you have to also add your justification ie why do you believe such identity justly represents youyour role it should be selfexplainable technical maturely and reasonably justified so avoid the likes of ninja unicorn guru unless you can maturely make a compelling argument you must be open to criticism and being challenged other redditors are not compelled to agree with your selfidentity ill also add my own response in the comments because i do not want it to be the center focus of the discussion,,,,,
1hr8ifj,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-01-01 18:08:36,what was your favorite workproject of and why was it personally fulfilling im curious what the state of data science was in and what may bring based on what data scientists prefer to be working on so let us know what project or type of work you most enjoyed last year that you may want to do more of in,,,,,
1hqkw4y,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-31 18:32:28,any help for advanced numpy i am working on something where i need to process data using numpy its a tabular data and i need to convert it to multi dimensional arrays and then perform operations efficiently can anyone suggest some resources for advanced numpy so that i can understand and visualise numpy arrays concept of axis broadcasting etc i need to convert my data in such a way that i can do efficient operations on them for that i need to understand multi dimensional numpy arrays and axis well enough,,,,,
1hqacf9,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-31 08:18:25,duolingo for data science and machine learning edit thank you guys for all your recommendations i really appreciate datacamp has exactly what im looking for brilliant is a close second thanks once again is there an app like duolingo for practicing data science and machine learning solo learn and mimo are both for python and i was wondering if there are any apps like that but tailored for data science i installed some from playstore but its just courses where i have to read things i dont want to read things i want to apply the technical coding aspects like in the mimo apps i know about kaggle and udemy but im looking for something like mimo,,,,,
1hq0s6q,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-30 23:30:17,what would be the fastest way for me to get from novice to advanced level python im a data scientist with ten years experience ive always worked at r shops and havent been forced to learn python on the job so my knowledge of the language is just from piddling around with it on my own and distinctly novice if i was prepared to sink hours a day into it what would be my best bet in terms of fastest way to hone my skills,,,,,
1hpqjrk,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-30 16:09:10,how did you learn git what resources did you find most helpful when learning to use git im playing with it for a project right now by asking everything to chatgpt but still wanted to get a better understanding of it especially how its used in combination with github to collaborate with other people im also reading at the same time the book git pocket guide but it seems written in a foreign language lol,,,,,
1hpfkyr,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-30 05:01:22,weekly entering transitioning thread dec jan welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1hpaa3c,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-30 00:27:18,looking for some senior ds advice hello everyone i think this is okay to be a post since its not about enteringtransitioning but if i need to repost in the weekly threads please let me know tldr i started working as a data scientist at a medium to large company almost years ago i spent the majority of my time doing more software engineeringdata engineering related tasks with ds projects sprinkled in a reorg changed the entire landscape of my company and potential growth at the company i dont know what to do because i dont know if i got solid enough experience to leave for another ds job but my current situation is very uncomfortable looking for any seasoned perspectiveadvice on the situation to help anchor me since im in a bit of a doom spiral i am looking for some career advice i dont want to write a novel about my journey to this point but it was a hell of a lot of work a snippet of my relevant work experience is i worked at various tech startups doing data analystengineering work before i found my way to ds i graduated with my ms in data science back in and i landed a job at a mediumlarge global business in the retail space to my surprise it was the common meme situation where they had no infrastructure put in place for ds work and on top of that a former ibm ds had built a python application being used by an internal team that was barely hanging on year my boss asked if id be able to modernize the application and since i have a bit of a programming background i told them id be happy to do that to get my feet wet with the org i am going to way oversimplify the work i did for the sake of time the important part is this project took around months as the org had everything onprem so i had to go through approvals to get the more modern tech i refactored a large portion of it containerized it and deployed it via an openshift redhats kubernetes product cluster the bulk of the program was a massive jupyter notebook lines of code with some custombuilt math libraries that an analyst would execute each cell after a request was made this notebook housed all the business logic so i just wrapped all that up to be executed automatically when the internal team interacted with the new app by the end of it i had a firm grasp on various business processes and was already talking to my boss about possibilities additionally i found out that i was the only data scientist on staff and i was a little bummed because i had chosen to work for a larger org in hopes of getting some sort of mentorlearnbyosmosis going on however since my background is in startups i wasnt overly concerned because i knew i could utilize this environment to grow by trailblazing the conversation then shifted to the logic in the notebook and the fact that no one really knew what was happening inside it this notebook was driving a fairly important piece of the business by analyzing various datapoints applying business rules and spitting out results to be used day to day they asked if i could dissect it and i readily agreed really wish llms were as commercialized as they are now i spent the next months working out bugs in the newly deployed app and flow charting out all the business logic inside the notebook into nice confluence pages it was fairly spaghettified so making changes to it was going to prove challenging i put my product manager hat on and asked what their goals were with this application the logic measuring success etc i was asked to start a rewrite so that the laundry list of changes they had wanted to make could be done it was also at this time my boss was super happy with the ideaswork i had done i had several other smaller projects i did during this time so they began speaking to me about being promoted up how wed get an actual software engineer on my team so i could focus on more of the data science stuff i was super excitedanxious because i was hoping to get more handson ds experience before leading a team however once again i come from startups so sort of par for the course year the it department announces a reorg a month before my promotion by this point i had job descriptions for a few new positions and we had made plans for who would be shifting to my team all of this gets put on hold and theres tons of uncertainty i spend the next year doing the rewrite by myself i build a few classification models in the process to help a few other internal teams operate more efficiently basically they come through with a domaindriven design philosophy so that the software teams can build more efficiently by having more autonomy they establish practices across the domains and they had a dataml practice initially that gave me some confidence that id at least have peers when it was all said and done year current year i get moved into a domain and they establish a separate bi analytics domain they decentralized everything else but anything to do with data work i am given a promotion to ds manager with a single employee a data engineer it has been super confusing all year with things taking much longer as the org adjusts for the new bureaucratic processes that have been introduced tooling now has to be approved business analyst delivery leads pmo offices etc i meet with the head of engineering to ask how i go about getting tools approved sage maker endpoints and to get a sense of our overall data strategy im basically told there isnt one in place but they hope to get one together soonish a lot has happened and it all feels very confusing basically no one is empowered to make decisions the bi domain is leading the charge for their stuff and me and my team are sort of this island that exists outside of everything else going on i tried to keep that as short as possible and happy to give further detail if you believe itd help heres my main issue i spent these years doing what needed to be done but there really isnt a path of growth because they arent really accounting for data scientists yet though they say they hope to hire them it was clear in the first year what the path would probably look like but with everything becoming more corporate it feels like i could easily get shafted in one way or another however because i spent these years being the good employee and doing what needed to be done instead of what was best for my own experience i think it may be hard for me to get a ds job at another org im hoping to get some perspective from all of you more seasoned professionals,,,,,
1hp65ll,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-29 21:19:59,iye how does the computational infrastructure for ai models and their cost impact developers and users has your org ever bottlenecked development by cost to deploy the ai solution either for you or in their pricing for clients im curious how the expense of ai factors into business it seems like an individual could write code that impacts their cost of employment and that llm training algorithms and other ai work would be more expensive im wondering how businesses are governing the cost of a data scientistsoftware developers choices with ai,,,,,
1hp0cbx,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-29 17:04:27,building productionready ai agents llm programs with dspy tips and code snippets ,,,,,
1hoy3dm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-29 15:20:20,recommend me the best statistics textbook for data science i am intermediate level student who already studied stats but i want to revisit it from ds and ml perspective,,,,,
1houdgh,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-29 11:41:52,what are some of the most interesting applied ml papersblogs you read in or projects you worked on i am looking for some interesting successfulunsuccessful realworld machine learning applications you are also free to share experiences building applications with machine learning that have actually had some real world impact something of this type linkedin has developed a new family of domainadapted foundation models called economic opportunity network eon to enhance their platforms ai capabilities edit just to encourage this conversation here is my own personal saas app this is how l have been applying machine learning in the real world as a machine learning engineer its not much but its something this is a side projectbuilt during weekends and evenings which flopped and has no users clipbard i mostly keep it around to enhance my resume my main audience were educators would like to improve engagement with the younger tiktok generation i assumed this would be a better way of sharing things like history in a more memorable way as opposed to a wall of text i also targeted groups like churches sunday school childrens church who want to bring bible stories to life or tell stories with lessons or parents who want to bring bedtime stories to life every evening,,,,,
1hoq8yb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-29 06:41:25,modernbert vs bert ,,,,,
1ho91f8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-28 16:21:44,will the official year end salary thread be posted for i tried searching for it with the salary as the keyword usually that thread is up by now was just curious as i was looking for comparisons to my own salary,,,,,
1ho4com,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-28 12:03:59,metas byte latent transformer new llm architecture improved transformer byte latent transformer is a new improvised transformer architecture introduced by meta which doesnt uses tokenization and can work on raw bytes directly it introduces the concept of entropy based patches understand the full architecture and how it works with example here,,,,,
1hnnwf5,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-27 20:19:35,euchre simulation and winning chances i tried posting this to reuchre but it got removed immediately ive been working on a project that calculates the odds of winning a round of euchre based on the hand youre dealt for example i used the program to calculate this scenario if you in the first seat to the left of the dealer a hand with the right and left bower along with the three nontrump s wins results in a win of the time based on simulations for the euchre players here would knowing the winning chances for specific hands change how you approach the game could this kind of information improve strategy or would it take away from the fun of figuring it out on the fly what other scenarios or patterns would you find valuable to analyze im excited about the potential applications of this but id love to hear from any euchre players do you think this kind of data would add to the game or do you prefer to rely purely on instinct and experience here is the github link,,,,,
1hnlbhw,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-27 18:26:01,prepost implementation analysis interpretation i am using an interrupted time series to understand whether a certain implementation affected the behavior of the users we cant do a proper ab testing since we introduced the feature to all the users lets say we were able to create a model and predict the post implementation daily usage to create the counterfactual which would be what would be the usage look like if there was no implementation since i have the actual postimplementation usage now i can use it to find the cumulative differenceresidual but my question is since the model is trained on the preimplementation data doesnt it make sense for the residual error to be high against the counter factual the data points in preimplementation are mostly even across the lower and higher boundary and its clear that there are more data points in the lower boundaries in the postimplementation but not sure how i would correctly test this i want to understand the direction so was thinking about using mbe mean bias deviation any thoughts,,,,,
1hnl48d,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-27 18:17:21,imputation use cases im wondering how and why people use this technique i learned about it early on in my career and have avoided it entirely after trying it a few times if people could provide examples of how theyve used this in a real life situation it would be very helpful i personally think its highly problematic in nearly every situation for a variety of reasons the most important reason for me is that nulls are often very meaningful also i think it introduces unnecessary bias into the data itself so why and when do people use this,,,,,
1hng96m,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-27 14:40:24,puppy organize your python projects tldr is a transparent wrapper around pixi and uv with simple apis and recipes for using them to help write reproducible futureproof scripts and notebooks from to rich toolset in one command start in an empty folder curl fssl bash installs python and dependencies in complete isolation from any existing python on your system mix and match url query params to specify python version tools and venvs to create the above also installs puppys cli pup help cli kind of like uvlite pup add myenv pkg pkg install packages to myenv folder using uv pup list view whats installed across all projects pup clone and pup sync clone and build external repos must have buildable pyprojecttoml files pup as a module no more notebook kernels the original motivation for writing puppy was to simplify handling kernels but you might just not need them at all activatecreatemodify kernels interactively with import pup pupfetchmyenv activate packages in myenv are now importable pupfetchmyenv pkg pkg install and activate equivalent to pup add myenv pkg pkg of course youre welcome to use uv pip install but after times its liable to get messy target audience loosely defining personas getting started with python or herding folks who are puppy is the easiest way to go from to modern python onecommand installer that lets you specify python version venvs to build repos to clone getting everyone from to in an easy and standardized way if youre confused about virtual environments and notebook kernels and install full jupyter into every project competent check out multipuppyverse and where pixi shines sections you have work and hobby projects going at the same time and need a better way to organize them for packaging deployment or even to find stuff months later you need support for conda and nonpython stuff you have many fastmoving external and internal dependencies check out pup clone and pup sync workflows and dockerized examples filesystem is your friend puppy recommends a sensible folder structure where each outer folder houses one and only one python executable in isolation from each other and any other python on your system pup is tied to a python executable that is installed by pixi along with projectlevel tools like jupyter conda packages and nonpython tools nodejs make etc puppy commands work the same from anywhere within this folder the inner folders are gitready projects defined by pyprojecttoml with projectspecific packages handled by uv puphome python lives here publicproject git this folder may be a git repo see pup clone venv pyprojecttoml env venv this one is in pregit development pyprojecttoml pixitoml puppy puptorch python here env env pixitoml puppy pupbeta here env pixitoml puppy puppy embraces explicit is better than implicit from the zen of python it logs what its doing with absolute paths so that you always know where you are and how you got there ps ive benefited a great deal from the many peoples oss work now trying to pay it forward the ideas laid out in puppys readme and implementation have come together after many years of working in different orgs where average how do you rate yourself in python ranged from zero excel ever to highly sophisticated the matter of how do we build stuff is kind of never settled and this is my take thanks for checking this out suggestions and feedback are welcome,,,,,
1hn1eqn,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-26 23:43:02,whats your resolution as a ds as wraps up its time to reflect and plan ahead whats your new year resolution as a data scientist are you aiming for a promotion a pay bump or a new job maybe youre planning to dive into learning a new skill step into a people manager role or pivot to a different field curious to hear whats on your radar for of course coasting counts too,,,,,
1hn0k9f,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-26 23:02:04,i analyzed you guys in my quest for finding an internship and figuring what i want to do with my life workwise i decided to analyze how yall feel about jobs in data science one of the fields i am interested in is machine learningdata science so i decided to do a project that would help me see what other people think about this field the project is available here sentiment analysis part teds cave i would really appreciate any advice on the project itself if anyone bothers to read through it or on the problem of how im supposed to figure out what my passions are and how do i commit to one thing and how do i land an internship lol anyways i thought i would share with my dataset the project i did thanks yall,,,,,
1hmuob8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-26 18:34:32,regression on multiple independent variable hello everyone ive come across a use case thats got me stumped and id like your opinion i have around million pieces of data representing the profit of various projects over a period of time each project has its id its profits at the date the date and a few other independent variables such as the project manager city etc so i have projects over years with monthly granularity several projects can be running simultaneously id like to be able to predict a projects performance at a specific date based on profits the problem ive encountered is that each project only lasts year on average which means we have data points per project so its impossible to do lstm per project as far as i know you cant generalise lstm for a case like mine similar periods of time for different projects how do you build a model that could generalise the prediction of the benefits of a project over its lifecycle what ive done for the moment is classic regression xgboost decision tree with variables such as the age of the project in months the date the benefits over m m m ive chosen or as the target variable positive or negative margin at the current month im afraid that regression wont be enough to capture more complex trends lagged trend especially which kind of model would you advise me to go am i on a good direction,,,,,
1hmrwcw,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-26 16:29:10,deepseekv looks the best opensourced llm released ,,,,,
1hmdpjm,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-26 01:24:18,nontechnical job alternatives for former data scientist some context i have a phd in a hard science and i worked as a data scientist at a medical company for about years and learned quite a bit and felt overall useful from machine learning to stats reports dashboards and python writing i have good social and communication skills as well though they were not needed at my position as data scientist however i felt like the amount of work and the nature of work just wasnt a match for me it felt like manual labour except with my brain constant and never ending work and problem solving no where near as difficult as the graduate work but much more abundant and relentless at some point i guess you could say burnout occurred i dont mind problem solving and writing code but at a human pace with intellectual freedom has anyone been in my situation what sort of jobs aside from management did you transition to if anyone knows of any specific roles or advice please do share i would be happy to provide more context if necessary thank you,,,,,
1hm9he8,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-25 21:30:24,am i cooked or is it this job market ,,,,,
1hm7es6,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-25 19:39:46,updated with questions ds questions hi everyone just wanted to give a heads up we updated our list of data science interview questions to now have almost questions for you guys to try out and access for yourselves again with a free plan you can access most of the content on the site hope this helps you guys in your interview prep merry christmas,,,,,
1hlz38v,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-25 11:27:09,where can i find realworld mlds experience volunteering works too hey everyone so im trying to get some handson experience in machine learning and data sciencenot just the do more projects advice ive already done a bunch but actual realworld stuff where i can work on meaningful problems paid or unpaid doesnt really matter to meid even love to volunteer if it means i get to learn and grow i recently applied for an omdena project and im wondering if anyone here has done something with them whats it like did it actually help you gain valuable experience or was it just another group project kind of thing also are there other platforms or places where i could jump into something similar im trying to avoid the whole chasing certifications rabbit hole i just want to get better at solving real problems not stacking credentials would love to hear your thoughts or any experiences youve had thanks in advance bit about me im a rdyear undergrad in computer science with a minor in statistics and i just got an internship for a data role at a pretty big company super excited about it but i want to keep building my skills and exploring different opportunities in mlds,,,,,
1hlup8w,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-25 05:40:38,langchain in your pocket generative ai book packt published free audiobook hi everyone its been almost a year now since i published my debut book langchain in your pocket beginners guide to building generative ai applications using llms and what a journey it has been the book saw major milestones becoming a national and even international bestseller in the ai category so to celebrate its success ive released the free audiobook version of langchain in your pocket making it accessible to all users free of cost i hope this is useful the book is currently rated at on amazon india and on amazon com making it amongst the toprated books on langchain and is published by packt as well more details table of contents introduction hello world different langchain modules models prompts chains agents outputparsers memory callbacks rag framework vector databases langchain for nlp problems handling llm hallucinations evaluating llms advanced prompt engineering autonomous ai agents langsmith langserve additional features edit unable to post direct link maybe reddit guidelines hence posted medium post with the link,,,,,
1hl9xdo,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-24 09:16:38,days of openai summarized ,,,,,
1hkgk35,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-23 05:01:21,weekly entering transitioning thread dec dec welcome to this weeks entering transitioning thread this thread is for any questions about getting started studying or transitioning into the data science field topics include learning resources eg books tutorials videos traditional education eg schools degrees electives alternative education eg online courses bootcamps job search questions eg resumes applying career prospects elementary questions eg where to start what next while you wait for answers from the community check out the faq and resources pages on our wiki you can also search for answers in past weekly threads,,,,,
1hk7uvs,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-22 21:12:24,you get a dataset and need to find a good model quickly in hours or days whats your strategy typical scenario your friend gives you a dataset and challenges you to beat their models performance they dont tell you what they did but they provide a single csv file and the performance metric to optimize assumptions almost always tabular data so no need learning needed the dataset is typically smallish k rows columns so it fits into memory its always some kind of classificationregression sometimes time series forecasting the data is generally ready for modeling minimal cleaning needed single data metric to optimize if they dont have one i force them to pick one and only one no additional data is available you have days to do your best maybe theres a hold out test set or maybe youre optimizing repeated kfold crossvalidation ive been in this situation perhaps a few dozen times over the years typically its friends of friends typically its a work prototype or a grad student project sometimes its paid work always i feel like my honor is on the line so i go hard and dont sleep for days have you been there heres how i typically approach it establish a test harness if theres a hold out test set i do a traintest split sensitivity analysis and find a ratio that preserves dataperformance distributions high correlation no statistical difference in means if theres no holdout set i ask them to evaluate their model if they have one using xfold cv and save the result sometimes i want to know their result sometimes not having a target to beat is very motivating establish a baseline start with dummy models get a baseline performance anything above this has skill spot checking run a suite of all scikitlearn models with default configs and default sensible data prep pipelines repeat with asuite grid of standard configs for all models spot check more advanced models in third party libs like gbm libs xgboost catboost lightgbm superlearner imbalanced learn if needed etc i want to know what the performance frontier looks like within a few hours and what looks good out of the box hyperparameter tuning focus on models that perform well and use grid search or bayesian optimization for hyperparameter tuning i setup background gridrandom searches to run when i have nothing else going on ill try some bayes optsome tpotauto sklearn etc to see if anything interesting surfaces pipeline optimization experiment with data preprocessing and feature engineering pipelines sometimes you find that a lesser used transform for an unlikely model surfaces something interesting ensemble methods combine topperforming models using stackingvotingaveraging i schedule this to run every min and to try look for diverse models in the result set ensemble them together and try and squeeze out some more performance iterate until time runs out keep refining and experimenting based on the results there should always be some kind of hyperparameterpipelineensemble optimization running as background tasks foreground is for wild ideas i dream up perhaps a split of cores or or if im onto something and need more compute not a ton of time for edafeature engineering i might circle back after we have the performance frontier mapped and the optimizers are grinding things are calmer i have something to show by then and can burn a few hours on creating clever features i dump all configs results into an sqlite db and have a flask crud app that allows me to searchsummarize the performance frontier i dont use tools like mlflow and friends because they didnt really exist when i started doing this a decade ago maybe its time to switch things up also they dont do the continuous optimization thing i need as far as i know i rehack my scripts for each project theyre a mess oh well i often dream of turning this into an auto ml like service just to make my life easier in the future what is or would be your strategy in this situation how do you maximize results in such a short timeframe would you do anything differently or in a different order looking forward to hearing your thoughts and ideas,,,,,
1hk7fx3,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-22 20:52:29,do data scientists do research and analysis of business problems or is that business analysis done by data analysts whats the distinction are data scientists scientists of data itself but not applied analysts producing business analysis for business leaders put another way are data scientists like drug dealers that dont get high on their own supply so other people actually use the data to add value and data scientists add value to the data so analysts can add value to the business with the data where is the distinction can someone be both at large companies does it matter i get paid to define and solve business problems with data i like that advanced statistical business analysis since it feels like scientific discovery i have an offer to work in a new ai shop at work but fear that sort of data science is for toolbuilders not researchers,,,,,
1hk1ot7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-22 16:18:02,ml pipeline questions i am building an application that processes videos and that needs to run many tasks some need to be sequentially and some in parallel think audio extraction asr diarization translation video classification etc note that this is in supposed to be run online ie this is supposed to be used in a web app where the user uploads a video and this pipeline i just described is run the output is either stores in a bucket or a database and the results are shown after some time when i look up ml pipelines on goole i get stuff like kubeflow pipelines or vertex ai pipelines so here is my first question are these pipeline tools supposed to be run in productiononline like in the use case i just described or are they meant to build ml pipelines for model training preprocessing data training a model and building a docker with the model weights example that are scheduled every so often it feels like these tools are not what i want because they seem to be aimed at building models and not serving them after some googling i realized one good option would be to use ray with kubernetes they allow for model composition and allow for node configuration for each task which is exactly what i was looking for but my second question is what else could i use for this task plain kubernetes seems to be another option but more complex at setting up it seems weird to me that there are no more tools for this purpose multi model serving with different hardware requirements unless i can do this with kubeflow or vertex ai pipelines,,,,,
1hk0yh1,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-22 15:42:41,saw this linkedin post really think it explains the advances o has made well while also showing the room for improvement check it out ,,,,,
1hjy9nb,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-22 13:14:41,the windows ml ecosytem ,,,,,
1hjx3q0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-22 11:56:16,is openai o really agi ,,,,,
1hjrill,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-22 04:50:22,genesis physics ai engine for generating d robotic simulations one of the trending repos on github for a week genesisworld is a python package which can generate realistic d physics simulations with no irregularities in any mechanism given just a prompt the early samples looks great and the package is opensourced except the genai part check more details here,,,,,
1hjn3ad,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-22 00:26:05,data scientist interviewuk coming soon any tips hi all final round interview coming up with a major insurance company in the uk so basically they gave me an takehome assessment where i need to do some eda and come up with an algorithm to predict mental health and also create presentation slides which i did and sent it to them and received an interview invite after they also gave me some feedback acknowledging the assessment so my questions are tips for the interview on what to keep in mind and what major things should i keep in mind they also told me to do a presentation on the slides i created keeping in mind the technical audiences and nontechnical audiences any tips for this will really help me thank you to everyone for reading this post and for upcoming suggestions yours loving redditor,,,,,
1hjluem,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-21 23:19:27,statisticians scripts and chaos my journey back to the s we often hear a lot about how data science teams can lack statistical expertise and how this can lead to flawed analyses or misinterpretation of results its a valid concern and the dangers are real but let me tell you theres another side of the coin that had me saying holy bleep this year i joined a project where the team is dominated by statisticians and economists sounds like a data science dream team right not so fast it feels like i hopped into a time machine and landed in the s git never heard of it instead weve got the oldschool hierarchy of script_v script_final_version_ script_final_version_ all the way to script_final_version_n its a wild ride code reviews absolutely nonexistent every script is its own handcrafted masterpiece riddled with what i can only describe as surprise features in the preprocessing pipeline bugs arent bugs apparently if you just pay close attention and read your code twice youll see theres no issue they tell me uh sure i dont trust a single output right now because i know that behind every analysis bugs are having the party of their lives chances are statisticians have absolutely no idea how a modern database actually works have never heard of a nonbasic data structure like a hyperloglog and have likely never wrestled with a truly messy realworld dataset,,,,,
1hjc9e0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-21 15:37:45,doctorate in quantitative marketing marketing worth it ill be graduating with my ms stats in the spring and then working as a data scientist within the ad tech retail marketing space my current ms thesis despite it being statistics causal inference focused its rooted in applications within business and my advisors are statsmarketing folks in the business school after my first year of graduate school i immediately knew a phd n statistics would not be for me that degree is really for me not as interesting as im not obsessive about knowing the inner details and theory behind statistics and want to create more theory im motivated towards applications in business marketing and data science settings topics of interest of mine have been how statistical methods have been used in the marketing space and its intersection with modern machine learning i decided that id take a job as a data scientist post graduation to build some experience and frankly make some money a few things ive thought about regarding my career trajectory build a niche skillset as a data scientist within the industry within marketingexperimentation and try and get to a staff ds in faang experimentation type roles a lot of my masters thesis literature review was on topics like causal inference and online experimentation these types of roles in industry would be something id like to work in after yo experience in my current marketing ds role go back to academia at a top tier business school and do a phd in quantitative marketing or marketing with a focus on publishing research regarding statistical methods for marketing applications ive read through a lot of the research focus of a lot of different quant marketing phd programs and they seem to align with my interests my current ms thesis in ways to estimate cate functions and heterogenous treatment effect and these are generally of interest in marketing phd programs ive always thought working in an academic setting would give me more freedom to work on problems that interest me rather than be limited to the scope of industry if i were to go this route id try and make tenure at an r business school id like to hear your thoughts on both of these pathways and weigh in on which of these sounds better given my goals which is the most practical for anyone whose done a phd in quantitative marketing and or phd in marketing with an emphasis in quantitative methods what that was like and if its worth doing especially if i got into a top business school,,,,,
1hjb4m7,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-21 14:40:21,data science interview prep hi everyone my friend marc and i broke into data science a while back and we understand how hard the job market is so weve have been working on a interview prep platform for data science students that wed enjoy using ourselves right now we have questions including coding probability and statistics questions with most free to answer we are adding new questions daily and want to grow a community where we can help one another out all we need now is good feedback id appreciate if you guys could check it out and give us some,,,,,
1hisd3a,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-20 20:02:17,advice on analyzing geospatial soil dataset how to connect data for better insights hi everyone im working on analyzing a dataset rows containing geospatial and soil measurements collected along a stretch of land the data includes the following fields latitude longitude geospatial coordinates for each measurement height elevation at the measurement point slope slope of the land at the point soil height to baseline the difference in soil height relative to a baseline repeated measurements some locations have multiple measurements over time allowing for variance analysis currently the data points seem disconnected not linked by any obvious structure like a continuous line or relationships between points my challenge is that i believe i need to connect or group this data in some way to perform more meaningful analyses such as tracking changes over time or identifying spatial trend aside from my ideas do you have any thoughts for how this could be a useful dataset what analysis can be done,,,,,
1hirjaq,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-20 19:25:05,openai o and omini annouced metrics are crazy so openai has released o and omini which looks great on coding and mathematical tasks the arc agi numbers looks crazy checkout all the details summarized in this post,,,,,
1hiefi0,,,,,,,,,datascience,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2024-12-20 07:12:58,googles reasoning llm gemini flash thinking looks good ,,,,,
1jwmwdy,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 10:48:14,linus torvalds built git in days and never imagined it would last years ,,,,,
1ju6ils,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 05:51:17,sam altman says ai will make coders x more productive not replace them even bill gates claims the field is too complex ,,,,,
1jvfxl3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 20:29:14,oktas ceo says software engineers will be more in demand not less business insider ,,,,,
1jsrtrt,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 11:17:01,the insanity of being a software engineer ,,,,,
1jxpl9c,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 19:41:48,clever code is probably the worst code you could write ,,,,,
1jnb00a,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 12:06:31,malware is harder to find when written in obscure languages like delphi and haskell ,,,,,
1jrl2zw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 19:57:33,microsoft has released their own agent mode so theyve blocked vscodederived editors like cursor from using ms extensions not sure how i feel about this what do you think,,,,,
1jms5sv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 17:59:54,karpathys vibe coding movement considered harmful ,,,,,
1jpribc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 15:32:07,interview with vibe coder vibe coding meaning full reliance on ai ,,,,,
1julofe,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 19:04:46,senior engineer tries vibe coding ,,,,,
1judf0y,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 13:21:42,ai coding mandates are driving developers to the brink ,,,,,
1joqlry,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 08:24:31,the software engineering laws ,,,,,
1jv3emt,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 11:24:52,nvidia drops a gamechanger native python support hits cuda ,,,,,
1jo0dzz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 10:52:45,there is no vibe engineering ,,,,,
1jvujzu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 10:23:50,how to spoof a pokémon red trade with go this is a write up of some notes i took when i tried to spoof a pokémon trade as a weekend project maybe someone here finds this interesting,,,,,
1jqypxq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 00:20:52,in retrospect devops was a bad idea ,,,,,
1jqwybf,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 22:59:29,years of microsoft with the companys original source code ,,,,,
1joeiaj,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 21:20:02,programming with an ai copilot my perspective as a senior dev ,,,,,
1jwiqfp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 05:45:30,openssh relies on standards for quantumsafe key exchange ,,,,,
1jmlgue,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 12:44:24,the manager i hated and the lesson he taught me ,,,,,
1jtkfpq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 12:48:57,writing c for curl danielhaxxse ,,,,,
1jtr45e,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 17:34:25,the s in mcp stands for security ,,,,,
1jqodtw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 17:22:05,notepadnext a crossplatform reimplementation of notepad ,,,,,
1js8gqz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 17:18:07,emulating an iphone in qemu ,,,,,
1ju1f1g,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 01:02:22,years of git ,,,,,
1jsnn5b,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 06:17:08,i asked an engineering manager how software engineers can prepare for leadership roles ,,,,,
1jo66p4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 15:40:41,quantum computer generates truly random number in scientific first ,,,,,
1jwjw7b,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 07:08:26,tauri vs electron benchmark less memory smaller bundle our findings and why we chose tauri ,,,,,
1jqc8gy,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 07:32:53,new python lock file format will specify dependencies your thoughts pythons builders have accepted a proposal to create a universal lock file format for python projects that would specify dependencies enabling installation reproducibility in a python environment python enhancement proposal pep accepted march aims to create a new file format for specifying dependencies that is machinegenerated and humanreadable installers consuming the file should be able to calculate what to install without needing dependency resolution at installtime according to the proposal currently no standard exists to create an immutable record such as a lock file that specifies what direct and indirect dependencies should be installed into a python virtual environment the proposal states there have been at least five wellknown solutions to the problem in the community including pdm pip freeze piptools poetry and uv but these tools vary in what locking scenarios are supported by not having compatibility and interoperability it fractures tooling around lock files where both users and tools have to choose what lock file format to use upfront making it costly to useswitch to other formats the proposal says human readability of the file format enables contents of the file to be audited to make sure no undesired dependencies are included in the lock file the file format also is designed to not require a resolver at install time this simplifies reasoning about what would be installed when consuming a lock file it should also lead to faster installs which are much more frequent than creating a lock file the format has not yet been associated with a specific release of python but is guidance for tooling going forward actual adoption remains openended acceptance of the format is full and final not provisional the universal format has been the subject of an estimated four years of discussion and design,,,,,
1juufhv,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 01:43:13,hacking the playstation boot logo the classic playstation boot logo is actually a d model rendered real time from the disc learn more about how this works and the technical reasons behind this quirky design the source code for extracting and patching psx licenses is found at github,,,,,
1jo59ba,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 15:01:07,the select element can now be customized with css in chromium browsers ,,,,,
1jrlr8r,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 20:25:26,nvidia adds native python support to cuda ,,,,,
1jw88ct,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 20:41:30,pep template strings has been accepted ,,,,,
1jxeinw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 10:46:08,a flowing webgl gradient deconstructed ,,,,,
1jpll84,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 10:47:19,qt released ,,,,,
1jop2wi,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 06:30:50,bold move by european commission towards the memory safe language seed the european commission issued a strategy paper about memory safety they propose a european concept of memory safety they introduce categories of memory safety and the categories are summarized in the memorysafety levels to language features are categorized regarding their support of memory safety they introduced the terms wildpointer which is essentially a c pointer and checkedpointer inside the category of checkedpointers they further distinguish between ones which can be null and ones that cannot be null so java references count as checkedpointers which can be null interesting fact although c references cannot be null they count as wildpointers because there are ways to cast a c pointer to a reference regarding unsafeparts and inlineassembly they state that they are overused which compromises safety they made a study about languages with unsafeparts and inlineassembly the study found out about of all rust crates incorporate some use of unsafe rust the study also states of rust developers are calling unsafe code through foreign functions in their language evaluation the language seed is the clear winner it is the clear winner because it is memory safe and has no unsafe parts as a consequence the european commission proposes the use of seed in many areas of software development there will be a europewide research fund to facilitate the use of seed in more areas companies will have tax reductions if they rewrite programs or libraries in seed this is seen as long term commitment of the european union to improve software quality and to make europe independent in the software industry,,,,,
1jrc228,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 13:36:19,build an bit computer from scratch ,,,,,
1jr2vdc,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 03:56:05,markov chains are the original language models ,,,,,
1jqg3d4,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 11:37:16,how i made the loading of a million spans possible without choking the ui ,,,,,
1jrlv3y,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 20:30:07,on javascripts weirdness ,,,,,
1jxxdnz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 02:16:19,ship software that does nothing ,,,,,
1jy3qb0,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 09:20:19,llms vs compilers why the rules dont align llmbased coding tools seem good but they will always fail on complex problems due to a fundamental difference in the workings of compilers and llms the prompttoprogram paradox referenced on linkedin explains why llms accept casual human instructions just fine compilers though are strict one semicolon error and its dead that gap makes ai struggle with tough coding tasks funny thing ai was supposed to replace us but were still fixing its wrong code now folks are coming up with rules for writing better prompts so exact theyre like code to get code turns out the better you prompt the more of a programmer you already are,,,,,
1jy78sa,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-13 13:08:10,you might not need websockets ,,,,,
1joczc6,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 20:17:19,undocumented instructions explained by the microcode ,,,,,
1jsasl3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 18:59:16,microsoft uses ai to find flaws in grub uboot barebox bootloaders ,,,,,
1jxuvey,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 23:57:00,interactive git log a smarter git gui for vscode interactive git log is a free vscode extension i built to make git more manageable especially in shared repos where you collaborate through pull requests it shows only the branches and commits that are active in your workflow so youre not buried in noise uncommitted changes appear just like git status and you can run git actions like committing rebasing resolving conflicts and managing branches all from the ui when paired with github cli it also shows pr status ci results and comment counts inline its inspired by metas smartlog from the sapling source control system but adapted for git would love feedback if you try it out,,,,,
1jvxwpu,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 13:28:19,usability improvements in gcc ,,,,,
1jo5r2j,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 15:22:10,the freelance mirage why of coders crash before they hit paydirt ,,,,,
1jphmgw,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 05:54:18,optimized a java function cut production cpu from to ,,,,,
1jovme5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 13:30:20,eventually green tests a new paradigm in software testing ,,,,,
1juxmy5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 04:41:10,openssl now contains postquantum procedures ,,,,,
1jo66kx,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 15:40:33,malware hiding in plain sight spying on north korean hackers ,,,,,
1jtk7ky,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 12:37:28,the best programmers i know matthias endler ,,,,,
1jmq53i,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 16:30:46,cracks in containerized development ,,,,,
1jpn7oo,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 12:21:42,the decline of stack overflow which questions are most affected by ai ,,,,,
1jn099y,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-30 00:18:02,we found found the atop bug everyone is going crazy about ,,,,,
1jukuv3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 18:31:05,demystifying the shebang kernel adventures ,,,,,
1jos4s2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 10:16:06,why i stopped using ai code editors article i wrote an article about why i stopped using ai code editors,,,,,
1jqk43q,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 14:36:37,minimal cssonly blurry image placeholders ,,,,,
1jq7o3e,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 03:03:02,heres the latest quarterly progress report for graphite the foss d graphics editor ive been building for years ,,,,,
1jtp3z2,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 16:13:11,rsync replaced with openrsync on macos sequoia ,,,,,
1jtjzl5,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 12:26:02,dont mock your framework writing tests you wont regret ,,,,,
1jsr4ue,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 10:29:35,scaling to millions the secret behind nginxs concurrent connection handling ,,,,,
1joanyp,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-31 18:43:08,years of programming the history of ides from to unpaywalled,,,,,
1jwxxbn,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 19:10:04,how we clone a running vm in seconds ,,,,,
1jwxvtn,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 19:08:17,erlangs not about lightweight processes and message passing ,,,,,
1jwxz74,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-11 19:12:21,default styles for h elements are changing ,,,,,
1jv9wi3,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 16:23:19,a surprising enum size optimization in the rust compiler ,,,,,
1jtjp2c,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-07 12:10:13,message queues in diagram and words ,,,,,
1jw39fl,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 17:16:33,why i chose calendar versioning for my open source project hi all last weekend i tagged the first version of vigilant an opensource self hostable website monitoring application ive received positive feedback which i am very happy with i wanted to share why i chose for calendar versioning instead of the more traditional semver let me know what you think and if this is the best way for managing versions,,,,,
1jrluud,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-04 20:29:48,the best refactoring youve never heard of ,,,,,
1js8w4w,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 17:36:48,gos http server patterns in java ,,,,,
1jrvnx9,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-05 04:47:28,opensource is just that ,,,,,
1jmzkug,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 23:44:21,git as a binary distribution system dotbins for portable developer tools im sharing a different approach to managing developer tools across systems problem every os has different packages and versions moving between systems means constant tool reinstallation solution dotbins download binaries once version control them clone anywhere the workflow define your tools in a yaml file run dotbins sync to download binaries for all platforms store everything in a git repo with optional lfs clone that repo on any new system create a dotbinsyaml file with contents yaml platforms linux amd arm macos arm tools standard tools bat sharkdpbat fzf junegunnfzf with shell integration bat repo sharkdpbat shell_code alias catbat plain pagingnever alias lessbat pagingalways ripgrep repo burntsushiripgrep binary_name rg after running dotbins sync youll have binaries for all platformsarchitectures in your dotbins directory bash on your main machine cd dotbins git init git lfs install lfs recommended for binaries git lfs track bin git add git commit m initial commit git push to your repo on any new system git clone dotbins source dotbinsshellbashsh or zshfishetc this approach has been a gamechanger for me i clone my dotfiles repo and my dotbins repo and im instantly productive on any system my personal dotbins collection project has anyone else tried this gitbased approach to tool distribution,,,,,
1jpq3sy,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-02 14:34:51,we need more words for snow for people whose job it is to manage complexity were pretty bad at describing it ,,,,,
1jv9u41,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-09 16:20:37,how does c code become assembly ,,,,,
1jmwzpg,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-03-29 21:40:41,i built a beautiful open source json schema builder ,,,,,
1jslcsq,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-06 03:48:58,rewriting the same project over and over a small postmortem about engine development ive been working on a c game engine for a few years now and have rebuilt large parts of it more times than id like to admit mostly chasing better architecture and cleaner systemsbut its a slippery slope,,,,,
1ju8qbn,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-08 08:34:35,why i value firebreak sprints for managing technical debt ,,,,,
1jx75lz,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-12 02:31:19,how indexes work in partitioned databases ,,,,,
1jqbm3m,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-03 06:51:30,programming with an ai copilot my perspective as a senior dev ,,,,,
1jp2n0t,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-01 18:17:00,faking adts and gadts in languages that shouldnt have them ,,,,,
1jvlx0w,,,,,,,,,programming,,,,,,,,Tech & Programming,,,,,,,,,,,,,,,,,,2025-04-10 01:08:45,the egraph data structure ,,,,,
