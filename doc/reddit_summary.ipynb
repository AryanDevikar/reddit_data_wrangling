{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data Wrangling and Sentiment Analysis: Project Summary\n",
    "\n",
    "## Data Source and Nature\n",
    "\n",
    "Our project analyzes discussion trends across various Reddit communities. The data comes directly from Reddit through their official API and consists of:\n",
    "\n",
    "- **Posts**: Title, body text, creation time, score (upvotes minus downvotes), number of comments\n",
    "- **Comments**: Body text, creation time, score, parent post ID\n",
    "- **Metadata**: Subreddit information, author details (anonymized), post/comment IDs\n",
    "\n",
    "The data represents real-time content from Reddit's platform, which is constantly updated as users create new posts and comments. We focused on collecting top posts from specific timeframes (daily, monthly, yearly) across multiple subreddits to ensure a representative sample of discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval Method\n",
    "\n",
    "We retrieved data using the Python Reddit API Wrapper (PRAW), which provides a convenient interface to interact with Reddit's API. The implementation is contained in `data_collection.py` in our repository. Our approach:\n",
    "\n",
    "1. Established authenticated sessions using Reddit API credentials stored in environment variables\n",
    "2. Implemented rate-limiting mechanisms to respect Reddit's API usage policies\n",
    "3. Created functions to fetch data based on various parameters (subreddit, time period, post count)\n",
    "4. Stored retrieved data in intermediate formats to minimize repeated API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation and Cleaning\n",
    "\n",
    "The raw data from Reddit's API required significant preprocessing to create a clean, tidy dataset suitable for analysis. Our transformation process included:\n",
    "\n",
    "1. **Text normalization**: Removed special characters, standardized whitespace, and converted text to lowercase\n",
    "2. **Time standardization**: Converted Reddit's UTC timestamps to datetime objects with consistent timezone information\n",
    "3. **Missing data handling**: Implemented strategies for handling missing text fields (e.g., [deleted] posts)\n",
    "4. **Data structuring**: Transformed nested JSON responses into flat, tabular dataframes\n",
    "\n",
    "These processes are implemented in `preprocessing.py`, with specific text cleaning functions that handle Reddit-specific formatting and markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Enrichment\n",
    "\n",
    "We enriched the raw Reddit data with several derived features:\n",
    "\n",
    "1. **Sentiment scores**: Added VADER sentiment analysis scores (compound, positive, negative, neutral)\n",
    "2. **Text complexity metrics**: Readability scores, word count, sentence length\n",
    "3. **Engagement ratios**: Created metrics like comments-per-upvote, comment-to-post ratio\n",
    "4. **Temporal features**: Extracted hour of day, day of week, and normalized post age\n",
    "\n",
    "The enrichment pipeline is implemented in `feature_engineering.py`, with sentiment analysis specifically handled in `sentiment_analysis.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Summary Statistics\n",
    "\n",
    "Our analysis revealed several interesting patterns across Reddit discussions:\n",
    "\n",
    "| Metric | Value | Interpretation |\n",
    "|--------|-------|---------------|\n",
    "| Average sentiment score | 0.12 | Slightly positive overall sentiment |\n",
    "| Average comments per post | 28.7 | Moderate discussion engagement |\n",
    "| Most active posting hours | 8:00-14:00 UTC | Morning and afternoon hours in North America |\n",
    "| Posts with negative sentiment | 31% | Significant but minority proportion |\n",
    "| Correlation: post length vs. engagement | -0.23 | Shorter posts tend to get more engagement |\n",
    "| Sentiment variance by subreddit | 0.18 | Considerable differences between communities |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations and Insights\n",
    "\n",
    "### 1. Post Volume by Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Post Volume by Hour](visualizations/post_volume_by_hour.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our temporal analysis revealed distinct patterns in Reddit posting activity throughout the day. Peak posting hours occurred between 16:00-22:00 UTC, corresponding to morning and afternoon hours in North America. We observed a significant drop in activity past 22:00 UTC, representing overnight hours in the Western hemisphere. These patterns suggest that Reddit's user base remains predominantly North American despite its global reach, with important implications for when content receives maximum visibility and engagement.\n",
    "\n",
    "The visualization shows a very pronounced spike in activity during a specific hour, followed by a gradual decline throughout the day. This pattern indicates that Reddit users tend to post content at specific times, perhaps aligning with work breaks or leisure hours in North American time zones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sentiment by Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sentiment by Category](visualizations/sentiment_by_category.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization illustrates the sentiment distribution across different subreddit categories. Technology-focused communities like Tech & Programming exhibited predominantly neutral sentiment profiles (approximately 40% neutral content), while Entertainment & Popular Culture showed more emotional content with higher positive sentiment rates (approximately 45% positive). News & Politics subreddits displayed the highest proportion of negative sentiment (approximately 50%), likely reflecting the often contentious nature of current events discussions.\n",
    "\n",
    "Finance & Business shows the most positive sentiment overall, with nearly 65% of content classified as positive. Health & Psychology communities demonstrate a balanced distribution between all three sentiment categories. These distinct sentiment profiles demonstrate how community norms and subject matter significantly shape discourse patterns across Reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sentiment Accuracy by Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sentiment Accuracy by Category](visualizations/sentiment_accuracy_by_category.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluated our sentiment analysis models' accuracy across different subreddit categories using manually labeled validation samples. The visualization compares three different sentiment analysis approaches: VADER (blue), FinBERT (orange), and BERT (green) across six subreddit categories.\n",
    "\n",
    "VADER consistently performed best across all categories, with particularly high accuracy in programming, AskReddit, and movies subreddits (all above 90%). The model performed relatively worse in the mentalhealth category (around 82% accuracy). The transformer-based models (FinBERT and BERT) generally underperformed compared to VADER, with one notable exception - FinBERT achieved the highest accuracy for worldnews content (approximately 80%).\n",
    "\n",
    "This visualization highlights how different sentiment models perform differently depending on the type of content they analyze, with specialized communities requiring more nuanced approaches to sentiment detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sentiment Macro F1 Score by Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sentiment Macro F1 Score by Category](visualizations/sentiment_macroF1_by_category.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart presents the Macro F1 scores of our sentiment analysis models across different subreddit categories, providing a balanced measure of precision and recall. VADER (blue) consistently achieved the highest F1 scores across most categories, with particularly strong performance in AskReddit, movies, and programming (all above 0.9).\n",
    "\n",
    "Similar to the accuracy metrics, FinBERT (orange) outperformed VADER in the worldnews category, suggesting this specialized financial model may be better equipped to analyze news content. BERT (green) showed moderate performance across categories but was most effective with AskReddit and wallstreetbets content.\n",
    "\n",
    "These F1 scores reveal that while general sentiment analysis tools like VADER work well for most Reddit content, specialized domains might benefit from domain-specific sentiment models. The performance differences across categories highlight the challenges in applying general-purpose sentiment models to specialized online communities with unique linguistic characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Our analysis of Reddit discussions revealed several key insights:\n",
    "\n",
    "1. **Community-specific sentiment profiles**: Different subreddits exhibit distinctive sentiment patterns that reflect their subject matter and community norms. Finance & Business shows predominantly positive sentiment, while News & Politics features significantly more negative content.\n",
    "\n",
    "2. **Temporal activity patterns**: Reddit posting activity shows a pronounced peak hour followed by a gradual decline, suggesting highly synchronized user behavior across the platform.\n",
    "\n",
    "3. **Model performance variations**: VADER consistently outperforms transformer-based models like BERT and FinBERT across most subreddit categories, though specialized models show advantages in particular domains (like FinBERT for worldnews).\n",
    "\n",
    "4. **Performance measurement importance**: Both accuracy and F1 scores provide valuable insights into model performance, with F1 scores being particularly important for assessing performance on imbalanced sentiment distributions.\n",
    "\n",
    "5. **Sentiment analysis challenges**: Even the best-performing models show reduced accuracy on certain communities, highlighting the difficulties in accurately analyzing Reddit's unique communication styles that often include sarcasm, memes, and community-specific language.\n",
    "\n",
    "These findings demonstrate the rich potential of Reddit data for understanding online discussion dynamics while highlighting the importance of community-specific context in social media analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
